SQLAlchemy Core
The breadth of SQLAlchemy’s SQL rendering engine, DBAPI integration, transaction integration, and schema description services are documented here. In contrast to the ORM’s domain-centric mode of usage, the SQL Expression Language provides a schema-centric usage paradigm.
• SQL Statements and Expressions API
o Column Elements and Expressions
o Operator Reference
o SELECT and Related Constructs
o Insert, Updates, Deletes
o SQL and Generic Functions
o Custom SQL Constructs and Compilation Extension
o Expression Serializer Extension
o SQL Expression Language Foundational Constructs
o Visitor and Traversal Utilities
• Schema Definition Language
o Describing Databases with MetaData
o Reflecting Database Objects
o Column INSERT/UPDATE Defaults
o Defining Constraints and Indexes
o Customizing DDL
• SQL Datatype Objects
o The Type Hierarchy
o Custom Types
o Base Type API
• Engine and Connection Use
o Engine Configuration
o Working with Engines and Connections
o Connection Pooling
o Core Events
• Core API Basics
o Events
o Runtime Inspection API
o Core Exceptions
o Core Internals
SQL Statements and Expressions API¶
This section presents the API reference for the SQL Expression Language. For an introduction, start with Working with Data in the SQLAlchemy Unified Tutorial.
• Column Elements and Expressions
o Column Element Foundational Constructors
• and_()
• bindparam()
• bitwise_not()
• case()
• cast()
• column()
• custom_op
• distinct()
• extract()
• false()
• func
• lambda_stmt()
• literal()
• literal_column()
• not_()
• null()
• or_()
• outparam()
• text()
• true()
• try_cast()
• tuple_()
• type_coerce()
• quoted_name
o Column Element Modifier Constructors
• all_()
• any_()
• asc()
• between()
• collate()
• desc()
• funcfilter()
• label()
• nulls_first()
• nullsfirst()
• nulls_last()
• nullslast()
• over()
• within_group()
o Column Element Class Documentation
• BinaryExpression
• BindParameter
• Case
• Cast
• ClauseList
• ColumnClause
• ColumnCollection
• ColumnElement
• ColumnExpressionArgument
• ColumnOperators
• Extract
• False_
• FunctionFilter
• Label
• Null
• Operators
• Over
• SQLColumnExpression
• TextClause
• TryCast
• Tuple
• WithinGroup
• WrapsColumnExpression
• True_
• TypeCoerce
• UnaryExpression
o Column Element Typing Utilities
• NotNullable()
• Nullable()
• Operator Reference
o Comparison Operators
o IN Comparisons
• IN against a list of values
• Empty IN Expressions
• NOT IN
• Tuple IN Expressions
• Subquery IN
o Identity Comparisons
o String Comparisons
o String Containment
o String matching
o String Alteration
o Arithmetic Operators
o Bitwise Operators
o Using Conjunctions and Negations
o Conjunction Operators
o Parentheses and Grouping
• SELECT and Related Constructs
o Selectable Foundational Constructors
• except_()
• except_all()
• exists()
• intersect()
• intersect_all()
• select()
• table()
• union()
• union_all()
• values()
o Selectable Modifier Constructors
• alias()
• cte()
• join()
• lateral()
• outerjoin()
• tablesample()
o Selectable Class Documentation
• Alias
• AliasedReturnsRows
• CompoundSelect
• CTE
• Executable
• Exists
• FromClause
• GenerativeSelect
• HasCTE
• HasPrefixes
• HasSuffixes
• Join
• Lateral
• ReturnsRows
• ScalarSelect
• Select
• Selectable
• SelectBase
• Subquery
• TableClause
• TableSample
• TableValuedAlias
• TextualSelect
• Values
• ScalarValues
o Label Style Constants
• SelectLabelStyle
• Insert, Updates, Deletes
o DML Foundational Constructors
• delete()
• insert()
• update()
o DML Class Documentation Constructors
• Delete
• Insert
• Update
• UpdateBase
• ValuesBase
• SQL and Generic Functions
o Function API
• AnsiFunction
• Function
• FunctionElement
• GenericFunction
• register_function()
o Selected “Known” Functions
• aggregate_strings
• array_agg
• char_length
• coalesce
• concat
• count
• cube
• cume_dist
• current_date
• current_time
• current_timestamp
• current_user
• dense_rank
• grouping_sets
• localtime
• localtimestamp
• max
• min
• mode
• next_value
• now
• percent_rank
• percentile_cont
• percentile_disc
• random
• rank
• rollup
• session_user
• sum
• sysdate
• user
• Custom SQL Constructs and Compilation Extension
o Synopsis
o Dialect-specific compilation rules
o Compiling sub-elements of a custom expression construct
• Cross Compiling between SQL and DDL compilers
o Changing the default compilation of existing constructs
o Changing Compilation of Types
o Subclassing Guidelines
o Enabling Caching Support for Custom Constructs
o Further Examples
• “UTC timestamp” function
• “GREATEST” function
• “false” expression
o compiles()
o deregister()
• Expression Serializer Extension
o Deserializer
• Deserializer.get_engine()
• Deserializer.persistent_load()
o Serializer
• Serializer.persistent_id()
o dumps()
o loads()
• SQL Expression Language Foundational Constructs
o CacheKey
• CacheKey.bindparams
• CacheKey.key
• CacheKey.to_offline_string()
o ClauseElement
• ClauseElement.compare()
• ClauseElement.compile()
• ClauseElement.get_children()
• ClauseElement.inherit_cache
• ClauseElement.params()
• ClauseElement.self_group()
• ClauseElement.unique_params()
o DialectKWArgs
• DialectKWArgs.argument_for()
• DialectKWArgs.dialect_kwargs
• DialectKWArgs.dialect_options
• DialectKWArgs.kwargs
o HasCacheKey
• HasCacheKey.inherit_cache
o LambdaElement
o StatementLambdaElement
• StatementLambdaElement.add_criteria()
• StatementLambdaElement.is_delete
• StatementLambdaElement.is_dml
• StatementLambdaElement.is_insert
• StatementLambdaElement.is_select
• StatementLambdaElement.is_text
• StatementLambdaElement.is_update
• StatementLambdaElement.spoil()
• Visitor and Traversal Utilities
o ExternalTraversal
• ExternalTraversal.chain()
• ExternalTraversal.iterate()
• ExternalTraversal.traverse()
• ExternalTraversal.visitor_iterator
o InternalTraversal
• InternalTraversal.dp_annotations_key
• InternalTraversal.dp_anon_name
• InternalTraversal.dp_boolean
• InternalTraversal.dp_clauseelement
• InternalTraversal.dp_clauseelement_list
• InternalTraversal.dp_clauseelement_tuple
• InternalTraversal.dp_clauseelement_tuples
• InternalTraversal.dp_dialect_options
• InternalTraversal.dp_dml_multi_values
• InternalTraversal.dp_dml_ordered_values
• InternalTraversal.dp_dml_values
• InternalTraversal.dp_fromclause_canonical_column_collection
• InternalTraversal.dp_fromclause_ordered_set
• InternalTraversal.dp_has_cache_key
• InternalTraversal.dp_has_cache_key_list
• InternalTraversal.dp_has_cache_key_tuples
• InternalTraversal.dp_ignore
• InternalTraversal.dp_inspectable
• InternalTraversal.dp_inspectable_list
• InternalTraversal.dp_multi
• InternalTraversal.dp_multi_list
• InternalTraversal.dp_named_ddl_element
• InternalTraversal.dp_operator
• InternalTraversal.dp_plain_dict
• InternalTraversal.dp_plain_obj
• InternalTraversal.dp_prefix_sequence
• InternalTraversal.dp_propagate_attrs
• InternalTraversal.dp_statement_hint_list
• InternalTraversal.dp_string
• InternalTraversal.dp_string_clauseelement_dict
• InternalTraversal.dp_string_list
• InternalTraversal.dp_string_multi_dict
• InternalTraversal.dp_table_hint_list
• InternalTraversal.dp_type
• InternalTraversal.dp_unknown_structure
o Visitable
o anon_map
o cloned_traverse()
o iterate()
o replacement_traverse()
o traverse()
o traverse_using()
Column Elements and Expressions
The expression API consists of a series of classes each of which represents a specific lexical element within a SQL string. Composed together into a larger structure, they form a statement construct that may be compiled into a string representation that can be passed to a database. The classes are organized into a hierarchy that begins at the basemost ClauseElement class. Key subclasses include ColumnElement, which represents the role of any column-based expression in a SQL statement, such as in the columns clause, WHERE clause, and ORDER BY clause, and FromClause, which represents the role of a token that is placed in the FROM clause of a SELECT statement.
Column Element Foundational Constructors
Standalone functions imported from the sqlalchemy namespace which are used when building up SQLAlchemy Expression Language constructs.
Object NameDescriptionand_(*clauses)Produce a conjunction of expressions joined by AND.bindparam(key[, value, type_, unique, ...])Produce a “bound expression”.bitwise_not(expr)Produce a unary bitwise NOT clause, typically via the ~ operator.case(*whens, [value, else_])Produce a CASE expression.cast(expression, type_)Produce a CAST expression.column(text[, type_, is_literal, _selectable])Produce a ColumnClause object.custom_opRepresent a ‘custom’ operator.distinct(expr)Produce an column-expression-level unary DISTINCT clause.extract(field, expr)Return a Extract construct.false()Return a False_ construct.funcGenerate SQL function expressions.lambda_stmt(lmb[, enable_tracking, track_closure_variables, track_on, ...])Produce a SQL statement that is cached as a lambda.literal(value[, type_, literal_execute])Return a literal clause, bound to a bind parameter.literal_column(text[, type_])Produce a ColumnClause object that has the column.is_literal flag set to True.not_(clause)Return a negation of the given clause, i.e. NOT(clause).null()Return a constant Null construct.or_(*clauses)Produce a conjunction of expressions joined by OR.outparam(key[, type_])Create an ‘OUT’ parameter for usage in functions (stored procedures), for databases which support them.quoted_nameRepresent a SQL identifier combined with quoting preferences.text(text)Construct a new TextClause clause, representing a textual SQL string directly.true()Return a constant True_ construct.try_cast(expression, type_)Produce a TRY_CAST expression for backends which support it; this is a CAST which returns NULL for un-castable conversions.tuple_(*clauses, [types])Return a Tuple.type_coerce(expression, type_)Associate a SQL expression with a particular type, without rendering CAST.function sqlalchemy.sql.expression.and_(*clauses)
Produce a conjunction of expressions joined by AND.
E.g.:
from sqlalchemy import and_

stmt = select(users_table).where(
    and_(users_table.c.name == "wendy", users_table.c.enrolled == True)
)
The and_() conjunction is also available using the Python & operator (though note that compound expressions need to be parenthesized in order to function with Python operator precedence behavior):
stmt = select(users_table).where(
    (users_table.c.name == "wendy") & (users_table.c.enrolled == True)
)
The and_() operation is also implicit in some cases; the Select.where() method for example can be invoked multiple times against a statement, which will have the effect of each clause being combined using and_():
stmt = (
    select(users_table)
    .where(users_table.c.name == "wendy")
    .where(users_table.c.enrolled == True)
)
The and_() construct must be given at least one positional argument in order to be valid; a and_() construct with no arguments is ambiguous. To produce an “empty” or dynamically generated and_() expression, from a given list of expressions, a “default” element of true() (or just True) should be specified:
from sqlalchemy import true

criteria = and_(true(), *expressions)
The above expression will compile to SQL as the expression true or 1 = 1, depending on backend, if no other expressions are present. If expressions are present, then the true() value is ignored as it does not affect the outcome of an AND expression that has other elements.
Deprecated since version 1.4: The and_() element now requires that at least one argument is passed; creating the and_() construct with no arguments is deprecated, and will emit a deprecation warning while continuing to produce a blank SQL string.
See also
or_()
function sqlalchemy.sql.expression.bindparam(key: str | None, value: Any = _NoArg.NO_ARG, type_: _TypeEngineArgument[_T] | None = None, unique: bool = False, required: bool | Literal[_NoArg.NO_ARG] = _NoArg.NO_ARG, quote: bool | None = None, callable_: Callable[[], Any] | None = None, expanding: bool = False, isoutparam: bool = False, literal_execute: bool = False) → BindParameter[_T]
Produce a “bound expression”.
The return value is an instance of BindParameter; this is a ColumnElement subclass which represents a so-called “placeholder” value in a SQL expression, the value of which is supplied at the point at which the statement in executed against a database connection.
In SQLAlchemy, the bindparam() construct has the ability to carry along the actual value that will be ultimately used at expression time. In this way, it serves not just as a “placeholder” for eventual population, but also as a means of representing so-called “unsafe” values which should not be rendered directly in a SQL statement, but rather should be passed along to the DBAPI as values which need to be correctly escaped and potentially handled for type-safety.
When using bindparam() explicitly, the use case is typically one of traditional deferment of parameters; the bindparam() construct accepts a name which can then be referred to at execution time:
from sqlalchemy import bindparam

stmt = select(users_table).where(
    users_table.c.name == bindparam("username")
)
The above statement, when rendered, will produce SQL similar to:
SELECT id, name FROM user WHERE name = :username
In order to populate the value of :username above, the value would typically be applied at execution time to a method like Connection.execute():
result = connection.execute(stmt, {"username": "wendy"})
Explicit use of bindparam() is also common when producing UPDATE or DELETE statements that are to be invoked multiple times, where the WHERE criterion of the statement is to change on each invocation, such as:
stmt = (
    users_table.update()
    .where(user_table.c.name == bindparam("username"))
    .values(fullname=bindparam("fullname"))
)

connection.execute(
    stmt,
    [
        {"username": "wendy", "fullname": "Wendy Smith"},
        {"username": "jack", "fullname": "Jack Jones"},
    ],
)
SQLAlchemy’s Core expression system makes wide use of bindparam() in an implicit sense. It is typical that Python literal values passed to virtually all SQL expression functions are coerced into fixed bindparam() constructs. For example, given a comparison operation such as:
expr = users_table.c.name == "Wendy"
The above expression will produce a BinaryExpression construct, where the left side is the Column object representing the name column, and the right side is a BindParameter representing the literal value:
print(repr(expr.right))
BindParameter("%(4327771088 name)s", "Wendy", type_=String())
The expression above will render SQL such as:
user.name = :name_1
Where the :name_1 parameter name is an anonymous name. The actual string Wendy is not in the rendered string, but is carried along where it is later used within statement execution. If we invoke a statement like the following:
stmt = select(users_table).where(users_table.c.name == "Wendy")
result = connection.execute(stmt)
We would see SQL logging output as:
SELECT "user".id, "user".name
FROM "user"
WHERE "user".name = %(name_1)s
{'name_1': 'Wendy'}
Above, we see that Wendy is passed as a parameter to the database, while the placeholder :name_1 is rendered in the appropriate form for the target database, in this case the PostgreSQL database.
Similarly, bindparam() is invoked automatically when working with CRUD statements as far as the “VALUES” portion is concerned. The insert() construct produces an INSERT expression which will, at statement execution time, generate bound placeholders based on the arguments passed, as in:
stmt = users_table.insert()
result = connection.execute(stmt, {"name": "Wendy"})
The above will produce SQL output as:
INSERT INTO "user" (name) VALUES (%(name)s)
{'name': 'Wendy'}
The Insert construct, at compilation/execution time, rendered a single bindparam() mirroring the column name name as a result of the single name parameter we passed to the Connection.execute() method.
Parameters:
• key – 
the key (e.g. the name) for this bind param. Will be used in the generated SQL statement for dialects that use named parameters. This value may be modified when part of a compilation operation, if other BindParameter objects exist with the same key, or if its length is too long and truncation is required.
If omitted, an “anonymous” name is generated for the bound parameter; when given a value to bind, the end result is equivalent to calling upon the literal() function with a value to bind, particularly if the bindparam.unique parameter is also provided.
• value – Initial value for this bind param. Will be used at statement execution time as the value for this parameter passed to the DBAPI, if no other value is indicated to the statement execution method for this particular parameter name. Defaults to None.
• callable_ – A callable function that takes the place of “value”. The function will be called at statement execution time to determine the ultimate value. Used for scenarios where the actual bind value cannot be determined at the point at which the clause construct is created, but embedded bind values are still desirable.
• type_ – 
A TypeEngine class or instance representing an optional datatype for this bindparam(). If not passed, a type may be determined automatically for the bind, based on the given value; for example, trivial Python types such as str, int, bool may result in the String, Integer or Boolean types being automatically selected.
The type of a bindparam() is significant especially in that the type will apply pre-processing to the value before it is passed to the database. For example, a bindparam() which refers to a datetime value, and is specified as holding the DateTime type, may apply conversion needed to the value (such as stringification on SQLite) before passing the value to the database.
• unique – if True, the key name of this BindParameter will be modified if another BindParameter of the same name already has been located within the containing expression. This flag is used generally by the internals when producing so-called “anonymous” bound expressions, it isn’t generally applicable to explicitly-named bindparam() constructs.
• required – If True, a value is required at execution time. If not passed, it defaults to True if neither bindparam.value or bindparam.callable were passed. If either of these parameters are present, then bindparam.required defaults to False.
• quote – True if this parameter name requires quoting and is not currently known as a SQLAlchemy reserved word; this currently only applies to the Oracle Database backends, where bound names must sometimes be quoted.
• isoutparam – if True, the parameter should be treated like a stored procedure “OUT” parameter. This applies to backends such as Oracle Database which support OUT parameters.
• expanding – 
if True, this parameter will be treated as an “expanding” parameter at execution time; the parameter value is expected to be a sequence, rather than a scalar value, and the string SQL statement will be transformed on a per-execution basis to accommodate the sequence with a variable number of parameter slots passed to the DBAPI. This is to allow statement caching to be used in conjunction with an IN clause.
See also
ColumnOperators.in_()
Using IN expressions - with baked queries
Note
The “expanding” feature does not support “executemany”- style parameter sets.
Added in version 1.2.
Changed in version 1.3: the “expanding” bound parameter feature now supports empty lists.
• literal_execute – 
if True, the bound parameter will be rendered in the compile phase with a special “POSTCOMPILE” token, and the SQLAlchemy compiler will render the final value of the parameter into the SQL statement at statement execution time, omitting the value from the parameter dictionary / list passed to DBAPI cursor.execute(). This produces a similar effect as that of using the literal_binds, compilation flag, however takes place as the statement is sent to the DBAPI cursor.execute() method, rather than when the statement is compiled. The primary use of this capability is for rendering LIMIT / OFFSET clauses for database drivers that can’t accommodate for bound parameters in these contexts, while allowing SQL constructs to be cacheable at the compilation level.
Added in version 1.4: Added “post compile” bound parameters
See also
New “post compile” bound parameters used for LIMIT/OFFSET in Oracle, SQL Server.
See also
Sending Parameters - in the SQLAlchemy Unified Tutorial
function sqlalchemy.sql.expression.bitwise_not(expr: _ColumnExpressionArgument[_T]) → UnaryExpression[_T]
Produce a unary bitwise NOT clause, typically via the ~ operator.
Not to be confused with boolean negation not_().
Added in version 2.0.2.
See also
Bitwise Operators
function sqlalchemy.sql.expression.case(*whens: typing_Tuple[_ColumnExpressionArgument[bool], Any] | Mapping[Any, Any], value: Any | None = None, else_: Any | None = None) → Case[Any]
Produce a CASE expression.
The CASE construct in SQL is a conditional object that acts somewhat analogously to an “if/then” construct in other languages. It returns an instance of Case.
case() in its usual form is passed a series of “when” constructs, that is, a list of conditions and results as tuples:
from sqlalchemy import case

stmt = select(users_table).where(
    case(
        (users_table.c.name == "wendy", "W"),
        (users_table.c.name == "jack", "J"),
        else_="E",
    )
)
The above statement will produce SQL resembling:
SELECT id, name FROM user
WHERE CASE
    WHEN (name = :name_1) THEN :param_1
    WHEN (name = :name_2) THEN :param_2
    ELSE :param_3
END
When simple equality expressions of several values against a single parent column are needed, case() also has a “shorthand” format used via the case.value parameter, which is passed a column expression to be compared. In this form, the case.whens parameter is passed as a dictionary containing expressions to be compared against keyed to result expressions. The statement below is equivalent to the preceding statement:
stmt = select(users_table).where(
    case({"wendy": "W", "jack": "J"}, value=users_table.c.name, else_="E")
)
The values which are accepted as result values in case.whens as well as with case.else_ are coerced from Python literals into bindparam() constructs. SQL expressions, e.g. ColumnElement constructs, are accepted as well. To coerce a literal string expression into a constant expression rendered inline, use the literal_column() construct, as in:
from sqlalchemy import case, literal_column

case(
    (orderline.c.qty > 100, literal_column("'greaterthan100'")),
    (orderline.c.qty > 10, literal_column("'greaterthan10'")),
    else_=literal_column("'lessthan10'"),
)
The above will render the given constants without using bound parameters for the result values (but still for the comparison values), as in:
CASE
    WHEN (orderline.qty > :qty_1) THEN 'greaterthan100'
    WHEN (orderline.qty > :qty_2) THEN 'greaterthan10'
    ELSE 'lessthan10'
END
Parameters:
• *whens – 
The criteria to be compared against, case.whens accepts two different forms, based on whether or not case.value is used.
Changed in version 1.4: the case() function now accepts the series of WHEN conditions positionally
In the first form, it accepts multiple 2-tuples passed as positional arguments; each 2-tuple consists of (<sql expression>, <value>), where the SQL expression is a boolean expression and “value” is a resulting value, e.g.:
case(
    (users_table.c.name == "wendy", "W"),
    (users_table.c.name == "jack", "J"),
)
In the second form, it accepts a Python dictionary of comparison values mapped to a resulting value; this form requires case.value to be present, and values will be compared using the == operator, e.g.:
case({"wendy": "W", "jack": "J"}, value=users_table.c.name)
• 
• value – An optional SQL expression which will be used as a fixed “comparison point” for candidate values within a dictionary passed to case.whens.
• else_ – An optional SQL expression which will be the evaluated result of the CASE construct if all expressions within case.whens evaluate to false. When omitted, most databases will produce a result of NULL if none of the “when” expressions evaluate to true.
function sqlalchemy.sql.expression.cast(expression: _ColumnExpressionOrLiteralArgument[Any], type_: _TypeEngineArgument[_T]) → Cast[_T]
Produce a CAST expression.
cast() returns an instance of Cast.
E.g.:
from sqlalchemy import cast, Numeric

stmt = select(cast(product_table.c.unit_price, Numeric(10, 4)))
The above statement will produce SQL resembling:
SELECT CAST(unit_price AS NUMERIC(10, 4)) FROM product
The cast() function performs two distinct functions when used. The first is that it renders the CAST expression within the resulting SQL string. The second is that it associates the given type (e.g. TypeEngine class or instance) with the column expression on the Python side, which means the expression will take on the expression operator behavior associated with that type, as well as the bound-value handling and result-row-handling behavior of the type.
An alternative to cast() is the type_coerce() function. This function performs the second task of associating an expression with a specific type, but does not render the CAST expression in SQL.
Parameters:
• expression – A SQL expression, such as a ColumnElement expression or a Python string which will be coerced into a bound literal value.
• type_ – A TypeEngine class or instance indicating the type to which the CAST should apply.
See also
Data Casts and Type Coercion
try_cast() - an alternative to CAST that results in NULLs when the cast fails, instead of raising an error. Only supported by some dialects.
type_coerce() - an alternative to CAST that coerces the type on the Python side only, which is often sufficient to generate the correct SQL and data coercion.
function sqlalchemy.sql.expression.column(text: str, type_: _TypeEngineArgument[_T] | None = None, is_literal: bool = False, _selectable: FromClause | None = None) → ColumnClause[_T]
Produce a ColumnClause object.
The ColumnClause is a lightweight analogue to the Column class. The column() function can be invoked with just a name alone, as in:
from sqlalchemy import column

id, name = column("id"), column("name")
stmt = select(id, name).select_from("user")
The above statement would produce SQL like:
SELECT id, name FROM user
Once constructed, column() may be used like any other SQL expression element such as within select() constructs:
from sqlalchemy.sql import column

id, name = column("id"), column("name")
stmt = select(id, name).select_from("user")
The text handled by column() is assumed to be handled like the name of a database column; if the string contains mixed case, special characters, or matches a known reserved word on the target backend, the column expression will render using the quoting behavior determined by the backend. To produce a textual SQL expression that is rendered exactly without any quoting, use literal_column() instead, or pass True as the value of column.is_literal. Additionally, full SQL statements are best handled using the text() construct.
column() can be used in a table-like fashion by combining it with the table() function (which is the lightweight analogue to Table ) to produce a working table construct with minimal boilerplate:
from sqlalchemy import table, column, select

user = table(
    "user",
    column("id"),
    column("name"),
    column("description"),
)

stmt = select(user.c.description).where(user.c.name == "wendy")
A column() / table() construct like that illustrated above can be created in an ad-hoc fashion and is not associated with any MetaData, DDL, or events, unlike its Table counterpart.
Parameters:
• text – the text of the element.
• type – TypeEngine object which can associate this ColumnClause with a type.
• is_literal – if True, the ColumnClause is assumed to be an exact expression that will be delivered to the output with no quoting rules applied regardless of case sensitive settings. the literal_column() function essentially invokes column() while passing is_literal=True.
See also
Column
literal_column()
table()
text()
Selecting with Textual Column Expressions
class sqlalchemy.sql.expression.custom_op
Represent a ‘custom’ operator.
custom_op is normally instantiated when the Operators.op() or Operators.bool_op() methods are used to create a custom operator callable. The class can also be used directly when programmatically constructing expressions. E.g. to represent the “factorial” operation:
from sqlalchemy.sql import UnaryExpression
from sqlalchemy.sql import operators
from sqlalchemy import Numeric

unary = UnaryExpression(
    table.c.somecolumn, modifier=operators.custom_op("!"), type_=Numeric
)
See also
Operators.op()
Operators.bool_op()
Class signature
class sqlalchemy.sql.expression.custom_op (sqlalchemy.sql.expression.OperatorType, typing.Generic)
function sqlalchemy.sql.expression.distinct(expr: _ColumnExpressionArgument[_T]) → UnaryExpression[_T]
Produce an column-expression-level unary DISTINCT clause.
This applies the DISTINCT keyword to an individual column expression (e.g. not the whole statement), and renders specifically in that column position; this is used for containment within an aggregate function, as in:
from sqlalchemy import distinct, func

stmt = select(users_table.c.id, func.count(distinct(users_table.c.name)))
The above would produce an statement resembling:
SELECT user.id, count(DISTINCT user.name) FROM user
Tip
The distinct() function does not apply DISTINCT to the full SELECT statement, instead applying a DISTINCT modifier to individual column expressions. For general SELECT DISTINCT support, use the Select.distinct() method on Select.
The distinct() function is also available as a column-level method, e.g. ColumnElement.distinct(), as in:
stmt = select(func.count(users_table.c.name.distinct()))
The distinct() operator is different from the Select.distinct() method of Select, which produces a SELECT statement with DISTINCT applied to the result set as a whole, e.g. a SELECT DISTINCT expression. See that method for further information.
See also
ColumnElement.distinct()
Select.distinct()
func
function sqlalchemy.sql.expression.extract(field: str, expr: _ColumnExpressionArgument[Any]) → Extract
Return a Extract construct.
This is typically available as extract() as well as func.extract from the func namespace.
Parameters:
• field – 
The field to extract.
Warning
This field is used as a literal SQL string. DO NOT PASS UNTRUSTED INPUT TO THIS STRING.
• expr – A column or Python scalar expression serving as the right side of the EXTRACT expression.
E.g.:
from sqlalchemy import extract
from sqlalchemy import table, column

logged_table = table(
    "user",
    column("id"),
    column("date_created"),
)

stmt = select(logged_table.c.id).where(
    extract("YEAR", logged_table.c.date_created) == 2021
)
In the above example, the statement is used to select ids from the database where the YEAR component matches a specific value.
Similarly, one can also select an extracted component:
stmt = select(extract("YEAR", logged_table.c.date_created)).where(
    logged_table.c.id == 1
)
The implementation of EXTRACT may vary across database backends. Users are reminded to consult their database documentation.
function sqlalchemy.sql.expression.false() → False_
Return a False_ construct.
E.g.:
>>> from sqlalchemy import false
>>> print(select(t.c.x).where(false()))
SELECT x FROM t WHERE false
A backend which does not support true/false constants will render as an expression against 1 or 0:
>>> print(select(t.c.x).where(false()))
SELECT x FROM t WHERE 0 = 1
The true() and false() constants also feature “short circuit” operation within an and_() or or_() conjunction:
>>> print(select(t.c.x).where(or_(t.c.x > 5, true())))
SELECT x FROM t WHERE true
>>> print(select(t.c.x).where(and_(t.c.x > 5, false())))
SELECT x FROM t WHERE false
See also
true()
sqlalchemy.sql.expression.func = <sqlalchemy.sql.functions._FunctionGenerator object>
Generate SQL function expressions.
func is a special object instance which generates SQL functions based on name-based attributes, e.g.:
>>> print(func.count(1))
count(:param_1)
The returned object is an instance of Function, and is a column-oriented SQL element like any other, and is used in that way:
>>> print(select(func.count(table.c.id)))
SELECT count(sometable.id) FROM sometable
Any name can be given to func. If the function name is unknown to SQLAlchemy, it will be rendered exactly as is. For common SQL functions which SQLAlchemy is aware of, the name may be interpreted as a generic function which will be compiled appropriately to the target database:
>>> print(func.current_timestamp())
CURRENT_TIMESTAMP
To call functions which are present in dot-separated packages, specify them in the same manner:
>>> print(func.stats.yield_curve(5, 10))
stats.yield_curve(:yield_curve_1, :yield_curve_2)
SQLAlchemy can be made aware of the return type of functions to enable type-specific lexical and result-based behavior. For example, to ensure that a string-based function returns a Unicode value and is similarly treated as a string in expressions, specify Unicode as the type:
>>> print(
...     func.my_string("hi", type_=Unicode)
...     + " "
...     + func.my_string("there", type_=Unicode)
... )
my_string(:my_string_1) || :my_string_2 || my_string(:my_string_3)
The object returned by a func call is usually an instance of Function. This object meets the “column” interface, including comparison and labeling functions. The object can also be passed the Connectable.execute() method of a Connection or Engine, where it will be wrapped inside of a SELECT statement first:
print(connection.execute(func.current_timestamp()).scalar())
In a few exception cases, the func accessor will redirect a name to a built-in expression such as cast() or extract(), as these names have well-known meaning but are not exactly the same as “functions” from a SQLAlchemy perspective.
Functions which are interpreted as “generic” functions know how to calculate their return type automatically. For a listing of known generic functions, see SQL and Generic Functions.
Note
The func construct has only limited support for calling standalone “stored procedures”, especially those with special parameterization concerns.
See the section Calling Stored Procedures and User Defined Functions for details on how to use the DBAPI-level callproc() method for fully traditional stored procedures.
See also
Working with SQL Functions - in the SQLAlchemy Unified Tutorial
Function
function sqlalchemy.sql.expression.lambda_stmt(lmb: Callable[[], Any], enable_tracking: bool = True, track_closure_variables: bool = True, track_on: object | None = None, global_track_bound_values: bool = True, track_bound_values: bool = True, lambda_cache: MutableMapping[Tuple[Any, ...], NonAnalyzedFunction | AnalyzedFunction] | None = None) → StatementLambdaElement
Produce a SQL statement that is cached as a lambda.
The Python code object within the lambda is scanned for both Python literals that will become bound parameters as well as closure variables that refer to Core or ORM constructs that may vary. The lambda itself will be invoked only once per particular set of constructs detected.
E.g.:
from sqlalchemy import lambda_stmt

stmt = lambda_stmt(lambda: table.select())
stmt += lambda s: s.where(table.c.id == 5)

result = connection.execute(stmt)
The object returned is an instance of StatementLambdaElement.
Added in version 1.4.
Parameters:
• lmb – a Python function, typically a lambda, which takes no arguments and returns a SQL expression construct
• enable_tracking – when False, all scanning of the given lambda for changes in closure variables or bound parameters is disabled. Use for a lambda that produces the identical results in all cases with no parameterization.
• track_closure_variables – when False, changes in closure variables within the lambda will not be scanned. Use for a lambda where the state of its closure variables will never change the SQL structure returned by the lambda.
• track_bound_values – when False, bound parameter tracking will be disabled for the given lambda. Use for a lambda that either does not produce any bound values, or where the initial bound values never change.
• global_track_bound_values – when False, bound parameter tracking will be disabled for the entire statement including additional links added via the StatementLambdaElement.add_criteria() method.
• lambda_cache – a dictionary or other mapping-like object where information about the lambda’s Python code as well as the tracked closure variables in the lambda itself will be stored. Defaults to a global LRU cache. This cache is independent of the “compiled_cache” used by the Connection object.
See also
Using Lambdas to add significant speed gains to statement production
function sqlalchemy.sql.expression.literal(value: Any, type_: _TypeEngineArgument[Any] | None = None, literal_execute: bool = False) → BindParameter[Any]
Return a literal clause, bound to a bind parameter.
Literal clauses are created automatically when non- ClauseElement objects (such as strings, ints, dates, etc.) are used in a comparison operation with a ColumnElement subclass, such as a Column object. Use this function to force the generation of a literal clause, which will be created as a BindParameter with a bound value.
Parameters:
• value – the value to be bound. Can be any Python object supported by the underlying DB-API, or is translatable via the given type argument.
• type_ – an optional TypeEngine which will provide bind-parameter translation for this literal.
• literal_execute – 
optional bool, when True, the SQL engine will attempt to render the bound value directly in the SQL statement at execution time rather than providing as a parameter value.
Added in version 2.0.
function sqlalchemy.sql.expression.literal_column(text: str, type_: _TypeEngineArgument[_T] | None = None) → ColumnClause[_T]
Produce a ColumnClause object that has the column.is_literal flag set to True.
literal_column() is similar to column(), except that it is more often used as a “standalone” column expression that renders exactly as stated; while column() stores a string name that will be assumed to be part of a table and may be quoted as such, literal_column() can be that, or any other arbitrary column-oriented expression.
Parameters:
• text – the text of the expression; can be any SQL expression. Quoting rules will not be applied. To specify a column-name expression which should be subject to quoting rules, use the column() function.
• type_ – an optional TypeEngine object which will provide result-set translation and additional expression semantics for this column. If left as None the type will be NullType.
See also
column()
text()
Selecting with Textual Column Expressions
function sqlalchemy.sql.expression.not_(clause: _ColumnExpressionArgument[_T]) → ColumnElement[_T]
Return a negation of the given clause, i.e. NOT(clause).
The ~ operator is also overloaded on all ColumnElement subclasses to produce the same result.
function sqlalchemy.sql.expression.null() → Null
Return a constant Null construct.
function sqlalchemy.sql.expression.or_(*clauses)
Produce a conjunction of expressions joined by OR.
E.g.:
from sqlalchemy import or_

stmt = select(users_table).where(
    or_(users_table.c.name == "wendy", users_table.c.name == "jack")
)
The or_() conjunction is also available using the Python | operator (though note that compound expressions need to be parenthesized in order to function with Python operator precedence behavior):
stmt = select(users_table).where(
    (users_table.c.name == "wendy") | (users_table.c.name == "jack")
)
The or_() construct must be given at least one positional argument in order to be valid; a or_() construct with no arguments is ambiguous. To produce an “empty” or dynamically generated or_() expression, from a given list of expressions, a “default” element of false() (or just False) should be specified:
from sqlalchemy import false

or_criteria = or_(false(), *expressions)
The above expression will compile to SQL as the expression false or 0 = 1, depending on backend, if no other expressions are present. If expressions are present, then the false() value is ignored as it does not affect the outcome of an OR expression which has other elements.
Deprecated since version 1.4: The or_() element now requires that at least one argument is passed; creating the or_() construct with no arguments is deprecated, and will emit a deprecation warning while continuing to produce a blank SQL string.
See also
and_()
function sqlalchemy.sql.expression.outparam(key: str, type_: TypeEngine[_T] | None = None) → BindParameter[_T]
Create an ‘OUT’ parameter for usage in functions (stored procedures), for databases which support them.
The outparam can be used like a regular function parameter. The “output” value will be available from the CursorResult object via its out_parameters attribute, which returns a dictionary containing the values.
function sqlalchemy.sql.expression.text(text: str) → TextClause
Construct a new TextClause clause, representing a textual SQL string directly.
E.g.:
from sqlalchemy import text

t = text("SELECT * FROM users")
result = connection.execute(t)
The advantages text() provides over a plain string are backend-neutral support for bind parameters, per-statement execution options, as well as bind parameter and result-column typing behavior, allowing SQLAlchemy type constructs to play a role when executing a statement that is specified literally. The construct can also be provided with a .c collection of column elements, allowing it to be embedded in other SQL expression constructs as a subquery.
Bind parameters are specified by name, using the format :name. E.g.:
t = text("SELECT * FROM users WHERE id=:user_id")
result = connection.execute(t, {"user_id": 12})
For SQL statements where a colon is required verbatim, as within an inline string, use a backslash to escape:
t = text(r"SELECT * FROM users WHERE name='\:username'")
The TextClause construct includes methods which can provide information about the bound parameters as well as the column values which would be returned from the textual statement, assuming it’s an executable SELECT type of statement. The TextClause.bindparams() method is used to provide bound parameter detail, and TextClause.columns() method allows specification of return columns including names and types:
t = (
    text("SELECT * FROM users WHERE id=:user_id")
    .bindparams(user_id=7)
    .columns(id=Integer, name=String)
)

for id, name in connection.execute(t):
    print(id, name)
The text() construct is used in cases when a literal string SQL fragment is specified as part of a larger query, such as for the WHERE clause of a SELECT statement:
s = select(users.c.id, users.c.name).where(text("id=:user_id"))
result = connection.execute(s, {"user_id": 12})
text() is also used for the construction of a full, standalone statement using plain text. As such, SQLAlchemy refers to it as an Executable object and may be used like any other statement passed to an .execute() method.
Parameters:
text – the text of the SQL statement to be created. Use :<param> to specify bind parameters; they will be compiled to their engine-specific format.
See also
Selecting with Textual Column Expressions
function sqlalchemy.sql.expression.true() → True_
Return a constant True_ construct.
E.g.:
>>> from sqlalchemy import true
>>> print(select(t.c.x).where(true()))
SELECT x FROM t WHERE true
A backend which does not support true/false constants will render as an expression against 1 or 0:
>>> print(select(t.c.x).where(true()))
SELECT x FROM t WHERE 1 = 1
The true() and false() constants also feature “short circuit” operation within an and_() or or_() conjunction:
>>> print(select(t.c.x).where(or_(t.c.x > 5, true())))
SELECT x FROM t WHERE true
>>> print(select(t.c.x).where(and_(t.c.x > 5, false())))
SELECT x FROM t WHERE false
See also
false()
function sqlalchemy.sql.expression.try_cast(expression: _ColumnExpressionOrLiteralArgument[Any], type_: _TypeEngineArgument[_T]) → TryCast[_T]
Produce a TRY_CAST expression for backends which support it; this is a CAST which returns NULL for un-castable conversions.
In SQLAlchemy, this construct is supported only by the SQL Server dialect, and will raise a CompileError if used on other included backends. However, third party backends may also support this construct.
Tip
As try_cast() originates from the SQL Server dialect, it’s importable both from sqlalchemy. as well as from sqlalchemy.dialects.mssql.
try_cast() returns an instance of TryCast and generally behaves similarly to the Cast construct; at the SQL level, the difference between CAST and TRY_CAST is that TRY_CAST returns NULL for an un-castable expression, such as attempting to cast a string "hi" to an integer value.
E.g.:
from sqlalchemy import select, try_cast, Numeric

stmt = select(try_cast(product_table.c.unit_price, Numeric(10, 4)))
The above would render on Microsoft SQL Server as:
SELECT TRY_CAST (product_table.unit_price AS NUMERIC(10, 4))
FROM product_table
Added in version 2.0.14: try_cast() has been generalized from the SQL Server dialect into a general use construct that may be supported by additional dialects.
function sqlalchemy.sql.expression.tuple_(*clauses: _ColumnExpressionArgument[Any], types: Sequence[_TypeEngineArgument[Any]] | None = None) → Tuple
Return a Tuple.
Main usage is to produce a composite IN construct using ColumnOperators.in_()
from sqlalchemy import tuple_

tuple_(table.c.col1, table.c.col2).in_([(1, 2), (5, 12), (10, 19)])
Changed in version 1.3.6: Added support for SQLite IN tuples.
Warning
The composite IN construct is not supported by all backends, and is currently known to work on PostgreSQL, MySQL, and SQLite. Unsupported backends will raise a subclass of DBAPIError when such an expression is invoked.
function sqlalchemy.sql.expression.type_coerce(expression: _ColumnExpressionOrLiteralArgument[Any], type_: _TypeEngineArgument[_T]) → TypeCoerce[_T]
Associate a SQL expression with a particular type, without rendering CAST.
E.g.:
from sqlalchemy import type_coerce

stmt = select(type_coerce(log_table.date_string, StringDateTime()))
The above construct will produce a TypeCoerce object, which does not modify the rendering in any way on the SQL side, with the possible exception of a generated label if used in a columns clause context:
SELECT date_string AS date_string FROM log
When result rows are fetched, the StringDateTime type processor will be applied to result rows on behalf of the date_string column.
Note
the type_coerce() construct does not render any SQL syntax of its own, including that it does not imply parenthesization. Please use TypeCoerce.self_group() if explicit parenthesization is required.
In order to provide a named label for the expression, use ColumnElement.label():
stmt = select(
    type_coerce(log_table.date_string, StringDateTime()).label("date")
)
A type that features bound-value handling will also have that behavior take effect when literal values or bindparam() constructs are passed to type_coerce() as targets. For example, if a type implements the TypeEngine.bind_expression() method or TypeEngine.bind_processor() method or equivalent, these functions will take effect at statement compilation/execution time when a literal value is passed, as in:
# bound-value handling of MyStringType will be applied to the
# literal value "some string"
stmt = select(type_coerce("some string", MyStringType))
When using type_coerce() with composed expressions, note that parenthesis are not applied. If type_coerce() is being used in an operator context where the parenthesis normally present from CAST are necessary, use the TypeCoerce.self_group() method:
>>> some_integer = column("someint", Integer)
>>> some_string = column("somestr", String)
>>> expr = type_coerce(some_integer + 5, String) + some_string
>>> print(expr)
someint + :someint_1 || somestr
>>> expr = type_coerce(some_integer + 5, String).self_group() + some_string
>>> print(expr)
(someint + :someint_1) || somestr
Parameters:
• expression – A SQL expression, such as a ColumnElement expression or a Python string which will be coerced into a bound literal value.
• type_ – A TypeEngine class or instance indicating the type to which the expression is coerced.
See also
Data Casts and Type Coercion
cast()
class sqlalchemy.sql.expression.quoted_name
Represent a SQL identifier combined with quoting preferences.
quoted_name is a Python unicode/str subclass which represents a particular identifier name along with a quote flag. This quote flag, when set to True or False, overrides automatic quoting behavior for this identifier in order to either unconditionally quote or to not quote the name. If left at its default of None, quoting behavior is applied to the identifier on a per-backend basis based on an examination of the token itself.
A quoted_name object with quote=True is also prevented from being modified in the case of a so-called “name normalize” option. Certain database backends, such as Oracle Database, Firebird, and DB2 “normalize” case-insensitive names as uppercase. The SQLAlchemy dialects for these backends convert from SQLAlchemy’s lower-case-means-insensitive convention to the upper-case-means-insensitive conventions of those backends. The quote=True flag here will prevent this conversion from occurring to support an identifier that’s quoted as all lower case against such a backend.
The quoted_name object is normally created automatically when specifying the name for key schema constructs such as Table, Column, and others. The class can also be passed explicitly as the name to any function that receives a name which can be quoted. Such as to use the Engine.has_table() method with an unconditionally quoted name:
from sqlalchemy import create_engine
from sqlalchemy import inspect
from sqlalchemy.sql import quoted_name

engine = create_engine("oracle+oracledb://some_dsn")
print(inspect(engine).has_table(quoted_name("some_table", True)))
The above logic will run the “has table” logic against the Oracle Database backend, passing the name exactly as "some_table" without converting to upper case.
Changed in version 1.2: The quoted_name construct is now importable from sqlalchemy.sql, in addition to the previous location of sqlalchemy.sql.elements.
Members
quote
Class signature
class sqlalchemy.sql.expression.quoted_name (sqlalchemy.util.langhelpers.MemoizedSlots, builtins.str)
attribute sqlalchemy.sql.expression.quoted_name.quote
whether the string should be unconditionally quoted
Column Element Modifier Constructors
Functions listed here are more commonly available as methods from any ColumnElement construct, for example, the label() function is usually invoked via the ColumnElement.label() method.
Object NameDescriptionall_(expr)Produce an ALL expression.any_(expr)Produce an ANY expression.asc(column)Produce an ascending ORDER BY clause element.between(expr, lower_bound, upper_bound[, symmetric])Produce a BETWEEN predicate clause.collate(expression, collation)Return the clause expression COLLATE collation.desc(column)Produce a descending ORDER BY clause element.funcfilter(func, *criterion)Produce a FunctionFilter object against a function.label(name, element[, type_])Return a Label object for the given ColumnElement.nulls_first(column)Produce the NULLS FIRST modifier for an ORDER BY expression.nulls_last(column)Produce the NULLS LAST modifier for an ORDER BY expression.nullsfirstSynonym for the nulls_first() function.nullslastLegacy synonym for the nulls_last() function.over(element[, partition_by, order_by, range_, ...])Produce an Over object against a function.within_group(element, *order_by)Produce a WithinGroup object against a function.function sqlalchemy.sql.expression.all_(expr: _ColumnExpressionArgument[_T]) → CollectionAggregate[bool]
Produce an ALL expression.
For dialects such as that of PostgreSQL, this operator applies to usage of the ARRAY datatype, for that of MySQL, it may apply to a subquery. e.g.:
# renders on PostgreSQL:
# '5 = ALL (somearray)'
expr = 5 == all_(mytable.c.somearray)

# renders on MySQL:
# '5 = ALL (SELECT value FROM table)'
expr = 5 == all_(select(table.c.value))
Comparison to NULL may work using None:
None == all_(mytable.c.somearray)
The any_() / all_() operators also feature a special “operand flipping” behavior such that if any_() / all_() are used on the left side of a comparison using a standalone operator such as ==, !=, etc. (not including operator methods such as ColumnOperators.is_()) the rendered expression is flipped:
# would render '5 = ALL (column)`
all_(mytable.c.column) == 5
Or with None, which note will not perform the usual step of rendering “IS” as is normally the case for NULL:
# would render 'NULL = ALL(somearray)'
all_(mytable.c.somearray) == None
Changed in version 1.4.26: repaired the use of any_() / all_() comparing to NULL on the right side to be flipped to the left.
The column-level ColumnElement.all_() method (not to be confused with ARRAY level Comparator.all()) is shorthand for all_(col):
5 == mytable.c.somearray.all_()
See also
ColumnOperators.all_()
any_()
function sqlalchemy.sql.expression.any_(expr: _ColumnExpressionArgument[_T]) → CollectionAggregate[bool]
Produce an ANY expression.
For dialects such as that of PostgreSQL, this operator applies to usage of the ARRAY datatype, for that of MySQL, it may apply to a subquery. e.g.:
# renders on PostgreSQL:
# '5 = ANY (somearray)'
expr = 5 == any_(mytable.c.somearray)

# renders on MySQL:
# '5 = ANY (SELECT value FROM table)'
expr = 5 == any_(select(table.c.value))
Comparison to NULL may work using None or null():
None == any_(mytable.c.somearray)
The any_() / all_() operators also feature a special “operand flipping” behavior such that if any_() / all_() are used on the left side of a comparison using a standalone operator such as ==, !=, etc. (not including operator methods such as ColumnOperators.is_()) the rendered expression is flipped:
# would render '5 = ANY (column)`
any_(mytable.c.column) == 5
Or with None, which note will not perform the usual step of rendering “IS” as is normally the case for NULL:
# would render 'NULL = ANY(somearray)'
any_(mytable.c.somearray) == None
Changed in version 1.4.26: repaired the use of any_() / all_() comparing to NULL on the right side to be flipped to the left.
The column-level ColumnElement.any_() method (not to be confused with ARRAY level Comparator.any()) is shorthand for any_(col):
5 = mytable.c.somearray.any_()
See also
ColumnOperators.any_()
all_()
function sqlalchemy.sql.expression.asc(column: _ColumnExpressionOrStrLabelArgument[_T]) → UnaryExpression[_T]
Produce an ascending ORDER BY clause element.
e.g.:
from sqlalchemy import asc

stmt = select(users_table).order_by(asc(users_table.c.name))
will produce SQL as:
SELECT id, name FROM user ORDER BY name ASC
The asc() function is a standalone version of the ColumnElement.asc() method available on all SQL expressions, e.g.:
stmt = select(users_table).order_by(users_table.c.name.asc())
Parameters:
column – A ColumnElement (e.g. scalar SQL expression) with which to apply the asc() operation.
See also
desc()
nulls_first()
nulls_last()
Select.order_by()
function sqlalchemy.sql.expression.between(expr: _ColumnExpressionOrLiteralArgument[_T], lower_bound: Any, upper_bound: Any, symmetric: bool = False) → BinaryExpression[bool]
Produce a BETWEEN predicate clause.
E.g.:
from sqlalchemy import between

stmt = select(users_table).where(between(users_table.c.id, 5, 7))
Would produce SQL resembling:
SELECT id, name FROM user WHERE id BETWEEN :id_1 AND :id_2
The between() function is a standalone version of the ColumnElement.between() method available on all SQL expressions, as in:
stmt = select(users_table).where(users_table.c.id.between(5, 7))
All arguments passed to between(), including the left side column expression, are coerced from Python scalar values if a the value is not a ColumnElement subclass. For example, three fixed values can be compared as in:
print(between(5, 3, 7))
Which would produce:
:param_1 BETWEEN :param_2 AND :param_3
Parameters:
• expr – a column expression, typically a ColumnElement instance or alternatively a Python scalar expression to be coerced into a column expression, serving as the left side of the BETWEEN expression.
• lower_bound – a column or Python scalar expression serving as the lower bound of the right side of the BETWEEN expression.
• upper_bound – a column or Python scalar expression serving as the upper bound of the right side of the BETWEEN expression.
• symmetric – if True, will render “ BETWEEN SYMMETRIC “. Note that not all databases support this syntax.
See also
ColumnElement.between()
function sqlalchemy.sql.expression.collate(expression: _ColumnExpressionArgument[str], collation: str) → BinaryExpression[str]
Return the clause expression COLLATE collation.
e.g.:
collate(mycolumn, "utf8_bin")
produces:
mycolumn COLLATE utf8_bin
The collation expression is also quoted if it is a case sensitive identifier, e.g. contains uppercase characters.
Changed in version 1.2: quoting is automatically applied to COLLATE expressions if they are case sensitive.
function sqlalchemy.sql.expression.desc(column: _ColumnExpressionOrStrLabelArgument[_T]) → UnaryExpression[_T]
Produce a descending ORDER BY clause element.
e.g.:
from sqlalchemy import desc

stmt = select(users_table).order_by(desc(users_table.c.name))
will produce SQL as:
SELECT id, name FROM user ORDER BY name DESC
The desc() function is a standalone version of the ColumnElement.desc() method available on all SQL expressions, e.g.:
stmt = select(users_table).order_by(users_table.c.name.desc())
Parameters:
column – A ColumnElement (e.g. scalar SQL expression) with which to apply the desc() operation.
See also
asc()
nulls_first()
nulls_last()
Select.order_by()
function sqlalchemy.sql.expression.funcfilter(func: FunctionElement[_T], *criterion: _ColumnExpressionArgument[bool]) → FunctionFilter[_T]
Produce a FunctionFilter object against a function.
Used against aggregate and window functions, for database backends that support the “FILTER” clause.
E.g.:
from sqlalchemy import funcfilter

funcfilter(func.count(1), MyClass.name == "some name")
Would produce “COUNT(1) FILTER (WHERE myclass.name = ‘some name’)”.
This function is also available from the func construct itself via the FunctionElement.filter() method.
See also
Special Modifiers WITHIN GROUP, FILTER - in the SQLAlchemy Unified Tutorial
FunctionElement.filter()
function sqlalchemy.sql.expression.label(name: str, element: _ColumnExpressionArgument[_T], type_: _TypeEngineArgument[_T] | None = None) → Label[_T]
Return a Label object for the given ColumnElement.
A label changes the name of an element in the columns clause of a SELECT statement, typically via the AS SQL keyword.
This functionality is more conveniently available via the ColumnElement.label() method on ColumnElement.
Parameters:
• name – label name
• obj – a ColumnElement.
function sqlalchemy.sql.expression.nulls_first(column: _ColumnExpressionArgument[_T]) → UnaryExpression[_T]
Produce the NULLS FIRST modifier for an ORDER BY expression.
nulls_first() is intended to modify the expression produced by asc() or desc(), and indicates how NULL values should be handled when they are encountered during ordering:
from sqlalchemy import desc, nulls_first

stmt = select(users_table).order_by(nulls_first(desc(users_table.c.name)))
The SQL expression from the above would resemble:
SELECT id, name FROM user ORDER BY name DESC NULLS FIRST
Like asc() and desc(), nulls_first() is typically invoked from the column expression itself using ColumnElement.nulls_first(), rather than as its standalone function version, as in:
stmt = select(users_table).order_by(
    users_table.c.name.desc().nulls_first()
)
Changed in version 1.4: nulls_first() is renamed from nullsfirst() in previous releases. The previous name remains available for backwards compatibility.
See also
asc()
desc()
nulls_last()
Select.order_by()
function sqlalchemy.sql.expression.nullsfirst()
Synonym for the nulls_first() function.
Changed in version 2.0.5: restored missing legacy symbol nullsfirst().
function sqlalchemy.sql.expression.nulls_last(column: _ColumnExpressionArgument[_T]) → UnaryExpression[_T]
Produce the NULLS LAST modifier for an ORDER BY expression.
nulls_last() is intended to modify the expression produced by asc() or desc(), and indicates how NULL values should be handled when they are encountered during ordering:
from sqlalchemy import desc, nulls_last

stmt = select(users_table).order_by(nulls_last(desc(users_table.c.name)))
The SQL expression from the above would resemble:
SELECT id, name FROM user ORDER BY name DESC NULLS LAST
Like asc() and desc(), nulls_last() is typically invoked from the column expression itself using ColumnElement.nulls_last(), rather than as its standalone function version, as in:
stmt = select(users_table).order_by(users_table.c.name.desc().nulls_last())
Changed in version 1.4: nulls_last() is renamed from nullslast() in previous releases. The previous name remains available for backwards compatibility.
See also
asc()
desc()
nulls_first()
Select.order_by()
function sqlalchemy.sql.expression.nullslast()
Legacy synonym for the nulls_last() function.
Changed in version 2.0.5: restored missing legacy symbol nullslast().
function sqlalchemy.sql.expression.over(element: FunctionElement[_T], partition_by: _ByArgument | None = None, order_by: _ByArgument | None = None, range_: typing_Tuple[int | None, int | None] | None = None, rows: typing_Tuple[int | None, int | None] | None = None, groups: typing_Tuple[int | None, int | None] | None = None) → Over[_T]
Produce an Over object against a function.
Used against aggregate or so-called “window” functions, for database backends that support window functions.
over() is usually called using the FunctionElement.over() method, e.g.:
func.row_number().over(order_by=mytable.c.some_column)
Would produce:
ROW_NUMBER() OVER(ORDER BY some_column)
Ranges are also possible using the over.range_, over.rows, and over.groups parameters. These mutually-exclusive parameters each accept a 2-tuple, which contains a combination of integers and None:
func.row_number().over(order_by=my_table.c.some_column, range_=(None, 0))
The above would produce:
ROW_NUMBER() OVER(ORDER BY some_column
RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)
A value of None indicates “unbounded”, a value of zero indicates “current row”, and negative / positive integers indicate “preceding” and “following”:
• RANGE BETWEEN 5 PRECEDING AND 10 FOLLOWING:
func.row_number().over(order_by="x", range_=(-5, 10))
ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW:
func.row_number().over(order_by="x", rows=(None, 0))
RANGE BETWEEN 2 PRECEDING AND UNBOUNDED FOLLOWING:
func.row_number().over(order_by="x", range_=(-2, None))
RANGE BETWEEN 1 FOLLOWING AND 3 FOLLOWING:
func.row_number().over(order_by="x", range_=(1, 3))
GROUPS BETWEEN 1 FOLLOWING AND 3 FOLLOWING:
func.row_number().over(order_by="x", groups=(1, 3))
Parameters:
• element – a FunctionElement, WithinGroup, or other compatible construct.
• partition_by – a column element or string, or a list of such, that will be used as the PARTITION BY clause of the OVER construct.
• order_by – a column element or string, or a list of such, that will be used as the ORDER BY clause of the OVER construct.
• range_ – optional range clause for the window. This is a tuple value which can contain integer values or None, and will render a RANGE BETWEEN PRECEDING / FOLLOWING clause.
• rows – optional rows clause for the window. This is a tuple value which can contain integer values or None, and will render a ROWS BETWEEN PRECEDING / FOLLOWING clause.
• groups – 
optional groups clause for the window. This is a tuple value which can contain integer values or None, and will render a GROUPS BETWEEN PRECEDING / FOLLOWING clause.
Added in version 2.0.40.
This function is also available from the func construct itself via the FunctionElement.over() method.
See also
Using Window Functions - in the SQLAlchemy Unified Tutorial
func
within_group()
function sqlalchemy.sql.expression.within_group(element: FunctionElement[_T], *order_by: _ColumnExpressionArgument[Any]) → WithinGroup[_T]
Produce a WithinGroup object against a function.
Used against so-called “ordered set aggregate” and “hypothetical set aggregate” functions, including percentile_cont, rank, dense_rank, etc.
within_group() is usually called using the FunctionElement.within_group() method, e.g.:
from sqlalchemy import within_group

stmt = select(
    department.c.id,
    func.percentile_cont(0.5).within_group(department.c.salary.desc()),
)
The above statement would produce SQL similar to SELECT department.id, percentile_cont(0.5) WITHIN GROUP (ORDER BY department.salary DESC).
Parameters:
• element – a FunctionElement construct, typically generated by func.
• *order_by – one or more column elements that will be used as the ORDER BY clause of the WITHIN GROUP construct.
See also
Special Modifiers WITHIN GROUP, FILTER - in the SQLAlchemy Unified Tutorial
func
over()
Column Element Class Documentation
The classes here are generated using the constructors listed at Column Element Foundational Constructors and Column Element Modifier Constructors.
Object NameDescriptionBinaryExpressionRepresent an expression that is LEFT <operator> RIGHT.BindParameterRepresent a “bound expression”.CaseRepresent a CASE expression.CastRepresent a CAST expression.ClauseListDescribe a list of clauses, separated by an operator.ColumnClauseRepresents a column expression from any textual string.ColumnCollectionCollection of ColumnElement instances, typically for FromClause objects.ColumnElementRepresent a column-oriented SQL expression suitable for usage in the “columns” clause, WHERE clause etc. of a statement.ColumnExpressionArgumentGeneral purpose “column expression” argument.ColumnOperatorsDefines boolean, comparison, and other operators for ColumnElement expressions.ExtractRepresent a SQL EXTRACT clause, extract(field FROM expr).False_Represent the false keyword, or equivalent, in a SQL statement.FunctionFilterRepresent a function FILTER clause.LabelRepresents a column label (AS).NullRepresent the NULL keyword in a SQL statement.OperatorsBase of comparison and logical operators.OverRepresent an OVER clause.SQLColumnExpressionA type that may be used to indicate any SQL column element or object that acts in place of one.TextClauseRepresent a literal SQL text fragment.True_Represent the true keyword, or equivalent, in a SQL statement.TryCastRepresent a TRY_CAST expression.TupleRepresent a SQL tuple.TypeCoerceRepresent a Python-side type-coercion wrapper.UnaryExpressionDefine a ‘unary’ expression.WithinGroupRepresent a WITHIN GROUP (ORDER BY) clause.WrapsColumnExpressionMixin that defines a ColumnElement as a wrapper with special labeling behavior for an expression that already has a name.class sqlalchemy.sql.expression.BinaryExpression
Represent an expression that is LEFT <operator> RIGHT.
A BinaryExpression is generated automatically whenever two column expressions are used in a Python binary expression:
>>> from sqlalchemy.sql import column
>>> column("a") + column("b")
<sqlalchemy.sql.expression.BinaryExpression object at 0x101029dd0>
>>> print(column("a") + column("b"))
a + b
Class signature
class sqlalchemy.sql.expression.BinaryExpression (sqlalchemy.sql.expression.OperatorExpression)
class sqlalchemy.sql.expression.BindParameter
Represent a “bound expression”.
BindParameter is invoked explicitly using the bindparam() function, as in:
from sqlalchemy import bindparam

stmt = select(users_table).where(
    users_table.c.name == bindparam("username")
)
Detailed discussion of how BindParameter is used is at bindparam().
See also
bindparam()
Members
effective_value, inherit_cache, render_literal_execute()
Class signature
class sqlalchemy.sql.expression.BindParameter (sqlalchemy.sql.roles.InElementRole, sqlalchemy.sql.expression.KeyedColumnElement)
attribute sqlalchemy.sql.expression.BindParameter.effective_value
Return the value of this bound parameter, taking into account if the callable parameter was set.
The callable value will be evaluated and returned if present, else value.
attribute sqlalchemy.sql.expression.BindParameter.inherit_cache: bool | None = True
Indicate if this HasCacheKey instance should make use of the cache key generation scheme used by its immediate superclass.
The attribute defaults to None, which indicates that a construct has not yet taken into account whether or not its appropriate for it to participate in caching; this is functionally equivalent to setting the value to False, except that a warning is also emitted.
This flag can be set to True on a particular class, if the SQL that corresponds to the object does not change based on attributes which are local to this class, and not its superclass.
See also
Enabling Caching Support for Custom Constructs - General guideslines for setting the HasCacheKey.inherit_cache attribute for third-party or user defined SQL constructs.
method sqlalchemy.sql.expression.BindParameter.render_literal_execute() → BindParameter[_T]
Produce a copy of this bound parameter that will enable the BindParameter.literal_execute flag.
The BindParameter.literal_execute flag will have the effect of the parameter rendered in the compiled SQL string using [POSTCOMPILE] form, which is a special form that is converted to be a rendering of the literal value of the parameter at SQL execution time. The rationale is to support caching of SQL statement strings that can embed per-statement literal values, such as LIMIT and OFFSET parameters, in the final SQL string that is passed to the DBAPI. Dialects in particular may want to use this method within custom compilation schemes.
Added in version 1.4.5.
See also
Caching for Third Party Dialects
class sqlalchemy.sql.expression.Case
Represent a CASE expression.
Case is produced using the case() factory function, as in:
from sqlalchemy import case

stmt = select(users_table).where(
    case(
        (users_table.c.name == "wendy", "W"),
        (users_table.c.name == "jack", "J"),
        else_="E",
    )
)
Details on Case usage is at case().
See also
case()
Class signature
class sqlalchemy.sql.expression.Case (sqlalchemy.sql.expression.ColumnElement)
class sqlalchemy.sql.expression.Cast
Represent a CAST expression.
Cast is produced using the cast() factory function, as in:
from sqlalchemy import cast, Numeric

stmt = select(cast(product_table.c.unit_price, Numeric(10, 4)))
Details on Cast usage is at cast().
See also
Data Casts and Type Coercion
cast()
try_cast()
type_coerce() - an alternative to CAST that coerces the type on the Python side only, which is often sufficient to generate the correct SQL and data coercion.
Class signature
class sqlalchemy.sql.expression.Cast (sqlalchemy.sql.expression.WrapsColumnExpression)
class sqlalchemy.sql.expression.ClauseList
Describe a list of clauses, separated by an operator.
By default, is comma-separated, such as a column listing.
Members
self_group()
Class signature
class sqlalchemy.sql.expression.ClauseList (sqlalchemy.sql.roles.InElementRole, sqlalchemy.sql.roles.OrderByRole, sqlalchemy.sql.roles.ColumnsClauseRole, sqlalchemy.sql.roles.DMLColumnRole, sqlalchemy.sql.expression.DQLDMLClauseElement)
method sqlalchemy.sql.expression.ClauseList.self_group(against: OperatorType | None = None) → Self | Grouping[Any]
Apply a ‘grouping’ to this ClauseElement.
This method is overridden by subclasses to return a “grouping” construct, i.e. parenthesis. In particular it’s used by “binary” expressions to provide a grouping around themselves when placed into a larger expression, as well as by select() constructs when placed into the FROM clause of another select(). (Note that subqueries should be normally created using the Select.alias() method, as many platforms require nested SELECT statements to be named).
As expressions are composed together, the application of self_group() is automatic - end-user code should never need to use this method directly. Note that SQLAlchemy’s clause constructs take operator precedence into account - so parenthesis might not be needed, for example, in an expression like x OR (y AND z) - AND takes precedence over OR.
The base self_group() method of ClauseElement just returns self.
class sqlalchemy.sql.expression.ColumnClause
Represents a column expression from any textual string.
The ColumnClause, a lightweight analogue to the Column class, is typically invoked using the column() function, as in:
from sqlalchemy import column

id, name = column("id"), column("name")
stmt = select(id, name).select_from("user")
The above statement would produce SQL like:
SELECT id, name FROM user
ColumnClause is the immediate superclass of the schema-specific Column object. While the Column class has all the same capabilities as ColumnClause, the ColumnClause class is usable by itself in those cases where behavioral requirements are limited to simple SQL expression generation. The object has none of the associations with schema-level metadata or with execution-time behavior that Column does, so in that sense is a “lightweight” version of Column.
Full details on ColumnClause usage is at column().
See also
column()
Column
Members
get_children()
Class signature
class sqlalchemy.sql.expression.ColumnClause (sqlalchemy.sql.roles.DDLReferredColumnRole, sqlalchemy.sql.roles.LabeledColumnExprRole, sqlalchemy.sql.roles.StrAsPlainColumnRole, sqlalchemy.sql.expression.Immutable, sqlalchemy.sql.expression.NamedColumn)
method sqlalchemy.sql.expression.ColumnClause.get_children(*, column_tables=False, **kw)
Return immediate child HasTraverseInternals elements of this HasTraverseInternals.
This is used for visit traversal.
**kw may contain flags that change the collection that is returned, for example to return a subset of items in order to cut down on larger traversals, or to return child items from a different context (such as schema-level collections instead of clause-level).
class sqlalchemy.sql.expression.ColumnCollection
Collection of ColumnElement instances, typically for FromClause objects.
The ColumnCollection object is most commonly available as the Table.c or Table.columns collection on the Table object, introduced at Accessing Tables and Columns.
The ColumnCollection has both mapping- and sequence- like behaviors. A ColumnCollection usually stores Column objects, which are then accessible both via mapping style access as well as attribute access style.
To access Column objects using ordinary attribute-style access, specify the name like any other object attribute, such as below a column named employee_name is accessed:
>>> employee_table.c.employee_name
To access columns that have names with special characters or spaces, index-style access is used, such as below which illustrates a column named employee ' payment is accessed:
>>> employee_table.c["employee ' payment"]
As the ColumnCollection object provides a Python dictionary interface, common dictionary method names like ColumnCollection.keys(), ColumnCollection.values(), and ColumnCollection.items() are available, which means that database columns that are keyed under these names also need to use indexed access:
>>> employee_table.c["values"]
The name for which a Column would be present is normally that of the Column.key parameter. In some contexts, such as a Select object that uses a label style set using the Select.set_label_style() method, a column of a certain key may instead be represented under a particular label name such as tablename_columnname:
>>> from sqlalchemy import select, column, table
>>> from sqlalchemy import LABEL_STYLE_TABLENAME_PLUS_COL
>>> t = table("t", column("c"))
>>> stmt = select(t).set_label_style(LABEL_STYLE_TABLENAME_PLUS_COL)
>>> subq = stmt.subquery()
>>> subq.c.t_c
<sqlalchemy.sql.elements.ColumnClause at 0x7f59dcf04fa0; t_c>
ColumnCollection also indexes the columns in order and allows them to be accessible by their integer position:
>>> cc[0]
Column('x', Integer(), table=None)
>>> cc[1]
Column('y', Integer(), table=None)
Added in version 1.4: ColumnCollection allows integer-based index access to the collection.
Iterating the collection yields the column expressions in order:
>>> list(cc)
[Column('x', Integer(), table=None),
 Column('y', Integer(), table=None)]
The base ColumnCollection object can store duplicates, which can mean either two columns with the same key, in which case the column returned by key access is arbitrary:
>>> x1, x2 = Column("x", Integer), Column("x", Integer)
>>> cc = ColumnCollection(columns=[(x1.name, x1), (x2.name, x2)])
>>> list(cc)
[Column('x', Integer(), table=None),
 Column('x', Integer(), table=None)]
>>> cc["x"] is x1
False
>>> cc["x"] is x2
True
Or it can also mean the same column multiple times. These cases are supported as ColumnCollection is used to represent the columns in a SELECT statement which may include duplicates.
A special subclass DedupeColumnCollection exists which instead maintains SQLAlchemy’s older behavior of not allowing duplicates; this collection is used for schema level objects like Table and PrimaryKeyConstraint where this deduping is helpful. The DedupeColumnCollection class also has additional mutation methods as the schema constructs have more use cases that require removal and replacement of columns.
Changed in version 1.4: ColumnCollection now stores duplicate column keys as well as the same column in multiple positions. The DedupeColumnCollection class is added to maintain the former behavior in those cases where deduplication as well as additional replace/remove operations are needed.
Members
add(), as_readonly(), clear(), compare(), contains_column(), corresponding_column(), get(), items(), keys(), update(), values()
Class signature
class sqlalchemy.sql.expression.ColumnCollection (typing.Generic)
method sqlalchemy.sql.expression.ColumnCollection.add(column: ColumnElement[Any], key: _COLKEY | None = None) → None
Add a column to this ColumnCollection.
Note
This method is not normally used by user-facing code, as the ColumnCollection is usually part of an existing object such as a Table. To add a Column to an existing Table object, use the Table.append_column() method.
method sqlalchemy.sql.expression.ColumnCollection.as_readonly() → ReadOnlyColumnCollection[_COLKEY, _COL_co]
Return a “read only” form of this ColumnCollection.
method sqlalchemy.sql.expression.ColumnCollection.clear() → NoReturn
Dictionary clear() is not implemented for ColumnCollection.
method sqlalchemy.sql.expression.ColumnCollection.compare(other: ColumnCollection[Any, Any]) → bool
Compare this ColumnCollection to another based on the names of the keys
method sqlalchemy.sql.expression.ColumnCollection.contains_column(col: ColumnElement[Any]) → bool
Checks if a column object exists in this collection
method sqlalchemy.sql.expression.ColumnCollection.corresponding_column(column: _COL, require_embedded: bool = False) → _COL | _COL_co | None
Given a ColumnElement, return the exported ColumnElement object from this ColumnCollection which corresponds to that original ColumnElement via a common ancestor column.
Parameters:
• column – the target ColumnElement to be matched.
• require_embedded – only return corresponding columns for the given ColumnElement, if the given ColumnElement is actually present within a sub-element of this Selectable. Normally the column will match if it merely shares a common ancestor with one of the exported columns of this Selectable.
See also
Selectable.corresponding_column() - invokes this method against the collection returned by Selectable.exported_columns.
Changed in version 1.4: the implementation for corresponding_column was moved onto the ColumnCollection itself.
method sqlalchemy.sql.expression.ColumnCollection.get(key: str, default: _COL | None = None) → _COL | _COL_co | None
Get a ColumnClause or Column object based on a string key name from this ColumnCollection.
method sqlalchemy.sql.expression.ColumnCollection.items() → List[Tuple[_COLKEY, _COL_co]]
Return a sequence of (key, column) tuples for all columns in this collection each consisting of a string key name and a ColumnClause or Column object.
method sqlalchemy.sql.expression.ColumnCollection.keys() → List[_COLKEY]
Return a sequence of string key names for all columns in this collection.
method sqlalchemy.sql.expression.ColumnCollection.update(iter_: Any) → NoReturn
Dictionary update() is not implemented for ColumnCollection.
method sqlalchemy.sql.expression.ColumnCollection.values() → List[_COL_co]
Return a sequence of ColumnClause or Column objects for all columns in this collection.
class sqlalchemy.sql.expression.ColumnElement
Represent a column-oriented SQL expression suitable for usage in the “columns” clause, WHERE clause etc. of a statement.
While the most familiar kind of ColumnElement is the Column object, ColumnElement serves as the basis for any unit that may be present in a SQL expression, including the expressions themselves, SQL functions, bound parameters, literal expressions, keywords such as NULL, etc. ColumnElement is the ultimate base class for all such elements.
A wide variety of SQLAlchemy Core functions work at the SQL expression level, and are intended to accept instances of ColumnElement as arguments. These functions will typically document that they accept a “SQL expression” as an argument. What this means in terms of SQLAlchemy usually refers to an input which is either already in the form of a ColumnElement object, or a value which can be coerced into one. The coercion rules followed by most, but not all, SQLAlchemy Core functions with regards to SQL expressions are as follows:
• a literal Python value, such as a string, integer or floating point value, boolean, datetime, Decimal object, or virtually any other Python object, will be coerced into a “literal bound value”. This generally means that a bindparam() will be produced featuring the given value embedded into the construct; the resulting BindParameter object is an instance of ColumnElement. The Python value will ultimately be sent to the DBAPI at execution time as a parameterized argument to the execute() or executemany() methods, after SQLAlchemy type-specific converters (e.g. those provided by any associated TypeEngine objects) are applied to the value.
• any special object value, typically ORM-level constructs, which feature an accessor called __clause_element__(). The Core expression system looks for this method when an object of otherwise unknown type is passed to a function that is looking to coerce the argument into a ColumnElement and sometimes a SelectBase expression. It is used within the ORM to convert from ORM-specific objects like mapped classes and mapped attributes into Core expression objects.
• The Python None value is typically interpreted as NULL, which in SQLAlchemy Core produces an instance of null().
A ColumnElement provides the ability to generate new ColumnElement objects using Python expressions. This means that Python operators such as ==, != and < are overloaded to mimic SQL operations, and allow the instantiation of further ColumnElement instances which are composed from other, more fundamental ColumnElement objects. For example, two ColumnClause objects can be added together with the addition operator + to produce a BinaryExpression. Both ColumnClause and BinaryExpression are subclasses of ColumnElement:
>>> from sqlalchemy.sql import column
>>> column("a") + column("b")
<sqlalchemy.sql.expression.BinaryExpression object at 0x101029dd0>
>>> print(column("a") + column("b"))
a + b
See also
Column
column()
Members
__eq__(), __le__(), __lt__(), __ne__(), all_(), allows_lambda, anon_key_label, anon_label, any_(), asc(), base_columns, between(), bitwise_and(), bitwise_lshift(), bitwise_not(), bitwise_or(), bitwise_rshift(), bitwise_xor(), bool_op(), cast(), collate(), comparator, compare(), compile(), concat(), contains(), desc(), description, distinct(), endswith(), entity_namespace, expression, foreign_keys, get_children(), icontains(), iendswith(), ilike(), in_(), inherit_cache, is_(), is_clause_element, is_distinct_from(), is_dml, is_not(), is_not_distinct_from(), is_selectable, isnot(), isnot_distinct_from(), istartswith(), key, label(), like(), match(), negation_clause, not_ilike(), not_in(), not_like(), notilike(), notin_(), notlike(), nulls_first(), nulls_last(), nullsfirst(), nullslast(), op(), operate(), params(), primary_key, proxy_set, regexp_match(), regexp_replace(), reverse_operate(), self_group(), shares_lineage(), startswith(), stringify_dialect, supports_execution, timetuple, type, unique_params(), uses_inspection
Class signature
class sqlalchemy.sql.expression.ColumnElement (sqlalchemy.sql.roles.ColumnArgumentOrKeyRole, sqlalchemy.sql.roles.StatementOptionRole, sqlalchemy.sql.roles.WhereHavingRole, sqlalchemy.sql.roles.BinaryElementRole, sqlalchemy.sql.roles.OrderByRole, sqlalchemy.sql.roles.ColumnsClauseRole, sqlalchemy.sql.roles.LimitOffsetRole, sqlalchemy.sql.roles.DMLColumnRole, sqlalchemy.sql.roles.DDLConstraintColumnRole, sqlalchemy.sql.roles.DDLExpressionRole, sqlalchemy.sql.expression.SQLColumnExpression, sqlalchemy.sql.expression.DQLDMLClauseElement)
method sqlalchemy.sql.expression.ColumnElement.__eq__(other: Any) → ColumnOperators
inherited from the sqlalchemy.sql.expression.ColumnOperators.__eq__ method of ColumnOperators
Implement the == operator.
In a column context, produces the clause a = b. If the target is None, produces a IS NULL.
method sqlalchemy.sql.expression.ColumnElement.__le__(other: Any) → ColumnOperators
inherited from the sqlalchemy.sql.expression.ColumnOperators.__le__ method of ColumnOperators
Implement the <= operator.
In a column context, produces the clause a <= b.
method sqlalchemy.sql.expression.ColumnElement.__lt__(other: Any) → ColumnOperators
inherited from the sqlalchemy.sql.expression.ColumnOperators.__lt__ method of ColumnOperators
Implement the < operator.
In a column context, produces the clause a < b.
method sqlalchemy.sql.expression.ColumnElement.__ne__(other: Any) → ColumnOperators
inherited from the sqlalchemy.sql.expression.ColumnOperators.__ne__ method of ColumnOperators
Implement the != operator.
In a column context, produces the clause a != b. If the target is None, produces a IS NOT NULL.
method sqlalchemy.sql.expression.ColumnElement.all_() → ColumnOperators
inherited from the ColumnOperators.all_() method of ColumnOperators
Produce an all_() clause against the parent object.
See the documentation for all_() for examples.
Note
be sure to not confuse the newer ColumnOperators.all_() method with the legacy version of this method, the Comparator.all() method that’s specific to ARRAY, which uses a different calling style.
attribute sqlalchemy.sql.expression.ColumnElement.allows_lambda = True
attribute sqlalchemy.sql.expression.ColumnElement.anon_key_label
Deprecated since version 1.4: The ColumnElement.anon_key_label attribute is now private, and the public accessor is deprecated.
attribute sqlalchemy.sql.expression.ColumnElement.anon_label
Deprecated since version 1.4: The ColumnElement.anon_label attribute is now private, and the public accessor is deprecated.
method sqlalchemy.sql.expression.ColumnElement.any_() → ColumnOperators
inherited from the ColumnOperators.any_() method of ColumnOperators
Produce an any_() clause against the parent object.
See the documentation for any_() for examples.
Note
be sure to not confuse the newer ColumnOperators.any_() method with the legacy version of this method, the Comparator.any() method that’s specific to ARRAY, which uses a different calling style.
method sqlalchemy.sql.expression.ColumnElement.asc() → ColumnOperators
inherited from the ColumnOperators.asc() method of ColumnOperators
Produce a asc() clause against the parent object.
attribute sqlalchemy.sql.expression.ColumnElement.base_columns
method sqlalchemy.sql.expression.ColumnElement.between(cleft: Any, cright: Any, symmetric: bool = False) → ColumnOperators
inherited from the ColumnOperators.between() method of ColumnOperators
Produce a between() clause against the parent object, given the lower and upper range.
method sqlalchemy.sql.expression.ColumnElement.bitwise_and(other: Any) → ColumnOperators
inherited from the ColumnOperators.bitwise_and() method of ColumnOperators
Produce a bitwise AND operation, typically via the & operator.
Added in version 2.0.2.
See also
Bitwise Operators
method sqlalchemy.sql.expression.ColumnElement.bitwise_lshift(other: Any) → ColumnOperators
inherited from the ColumnOperators.bitwise_lshift() method of ColumnOperators
Produce a bitwise LSHIFT operation, typically via the << operator.
Added in version 2.0.2.
See also
Bitwise Operators
method sqlalchemy.sql.expression.ColumnElement.bitwise_not() → ColumnOperators
inherited from the ColumnOperators.bitwise_not() method of ColumnOperators
Produce a bitwise NOT operation, typically via the ~ operator.
Added in version 2.0.2.
See also
Bitwise Operators
method sqlalchemy.sql.expression.ColumnElement.bitwise_or(other: Any) → ColumnOperators
inherited from the ColumnOperators.bitwise_or() method of ColumnOperators
Produce a bitwise OR operation, typically via the | operator.
Added in version 2.0.2.
See also
Bitwise Operators
method sqlalchemy.sql.expression.ColumnElement.bitwise_rshift(other: Any) → ColumnOperators
inherited from the ColumnOperators.bitwise_rshift() method of ColumnOperators
Produce a bitwise RSHIFT operation, typically via the >> operator.
Added in version 2.0.2.
See also
Bitwise Operators
method sqlalchemy.sql.expression.ColumnElement.bitwise_xor(other: Any) → ColumnOperators
inherited from the ColumnOperators.bitwise_xor() method of ColumnOperators
Produce a bitwise XOR operation, typically via the ^ operator, or # for PostgreSQL.
Added in version 2.0.2.
See also
Bitwise Operators
method sqlalchemy.sql.expression.ColumnElement.bool_op(opstring: str, precedence: int = 0, python_impl: Callable[[...], Any] | None = None) → Callable[[Any], Operators]
inherited from the Operators.bool_op() method of Operators
Return a custom boolean operator.
This method is shorthand for calling Operators.op() and passing the Operators.op.is_comparison flag with True. A key advantage to using Operators.bool_op() is that when using column constructs, the “boolean” nature of the returned expression will be present for PEP 484 purposes.
See also
Operators.op()
method sqlalchemy.sql.expression.ColumnElement.cast(type_: _TypeEngineArgument[_OPT]) → Cast[_OPT]
Produce a type cast, i.e. CAST(<expression> AS <type>).
This is a shortcut to the cast() function.
See also
Data Casts and Type Coercion
cast()
type_coerce()
method sqlalchemy.sql.expression.ColumnElement.collate(collation: str) → ColumnOperators
inherited from the ColumnOperators.collate() method of ColumnOperators
Produce a collate() clause against the parent object, given the collation string.
See also
collate()
attribute sqlalchemy.sql.expression.ColumnElement.comparator
method sqlalchemy.sql.expression.ColumnElement.compare(other: ClauseElement, **kw: Any) → bool
inherited from the ClauseElement.compare() method of ClauseElement
Compare this ClauseElement to the given ClauseElement.
Subclasses should override the default behavior, which is a straight identity comparison.
**kw are arguments consumed by subclass compare() methods and may be used to modify the criteria for comparison (see ColumnElement).
method sqlalchemy.sql.expression.ColumnElement.compile(bind: _HasDialect | None = None, dialect: Dialect | None = None, **kw: Any) → Compiled
inherited from the CompilerElement.compile() method of CompilerElement
Compile this SQL expression.
The return value is a Compiled object. Calling str() or unicode() on the returned value will yield a string representation of the result. The Compiled object also can return a dictionary of bind parameter names and values using the params accessor.
Parameters:
• bind – An Connection or Engine which can provide a Dialect in order to generate a Compiled object. If the bind and dialect parameters are both omitted, a default SQL compiler is used.
• column_keys – Used for INSERT and UPDATE statements, a list of column names which should be present in the VALUES clause of the compiled statement. If None, all columns from the target table object are rendered.
• dialect – A Dialect instance which can generate a Compiled object. This argument takes precedence over the bind argument.
• compile_kwargs – 
optional dictionary of additional parameters that will be passed through to the compiler within all “visit” methods. This allows any custom flag to be passed through to a custom compilation construct, for example. It is also used for the case of passing the literal_binds flag through:
from sqlalchemy.sql import table, column, select

t = table("t", column("x"))

s = select(t).where(t.c.x == 5)

print(s.compile(compile_kwargs={"literal_binds": True}))
• 
See also
How do I render SQL expressions as strings, possibly with bound parameters inlined?
method sqlalchemy.sql.expression.ColumnElement.concat(other: Any) → ColumnOperators
inherited from the ColumnOperators.concat() method of ColumnOperators
Implement the ‘concat’ operator.
In a column context, produces the clause a || b, or uses the concat() operator on MySQL.
method sqlalchemy.sql.expression.ColumnElement.contains(other: Any, **kw: Any) → ColumnOperators
inherited from the ColumnOperators.contains() method of ColumnOperators
Implement the ‘contains’ operator.
Produces a LIKE expression that tests against a match for the middle of a string value:
column LIKE '%' || <other> || '%'
E.g.:
stmt = select(sometable).where(sometable.c.column.contains("foobar"))
Since the operator uses LIKE, wildcard characters "%" and "_" that are present inside the <other> expression will behave like wildcards as well. For literal string values, the ColumnOperators.contains.autoescape flag may be set to True to apply escaping to occurrences of these characters within the string value so that they match as themselves and not as wildcard characters. Alternatively, the ColumnOperators.contains.escape parameter will establish a given character as an escape character which can be of use when the target expression is not a literal string.
Parameters:
• other – expression to be compared. This is usually a plain string value, but can also be an arbitrary SQL expression. LIKE wildcard characters % and _ are not escaped by default unless the ColumnOperators.contains.autoescape flag is set to True.
• autoescape – 
boolean; when True, establishes an escape character within the LIKE expression, then applies it to all occurrences of "%", "_" and the escape character itself within the comparison value, which is assumed to be a literal string and not a SQL expression.
An expression such as:
somecolumn.contains("foo%bar", autoescape=True)
Will render as:
somecolumn LIKE '%' || :param || '%' ESCAPE '/'
•  With the value of :param as "foo/%bar".
•  escape – 
a character which when given will render with the ESCAPE keyword to establish that character as the escape character. This character can then be placed preceding occurrences of % and _ to allow them to act as themselves and not wildcard characters.
An expression such as:
somecolumn.contains("foo/%bar", escape="^")
Will render as:
somecolumn LIKE '%' || :param || '%' ESCAPE '^'
The parameter may also be combined with ColumnOperators.contains.autoescape:
somecolumn.contains("foo%bar^bat", escape="^", autoescape=True)
• Where above, the given literal parameter will be converted to "foo^%bar^^bat" before being passed to the database.
See also
ColumnOperators.startswith()
ColumnOperators.endswith()
ColumnOperators.like()
method sqlalchemy.sql.expression.ColumnElement.desc() → ColumnOperators
inherited from the ColumnOperators.desc() method of ColumnOperators
Produce a desc() clause against the parent object.
attribute sqlalchemy.sql.expression.ColumnElement.description
inherited from the ClauseElement.description attribute of ClauseElement
method sqlalchemy.sql.expression.ColumnElement.distinct() → ColumnOperators
inherited from the ColumnOperators.distinct() method of ColumnOperators
Produce a distinct() clause against the parent object.
method sqlalchemy.sql.expression.ColumnElement.endswith(other: Any, escape: str | None = None, autoescape: bool = False) → ColumnOperators
inherited from the ColumnOperators.endswith() method of ColumnOperators
Implement the ‘endswith’ operator.
Produces a LIKE expression that tests against a match for the end of a string value:
column LIKE '%' || <other>
E.g.:
stmt = select(sometable).where(sometable.c.column.endswith("foobar"))
Since the operator uses LIKE, wildcard characters "%" and "_" that are present inside the <other> expression will behave like wildcards as well. For literal string values, the ColumnOperators.endswith.autoescape flag may be set to True to apply escaping to occurrences of these characters within the string value so that they match as themselves and not as wildcard characters. Alternatively, the ColumnOperators.endswith.escape parameter will establish a given character as an escape character which can be of use when the target expression is not a literal string.
Parameters:
• other – expression to be compared. This is usually a plain string value, but can also be an arbitrary SQL expression. LIKE wildcard characters % and _ are not escaped by default unless the ColumnOperators.endswith.autoescape flag is set to True.
• autoescape – 
boolean; when True, establishes an escape character within the LIKE expression, then applies it to all occurrences of "%", "_" and the escape character itself within the comparison value, which is assumed to be a literal string and not a SQL expression.
An expression such as:
somecolumn.endswith("foo%bar", autoescape=True)
Will render as:
somecolumn LIKE '%' || :param ESCAPE '/'
•  With the value of :param as "foo/%bar".
•  escape – 
a character which when given will render with the ESCAPE keyword to establish that character as the escape character. This character can then be placed preceding occurrences of % and _ to allow them to act as themselves and not wildcard characters.
An expression such as:
somecolumn.endswith("foo/%bar", escape="^")
Will render as:
somecolumn LIKE '%' || :param ESCAPE '^'
The parameter may also be combined with ColumnOperators.endswith.autoescape:
somecolumn.endswith("foo%bar^bat", escape="^", autoescape=True)
• Where above, the given literal parameter will be converted to "foo^%bar^^bat" before being passed to the database.
See also
ColumnOperators.startswith()
ColumnOperators.contains()
ColumnOperators.like()
attribute sqlalchemy.sql.expression.ColumnElement.entity_namespace
inherited from the ClauseElement.entity_namespace attribute of ClauseElement
attribute sqlalchemy.sql.expression.ColumnElement.expression
Return a column expression.
Part of the inspection interface; returns self.
attribute sqlalchemy.sql.expression.ColumnElement.foreign_keys: AbstractSet[ForeignKey] = frozenset({})
method sqlalchemy.sql.expression.ColumnElement.get_children(*, omit_attrs: Tuple[str, ...] = (), **kw: Any) → Iterable[HasTraverseInternals]
inherited from the HasTraverseInternals.get_children() method of HasTraverseInternals
Return immediate child HasTraverseInternals elements of this HasTraverseInternals.
This is used for visit traversal.
**kw may contain flags that change the collection that is returned, for example to return a subset of items in order to cut down on larger traversals, or to return child items from a different context (such as schema-level collections instead of clause-level).
method sqlalchemy.sql.expression.ColumnElement.icontains(other: Any, **kw: Any) → ColumnOperators
inherited from the ColumnOperators.icontains() method of ColumnOperators
Implement the icontains operator, e.g. case insensitive version of ColumnOperators.contains().
Produces a LIKE expression that tests against an insensitive match for the middle of a string value:
lower(column) LIKE '%' || lower(<other>) || '%'
E.g.:
stmt = select(sometable).where(sometable.c.column.icontains("foobar"))
Since the operator uses LIKE, wildcard characters "%" and "_" that are present inside the <other> expression will behave like wildcards as well. For literal string values, the ColumnOperators.icontains.autoescape flag may be set to True to apply escaping to occurrences of these characters within the string value so that they match as themselves and not as wildcard characters. Alternatively, the ColumnOperators.icontains.escape parameter will establish a given character as an escape character which can be of use when the target expression is not a literal string.
Parameters:
• other – expression to be compared. This is usually a plain string value, but can also be an arbitrary SQL expression. LIKE wildcard characters % and _ are not escaped by default unless the ColumnOperators.icontains.autoescape flag is set to True.
• autoescape – 
boolean; when True, establishes an escape character within the LIKE expression, then applies it to all occurrences of "%", "_" and the escape character itself within the comparison value, which is assumed to be a literal string and not a SQL expression.
An expression such as:
somecolumn.icontains("foo%bar", autoescape=True)
Will render as:
lower(somecolumn) LIKE '%' || lower(:param) || '%' ESCAPE '/'
•  With the value of :param as "foo/%bar".
•  escape – 
a character which when given will render with the ESCAPE keyword to establish that character as the escape character. This character can then be placed preceding occurrences of % and _ to allow them to act as themselves and not wildcard characters.
An expression such as:
somecolumn.icontains("foo/%bar", escape="^")
Will render as:
lower(somecolumn) LIKE '%' || lower(:param) || '%' ESCAPE '^'
The parameter may also be combined with ColumnOperators.contains.autoescape:
somecolumn.icontains("foo%bar^bat", escape="^", autoescape=True)
• Where above, the given literal parameter will be converted to "foo^%bar^^bat" before being passed to the database.
See also
ColumnOperators.contains()
method sqlalchemy.sql.expression.ColumnElement.iendswith(other: Any, escape: str | None = None, autoescape: bool = False) → ColumnOperators
inherited from the ColumnOperators.iendswith() method of ColumnOperators
Implement the iendswith operator, e.g. case insensitive version of ColumnOperators.endswith().
Produces a LIKE expression that tests against an insensitive match for the end of a string value:
lower(column) LIKE '%' || lower(<other>)
E.g.:
stmt = select(sometable).where(sometable.c.column.iendswith("foobar"))
Since the operator uses LIKE, wildcard characters "%" and "_" that are present inside the <other> expression will behave like wildcards as well. For literal string values, the ColumnOperators.iendswith.autoescape flag may be set to True to apply escaping to occurrences of these characters within the string value so that they match as themselves and not as wildcard characters. Alternatively, the ColumnOperators.iendswith.escape parameter will establish a given character as an escape character which can be of use when the target expression is not a literal string.
Parameters:
• other – expression to be compared. This is usually a plain string value, but can also be an arbitrary SQL expression. LIKE wildcard characters % and _ are not escaped by default unless the ColumnOperators.iendswith.autoescape flag is set to True.
• autoescape – 
boolean; when True, establishes an escape character within the LIKE expression, then applies it to all occurrences of "%", "_" and the escape character itself within the comparison value, which is assumed to be a literal string and not a SQL expression.
An expression such as:
somecolumn.iendswith("foo%bar", autoescape=True)
Will render as:
lower(somecolumn) LIKE '%' || lower(:param) ESCAPE '/'
•  With the value of :param as "foo/%bar".
•  escape – 
a character which when given will render with the ESCAPE keyword to establish that character as the escape character. This character can then be placed preceding occurrences of % and _ to allow them to act as themselves and not wildcard characters.
An expression such as:
somecolumn.iendswith("foo/%bar", escape="^")
Will render as:
lower(somecolumn) LIKE '%' || lower(:param) ESCAPE '^'
The parameter may also be combined with ColumnOperators.iendswith.autoescape:
somecolumn.endswith("foo%bar^bat", escape="^", autoescape=True)
• Where above, the given literal parameter will be converted to "foo^%bar^^bat" before being passed to the database.
See also
ColumnOperators.endswith()
method sqlalchemy.sql.expression.ColumnElement.ilike(other: Any, escape: str | None = None) → ColumnOperators
inherited from the ColumnOperators.ilike() method of ColumnOperators
Implement the ilike operator, e.g. case insensitive LIKE.
In a column context, produces an expression either of the form:
lower(a) LIKE lower(other)
Or on backends that support the ILIKE operator:
a ILIKE other
E.g.:
stmt = select(sometable).where(sometable.c.column.ilike("%foobar%"))
Parameters:
• other – expression to be compared
• escape – 
optional escape character, renders the ESCAPE keyword, e.g.:
somecolumn.ilike("foo/%bar", escape="/")
• 
See also
ColumnOperators.like()
method sqlalchemy.sql.expression.ColumnElement.in_(other: Any) → ColumnOperators
inherited from the ColumnOperators.in_() method of ColumnOperators
Implement the in operator.
In a column context, produces the clause column IN <other>.
The given parameter other may be:
• A list of literal values, e.g.:
stmt.where(column.in_([1, 2, 3]))
In this calling form, the list of items is converted to a set of bound parameters the same length as the list given:
WHERE COL IN (?, ?, ?)
A list of tuples may be provided if the comparison is against a tuple_() containing multiple expressions:
from sqlalchemy import tuple_

stmt.where(tuple_(col1, col2).in_([(1, 10), (2, 20), (3, 30)]))
An empty list, e.g.:
stmt.where(column.in_([]))
In this calling form, the expression renders an “empty set” expression. These expressions are tailored to individual backends and are generally trying to get an empty SELECT statement as a subquery. Such as on SQLite, the expression is:
WHERE col IN (SELECT 1 FROM (SELECT 1) WHERE 1!=1)
•  Changed in version 1.4: empty IN expressions now use an execution-time generated SELECT subquery in all cases.
•  A bound parameter, e.g. bindparam(), may be used if it includes the bindparam.expanding flag:
stmt.where(column.in_(bindparam("value", expanding=True)))
In this calling form, the expression renders a special non-SQL placeholder expression that looks like:
WHERE COL IN ([EXPANDING_value])
This placeholder expression is intercepted at statement execution time to be converted into the variable number of bound parameter form illustrated earlier. If the statement were executed as:
connection.execute(stmt, {"value": [1, 2, 3]})
The database would be passed a bound parameter for each value:
WHERE COL IN (?, ?, ?)
Added in version 1.2: added “expanding” bound parameters
If an empty list is passed, a special “empty list” expression, which is specific to the database in use, is rendered. On SQLite this would be:
WHERE COL IN (SELECT 1 FROM (SELECT 1) WHERE 1!=1)
•  Added in version 1.3: “expanding” bound parameters now support empty lists
•  a select() construct, which is usually a correlated scalar select:
stmt.where(
    column.in_(select(othertable.c.y).where(table.c.x == othertable.c.x))
)
In this calling form, ColumnOperators.in_() renders as given:
WHERE COL IN (SELECT othertable.y
FROM othertable WHERE othertable.x = table.x)
Parameters:
other – a list of literals, a select() construct, or a bindparam() construct that includes the bindparam.expanding flag set to True.
attribute sqlalchemy.sql.expression.ColumnElement.inherit_cache: bool | None = None
inherited from the HasCacheKey.inherit_cache attribute of HasCacheKey
Indicate if this HasCacheKey instance should make use of the cache key generation scheme used by its immediate superclass.
The attribute defaults to None, which indicates that a construct has not yet taken into account whether or not its appropriate for it to participate in caching; this is functionally equivalent to setting the value to False, except that a warning is also emitted.
This flag can be set to True on a particular class, if the SQL that corresponds to the object does not change based on attributes which are local to this class, and not its superclass.
See also
Enabling Caching Support for Custom Constructs - General guideslines for setting the HasCacheKey.inherit_cache attribute for third-party or user defined SQL constructs.
method sqlalchemy.sql.expression.ColumnElement.is_(other: Any) → ColumnOperators
inherited from the ColumnOperators.is_() method of ColumnOperators
Implement the IS operator.
Normally, IS is generated automatically when comparing to a value of None, which resolves to NULL. However, explicit usage of IS may be desirable if comparing to boolean values on certain platforms.
See also
ColumnOperators.is_not()
attribute sqlalchemy.sql.expression.ColumnElement.is_clause_element = True
method sqlalchemy.sql.expression.ColumnElement.is_distinct_from(other: Any) → ColumnOperators
inherited from the ColumnOperators.is_distinct_from() method of ColumnOperators
Implement the IS DISTINCT FROM operator.
Renders “a IS DISTINCT FROM b” on most platforms; on some such as SQLite may render “a IS NOT b”.
attribute sqlalchemy.sql.expression.ColumnElement.is_dml = False
method sqlalchemy.sql.expression.ColumnElement.is_not(other: Any) → ColumnOperators
inherited from the ColumnOperators.is_not() method of ColumnOperators
Implement the IS NOT operator.
Normally, IS NOT is generated automatically when comparing to a value of None, which resolves to NULL. However, explicit usage of IS NOT may be desirable if comparing to boolean values on certain platforms.
Changed in version 1.4: The is_not() operator is renamed from isnot() in previous releases. The previous name remains available for backwards compatibility.
See also
ColumnOperators.is_()
method sqlalchemy.sql.expression.ColumnElement.is_not_distinct_from(other: Any) → ColumnOperators
inherited from the ColumnOperators.is_not_distinct_from() method of ColumnOperators
Implement the IS NOT DISTINCT FROM operator.
Renders “a IS NOT DISTINCT FROM b” on most platforms; on some such as SQLite may render “a IS b”.
Changed in version 1.4: The is_not_distinct_from() operator is renamed from isnot_distinct_from() in previous releases. The previous name remains available for backwards compatibility.
attribute sqlalchemy.sql.expression.ColumnElement.is_selectable = False
method sqlalchemy.sql.expression.ColumnElement.isnot(other: Any) → ColumnOperators
inherited from the ColumnOperators.isnot() method of ColumnOperators
Implement the IS NOT operator.
Normally, IS NOT is generated automatically when comparing to a value of None, which resolves to NULL. However, explicit usage of IS NOT may be desirable if comparing to boolean values on certain platforms.
Changed in version 1.4: The is_not() operator is renamed from isnot() in previous releases. The previous name remains available for backwards compatibility.
See also
ColumnOperators.is_()
method sqlalchemy.sql.expression.ColumnElement.isnot_distinct_from(other: Any) → ColumnOperators
inherited from the ColumnOperators.isnot_distinct_from() method of ColumnOperators
Implement the IS NOT DISTINCT FROM operator.
Renders “a IS NOT DISTINCT FROM b” on most platforms; on some such as SQLite may render “a IS b”.
Changed in version 1.4: The is_not_distinct_from() operator is renamed from isnot_distinct_from() in previous releases. The previous name remains available for backwards compatibility.
method sqlalchemy.sql.expression.ColumnElement.istartswith(other: Any, escape: str | None = None, autoescape: bool = False) → ColumnOperators
inherited from the ColumnOperators.istartswith() method of ColumnOperators
Implement the istartswith operator, e.g. case insensitive version of ColumnOperators.startswith().
Produces a LIKE expression that tests against an insensitive match for the start of a string value:
lower(column) LIKE lower(<other>) || '%'
E.g.:
stmt = select(sometable).where(sometable.c.column.istartswith("foobar"))
Since the operator uses LIKE, wildcard characters "%" and "_" that are present inside the <other> expression will behave like wildcards as well. For literal string values, the ColumnOperators.istartswith.autoescape flag may be set to True to apply escaping to occurrences of these characters within the string value so that they match as themselves and not as wildcard characters. Alternatively, the ColumnOperators.istartswith.escape parameter will establish a given character as an escape character which can be of use when the target expression is not a literal string.
Parameters:
• other – expression to be compared. This is usually a plain string value, but can also be an arbitrary SQL expression. LIKE wildcard characters % and _ are not escaped by default unless the ColumnOperators.istartswith.autoescape flag is set to True.
• autoescape – 
boolean; when True, establishes an escape character within the LIKE expression, then applies it to all occurrences of "%", "_" and the escape character itself within the comparison value, which is assumed to be a literal string and not a SQL expression.
An expression such as:
somecolumn.istartswith("foo%bar", autoescape=True)
Will render as:
lower(somecolumn) LIKE lower(:param) || '%' ESCAPE '/'
•  With the value of :param as "foo/%bar".
•  escape – 
a character which when given will render with the ESCAPE keyword to establish that character as the escape character. This character can then be placed preceding occurrences of % and _ to allow them to act as themselves and not wildcard characters.
An expression such as:
somecolumn.istartswith("foo/%bar", escape="^")
Will render as:
lower(somecolumn) LIKE lower(:param) || '%' ESCAPE '^'
The parameter may also be combined with ColumnOperators.istartswith.autoescape:
somecolumn.istartswith("foo%bar^bat", escape="^", autoescape=True)
• Where above, the given literal parameter will be converted to "foo^%bar^^bat" before being passed to the database.
See also
ColumnOperators.startswith()
attribute sqlalchemy.sql.expression.ColumnElement.key: str | None = None
The ‘key’ that in some circumstances refers to this object in a Python namespace.
This typically refers to the “key” of the column as present in the .c collection of a selectable, e.g. sometable.c["somekey"] would return a Column with a .key of “somekey”.
method sqlalchemy.sql.expression.ColumnElement.label(name: str | None) → Label[_T]
Produce a column label, i.e. <columnname> AS <name>.
This is a shortcut to the label() function.
If ‘name’ is None, an anonymous label name will be generated.
method sqlalchemy.sql.expression.ColumnElement.like(other: Any, escape: str | None = None) → ColumnOperators
inherited from the ColumnOperators.like() method of ColumnOperators
Implement the like operator.
In a column context, produces the expression:
a LIKE other
E.g.:
stmt = select(sometable).where(sometable.c.column.like("%foobar%"))
Parameters:
• other – expression to be compared
• escape – 
optional escape character, renders the ESCAPE keyword, e.g.:
somecolumn.like("foo/%bar", escape="/")
• 
See also
ColumnOperators.ilike()
method sqlalchemy.sql.expression.ColumnElement.match(other: Any, **kwargs: Any) → ColumnOperators
inherited from the ColumnOperators.match() method of ColumnOperators
Implements a database-specific ‘match’ operator.
ColumnOperators.match() attempts to resolve to a MATCH-like function or operator provided by the backend. Examples include:
• PostgreSQL - renders x @@ plainto_tsquery(y)
Changed in version 2.0: plainto_tsquery() is used instead of to_tsquery() for PostgreSQL now; for compatibility with other forms, see Full Text Search.
• MySQL - renders MATCH (x) AGAINST (y IN BOOLEAN MODE)
See also
match - MySQL specific construct with additional features.
• Oracle Database - renders CONTAINS(x, y)
• other backends may provide special implementations.
• Backends without any special implementation will emit the operator as “MATCH”. This is compatible with SQLite, for example.
attribute sqlalchemy.sql.expression.ColumnElement.negation_clause: ColumnElement[bool]
method sqlalchemy.sql.expression.ColumnElement.not_ilike(other: Any, escape: str | None = None) → ColumnOperators
inherited from the ColumnOperators.not_ilike() method of ColumnOperators
implement the NOT ILIKE operator.
This is equivalent to using negation with ColumnOperators.ilike(), i.e. ~x.ilike(y).
Changed in version 1.4: The not_ilike() operator is renamed from notilike() in previous releases. The previous name remains available for backwards compatibility.
See also
ColumnOperators.ilike()
method sqlalchemy.sql.expression.ColumnElement.not_in(other: Any) → ColumnOperators
inherited from the ColumnOperators.not_in() method of ColumnOperators
implement the NOT IN operator.
This is equivalent to using negation with ColumnOperators.in_(), i.e. ~x.in_(y).
In the case that other is an empty sequence, the compiler produces an “empty not in” expression. This defaults to the expression “1 = 1” to produce true in all cases. The create_engine.empty_in_strategy may be used to alter this behavior.
Changed in version 1.4: The not_in() operator is renamed from notin_() in previous releases. The previous name remains available for backwards compatibility.
Changed in version 1.2: The ColumnOperators.in_() and ColumnOperators.not_in() operators now produce a “static” expression for an empty IN sequence by default.
See also
ColumnOperators.in_()
method sqlalchemy.sql.expression.ColumnElement.not_like(other: Any, escape: str | None = None) → ColumnOperators
inherited from the ColumnOperators.not_like() method of ColumnOperators
implement the NOT LIKE operator.
This is equivalent to using negation with ColumnOperators.like(), i.e. ~x.like(y).
Changed in version 1.4: The not_like() operator is renamed from notlike() in previous releases. The previous name remains available for backwards compatibility.
See also
ColumnOperators.like()
method sqlalchemy.sql.expression.ColumnElement.notilike(other: Any, escape: str | None = None) → ColumnOperators
inherited from the ColumnOperators.notilike() method of ColumnOperators
implement the NOT ILIKE operator.
This is equivalent to using negation with ColumnOperators.ilike(), i.e. ~x.ilike(y).
Changed in version 1.4: The not_ilike() operator is renamed from notilike() in previous releases. The previous name remains available for backwards compatibility.
See also
ColumnOperators.ilike()
method sqlalchemy.sql.expression.ColumnElement.notin_(other: Any) → ColumnOperators
inherited from the ColumnOperators.notin_() method of ColumnOperators
implement the NOT IN operator.
This is equivalent to using negation with ColumnOperators.in_(), i.e. ~x.in_(y).
In the case that other is an empty sequence, the compiler produces an “empty not in” expression. This defaults to the expression “1 = 1” to produce true in all cases. The create_engine.empty_in_strategy may be used to alter this behavior.
Changed in version 1.4: The not_in() operator is renamed from notin_() in previous releases. The previous name remains available for backwards compatibility.
Changed in version 1.2: The ColumnOperators.in_() and ColumnOperators.not_in() operators now produce a “static” expression for an empty IN sequence by default.
See also
ColumnOperators.in_()
method sqlalchemy.sql.expression.ColumnElement.notlike(other: Any, escape: str | None = None) → ColumnOperators
inherited from the ColumnOperators.notlike() method of ColumnOperators
implement the NOT LIKE operator.
This is equivalent to using negation with ColumnOperators.like(), i.e. ~x.like(y).
Changed in version 1.4: The not_like() operator is renamed from notlike() in previous releases. The previous name remains available for backwards compatibility.
See also
ColumnOperators.like()
method sqlalchemy.sql.expression.ColumnElement.nulls_first() → ColumnOperators
inherited from the ColumnOperators.nulls_first() method of ColumnOperators
Produce a nulls_first() clause against the parent object.
Changed in version 1.4: The nulls_first() operator is renamed from nullsfirst() in previous releases. The previous name remains available for backwards compatibility.
method sqlalchemy.sql.expression.ColumnElement.nulls_last() → ColumnOperators
inherited from the ColumnOperators.nulls_last() method of ColumnOperators
Produce a nulls_last() clause against the parent object.
Changed in version 1.4: The nulls_last() operator is renamed from nullslast() in previous releases. The previous name remains available for backwards compatibility.
method sqlalchemy.sql.expression.ColumnElement.nullsfirst() → ColumnOperators
inherited from the ColumnOperators.nullsfirst() method of ColumnOperators
Produce a nulls_first() clause against the parent object.
Changed in version 1.4: The nulls_first() operator is renamed from nullsfirst() in previous releases. The previous name remains available for backwards compatibility.
method sqlalchemy.sql.expression.ColumnElement.nullslast() → ColumnOperators
inherited from the ColumnOperators.nullslast() method of ColumnOperators
Produce a nulls_last() clause against the parent object.
Changed in version 1.4: The nulls_last() operator is renamed from nullslast() in previous releases. The previous name remains available for backwards compatibility.
method sqlalchemy.sql.expression.ColumnElement.op(opstring: str, precedence: int = 0, is_comparison: bool = False, return_type: Type[TypeEngine[Any]] | TypeEngine[Any] | None = None, python_impl: Callable[..., Any] | None = None) → Callable[[Any], Operators]
inherited from the Operators.op() method of Operators
Produce a generic operator function.
e.g.:
somecolumn.op("*")(5)
produces:
somecolumn * 5
This function can also be used to make bitwise operators explicit. For example:
somecolumn.op("&")(0xFF)
is a bitwise AND of the value in somecolumn.
Parameters:
• opstring – a string which will be output as the infix operator between this element and the expression passed to the generated function.
• precedence – 
precedence which the database is expected to apply to the operator in SQL expressions. This integer value acts as a hint for the SQL compiler to know when explicit parenthesis should be rendered around a particular operation. A lower number will cause the expression to be parenthesized when applied against another operator with higher precedence. The default value of 0 is lower than all operators except for the comma (,) and AS operators. A value of 100 will be higher or equal to all operators, and -100 will be lower than or equal to all operators.
See also
I’m using op() to generate a custom operator and my parenthesis are not coming out correctly - detailed description of how the SQLAlchemy SQL compiler renders parenthesis
• is_comparison – 
legacy; if True, the operator will be considered as a “comparison” operator, that is which evaluates to a boolean true/false value, like ==, >, etc. This flag is provided so that ORM relationships can establish that the operator is a comparison operator when used in a custom join condition.
Using the is_comparison parameter is superseded by using the Operators.bool_op() method instead; this more succinct operator sets this parameter automatically, but also provides correct PEP 484 typing support as the returned object will express a “boolean” datatype, i.e. BinaryExpression[bool].
• return_type – a TypeEngine class or object that will force the return type of an expression produced by this operator to be of that type. By default, operators that specify Operators.op.is_comparison will resolve to Boolean, and those that do not will be of the same type as the left-hand operand.
• python_impl – 
an optional Python function that can evaluate two Python values in the same way as this operator works when run on the database server. Useful for in-Python SQL expression evaluation functions, such as for ORM hybrid attributes, and the ORM “evaluator” used to match objects in a session after a multi-row update or delete.
e.g.:
>>> expr = column("x").op("+", python_impl=lambda a, b: a + b)("y")
The operator for the above expression will also work for non-SQL left and right objects:
>>> expr.operator(5, 10)
15
• Added in version 2.0.
See also
Operators.bool_op()
Redefining and Creating New Operators
Using custom operators in join conditions
method sqlalchemy.sql.expression.ColumnElement.operate(op: OperatorType, *other: Any, **kwargs: Any) → ColumnElement[Any]
Operate on an argument.
This is the lowest level of operation, raises NotImplementedError by default.
Overriding this on a subclass can allow common behavior to be applied to all operations. For example, overriding ColumnOperators to apply func.lower() to the left and right side:
class MyComparator(ColumnOperators):
    def operate(self, op, other, **kwargs):
        return op(func.lower(self), func.lower(other), **kwargs)
Parameters:
• op – Operator callable.
• *other – the ‘other’ side of the operation. Will be a single scalar for most operations.
• **kwargs – modifiers. These may be passed by special operators such as ColumnOperators.contains().
method sqlalchemy.sql.expression.ColumnElement.params(_ClauseElement__optionaldict: Mapping[str, Any] | None = None, **kwargs: Any) → Self
inherited from the ClauseElement.params() method of ClauseElement
Return a copy with bindparam() elements replaced.
Returns a copy of this ClauseElement with bindparam() elements replaced with values taken from the given dictionary:
>>> clause = column("x") + bindparam("foo")
>>> print(clause.compile().params)
{'foo':None}
>>> print(clause.params({"foo": 7}).compile().params)
{'foo':7}
attribute sqlalchemy.sql.expression.ColumnElement.primary_key: bool = False
attribute sqlalchemy.sql.expression.ColumnElement.proxy_set: util.generic_fn_descriptor[FrozenSet[Any]]
set of all columns we are proxying
as of 2.0 this is explicitly deannotated columns. previously it was effectively deannotated columns but wasn’t enforced. annotated columns should basically not go into sets if at all possible because their hashing behavior is very non-performant.
method sqlalchemy.sql.expression.ColumnElement.regexp_match(pattern: Any, flags: str | None = None) → ColumnOperators
inherited from the ColumnOperators.regexp_match() method of ColumnOperators
Implements a database-specific ‘regexp match’ operator.
E.g.:
stmt = select(table.c.some_column).where(
    table.c.some_column.regexp_match("^(b|c)")
)
ColumnOperators.regexp_match() attempts to resolve to a REGEXP-like function or operator provided by the backend, however the specific regular expression syntax and flags available are not backend agnostic.
Examples include:
• PostgreSQL - renders x ~ y or x !~ y when negated.
• Oracle Database - renders REGEXP_LIKE(x, y)
• SQLite - uses SQLite’s REGEXP placeholder operator and calls into the Python re.match() builtin.
• other backends may provide special implementations.
• Backends without any special implementation will emit the operator as “REGEXP” or “NOT REGEXP”. This is compatible with SQLite and MySQL, for example.
Regular expression support is currently implemented for Oracle Database, PostgreSQL, MySQL and MariaDB. Partial support is available for SQLite. Support among third-party dialects may vary.
Parameters:
• pattern – The regular expression pattern string or column clause.
• flags – Any regular expression string flags to apply, passed as plain Python string only. These flags are backend specific. Some backends, like PostgreSQL and MariaDB, may alternatively specify the flags as part of the pattern. When using the ignore case flag ‘i’ in PostgreSQL, the ignore case regexp match operator ~* or !~* will be used.
Added in version 1.4.
Changed in version 1.4.48,: 2.0.18 Note that due to an implementation error, the “flags” parameter previously accepted SQL expression objects such as column expressions in addition to plain Python strings. This implementation did not work correctly with caching and was removed; strings only should be passed for the “flags” parameter, as these flags are rendered as literal inline values within SQL expressions.
See also
ColumnOperators.regexp_replace()
method sqlalchemy.sql.expression.ColumnElement.regexp_replace(pattern: Any, replacement: Any, flags: str | None = None) → ColumnOperators
inherited from the ColumnOperators.regexp_replace() method of ColumnOperators
Implements a database-specific ‘regexp replace’ operator.
E.g.:
stmt = select(
    table.c.some_column.regexp_replace("b(..)", "XY", flags="g")
)
ColumnOperators.regexp_replace() attempts to resolve to a REGEXP_REPLACE-like function provided by the backend, that usually emit the function REGEXP_REPLACE(). However, the specific regular expression syntax and flags available are not backend agnostic.
Regular expression replacement support is currently implemented for Oracle Database, PostgreSQL, MySQL 8 or greater and MariaDB. Support among third-party dialects may vary.
Parameters:
• pattern – The regular expression pattern string or column clause.
• pattern – The replacement string or column clause.
• flags – Any regular expression string flags to apply, passed as plain Python string only. These flags are backend specific. Some backends, like PostgreSQL and MariaDB, may alternatively specify the flags as part of the pattern.
Added in version 1.4.
Changed in version 1.4.48,: 2.0.18 Note that due to an implementation error, the “flags” parameter previously accepted SQL expression objects such as column expressions in addition to plain Python strings. This implementation did not work correctly with caching and was removed; strings only should be passed for the “flags” parameter, as these flags are rendered as literal inline values within SQL expressions.
See also
ColumnOperators.regexp_match()
method sqlalchemy.sql.expression.ColumnElement.reverse_operate(op: OperatorType, other: Any, **kwargs: Any) → ColumnElement[Any]
Reverse operate on an argument.
Usage is the same as operate().
method sqlalchemy.sql.expression.ColumnElement.self_group(against: OperatorType | None = None) → ColumnElement[Any]
Apply a ‘grouping’ to this ClauseElement.
This method is overridden by subclasses to return a “grouping” construct, i.e. parenthesis. In particular it’s used by “binary” expressions to provide a grouping around themselves when placed into a larger expression, as well as by select() constructs when placed into the FROM clause of another select(). (Note that subqueries should be normally created using the Select.alias() method, as many platforms require nested SELECT statements to be named).
As expressions are composed together, the application of self_group() is automatic - end-user code should never need to use this method directly. Note that SQLAlchemy’s clause constructs take operator precedence into account - so parenthesis might not be needed, for example, in an expression like x OR (y AND z) - AND takes precedence over OR.
The base self_group() method of ClauseElement just returns self.
method sqlalchemy.sql.expression.ColumnElement.shares_lineage(othercolumn: ColumnElement[Any]) → bool
Return True if the given ColumnElement has a common ancestor to this ColumnElement.
method sqlalchemy.sql.expression.ColumnElement.startswith(other: Any, escape: str | None = None, autoescape: bool = False) → ColumnOperators
inherited from the ColumnOperators.startswith() method of ColumnOperators
Implement the startswith operator.
Produces a LIKE expression that tests against a match for the start of a string value:
column LIKE <other> || '%'
E.g.:
stmt = select(sometable).where(sometable.c.column.startswith("foobar"))
Since the operator uses LIKE, wildcard characters "%" and "_" that are present inside the <other> expression will behave like wildcards as well. For literal string values, the ColumnOperators.startswith.autoescape flag may be set to True to apply escaping to occurrences of these characters within the string value so that they match as themselves and not as wildcard characters. Alternatively, the ColumnOperators.startswith.escape parameter will establish a given character as an escape character which can be of use when the target expression is not a literal string.
Parameters:
• other – expression to be compared. This is usually a plain string value, but can also be an arbitrary SQL expression. LIKE wildcard characters % and _ are not escaped by default unless the ColumnOperators.startswith.autoescape flag is set to True.
• autoescape – 
boolean; when True, establishes an escape character within the LIKE expression, then applies it to all occurrences of "%", "_" and the escape character itself within the comparison value, which is assumed to be a literal string and not a SQL expression.
An expression such as:
somecolumn.startswith("foo%bar", autoescape=True)
Will render as:
somecolumn LIKE :param || '%' ESCAPE '/'
•  With the value of :param as "foo/%bar".
•  escape – 
a character which when given will render with the ESCAPE keyword to establish that character as the escape character. This character can then be placed preceding occurrences of % and _ to allow them to act as themselves and not wildcard characters.
An expression such as:
somecolumn.startswith("foo/%bar", escape="^")
Will render as:
somecolumn LIKE :param || '%' ESCAPE '^'
The parameter may also be combined with ColumnOperators.startswith.autoescape:
somecolumn.startswith("foo%bar^bat", escape="^", autoescape=True)
• Where above, the given literal parameter will be converted to "foo^%bar^^bat" before being passed to the database.
See also
ColumnOperators.endswith()
ColumnOperators.contains()
ColumnOperators.like()
attribute sqlalchemy.sql.expression.ColumnElement.stringify_dialect = 'default'
attribute sqlalchemy.sql.expression.ColumnElement.supports_execution = False
attribute sqlalchemy.sql.expression.ColumnElement.timetuple: Literal[None] = None
inherited from the ColumnOperators.timetuple attribute of ColumnOperators
Hack, allows datetime objects to be compared on the LHS.
attribute sqlalchemy.sql.expression.ColumnElement.type: TypeEngine[_T]
method sqlalchemy.sql.expression.ColumnElement.unique_params(_ClauseElement__optionaldict: Dict[str, Any] | None = None, **kwargs: Any) → Self
inherited from the ClauseElement.unique_params() method of ClauseElement
Return a copy with bindparam() elements replaced.
Same functionality as ClauseElement.params(), except adds unique=True to affected bind parameters so that multiple statements can be used.
attribute sqlalchemy.sql.expression.ColumnElement.uses_inspection = True
sqlalchemy.sql.expression.ColumnExpressionArgument
General purpose “column expression” argument.
Added in version 2.0.13.
This type is used for “column” kinds of expressions that typically represent a single SQL column expression, including ColumnElement, as well as ORM-mapped attributes that will have a __clause_element__() method.
class sqlalchemy.sql.expression.ColumnOperators
Defines boolean, comparison, and other operators for ColumnElement expressions.
By default, all methods call down to operate() or reverse_operate(), passing in the appropriate operator function from the Python builtin operator module or a SQLAlchemy-specific operator function from sqlalchemy.expression.operators. For example the __eq__ function:
def __eq__(self, other):
    return self.operate(operators.eq, other)
Where operators.eq is essentially:
def eq(a, b):
    return a == b
The core column expression unit ColumnElement overrides Operators.operate() and others to return further ColumnElement constructs, so that the == operation above is replaced by a clause construct.
See also
Redefining and Creating New Operators
TypeEngine.comparator_factory
ColumnOperators
PropComparator
Members
__add__(), __and__(), __eq__(), __floordiv__(), __ge__(), __getitem__(), __gt__(), __hash__(), __invert__(), __le__(), __lshift__(), __lt__(), __mod__(), __mul__(), __ne__(), __neg__(), __or__(), __radd__(), __rfloordiv__(), __rmod__(), __rmul__(), __rshift__(), __rsub__(), __rtruediv__(), __sa_operate__(), __sub__(), __truediv__(), all_(), any_(), asc(), between(), bitwise_and(), bitwise_lshift(), bitwise_not(), bitwise_or(), bitwise_rshift(), bitwise_xor(), bool_op(), collate(), concat(), contains(), desc(), distinct(), endswith(), icontains(), iendswith(), ilike(), in_(), is_(), is_distinct_from(), is_not(), is_not_distinct_from(), isnot(), isnot_distinct_from(), istartswith(), like(), match(), not_ilike(), not_in(), not_like(), notilike(), notin_(), notlike(), nulls_first(), nulls_last(), nullsfirst(), nullslast(), op(), operate(), regexp_match(), regexp_replace(), reverse_operate(), startswith(), timetuple
Class signature
class sqlalchemy.sql.expression.ColumnOperators (sqlalchemy.sql.expression.Operators)
method sqlalchemy.sql.expression.ColumnOperators.__add__(other: Any) → ColumnOperators
Implement the + operator.
In a column context, produces the clause a + b if the parent object has non-string affinity. If the parent object has a string affinity, produces the concatenation operator, a || b - see ColumnOperators.concat().
method sqlalchemy.sql.expression.ColumnOperators.__and__(other: Any) → Operators
inherited from the sqlalchemy.sql.expression.Operators.__and__ method of Operators
Implement the & operator.
When used with SQL expressions, results in an AND operation, equivalent to and_(), that is:
a & b
is equivalent to:
from sqlalchemy import and_

and_(a, b)
Care should be taken when using & regarding operator precedence; the & operator has the highest precedence. The operands should be enclosed in parenthesis if they contain further sub expressions:
(a == 2) & (b == 4)
method sqlalchemy.sql.expression.ColumnOperators.__eq__(other: Any) → ColumnOperators
Implement the == operator.
In a column context, produces the clause a = b. If the target is None, produces a IS NULL.
method sqlalchemy.sql.expression.ColumnOperators.__floordiv__(other: Any) → ColumnOperators
Implement the // operator.
In a column context, produces the clause a / b, which is the same as “truediv”, but considers the result type to be integer.
Added in version 2.0.
method sqlalchemy.sql.expression.ColumnOperators.__ge__(other: Any) → ColumnOperators
Implement the >= operator.
In a column context, produces the clause a >= b.
method sqlalchemy.sql.expression.ColumnOperators.__getitem__(index: Any) → ColumnOperators
Implement the [] operator.
This can be used by some database-specific types such as PostgreSQL ARRAY and HSTORE.
method sqlalchemy.sql.expression.ColumnOperators.__gt__(other: Any) → ColumnOperators
Implement the > operator.
In a column context, produces the clause a > b.
method sqlalchemy.sql.expression.ColumnOperators.__hash__()
Return hash(self).
method sqlalchemy.sql.expression.ColumnOperators.__invert__() → Operators
inherited from the sqlalchemy.sql.expression.Operators.__invert__ method of Operators
Implement the ~ operator.
When used with SQL expressions, results in a NOT operation, equivalent to not_(), that is:
~a
is equivalent to:
from sqlalchemy import not_

not_(a)
method sqlalchemy.sql.expression.ColumnOperators.__le__(other: Any) → ColumnOperators
Implement the <= operator.
In a column context, produces the clause a <= b.
method sqlalchemy.sql.expression.ColumnOperators.__lshift__(other: Any) → ColumnOperators
implement the << operator.
Not used by SQLAlchemy core, this is provided for custom operator systems which want to use << as an extension point.
method sqlalchemy.sql.expression.ColumnOperators.__lt__(other: Any) → ColumnOperators
Implement the < operator.
In a column context, produces the clause a < b.
method sqlalchemy.sql.expression.ColumnOperators.__mod__(other: Any) → ColumnOperators
Implement the % operator.
In a column context, produces the clause a % b.
method sqlalchemy.sql.expression.ColumnOperators.__mul__(other: Any) → ColumnOperators
Implement the * operator.
In a column context, produces the clause a * b.
method sqlalchemy.sql.expression.ColumnOperators.__ne__(other: Any) → ColumnOperators
Implement the != operator.
In a column context, produces the clause a != b. If the target is None, produces a IS NOT NULL.
method sqlalchemy.sql.expression.ColumnOperators.__neg__() → ColumnOperators
Implement the - operator.
In a column context, produces the clause -a.
method sqlalchemy.sql.expression.ColumnOperators.__or__(other: Any) → Operators
inherited from the sqlalchemy.sql.expression.Operators.__or__ method of Operators
Implement the | operator.
When used with SQL expressions, results in an OR operation, equivalent to or_(), that is:
a | b
is equivalent to:
from sqlalchemy import or_

or_(a, b)
Care should be taken when using | regarding operator precedence; the | operator has the highest precedence. The operands should be enclosed in parenthesis if they contain further sub expressions:
(a == 2) | (b == 4)
method sqlalchemy.sql.expression.ColumnOperators.__radd__(other: Any) → ColumnOperators
Implement the + operator in reverse.
See ColumnOperators.__add__().
method sqlalchemy.sql.expression.ColumnOperators.__rfloordiv__(other: Any) → ColumnOperators
Implement the // operator in reverse.
See ColumnOperators.__floordiv__().
method sqlalchemy.sql.expression.ColumnOperators.__rmod__(other: Any) → ColumnOperators
Implement the % operator in reverse.
See ColumnOperators.__mod__().
method sqlalchemy.sql.expression.ColumnOperators.__rmul__(other: Any) → ColumnOperators
Implement the * operator in reverse.
See ColumnOperators.__mul__().
method sqlalchemy.sql.expression.ColumnOperators.__rshift__(other: Any) → ColumnOperators
implement the >> operator.
Not used by SQLAlchemy core, this is provided for custom operator systems which want to use >> as an extension point.
method sqlalchemy.sql.expression.ColumnOperators.__rsub__(other: Any) → ColumnOperators
Implement the - operator in reverse.
See ColumnOperators.__sub__().
method sqlalchemy.sql.expression.ColumnOperators.__rtruediv__(other: Any) → ColumnOperators
Implement the / operator in reverse.
See ColumnOperators.__truediv__().
method sqlalchemy.sql.expression.ColumnOperators.__sa_operate__(op: OperatorType, *other: Any, **kwargs: Any) → Operators
inherited from the sqlalchemy.sql.expression.Operators.__sa_operate__ method of Operators
Operate on an argument.
This is the lowest level of operation, raises NotImplementedError by default.
Overriding this on a subclass can allow common behavior to be applied to all operations. For example, overriding ColumnOperators to apply func.lower() to the left and right side:
class MyComparator(ColumnOperators):
    def operate(self, op, other, **kwargs):
        return op(func.lower(self), func.lower(other), **kwargs)
Parameters:
• op – Operator callable.
• *other – the ‘other’ side of the operation. Will be a single scalar for most operations.
• **kwargs – modifiers. These may be passed by special operators such as ColumnOperators.contains().
method sqlalchemy.sql.expression.ColumnOperators.__sub__(other: Any) → ColumnOperators
Implement the - operator.
In a column context, produces the clause a - b.
method sqlalchemy.sql.expression.ColumnOperators.__truediv__(other: Any) → ColumnOperators
Implement the / operator.
In a column context, produces the clause a / b, and considers the result type to be numeric.
Changed in version 2.0: The truediv operator against two integers is now considered to return a numeric value. Behavior on specific backends may vary.
method sqlalchemy.sql.expression.ColumnOperators.all_() → ColumnOperators
Produce an all_() clause against the parent object.
See the documentation for all_() for examples.
Note
be sure to not confuse the newer ColumnOperators.all_() method with the legacy version of this method, the Comparator.all() method that’s specific to ARRAY, which uses a different calling style.
method sqlalchemy.sql.expression.ColumnOperators.any_() → ColumnOperators
Produce an any_() clause against the parent object.
See the documentation for any_() for examples.
Note
be sure to not confuse the newer ColumnOperators.any_() method with the legacy version of this method, the Comparator.any() method that’s specific to ARRAY, which uses a different calling style.
method sqlalchemy.sql.expression.ColumnOperators.asc() → ColumnOperators
Produce a asc() clause against the parent object.
method sqlalchemy.sql.expression.ColumnOperators.between(cleft: Any, cright: Any, symmetric: bool = False) → ColumnOperators
Produce a between() clause against the parent object, given the lower and upper range.
method sqlalchemy.sql.expression.ColumnOperators.bitwise_and(other: Any) → ColumnOperators
Produce a bitwise AND operation, typically via the & operator.
Added in version 2.0.2.
See also
Bitwise Operators
method sqlalchemy.sql.expression.ColumnOperators.bitwise_lshift(other: Any) → ColumnOperators
Produce a bitwise LSHIFT operation, typically via the << operator.
Added in version 2.0.2.
See also
Bitwise Operators
method sqlalchemy.sql.expression.ColumnOperators.bitwise_not() → ColumnOperators
Produce a bitwise NOT operation, typically via the ~ operator.
Added in version 2.0.2.
See also
Bitwise Operators
method sqlalchemy.sql.expression.ColumnOperators.bitwise_or(other: Any) → ColumnOperators
Produce a bitwise OR operation, typically via the | operator.
Added in version 2.0.2.
See also
Bitwise Operators
method sqlalchemy.sql.expression.ColumnOperators.bitwise_rshift(other: Any) → ColumnOperators
Produce a bitwise RSHIFT operation, typically via the >> operator.
Added in version 2.0.2.
See also
Bitwise Operators
method sqlalchemy.sql.expression.ColumnOperators.bitwise_xor(other: Any) → ColumnOperators
Produce a bitwise XOR operation, typically via the ^ operator, or # for PostgreSQL.
Added in version 2.0.2.
See also
Bitwise Operators
method sqlalchemy.sql.expression.ColumnOperators.bool_op(opstring: str, precedence: int = 0, python_impl: Callable[[...], Any] | None = None) → Callable[[Any], Operators]
inherited from the Operators.bool_op() method of Operators
Return a custom boolean operator.
This method is shorthand for calling Operators.op() and passing the Operators.op.is_comparison flag with True. A key advantage to using Operators.bool_op() is that when using column constructs, the “boolean” nature of the returned expression will be present for PEP 484 purposes.
See also
Operators.op()
method sqlalchemy.sql.expression.ColumnOperators.collate(collation: str) → ColumnOperators
Produce a collate() clause against the parent object, given the collation string.
See also
collate()
method sqlalchemy.sql.expression.ColumnOperators.concat(other: Any) → ColumnOperators
Implement the ‘concat’ operator.
In a column context, produces the clause a || b, or uses the concat() operator on MySQL.
method sqlalchemy.sql.expression.ColumnOperators.contains(other: Any, **kw: Any) → ColumnOperators
Implement the ‘contains’ operator.
Produces a LIKE expression that tests against a match for the middle of a string value:
column LIKE '%' || <other> || '%'
E.g.:
stmt = select(sometable).where(sometable.c.column.contains("foobar"))
Since the operator uses LIKE, wildcard characters "%" and "_" that are present inside the <other> expression will behave like wildcards as well. For literal string values, the ColumnOperators.contains.autoescape flag may be set to True to apply escaping to occurrences of these characters within the string value so that they match as themselves and not as wildcard characters. Alternatively, the ColumnOperators.contains.escape parameter will establish a given character as an escape character which can be of use when the target expression is not a literal string.
Parameters:
• other – expression to be compared. This is usually a plain string value, but can also be an arbitrary SQL expression. LIKE wildcard characters % and _ are not escaped by default unless the ColumnOperators.contains.autoescape flag is set to True.
• autoescape – 
boolean; when True, establishes an escape character within the LIKE expression, then applies it to all occurrences of "%", "_" and the escape character itself within the comparison value, which is assumed to be a literal string and not a SQL expression.
An expression such as:
somecolumn.contains("foo%bar", autoescape=True)
Will render as:
somecolumn LIKE '%' || :param || '%' ESCAPE '/'
•  With the value of :param as "foo/%bar".
•  escape – 
a character which when given will render with the ESCAPE keyword to establish that character as the escape character. This character can then be placed preceding occurrences of % and _ to allow them to act as themselves and not wildcard characters.
An expression such as:
somecolumn.contains("foo/%bar", escape="^")
Will render as:
somecolumn LIKE '%' || :param || '%' ESCAPE '^'
The parameter may also be combined with ColumnOperators.contains.autoescape:
somecolumn.contains("foo%bar^bat", escape="^", autoescape=True)
• Where above, the given literal parameter will be converted to "foo^%bar^^bat" before being passed to the database.
See also
ColumnOperators.startswith()
ColumnOperators.endswith()
ColumnOperators.like()
method sqlalchemy.sql.expression.ColumnOperators.desc() → ColumnOperators
Produce a desc() clause against the parent object.
method sqlalchemy.sql.expression.ColumnOperators.distinct() → ColumnOperators
Produce a distinct() clause against the parent object.
method sqlalchemy.sql.expression.ColumnOperators.endswith(other: Any, escape: str | None = None, autoescape: bool = False) → ColumnOperators
Implement the ‘endswith’ operator.
Produces a LIKE expression that tests against a match for the end of a string value:
column LIKE '%' || <other>
E.g.:
stmt = select(sometable).where(sometable.c.column.endswith("foobar"))
Since the operator uses LIKE, wildcard characters "%" and "_" that are present inside the <other> expression will behave like wildcards as well. For literal string values, the ColumnOperators.endswith.autoescape flag may be set to True to apply escaping to occurrences of these characters within the string value so that they match as themselves and not as wildcard characters. Alternatively, the ColumnOperators.endswith.escape parameter will establish a given character as an escape character which can be of use when the target expression is not a literal string.
Parameters:
• other – expression to be compared. This is usually a plain string value, but can also be an arbitrary SQL expression. LIKE wildcard characters % and _ are not escaped by default unless the ColumnOperators.endswith.autoescape flag is set to True.
• autoescape – 
boolean; when True, establishes an escape character within the LIKE expression, then applies it to all occurrences of "%", "_" and the escape character itself within the comparison value, which is assumed to be a literal string and not a SQL expression.
An expression such as:
somecolumn.endswith("foo%bar", autoescape=True)
Will render as:
somecolumn LIKE '%' || :param ESCAPE '/'
•  With the value of :param as "foo/%bar".
•  escape – 
a character which when given will render with the ESCAPE keyword to establish that character as the escape character. This character can then be placed preceding occurrences of % and _ to allow them to act as themselves and not wildcard characters.
An expression such as:
somecolumn.endswith("foo/%bar", escape="^")
Will render as:
somecolumn LIKE '%' || :param ESCAPE '^'
The parameter may also be combined with ColumnOperators.endswith.autoescape:
somecolumn.endswith("foo%bar^bat", escape="^", autoescape=True)
• Where above, the given literal parameter will be converted to "foo^%bar^^bat" before being passed to the database.
See also
ColumnOperators.startswith()
ColumnOperators.contains()
ColumnOperators.like()
method sqlalchemy.sql.expression.ColumnOperators.icontains(other: Any, **kw: Any) → ColumnOperators
Implement the icontains operator, e.g. case insensitive version of ColumnOperators.contains().
Produces a LIKE expression that tests against an insensitive match for the middle of a string value:
lower(column) LIKE '%' || lower(<other>) || '%'
E.g.:
stmt = select(sometable).where(sometable.c.column.icontains("foobar"))
Since the operator uses LIKE, wildcard characters "%" and "_" that are present inside the <other> expression will behave like wildcards as well. For literal string values, the ColumnOperators.icontains.autoescape flag may be set to True to apply escaping to occurrences of these characters within the string value so that they match as themselves and not as wildcard characters. Alternatively, the ColumnOperators.icontains.escape parameter will establish a given character as an escape character which can be of use when the target expression is not a literal string.
Parameters:
• other – expression to be compared. This is usually a plain string value, but can also be an arbitrary SQL expression. LIKE wildcard characters % and _ are not escaped by default unless the ColumnOperators.icontains.autoescape flag is set to True.
• autoescape – 
boolean; when True, establishes an escape character within the LIKE expression, then applies it to all occurrences of "%", "_" and the escape character itself within the comparison value, which is assumed to be a literal string and not a SQL expression.
An expression such as:
somecolumn.icontains("foo%bar", autoescape=True)
Will render as:
lower(somecolumn) LIKE '%' || lower(:param) || '%' ESCAPE '/'
•  With the value of :param as "foo/%bar".
•  escape – 
a character which when given will render with the ESCAPE keyword to establish that character as the escape character. This character can then be placed preceding occurrences of % and _ to allow them to act as themselves and not wildcard characters.
An expression such as:
somecolumn.icontains("foo/%bar", escape="^")
Will render as:
lower(somecolumn) LIKE '%' || lower(:param) || '%' ESCAPE '^'
The parameter may also be combined with ColumnOperators.contains.autoescape:
somecolumn.icontains("foo%bar^bat", escape="^", autoescape=True)
• Where above, the given literal parameter will be converted to "foo^%bar^^bat" before being passed to the database.
See also
ColumnOperators.contains()
method sqlalchemy.sql.expression.ColumnOperators.iendswith(other: Any, escape: str | None = None, autoescape: bool = False) → ColumnOperators
Implement the iendswith operator, e.g. case insensitive version of ColumnOperators.endswith().
Produces a LIKE expression that tests against an insensitive match for the end of a string value:
lower(column) LIKE '%' || lower(<other>)
E.g.:
stmt = select(sometable).where(sometable.c.column.iendswith("foobar"))
Since the operator uses LIKE, wildcard characters "%" and "_" that are present inside the <other> expression will behave like wildcards as well. For literal string values, the ColumnOperators.iendswith.autoescape flag may be set to True to apply escaping to occurrences of these characters within the string value so that they match as themselves and not as wildcard characters. Alternatively, the ColumnOperators.iendswith.escape parameter will establish a given character as an escape character which can be of use when the target expression is not a literal string.
Parameters:
• other – expression to be compared. This is usually a plain string value, but can also be an arbitrary SQL expression. LIKE wildcard characters % and _ are not escaped by default unless the ColumnOperators.iendswith.autoescape flag is set to True.
• autoescape – 
boolean; when True, establishes an escape character within the LIKE expression, then applies it to all occurrences of "%", "_" and the escape character itself within the comparison value, which is assumed to be a literal string and not a SQL expression.
An expression such as:
somecolumn.iendswith("foo%bar", autoescape=True)
Will render as:
lower(somecolumn) LIKE '%' || lower(:param) ESCAPE '/'
•  With the value of :param as "foo/%bar".
•  escape – 
a character which when given will render with the ESCAPE keyword to establish that character as the escape character. This character can then be placed preceding occurrences of % and _ to allow them to act as themselves and not wildcard characters.
An expression such as:
somecolumn.iendswith("foo/%bar", escape="^")
Will render as:
lower(somecolumn) LIKE '%' || lower(:param) ESCAPE '^'
The parameter may also be combined with ColumnOperators.iendswith.autoescape:
somecolumn.endswith("foo%bar^bat", escape="^", autoescape=True)
• Where above, the given literal parameter will be converted to "foo^%bar^^bat" before being passed to the database.
See also
ColumnOperators.endswith()
method sqlalchemy.sql.expression.ColumnOperators.ilike(other: Any, escape: str | None = None) → ColumnOperators
Implement the ilike operator, e.g. case insensitive LIKE.
In a column context, produces an expression either of the form:
lower(a) LIKE lower(other)
Or on backends that support the ILIKE operator:
a ILIKE other
E.g.:
stmt = select(sometable).where(sometable.c.column.ilike("%foobar%"))
Parameters:
• other – expression to be compared
• escape – 
optional escape character, renders the ESCAPE keyword, e.g.:
somecolumn.ilike("foo/%bar", escape="/")
• 
See also
ColumnOperators.like()
method sqlalchemy.sql.expression.ColumnOperators.in_(other: Any) → ColumnOperators
Implement the in operator.
In a column context, produces the clause column IN <other>.
The given parameter other may be:
• A list of literal values, e.g.:
stmt.where(column.in_([1, 2, 3]))
In this calling form, the list of items is converted to a set of bound parameters the same length as the list given:
WHERE COL IN (?, ?, ?)
A list of tuples may be provided if the comparison is against a tuple_() containing multiple expressions:
from sqlalchemy import tuple_

stmt.where(tuple_(col1, col2).in_([(1, 10), (2, 20), (3, 30)]))
An empty list, e.g.:
stmt.where(column.in_([]))
In this calling form, the expression renders an “empty set” expression. These expressions are tailored to individual backends and are generally trying to get an empty SELECT statement as a subquery. Such as on SQLite, the expression is:
WHERE col IN (SELECT 1 FROM (SELECT 1) WHERE 1!=1)
•  Changed in version 1.4: empty IN expressions now use an execution-time generated SELECT subquery in all cases.
•  A bound parameter, e.g. bindparam(), may be used if it includes the bindparam.expanding flag:
stmt.where(column.in_(bindparam("value", expanding=True)))
In this calling form, the expression renders a special non-SQL placeholder expression that looks like:
WHERE COL IN ([EXPANDING_value])
This placeholder expression is intercepted at statement execution time to be converted into the variable number of bound parameter form illustrated earlier. If the statement were executed as:
connection.execute(stmt, {"value": [1, 2, 3]})
The database would be passed a bound parameter for each value:
WHERE COL IN (?, ?, ?)
Added in version 1.2: added “expanding” bound parameters
If an empty list is passed, a special “empty list” expression, which is specific to the database in use, is rendered. On SQLite this would be:
WHERE COL IN (SELECT 1 FROM (SELECT 1) WHERE 1!=1)
•  Added in version 1.3: “expanding” bound parameters now support empty lists
•  a select() construct, which is usually a correlated scalar select:
stmt.where(
    column.in_(select(othertable.c.y).where(table.c.x == othertable.c.x))
)
In this calling form, ColumnOperators.in_() renders as given:
WHERE COL IN (SELECT othertable.y
FROM othertable WHERE othertable.x = table.x)
Parameters:
other – a list of literals, a select() construct, or a bindparam() construct that includes the bindparam.expanding flag set to True.
method sqlalchemy.sql.expression.ColumnOperators.is_(other: Any) → ColumnOperators
Implement the IS operator.
Normally, IS is generated automatically when comparing to a value of None, which resolves to NULL. However, explicit usage of IS may be desirable if comparing to boolean values on certain platforms.
See also
ColumnOperators.is_not()
method sqlalchemy.sql.expression.ColumnOperators.is_distinct_from(other: Any) → ColumnOperators
Implement the IS DISTINCT FROM operator.
Renders “a IS DISTINCT FROM b” on most platforms; on some such as SQLite may render “a IS NOT b”.
method sqlalchemy.sql.expression.ColumnOperators.is_not(other: Any) → ColumnOperators
Implement the IS NOT operator.
Normally, IS NOT is generated automatically when comparing to a value of None, which resolves to NULL. However, explicit usage of IS NOT may be desirable if comparing to boolean values on certain platforms.
Changed in version 1.4: The is_not() operator is renamed from isnot() in previous releases. The previous name remains available for backwards compatibility.
See also
ColumnOperators.is_()
method sqlalchemy.sql.expression.ColumnOperators.is_not_distinct_from(other: Any) → ColumnOperators
Implement the IS NOT DISTINCT FROM operator.
Renders “a IS NOT DISTINCT FROM b” on most platforms; on some such as SQLite may render “a IS b”.
Changed in version 1.4: The is_not_distinct_from() operator is renamed from isnot_distinct_from() in previous releases. The previous name remains available for backwards compatibility.
method sqlalchemy.sql.expression.ColumnOperators.isnot(other: Any) → ColumnOperators
Implement the IS NOT operator.
Normally, IS NOT is generated automatically when comparing to a value of None, which resolves to NULL. However, explicit usage of IS NOT may be desirable if comparing to boolean values on certain platforms.
Changed in version 1.4: The is_not() operator is renamed from isnot() in previous releases. The previous name remains available for backwards compatibility.
See also
ColumnOperators.is_()
method sqlalchemy.sql.expression.ColumnOperators.isnot_distinct_from(other: Any) → ColumnOperators
Implement the IS NOT DISTINCT FROM operator.
Renders “a IS NOT DISTINCT FROM b” on most platforms; on some such as SQLite may render “a IS b”.
Changed in version 1.4: The is_not_distinct_from() operator is renamed from isnot_distinct_from() in previous releases. The previous name remains available for backwards compatibility.
method sqlalchemy.sql.expression.ColumnOperators.istartswith(other: Any, escape: str | None = None, autoescape: bool = False) → ColumnOperators
Implement the istartswith operator, e.g. case insensitive version of ColumnOperators.startswith().
Produces a LIKE expression that tests against an insensitive match for the start of a string value:
lower(column) LIKE lower(<other>) || '%'
E.g.:
stmt = select(sometable).where(sometable.c.column.istartswith("foobar"))
Since the operator uses LIKE, wildcard characters "%" and "_" that are present inside the <other> expression will behave like wildcards as well. For literal string values, the ColumnOperators.istartswith.autoescape flag may be set to True to apply escaping to occurrences of these characters within the string value so that they match as themselves and not as wildcard characters. Alternatively, the ColumnOperators.istartswith.escape parameter will establish a given character as an escape character which can be of use when the target expression is not a literal string.
Parameters:
• other – expression to be compared. This is usually a plain string value, but can also be an arbitrary SQL expression. LIKE wildcard characters % and _ are not escaped by default unless the ColumnOperators.istartswith.autoescape flag is set to True.
• autoescape – 
boolean; when True, establishes an escape character within the LIKE expression, then applies it to all occurrences of "%", "_" and the escape character itself within the comparison value, which is assumed to be a literal string and not a SQL expression.
An expression such as:
somecolumn.istartswith("foo%bar", autoescape=True)
Will render as:
lower(somecolumn) LIKE lower(:param) || '%' ESCAPE '/'
•  With the value of :param as "foo/%bar".
•  escape – 
a character which when given will render with the ESCAPE keyword to establish that character as the escape character. This character can then be placed preceding occurrences of % and _ to allow them to act as themselves and not wildcard characters.
An expression such as:
somecolumn.istartswith("foo/%bar", escape="^")
Will render as:
lower(somecolumn) LIKE lower(:param) || '%' ESCAPE '^'
The parameter may also be combined with ColumnOperators.istartswith.autoescape:
somecolumn.istartswith("foo%bar^bat", escape="^", autoescape=True)
• Where above, the given literal parameter will be converted to "foo^%bar^^bat" before being passed to the database.
See also
ColumnOperators.startswith()
method sqlalchemy.sql.expression.ColumnOperators.like(other: Any, escape: str | None = None) → ColumnOperators
Implement the like operator.
In a column context, produces the expression:
a LIKE other
E.g.:
stmt = select(sometable).where(sometable.c.column.like("%foobar%"))
Parameters:
• other – expression to be compared
• escape – 
optional escape character, renders the ESCAPE keyword, e.g.:
somecolumn.like("foo/%bar", escape="/")
• 
See also
ColumnOperators.ilike()
method sqlalchemy.sql.expression.ColumnOperators.match(other: Any, **kwargs: Any) → ColumnOperators
Implements a database-specific ‘match’ operator.
ColumnOperators.match() attempts to resolve to a MATCH-like function or operator provided by the backend. Examples include:
• PostgreSQL - renders x @@ plainto_tsquery(y)
Changed in version 2.0: plainto_tsquery() is used instead of to_tsquery() for PostgreSQL now; for compatibility with other forms, see Full Text Search.
• MySQL - renders MATCH (x) AGAINST (y IN BOOLEAN MODE)
See also
match - MySQL specific construct with additional features.
• Oracle Database - renders CONTAINS(x, y)
• other backends may provide special implementations.
• Backends without any special implementation will emit the operator as “MATCH”. This is compatible with SQLite, for example.
method sqlalchemy.sql.expression.ColumnOperators.not_ilike(other: Any, escape: str | None = None) → ColumnOperators
implement the NOT ILIKE operator.
This is equivalent to using negation with ColumnOperators.ilike(), i.e. ~x.ilike(y).
Changed in version 1.4: The not_ilike() operator is renamed from notilike() in previous releases. The previous name remains available for backwards compatibility.
See also
ColumnOperators.ilike()
method sqlalchemy.sql.expression.ColumnOperators.not_in(other: Any) → ColumnOperators
implement the NOT IN operator.
This is equivalent to using negation with ColumnOperators.in_(), i.e. ~x.in_(y).
In the case that other is an empty sequence, the compiler produces an “empty not in” expression. This defaults to the expression “1 = 1” to produce true in all cases. The create_engine.empty_in_strategy may be used to alter this behavior.
Changed in version 1.4: The not_in() operator is renamed from notin_() in previous releases. The previous name remains available for backwards compatibility.
Changed in version 1.2: The ColumnOperators.in_() and ColumnOperators.not_in() operators now produce a “static” expression for an empty IN sequence by default.
See also
ColumnOperators.in_()
method sqlalchemy.sql.expression.ColumnOperators.not_like(other: Any, escape: str | None = None) → ColumnOperators
implement the NOT LIKE operator.
This is equivalent to using negation with ColumnOperators.like(), i.e. ~x.like(y).
Changed in version 1.4: The not_like() operator is renamed from notlike() in previous releases. The previous name remains available for backwards compatibility.
See also
ColumnOperators.like()
method sqlalchemy.sql.expression.ColumnOperators.notilike(other: Any, escape: str | None = None) → ColumnOperators
implement the NOT ILIKE operator.
This is equivalent to using negation with ColumnOperators.ilike(), i.e. ~x.ilike(y).
Changed in version 1.4: The not_ilike() operator is renamed from notilike() in previous releases. The previous name remains available for backwards compatibility.
See also
ColumnOperators.ilike()
method sqlalchemy.sql.expression.ColumnOperators.notin_(other: Any) → ColumnOperators
implement the NOT IN operator.
This is equivalent to using negation with ColumnOperators.in_(), i.e. ~x.in_(y).
In the case that other is an empty sequence, the compiler produces an “empty not in” expression. This defaults to the expression “1 = 1” to produce true in all cases. The create_engine.empty_in_strategy may be used to alter this behavior.
Changed in version 1.4: The not_in() operator is renamed from notin_() in previous releases. The previous name remains available for backwards compatibility.
Changed in version 1.2: The ColumnOperators.in_() and ColumnOperators.not_in() operators now produce a “static” expression for an empty IN sequence by default.
See also
ColumnOperators.in_()
method sqlalchemy.sql.expression.ColumnOperators.notlike(other: Any, escape: str | None = None) → ColumnOperators
implement the NOT LIKE operator.
This is equivalent to using negation with ColumnOperators.like(), i.e. ~x.like(y).
Changed in version 1.4: The not_like() operator is renamed from notlike() in previous releases. The previous name remains available for backwards compatibility.
See also
ColumnOperators.like()
method sqlalchemy.sql.expression.ColumnOperators.nulls_first() → ColumnOperators
Produce a nulls_first() clause against the parent object.
Changed in version 1.4: The nulls_first() operator is renamed from nullsfirst() in previous releases. The previous name remains available for backwards compatibility.
method sqlalchemy.sql.expression.ColumnOperators.nulls_last() → ColumnOperators
Produce a nulls_last() clause against the parent object.
Changed in version 1.4: The nulls_last() operator is renamed from nullslast() in previous releases. The previous name remains available for backwards compatibility.
method sqlalchemy.sql.expression.ColumnOperators.nullsfirst() → ColumnOperators
Produce a nulls_first() clause against the parent object.
Changed in version 1.4: The nulls_first() operator is renamed from nullsfirst() in previous releases. The previous name remains available for backwards compatibility.
method sqlalchemy.sql.expression.ColumnOperators.nullslast() → ColumnOperators
Produce a nulls_last() clause against the parent object.
Changed in version 1.4: The nulls_last() operator is renamed from nullslast() in previous releases. The previous name remains available for backwards compatibility.
method sqlalchemy.sql.expression.ColumnOperators.op(opstring: str, precedence: int = 0, is_comparison: bool = False, return_type: Type[TypeEngine[Any]] | TypeEngine[Any] | None = None, python_impl: Callable[..., Any] | None = None) → Callable[[Any], Operators]
inherited from the Operators.op() method of Operators
Produce a generic operator function.
e.g.:
somecolumn.op("*")(5)
produces:
somecolumn * 5
This function can also be used to make bitwise operators explicit. For example:
somecolumn.op("&")(0xFF)
is a bitwise AND of the value in somecolumn.
Parameters:
• opstring – a string which will be output as the infix operator between this element and the expression passed to the generated function.
• precedence – 
precedence which the database is expected to apply to the operator in SQL expressions. This integer value acts as a hint for the SQL compiler to know when explicit parenthesis should be rendered around a particular operation. A lower number will cause the expression to be parenthesized when applied against another operator with higher precedence. The default value of 0 is lower than all operators except for the comma (,) and AS operators. A value of 100 will be higher or equal to all operators, and -100 will be lower than or equal to all operators.
See also
I’m using op() to generate a custom operator and my parenthesis are not coming out correctly - detailed description of how the SQLAlchemy SQL compiler renders parenthesis
• is_comparison – 
legacy; if True, the operator will be considered as a “comparison” operator, that is which evaluates to a boolean true/false value, like ==, >, etc. This flag is provided so that ORM relationships can establish that the operator is a comparison operator when used in a custom join condition.
Using the is_comparison parameter is superseded by using the Operators.bool_op() method instead; this more succinct operator sets this parameter automatically, but also provides correct PEP 484 typing support as the returned object will express a “boolean” datatype, i.e. BinaryExpression[bool].
• return_type – a TypeEngine class or object that will force the return type of an expression produced by this operator to be of that type. By default, operators that specify Operators.op.is_comparison will resolve to Boolean, and those that do not will be of the same type as the left-hand operand.
• python_impl – 
an optional Python function that can evaluate two Python values in the same way as this operator works when run on the database server. Useful for in-Python SQL expression evaluation functions, such as for ORM hybrid attributes, and the ORM “evaluator” used to match objects in a session after a multi-row update or delete.
e.g.:
>>> expr = column("x").op("+", python_impl=lambda a, b: a + b)("y")
The operator for the above expression will also work for non-SQL left and right objects:
>>> expr.operator(5, 10)
15
• Added in version 2.0.
See also
Operators.bool_op()
Redefining and Creating New Operators
Using custom operators in join conditions
method sqlalchemy.sql.expression.ColumnOperators.operate(op: OperatorType, *other: Any, **kwargs: Any) → Operators
inherited from the Operators.operate() method of Operators
Operate on an argument.
This is the lowest level of operation, raises NotImplementedError by default.
Overriding this on a subclass can allow common behavior to be applied to all operations. For example, overriding ColumnOperators to apply func.lower() to the left and right side:
class MyComparator(ColumnOperators):
    def operate(self, op, other, **kwargs):
        return op(func.lower(self), func.lower(other), **kwargs)
Parameters:
• op – Operator callable.
• *other – the ‘other’ side of the operation. Will be a single scalar for most operations.
• **kwargs – modifiers. These may be passed by special operators such as ColumnOperators.contains().
method sqlalchemy.sql.expression.ColumnOperators.regexp_match(pattern: Any, flags: str | None = None) → ColumnOperators
Implements a database-specific ‘regexp match’ operator.
E.g.:
stmt = select(table.c.some_column).where(
    table.c.some_column.regexp_match("^(b|c)")
)
ColumnOperators.regexp_match() attempts to resolve to a REGEXP-like function or operator provided by the backend, however the specific regular expression syntax and flags available are not backend agnostic.
Examples include:
• PostgreSQL - renders x ~ y or x !~ y when negated.
• Oracle Database - renders REGEXP_LIKE(x, y)
• SQLite - uses SQLite’s REGEXP placeholder operator and calls into the Python re.match() builtin.
• other backends may provide special implementations.
• Backends without any special implementation will emit the operator as “REGEXP” or “NOT REGEXP”. This is compatible with SQLite and MySQL, for example.
Regular expression support is currently implemented for Oracle Database, PostgreSQL, MySQL and MariaDB. Partial support is available for SQLite. Support among third-party dialects may vary.
Parameters:
• pattern – The regular expression pattern string or column clause.
• flags – Any regular expression string flags to apply, passed as plain Python string only. These flags are backend specific. Some backends, like PostgreSQL and MariaDB, may alternatively specify the flags as part of the pattern. When using the ignore case flag ‘i’ in PostgreSQL, the ignore case regexp match operator ~* or !~* will be used.
Added in version 1.4.
Changed in version 1.4.48,: 2.0.18 Note that due to an implementation error, the “flags” parameter previously accepted SQL expression objects such as column expressions in addition to plain Python strings. This implementation did not work correctly with caching and was removed; strings only should be passed for the “flags” parameter, as these flags are rendered as literal inline values within SQL expressions.
See also
ColumnOperators.regexp_replace()
method sqlalchemy.sql.expression.ColumnOperators.regexp_replace(pattern: Any, replacement: Any, flags: str | None = None) → ColumnOperators
Implements a database-specific ‘regexp replace’ operator.
E.g.:
stmt = select(
    table.c.some_column.regexp_replace("b(..)", "XY", flags="g")
)
ColumnOperators.regexp_replace() attempts to resolve to a REGEXP_REPLACE-like function provided by the backend, that usually emit the function REGEXP_REPLACE(). However, the specific regular expression syntax and flags available are not backend agnostic.
Regular expression replacement support is currently implemented for Oracle Database, PostgreSQL, MySQL 8 or greater and MariaDB. Support among third-party dialects may vary.
Parameters:
• pattern – The regular expression pattern string or column clause.
• pattern – The replacement string or column clause.
• flags – Any regular expression string flags to apply, passed as plain Python string only. These flags are backend specific. Some backends, like PostgreSQL and MariaDB, may alternatively specify the flags as part of the pattern.
Added in version 1.4.
Changed in version 1.4.48,: 2.0.18 Note that due to an implementation error, the “flags” parameter previously accepted SQL expression objects such as column expressions in addition to plain Python strings. This implementation did not work correctly with caching and was removed; strings only should be passed for the “flags” parameter, as these flags are rendered as literal inline values within SQL expressions.
See also
ColumnOperators.regexp_match()
method sqlalchemy.sql.expression.ColumnOperators.reverse_operate(op: OperatorType, other: Any, **kwargs: Any) → Operators
inherited from the Operators.reverse_operate() method of Operators
Reverse operate on an argument.
Usage is the same as operate().
method sqlalchemy.sql.expression.ColumnOperators.startswith(other: Any, escape: str | None = None, autoescape: bool = False) → ColumnOperators
Implement the startswith operator.
Produces a LIKE expression that tests against a match for the start of a string value:
column LIKE <other> || '%'
E.g.:
stmt = select(sometable).where(sometable.c.column.startswith("foobar"))
Since the operator uses LIKE, wildcard characters "%" and "_" that are present inside the <other> expression will behave like wildcards as well. For literal string values, the ColumnOperators.startswith.autoescape flag may be set to True to apply escaping to occurrences of these characters within the string value so that they match as themselves and not as wildcard characters. Alternatively, the ColumnOperators.startswith.escape parameter will establish a given character as an escape character which can be of use when the target expression is not a literal string.
Parameters:
• other – expression to be compared. This is usually a plain string value, but can also be an arbitrary SQL expression. LIKE wildcard characters % and _ are not escaped by default unless the ColumnOperators.startswith.autoescape flag is set to True.
• autoescape – 
boolean; when True, establishes an escape character within the LIKE expression, then applies it to all occurrences of "%", "_" and the escape character itself within the comparison value, which is assumed to be a literal string and not a SQL expression.
An expression such as:
somecolumn.startswith("foo%bar", autoescape=True)
Will render as:
somecolumn LIKE :param || '%' ESCAPE '/'
•  With the value of :param as "foo/%bar".
•  escape – 
a character which when given will render with the ESCAPE keyword to establish that character as the escape character. This character can then be placed preceding occurrences of % and _ to allow them to act as themselves and not wildcard characters.
An expression such as:
somecolumn.startswith("foo/%bar", escape="^")
Will render as:
somecolumn LIKE :param || '%' ESCAPE '^'
The parameter may also be combined with ColumnOperators.startswith.autoescape:
somecolumn.startswith("foo%bar^bat", escape="^", autoescape=True)
• Where above, the given literal parameter will be converted to "foo^%bar^^bat" before being passed to the database.
See also
ColumnOperators.endswith()
ColumnOperators.contains()
ColumnOperators.like()
attribute sqlalchemy.sql.expression.ColumnOperators.timetuple: Literal[None] = None
Hack, allows datetime objects to be compared on the LHS.
class sqlalchemy.sql.expression.Extract
Represent a SQL EXTRACT clause, extract(field FROM expr).
Class signature
class sqlalchemy.sql.expression.Extract (sqlalchemy.sql.expression.ColumnElement)
class sqlalchemy.sql.expression.False_
Represent the false keyword, or equivalent, in a SQL statement.
False_ is accessed as a constant via the false() function.
Class signature
class sqlalchemy.sql.expression.False_ (sqlalchemy.sql.expression.SingletonConstant, sqlalchemy.sql.roles.ConstExprRole, sqlalchemy.sql.expression.ColumnElement)
class sqlalchemy.sql.expression.FunctionFilter
Represent a function FILTER clause.
This is a special operator against aggregate and window functions, which controls which rows are passed to it. It’s supported only by certain database backends.
Invocation of FunctionFilter is via FunctionElement.filter():
func.count(1).filter(True)
See also
FunctionElement.filter()
Members
filter(), over(), self_group(), within_group()
Class signature
class sqlalchemy.sql.expression.FunctionFilter (sqlalchemy.sql.expression.Generative, sqlalchemy.sql.expression.ColumnElement)
method sqlalchemy.sql.expression.FunctionFilter.filter(*criterion: _ColumnExpressionArgument[bool]) → Self
Produce an additional FILTER against the function.
This method adds additional criteria to the initial criteria set up by FunctionElement.filter().
Multiple criteria are joined together at SQL render time via AND.
method sqlalchemy.sql.expression.FunctionFilter.over(partition_by: Iterable[_ColumnExpressionArgument[Any]] | _ColumnExpressionArgument[Any] | None = None, order_by: Iterable[_ColumnExpressionArgument[Any]] | _ColumnExpressionArgument[Any] | None = None, range_: typing_Tuple[int | None, int | None] | None = None, rows: typing_Tuple[int | None, int | None] | None = None, groups: typing_Tuple[int | None, int | None] | None = None) → Over[_T]
Produce an OVER clause against this filtered function.
Used against aggregate or so-called “window” functions, for database backends that support window functions.
The expression:
func.rank().filter(MyClass.y > 5).over(order_by="x")
is shorthand for:
from sqlalchemy import over, funcfilter

over(funcfilter(func.rank(), MyClass.y > 5), order_by="x")
See over() for a full description.
method sqlalchemy.sql.expression.FunctionFilter.self_group(against: OperatorType | None = None) → Self | Grouping[_T]
Apply a ‘grouping’ to this ClauseElement.
This method is overridden by subclasses to return a “grouping” construct, i.e. parenthesis. In particular it’s used by “binary” expressions to provide a grouping around themselves when placed into a larger expression, as well as by select() constructs when placed into the FROM clause of another select(). (Note that subqueries should be normally created using the Select.alias() method, as many platforms require nested SELECT statements to be named).
As expressions are composed together, the application of self_group() is automatic - end-user code should never need to use this method directly. Note that SQLAlchemy’s clause constructs take operator precedence into account - so parenthesis might not be needed, for example, in an expression like x OR (y AND z) - AND takes precedence over OR.
The base self_group() method of ClauseElement just returns self.
method sqlalchemy.sql.expression.FunctionFilter.within_group(*order_by: _ColumnExpressionArgument[Any]) → WithinGroup[_T]
Produce a WITHIN GROUP (ORDER BY expr) clause against this function.
class sqlalchemy.sql.expression.Label
Represents a column label (AS).
Represent a label, as typically applied to any column-level element using the AS sql keyword.
Members
foreign_keys, primary_key, self_group()
Class signature
class sqlalchemy.sql.expression.Label (sqlalchemy.sql.roles.LabeledColumnExprRole, sqlalchemy.sql.expression.NamedColumn)
attribute sqlalchemy.sql.expression.Label.foreign_keys: AbstractSet[ForeignKey]
attribute sqlalchemy.sql.expression.Label.primary_key: bool
method sqlalchemy.sql.expression.Label.self_group(against: OperatorType | None = None) → Label[_T]
Apply a ‘grouping’ to this ClauseElement.
This method is overridden by subclasses to return a “grouping” construct, i.e. parenthesis. In particular it’s used by “binary” expressions to provide a grouping around themselves when placed into a larger expression, as well as by select() constructs when placed into the FROM clause of another select(). (Note that subqueries should be normally created using the Select.alias() method, as many platforms require nested SELECT statements to be named).
As expressions are composed together, the application of self_group() is automatic - end-user code should never need to use this method directly. Note that SQLAlchemy’s clause constructs take operator precedence into account - so parenthesis might not be needed, for example, in an expression like x OR (y AND z) - AND takes precedence over OR.
The base self_group() method of ClauseElement just returns self.
class sqlalchemy.sql.expression.Null
Represent the NULL keyword in a SQL statement.
Null is accessed as a constant via the null() function.
Class signature
class sqlalchemy.sql.expression.Null (sqlalchemy.sql.expression.SingletonConstant, sqlalchemy.sql.roles.ConstExprRole, sqlalchemy.sql.expression.ColumnElement)
class sqlalchemy.sql.expression.Operators
Base of comparison and logical operators.
Implements base methods Operators.operate() and Operators.reverse_operate(), as well as Operators.__and__(), Operators.__or__(), Operators.__invert__().
Members
__and__(), __invert__(), __or__(), __sa_operate__(), bool_op(), op(), operate(), reverse_operate()
Usually is used via its most common subclass ColumnOperators.
method sqlalchemy.sql.expression.Operators.__and__(other: Any) → Operators
Implement the & operator.
When used with SQL expressions, results in an AND operation, equivalent to and_(), that is:
a & b
is equivalent to:
from sqlalchemy import and_

and_(a, b)
Care should be taken when using & regarding operator precedence; the & operator has the highest precedence. The operands should be enclosed in parenthesis if they contain further sub expressions:
(a == 2) & (b == 4)
method sqlalchemy.sql.expression.Operators.__invert__() → Operators
Implement the ~ operator.
When used with SQL expressions, results in a NOT operation, equivalent to not_(), that is:
~a
is equivalent to:
from sqlalchemy import not_

not_(a)
method sqlalchemy.sql.expression.Operators.__or__(other: Any) → Operators
Implement the | operator.
When used with SQL expressions, results in an OR operation, equivalent to or_(), that is:
a | b
is equivalent to:
from sqlalchemy import or_

or_(a, b)
Care should be taken when using | regarding operator precedence; the | operator has the highest precedence. The operands should be enclosed in parenthesis if they contain further sub expressions:
(a == 2) | (b == 4)
method sqlalchemy.sql.expression.Operators.__sa_operate__(op: OperatorType, *other: Any, **kwargs: Any) → Operators
Operate on an argument.
This is the lowest level of operation, raises NotImplementedError by default.
Overriding this on a subclass can allow common behavior to be applied to all operations. For example, overriding ColumnOperators to apply func.lower() to the left and right side:
class MyComparator(ColumnOperators):
    def operate(self, op, other, **kwargs):
        return op(func.lower(self), func.lower(other), **kwargs)
Parameters:
• op – Operator callable.
• *other – the ‘other’ side of the operation. Will be a single scalar for most operations.
• **kwargs – modifiers. These may be passed by special operators such as ColumnOperators.contains().
method sqlalchemy.sql.expression.Operators.bool_op(opstring: str, precedence: int = 0, python_impl: Callable[[...], Any] | None = None) → Callable[[Any], Operators]
Return a custom boolean operator.
This method is shorthand for calling Operators.op() and passing the Operators.op.is_comparison flag with True. A key advantage to using Operators.bool_op() is that when using column constructs, the “boolean” nature of the returned expression will be present for PEP 484 purposes.
See also
Operators.op()
method sqlalchemy.sql.expression.Operators.op(opstring: str, precedence: int = 0, is_comparison: bool = False, return_type: Type[TypeEngine[Any]] | TypeEngine[Any] | None = None, python_impl: Callable[..., Any] | None = None) → Callable[[Any], Operators]
Produce a generic operator function.
e.g.:
somecolumn.op("*")(5)
produces:
somecolumn * 5
This function can also be used to make bitwise operators explicit. For example:
somecolumn.op("&")(0xFF)
is a bitwise AND of the value in somecolumn.
Parameters:
• opstring – a string which will be output as the infix operator between this element and the expression passed to the generated function.
• precedence – 
precedence which the database is expected to apply to the operator in SQL expressions. This integer value acts as a hint for the SQL compiler to know when explicit parenthesis should be rendered around a particular operation. A lower number will cause the expression to be parenthesized when applied against another operator with higher precedence. The default value of 0 is lower than all operators except for the comma (,) and AS operators. A value of 100 will be higher or equal to all operators, and -100 will be lower than or equal to all operators.
See also
I’m using op() to generate a custom operator and my parenthesis are not coming out correctly - detailed description of how the SQLAlchemy SQL compiler renders parenthesis
• is_comparison – 
legacy; if True, the operator will be considered as a “comparison” operator, that is which evaluates to a boolean true/false value, like ==, >, etc. This flag is provided so that ORM relationships can establish that the operator is a comparison operator when used in a custom join condition.
Using the is_comparison parameter is superseded by using the Operators.bool_op() method instead; this more succinct operator sets this parameter automatically, but also provides correct PEP 484 typing support as the returned object will express a “boolean” datatype, i.e. BinaryExpression[bool].
• return_type – a TypeEngine class or object that will force the return type of an expression produced by this operator to be of that type. By default, operators that specify Operators.op.is_comparison will resolve to Boolean, and those that do not will be of the same type as the left-hand operand.
• python_impl – 
an optional Python function that can evaluate two Python values in the same way as this operator works when run on the database server. Useful for in-Python SQL expression evaluation functions, such as for ORM hybrid attributes, and the ORM “evaluator” used to match objects in a session after a multi-row update or delete.
e.g.:
>>> expr = column("x").op("+", python_impl=lambda a, b: a + b)("y")
The operator for the above expression will also work for non-SQL left and right objects:
>>> expr.operator(5, 10)
15
• Added in version 2.0.
See also
Operators.bool_op()
Redefining and Creating New Operators
Using custom operators in join conditions
method sqlalchemy.sql.expression.Operators.operate(op: OperatorType, *other: Any, **kwargs: Any) → Operators
Operate on an argument.
This is the lowest level of operation, raises NotImplementedError by default.
Overriding this on a subclass can allow common behavior to be applied to all operations. For example, overriding ColumnOperators to apply func.lower() to the left and right side:
class MyComparator(ColumnOperators):
    def operate(self, op, other, **kwargs):
        return op(func.lower(self), func.lower(other), **kwargs)
Parameters:
• op – Operator callable.
• *other – the ‘other’ side of the operation. Will be a single scalar for most operations.
• **kwargs – modifiers. These may be passed by special operators such as ColumnOperators.contains().
method sqlalchemy.sql.expression.Operators.reverse_operate(op: OperatorType, other: Any, **kwargs: Any) → Operators
Reverse operate on an argument.
Usage is the same as operate().
class sqlalchemy.sql.expression.Over
Represent an OVER clause.
This is a special operator against a so-called “window” function, as well as any aggregate function, which produces results relative to the result set itself. Most modern SQL backends now support window functions.
Members
element
Class signature
class sqlalchemy.sql.expression.Over (sqlalchemy.sql.expression.ColumnElement)
attribute sqlalchemy.sql.expression.Over.element: ColumnElement[_T]
The underlying expression object to which this Over object refers.
class sqlalchemy.sql.expression.SQLColumnExpression
A type that may be used to indicate any SQL column element or object that acts in place of one.
SQLColumnExpression is a base of ColumnElement, as well as within the bases of ORM elements such as InstrumentedAttribute, and may be used in PEP 484 typing to indicate arguments or return values that should behave as column expressions.
Added in version 2.0.0b4.
Class signature
class sqlalchemy.sql.expression.SQLColumnExpression (sqlalchemy.sql.expression.SQLCoreOperations, sqlalchemy.sql.roles.ExpressionElementRole, sqlalchemy.util.langhelpers.TypingOnly)
class sqlalchemy.sql.expression.TextClause
Represent a literal SQL text fragment.
E.g.:
from sqlalchemy import text

t = text("SELECT * FROM users")
result = connection.execute(t)
The TextClause construct is produced using the text() function; see that function for full documentation.
See also
text()
Members
bindparams(), columns(), self_group()
Class signature
class sqlalchemy.sql.expression.TextClause (sqlalchemy.sql.roles.DDLConstraintColumnRole, sqlalchemy.sql.roles.DDLExpressionRole, sqlalchemy.sql.roles.StatementOptionRole, sqlalchemy.sql.roles.WhereHavingRole, sqlalchemy.sql.roles.OrderByRole, sqlalchemy.sql.roles.FromClauseRole, sqlalchemy.sql.roles.SelectStatementRole, sqlalchemy.sql.roles.InElementRole, sqlalchemy.sql.expression.Generative, sqlalchemy.sql.expression.Executable, sqlalchemy.sql.expression.DQLDMLClauseElement, sqlalchemy.sql.roles.BinaryElementRole, sqlalchemy.inspection.Inspectable)
method sqlalchemy.sql.expression.TextClause.bindparams(*binds: BindParameter[Any], **names_to_values: Any) → Self
Establish the values and/or types of bound parameters within this TextClause construct.
Given a text construct such as:
from sqlalchemy import text

stmt = text(
    "SELECT id, name FROM user WHERE name=:name AND timestamp=:timestamp"
)
the TextClause.bindparams() method can be used to establish the initial value of :name and :timestamp, using simple keyword arguments:
stmt = stmt.bindparams(
    name="jack", timestamp=datetime.datetime(2012, 10, 8, 15, 12, 5)
)
Where above, new BindParameter objects will be generated with the names name and timestamp, and values of jack and datetime.datetime(2012, 10, 8, 15, 12, 5), respectively. The types will be inferred from the values given, in this case String and DateTime.
When specific typing behavior is needed, the positional *binds argument can be used in which to specify bindparam() constructs directly. These constructs must include at least the key argument, then an optional value and type:
from sqlalchemy import bindparam

stmt = stmt.bindparams(
    bindparam("name", value="jack", type_=String),
    bindparam("timestamp", type_=DateTime),
)
Above, we specified the type of DateTime for the timestamp bind, and the type of String for the name bind. In the case of name we also set the default value of "jack".
Additional bound parameters can be supplied at statement execution time, e.g.:
result = connection.execute(
    stmt, timestamp=datetime.datetime(2012, 10, 8, 15, 12, 5)
)
The TextClause.bindparams() method can be called repeatedly, where it will re-use existing BindParameter objects to add new information. For example, we can call TextClause.bindparams() first with typing information, and a second time with value information, and it will be combined:
stmt = text(
    "SELECT id, name FROM user WHERE name=:name "
    "AND timestamp=:timestamp"
)
stmt = stmt.bindparams(
    bindparam("name", type_=String), bindparam("timestamp", type_=DateTime)
)
stmt = stmt.bindparams(
    name="jack", timestamp=datetime.datetime(2012, 10, 8, 15, 12, 5)
)
The TextClause.bindparams() method also supports the concept of unique bound parameters. These are parameters that are “uniquified” on name at statement compilation time, so that multiple text() constructs may be combined together without the names conflicting. To use this feature, specify the BindParameter.unique flag on each bindparam() object:
stmt1 = text("select id from table where name=:name").bindparams(
    bindparam("name", value="name1", unique=True)
)
stmt2 = text("select id from table where name=:name").bindparams(
    bindparam("name", value="name2", unique=True)
)

union = union_all(stmt1.columns(column("id")), stmt2.columns(column("id")))
The above statement will render as:
select id from table where name=:name_1
UNION ALL select id from table where name=:name_2
Added in version 1.3.11: Added support for the BindParameter.unique flag to work with text() constructs.
method sqlalchemy.sql.expression.TextClause.columns(*cols: _ColumnExpressionArgument[Any], **types: _TypeEngineArgument[Any]) → TextualSelect
Turn this TextClause object into a TextualSelect object that serves the same role as a SELECT statement.
The TextualSelect is part of the SelectBase hierarchy and can be embedded into another statement by using the TextualSelect.subquery() method to produce a Subquery object, which can then be SELECTed from.
This function essentially bridges the gap between an entirely textual SELECT statement and the SQL expression language concept of a “selectable”:
from sqlalchemy.sql import column, text

stmt = text("SELECT id, name FROM some_table")
stmt = stmt.columns(column("id"), column("name")).subquery("st")

stmt = (
    select(mytable)
    .select_from(mytable.join(stmt, mytable.c.name == stmt.c.name))
    .where(stmt.c.id > 5)
)
Above, we pass a series of column() elements to the TextClause.columns() method positionally. These column() elements now become first class elements upon the TextualSelect.selected_columns column collection, which then become part of the Subquery.c collection after TextualSelect.subquery() is invoked.
The column expressions we pass to TextClause.columns() may also be typed; when we do so, these TypeEngine objects become the effective return type of the column, so that SQLAlchemy’s result-set-processing systems may be used on the return values. This is often needed for types such as date or boolean types, as well as for unicode processing on some dialect configurations:
stmt = text("SELECT id, name, timestamp FROM some_table")
stmt = stmt.columns(
    column("id", Integer),
    column("name", Unicode),
    column("timestamp", DateTime),
)

for id, name, timestamp in connection.execute(stmt):
    print(id, name, timestamp)
As a shortcut to the above syntax, keyword arguments referring to types alone may be used, if only type conversion is needed:
stmt = text("SELECT id, name, timestamp FROM some_table")
stmt = stmt.columns(id=Integer, name=Unicode, timestamp=DateTime)

for id, name, timestamp in connection.execute(stmt):
    print(id, name, timestamp)
The positional form of TextClause.columns() also provides the unique feature of positional column targeting, which is particularly useful when using the ORM with complex textual queries. If we specify the columns from our model to TextClause.columns(), the result set will match to those columns positionally, meaning the name or origin of the column in the textual SQL doesn’t matter:
stmt = text(
    "SELECT users.id, addresses.id, users.id, "
    "users.name, addresses.email_address AS email "
    "FROM users JOIN addresses ON users.id=addresses.user_id "
    "WHERE users.id = 1"
).columns(
    User.id,
    Address.id,
    Address.user_id,
    User.name,
    Address.email_address,
)

query = (
    session.query(User)
    .from_statement(stmt)
    .options(contains_eager(User.addresses))
)
The TextClause.columns() method provides a direct route to calling FromClause.subquery() as well as SelectBase.cte() against a textual SELECT statement:
stmt = stmt.columns(id=Integer, name=String).cte("st")

stmt = select(sometable).where(sometable.c.id == stmt.c.id)
Parameters:
• *cols – A series of ColumnElement objects, typically Column objects from a Table or ORM level column-mapped attributes, representing a set of columns that this textual string will SELECT from.
• **types – A mapping of string names to TypeEngine type objects indicating the datatypes to use for names that are SELECTed from the textual string. Prefer to use the *cols argument as it also indicates positional ordering.
method sqlalchemy.sql.expression.TextClause.self_group(against: OperatorType | None = None) → Self | Grouping[Any]
Apply a ‘grouping’ to this ClauseElement.
This method is overridden by subclasses to return a “grouping” construct, i.e. parenthesis. In particular it’s used by “binary” expressions to provide a grouping around themselves when placed into a larger expression, as well as by select() constructs when placed into the FROM clause of another select(). (Note that subqueries should be normally created using the Select.alias() method, as many platforms require nested SELECT statements to be named).
As expressions are composed together, the application of self_group() is automatic - end-user code should never need to use this method directly. Note that SQLAlchemy’s clause constructs take operator precedence into account - so parenthesis might not be needed, for example, in an expression like x OR (y AND z) - AND takes precedence over OR.
The base self_group() method of ClauseElement just returns self.
class sqlalchemy.sql.expression.TryCast
Represent a TRY_CAST expression.
Details on TryCast usage is at try_cast().
See also
try_cast()
Data Casts and Type Coercion
Members
inherit_cache
Class signature
class sqlalchemy.sql.expression.TryCast (sqlalchemy.sql.expression.Cast)
attribute sqlalchemy.sql.expression.TryCast.inherit_cache: bool | None = True
Indicate if this HasCacheKey instance should make use of the cache key generation scheme used by its immediate superclass.
The attribute defaults to None, which indicates that a construct has not yet taken into account whether or not its appropriate for it to participate in caching; this is functionally equivalent to setting the value to False, except that a warning is also emitted.
This flag can be set to True on a particular class, if the SQL that corresponds to the object does not change based on attributes which are local to this class, and not its superclass.
See also
Enabling Caching Support for Custom Constructs - General guideslines for setting the HasCacheKey.inherit_cache attribute for third-party or user defined SQL constructs.
class sqlalchemy.sql.expression.Tuple
Represent a SQL tuple.
Members
self_group()
Class signature
class sqlalchemy.sql.expression.Tuple (sqlalchemy.sql.expression.ClauseList, sqlalchemy.sql.expression.ColumnElement)
method sqlalchemy.sql.expression.Tuple.self_group(against: OperatorType | None = None) → Self
Apply a ‘grouping’ to this ClauseElement.
This method is overridden by subclasses to return a “grouping” construct, i.e. parenthesis. In particular it’s used by “binary” expressions to provide a grouping around themselves when placed into a larger expression, as well as by select() constructs when placed into the FROM clause of another select(). (Note that subqueries should be normally created using the Select.alias() method, as many platforms require nested SELECT statements to be named).
As expressions are composed together, the application of self_group() is automatic - end-user code should never need to use this method directly. Note that SQLAlchemy’s clause constructs take operator precedence into account - so parenthesis might not be needed, for example, in an expression like x OR (y AND z) - AND takes precedence over OR.
The base self_group() method of ClauseElement just returns self.
class sqlalchemy.sql.expression.WithinGroup
Represent a WITHIN GROUP (ORDER BY) clause.
This is a special operator against so-called “ordered set aggregate” and “hypothetical set aggregate” functions, including percentile_cont(), rank(), dense_rank(), etc.
It’s supported only by certain database backends, such as PostgreSQL, Oracle Database and MS SQL Server.
The WithinGroup construct extracts its type from the method FunctionElement.within_group_type(). If this returns None, the function’s .type is used.
Members
filter(), over()
Class signature
class sqlalchemy.sql.expression.WithinGroup (sqlalchemy.sql.expression.ColumnElement)
method sqlalchemy.sql.expression.WithinGroup.filter(*criterion: _ColumnExpressionArgument[bool]) → Self | FunctionFilter[_T]
Produce a FILTER clause against this function.
method sqlalchemy.sql.expression.WithinGroup.over(*, partition_by: _ByArgument | None = None, order_by: _ByArgument | None = None, rows: typing_Tuple[int | None, int | None] | None = None, range_: typing_Tuple[int | None, int | None] | None = None, groups: typing_Tuple[int | None, int | None] | None = None) → Over[_T]
Produce an OVER clause against this WithinGroup construct.
This function has the same signature as that of FunctionElement.over().
class sqlalchemy.sql.elements.WrapsColumnExpression
Mixin that defines a ColumnElement as a wrapper with special labeling behavior for an expression that already has a name.
Added in version 1.4.
See also
Improved column labeling for simple column expressions using CAST or similar
Class signature
class sqlalchemy.sql.expression.WrapsColumnExpression (sqlalchemy.sql.expression.ColumnElement)
class sqlalchemy.sql.expression.True_
Represent the true keyword, or equivalent, in a SQL statement.
True_ is accessed as a constant via the true() function.
Class signature
class sqlalchemy.sql.expression.True_ (sqlalchemy.sql.expression.SingletonConstant, sqlalchemy.sql.roles.ConstExprRole, sqlalchemy.sql.expression.ColumnElement)
class sqlalchemy.sql.expression.TypeCoerce
Represent a Python-side type-coercion wrapper.
TypeCoerce supplies the type_coerce() function; see that function for usage details.
See also
type_coerce()
cast()
Members
self_group()
Class signature
class sqlalchemy.sql.expression.TypeCoerce (sqlalchemy.sql.expression.WrapsColumnExpression)
method sqlalchemy.sql.expression.TypeCoerce.self_group(against: OperatorType | None = None) → TypeCoerce[_T]
Apply a ‘grouping’ to this ClauseElement.
This method is overridden by subclasses to return a “grouping” construct, i.e. parenthesis. In particular it’s used by “binary” expressions to provide a grouping around themselves when placed into a larger expression, as well as by select() constructs when placed into the FROM clause of another select(). (Note that subqueries should be normally created using the Select.alias() method, as many platforms require nested SELECT statements to be named).
As expressions are composed together, the application of self_group() is automatic - end-user code should never need to use this method directly. Note that SQLAlchemy’s clause constructs take operator precedence into account - so parenthesis might not be needed, for example, in an expression like x OR (y AND z) - AND takes precedence over OR.
The base self_group() method of ClauseElement just returns self.
class sqlalchemy.sql.expression.UnaryExpression
Define a ‘unary’ expression.
A unary expression has a single column expression and an operator. The operator can be placed on the left (where it is called the ‘operator’) or right (where it is called the ‘modifier’) of the column expression.
UnaryExpression is the basis for several unary operators including those used by desc(), asc(), distinct(), nulls_first() and nulls_last().
Members
self_group()
Class signature
class sqlalchemy.sql.expression.UnaryExpression (sqlalchemy.sql.expression.ColumnElement)
method sqlalchemy.sql.expression.UnaryExpression.self_group(against: OperatorType | None = None) → Self | Grouping[_T]
Apply a ‘grouping’ to this ClauseElement.
This method is overridden by subclasses to return a “grouping” construct, i.e. parenthesis. In particular it’s used by “binary” expressions to provide a grouping around themselves when placed into a larger expression, as well as by select() constructs when placed into the FROM clause of another select(). (Note that subqueries should be normally created using the Select.alias() method, as many platforms require nested SELECT statements to be named).
As expressions are composed together, the application of self_group() is automatic - end-user code should never need to use this method directly. Note that SQLAlchemy’s clause constructs take operator precedence into account - so parenthesis might not be needed, for example, in an expression like x OR (y AND z) - AND takes precedence over OR.
The base self_group() method of ClauseElement just returns self.
Column Element Typing Utilities
Standalone utility functions imported from the sqlalchemy namespace to improve support by type checkers.
Object NameDescriptionNotNullable(val)Types a column or ORM class as not nullable.Nullable(val)Types a column or ORM class as nullable.function sqlalchemy.NotNullable(val: _TypedColumnClauseArgument[_T | None] | Type[_T] | None) → _TypedColumnClauseArgument[_T]
Types a column or ORM class as not nullable.
This can be used in select and other contexts to express that the value of a column cannot be null, for example due to a where condition on a nullable column:
stmt = select(NotNullable(A.value)).where(A.value.is_not(None))
At runtime this method returns the input unchanged.
Added in version 2.0.20.
function sqlalchemy.Nullable(val: _TypedColumnClauseArgument[_T]) → _TypedColumnClauseArgument[_T | None]
Types a column or ORM class as nullable.
This can be used in select and other contexts to express that the value of a column can be null, for example due to an outer join:
stmt1 = select(A, Nullable(B)).outerjoin(A.bs)
stmt2 = select(A.data, Nullable(B.data)).outerjoin(A.bs)
At runtime this method returns the input unchanged.
Added in version 2.0.20.
Operator Reference
This section details usage of the operators that are available to construct SQL expressions.
These methods are presented in terms of the Operators and ColumnOperators base classes. The methods are then available on descendants of these classes, including:
• Column objects
• ColumnElement objects more generally, which are the root of all Core SQL Expression language column-level expressions
• InstrumentedAttribute objects, which are ORM level mapped attributes.
The operators are first introduced in the tutorial sections, including:
• SQLAlchemy Unified Tutorial - unified tutorial in 2.0 style
• Object Relational Tutorial - ORM tutorial in 1.x style
• SQL Expression Language Tutorial - Core tutorial in 1.x style
Comparison Operators
Basic comparisons which apply to many datatypes, including numerics, strings, dates, and many others:
• ColumnOperators.__eq__() (Python “==” operator):
• >>> print(column("x") == 5)
• x = :x_1
ColumnOperators.__ne__() (Python “!=” operator):
>>> print(column("x") != 5)
x != :x_1
ColumnOperators.__gt__() (Python “>” operator):
>>> print(column("x") > 5)
x > :x_1
ColumnOperators.__lt__() (Python “<” operator):
>>> print(column("x") < 5)
x < :x_1
ColumnOperators.__ge__() (Python “>=” operator):
>>> print(column("x") >= 5)
x >= :x_1
ColumnOperators.__le__() (Python “<=” operator):
>>> print(column("x") <= 5)
x <= :x_1
ColumnOperators.between():
>>> print(column("x").between(5, 10))
x BETWEEN :x_1 AND :x_2
IN Comparisons
The SQL IN operator is a subject all its own in SQLAlchemy. As the IN operator is usually used against a list of fixed values, SQLAlchemy’s feature of bound parameter coercion makes use of a special form of SQL compilation that renders an interim SQL string for compilation that’s formed into the final list of bound parameters in a second step. In other words, “it just works”.
IN against a list of values
IN is available most typically by passing a list of values to the ColumnOperators.in_() method:
>>> print(column("x").in_([1, 2, 3]))
x IN (__[POSTCOMPILE_x_1])
The special bound form __[POSTCOMPILE is rendered into individual parameters at execution time, illustrated below:
>>> stmt = select(User.id).where(User.id.in_([1, 2, 3]))
>>> result = conn.execute(stmt)
SELECT user_account.id
FROM user_account
WHERE user_account.id IN (?, ?, ?)
[...] (1, 2, 3)
Empty IN Expressions
SQLAlchemy produces a mathematically valid result for an empty IN expression by rendering a backend-specific subquery that returns no rows. Again in other words, “it just works”:
>>> stmt = select(User.id).where(User.id.in_([]))
>>> result = conn.execute(stmt)
SELECT user_account.id
FROM user_account
WHERE user_account.id IN (SELECT 1 FROM (SELECT 1) WHERE 1!=1)
[...] ()
The “empty set” subquery above generalizes correctly and is also rendered in terms of the IN operator which remains in place.
NOT IN
“NOT IN” is available via the ColumnOperators.not_in() operator:
>>> print(column("x").not_in([1, 2, 3]))
(x NOT IN (__[POSTCOMPILE_x_1]))
This is typically more easily available by negating with the ~ operator:
>>> print(~column("x").in_([1, 2, 3]))
(x NOT IN (__[POSTCOMPILE_x_1]))
Tuple IN Expressions
Comparison of tuples to tuples is common with IN, as among other use cases accommodates for the case when matching rows to a set of potential composite primary key values. The tuple_() construct provides the basic building block for tuple comparisons. The Tuple.in_() operator then receives a list of tuples:
>>> from sqlalchemy import tuple_
>>> tup = tuple_(column("x", Integer), column("y", Integer))
>>> expr = tup.in_([(1, 2), (3, 4)])
>>> print(expr)
(x, y) IN (__[POSTCOMPILE_param_1])
To illustrate the parameters rendered:
>>> tup = tuple_(User.id, Address.id)
>>> stmt = select(User.name).join(Address).where(tup.in_([(1, 1), (2, 2)]))
>>> conn.execute(stmt).all()
SELECT user_account.name
FROM user_account JOIN address ON user_account.id = address.user_id
WHERE (user_account.id, address.id) IN (VALUES (?, ?), (?, ?))
[...] (1, 1, 2, 2)
[('spongebob',), ('sandy',)]
Subquery IN
Finally, the ColumnOperators.in_() and ColumnOperators.not_in() operators work with subqueries. The form provides that a Select construct is passed in directly, without any explicit conversion to a named subquery:
>>> print(column("x").in_(select(user_table.c.id)))
x IN (SELECT user_account.id
FROM user_account)
Tuples work as expected:
>>> print(
...     tuple_(column("x"), column("y")).in_(
...         select(user_table.c.id, address_table.c.id).join(address_table)
...     )
... )
(x, y) IN (SELECT user_account.id, address.id
FROM user_account JOIN address ON user_account.id = address.user_id)
Identity Comparisons
These operators involve testing for special SQL values such as NULL, boolean constants such as true or false which some databases support:
• ColumnOperators.is_():
This operator will provide exactly the SQL for “x IS y”, most often seen as “<expr> IS NULL”. The NULL constant is most easily acquired using regular Python None:
>>> print(column("x").is_(None))
x IS NULL
SQL NULL is also explicitly available, if needed, using the null() construct:
>>> from sqlalchemy import null
>>> print(column("x").is_(null()))
x IS NULL
The ColumnOperators.is_() operator is automatically invoked when using the ColumnOperators.__eq__() overloaded operator, i.e. ==, in conjunction with the None or null() value. In this way, there’s typically not a need to use ColumnOperators.is_() explicitly, particularly when used with a dynamic value:
>>> a = None
>>> print(column("x") == a)
x IS NULL
•  Note that the Python is operator is not overloaded. Even though Python provides hooks to overload operators such as == and !=, it does not provide any way to redefine is.
•  ColumnOperators.is_not():
Similar to ColumnOperators.is_(), produces “IS NOT”:
>>> print(column("x").is_not(None))
x IS NOT NULL
Is similarly equivalent to != None:
>>> print(column("x") != None)
x IS NOT NULL
ColumnOperators.is_distinct_from():
Produces SQL IS DISTINCT FROM:
>>> print(column("x").is_distinct_from("some value"))
x IS DISTINCT FROM :x_1
ColumnOperators.isnot_distinct_from():
Produces SQL IS NOT DISTINCT FROM:
>>> print(column("x").isnot_distinct_from("some value"))
x IS NOT DISTINCT FROM :x_1
String Comparisons
• ColumnOperators.like():
• >>> print(column("x").like("word"))
• x LIKE :x_1
ColumnOperators.ilike():
Case insensitive LIKE makes use of the SQL lower() function on a generic backend. On the PostgreSQL backend it will use ILIKE:
>>> print(column("x").ilike("word"))
lower(x) LIKE lower(:x_1)
ColumnOperators.notlike():
>>> print(column("x").notlike("word"))
x NOT LIKE :x_1
ColumnOperators.notilike():
>>> print(column("x").notilike("word"))
lower(x) NOT LIKE lower(:x_1)
String Containment
String containment operators are basically built as a combination of LIKE and the string concatenation operator, which is || on most backends or sometimes a function like concat():
• ColumnOperators.startswith():
• >>> print(column("x").startswith("word"))
• x LIKE :x_1 || '%'
ColumnOperators.endswith():
>>> print(column("x").endswith("word"))
x LIKE '%' || :x_1
ColumnOperators.contains():
>>> print(column("x").contains("word"))
x LIKE '%' || :x_1 || '%'
String matching
Matching operators are always backend-specific and may provide different behaviors and results on different databases:
• ColumnOperators.match():
This is a dialect-specific operator that makes use of the MATCH feature of the underlying database, if available:
>>> print(column("x").match("word"))
x MATCH :x_1
ColumnOperators.regexp_match():
This operator is dialect specific. We can illustrate it in terms of for example the PostgreSQL dialect:
>>> from sqlalchemy.dialects import postgresql
>>> print(column("x").regexp_match("word").compile(dialect=postgresql.dialect()))
x ~ %(x_1)s
Or MySQL:
>>> from sqlalchemy.dialects import mysql
>>> print(column("x").regexp_match("word").compile(dialect=mysql.dialect()))
x REGEXP %s
String Alteration
• ColumnOperators.concat():
String concatenation:
>>> print(column("x").concat("some string"))
x || :x_1
This operator is available via ColumnOperators.__add__(), that is, the Python + operator, when working with a column expression that derives from String:
>>> print(column("x", String) + "some string")
x || :x_1
The operator will produce the appropriate database-specific construct, such as on MySQL it’s historically been the concat() SQL function:
>>> print((column("x", String) + "some string").compile(dialect=mysql.dialect()))
concat(x, %s)
ColumnOperators.regexp_replace():
Complementary to ColumnOperators.regexp() this produces REGEXP REPLACE equivalent for the backends which support it:
>>> print(column("x").regexp_replace("foo", "bar").compile(dialect=postgresql.dialect()))
REGEXP_REPLACE(x, %(x_1)s, %(x_2)s)
ColumnOperators.collate():
Produces the COLLATE SQL operator which provides for specific collations at expression time:
>>> print(
...     (column("x").collate("latin1_german2_ci") == "Müller").compile(
...         dialect=mysql.dialect()
...     )
... )
(x COLLATE latin1_german2_ci) = %s
To use COLLATE against a literal value, use the literal() construct:
>>> from sqlalchemy import literal
>>> print(
...     (literal("Müller").collate("latin1_german2_ci") == column("x")).compile(
...         dialect=mysql.dialect()
...     )
... )
(%s COLLATE latin1_german2_ci) = x
Arithmetic Operators
• ColumnOperators.__add__(), ColumnOperators.__radd__() (Python “+” operator):
• >>> print(column("x") + 5)
• x + :x_1
• >>> print(5 + column("x"))
• :x_1 + x
•  Note that when the datatype of the expression is String or similar, the ColumnOperators.__add__() operator instead produces string concatenation.
•  ColumnOperators.__sub__(), ColumnOperators.__rsub__() (Python “-” operator):
>>> print(column("x") - 5)
x - :x_1
>>> print(5 - column("x"))
:x_1 - x
ColumnOperators.__mul__(), ColumnOperators.__rmul__() (Python “*” operator):
>>> print(column("x") * 5)
x * :x_1
>>> print(5 * column("x"))
:x_1 * x
ColumnOperators.__truediv__(), ColumnOperators.__rtruediv__() (Python “/” operator). This is the Python truediv operator, which will ensure integer true division occurs:
>>> print(column("x") / 5)
x / CAST(:x_1 AS NUMERIC)
>>> print(5 / column("x"))
:x_1 / CAST(x AS NUMERIC)
•  Changed in version 2.0: The Python / operator now ensures integer true division takes place
•  ColumnOperators.__floordiv__(), ColumnOperators.__rfloordiv__() (Python “//” operator). This is the Python floordiv operator, which will ensure floor division occurs. For the default backend as well as backends such as PostgreSQL, the SQL / operator normally behaves this way for integer values:
>>> print(column("x") // 5)
x / :x_1
>>> print(5 // column("x", Integer))
:x_1 / x
For backends that don’t use floor division by default, or when used with numeric values, the FLOOR() function is used to ensure floor division:
>>> print(column("x") // 5.5)
FLOOR(x / :x_1)
>>> print(5 // column("x", Numeric))
FLOOR(:x_1 / x)
•  Added in version 2.0: Support for FLOOR division
•  ColumnOperators.__mod__(), ColumnOperators.__rmod__() (Python “%” operator):
>>> print(column("x") % 5)
x % :x_1
>>> print(5 % column("x"))
:x_1 % x
Bitwise Operators
Bitwise operator functions provide uniform access to bitwise operators across different backends, which are expected to operate on compatible values such as integers and bit-strings (e.g. PostgreSQL BIT and similar). Note that these are not general boolean operators.
Added in version 2.0.2: Added dedicated operators for bitwise operations.
• ColumnOperators.bitwise_not(), bitwise_not(). Available as a column-level method, producing a bitwise NOT clause against a parent object:
• >>> print(column("x").bitwise_not())
~x
This operator is also available as a column-expression-level method, applying bitwise NOT to an individual column expression:
>>> from sqlalchemy import bitwise_not
>>> print(bitwise_not(column("x")))
~x
ColumnOperators.bitwise_and() produces bitwise AND:
>>> print(column("x").bitwise_and(5))
x & :x_1
ColumnOperators.bitwise_or() produces bitwise OR:
>>> print(column("x").bitwise_or(5))
x | :x_1
ColumnOperators.bitwise_xor() produces bitwise XOR:
>>> print(column("x").bitwise_xor(5))
x ^ :x_1
For PostgreSQL dialects, “#” is used to represent bitwise XOR; this emits automatically when using one of these backends:
>>> from sqlalchemy.dialects import postgresql
>>> print(column("x").bitwise_xor(5).compile(dialect=postgresql.dialect()))
x # %(x_1)s
ColumnOperators.bitwise_rshift(), ColumnOperators.bitwise_lshift() produce bitwise shift operators:
>>> print(column("x").bitwise_rshift(5))
x >> :x_1
>>> print(column("x").bitwise_lshift(5))
x << :x_1
Using Conjunctions and Negations
The most common conjunction, “AND”, is automatically applied if we make repeated use of the Select.where() method, as well as similar methods such as Update.where() and Delete.where():
>>> print(
...     select(address_table.c.email_address)
...     .where(user_table.c.name == "squidward")
...     .where(address_table.c.user_id == user_table.c.id)
... )
SELECT address.email_address
FROM address, user_account
WHERE user_account.name = :name_1 AND address.user_id = user_account.id
Select.where(), Update.where() and Delete.where() also accept multiple expressions with the same effect:
>>> print(
...     select(address_table.c.email_address).where(
...         user_table.c.name == "squidward",
...         address_table.c.user_id == user_table.c.id,
...     )
... )
SELECT address.email_address
FROM address, user_account
WHERE user_account.name = :name_1 AND address.user_id = user_account.id
The “AND” conjunction, as well as its partner “OR”, are both available directly using the and_() and or_() functions:
>>> from sqlalchemy import and_, or_
>>> print(
...     select(address_table.c.email_address).where(
...         and_(
...             or_(user_table.c.name == "squidward", user_table.c.name == "sandy"),
...             address_table.c.user_id == user_table.c.id,
...         )
...     )
... )
SELECT address.email_address
FROM address, user_account
WHERE (user_account.name = :name_1 OR user_account.name = :name_2)
AND address.user_id = user_account.id
A negation is available using the not_() function. This will typically invert the operator in a boolean expression:
>>> from sqlalchemy import not_
>>> print(not_(column("x") == 5))
x != :x_1
It also may apply a keyword such as NOT when appropriate:
>>> from sqlalchemy import Boolean
>>> print(not_(column("x", Boolean)))
NOT x
Conjunction Operators
The above conjunction functions and_(), or_(), not_() are also available as overloaded Python operators:
Note
The Python &, | and ~ operators take high precedence in the language; as a result, parenthesis must usually be applied for operands that themselves contain expressions, as indicated in the examples below.
• Operators.__and__() (Python “&” operator):
The Python binary & operator is overloaded to behave the same as and_() (note parenthesis around the two operands):
>>> print((column("x") == 5) & (column("y") == 10))
x = :x_1 AND y = :y_1
Operators.__or__() (Python “|” operator):
The Python binary | operator is overloaded to behave the same as or_() (note parenthesis around the two operands):
>>> print((column("x") == 5) | (column("y") == 10))
x = :x_1 OR y = :y_1
Operators.__invert__() (Python “~” operator):
The Python binary ~ operator is overloaded to behave the same as not_(), either inverting the existing operator, or applying the NOT keyword to the expression as a whole:
>>> print(~(column("x") == 5))
x != :x_1
>>> from sqlalchemy import Boolean
>>> print(~column("x", Boolean))
NOT x
Parentheses and Grouping
Parenthesization of expressions is rendered based on operator precedence, not the placement of parentheses in Python code, since there is no means of detecting parentheses from interpreted Python expressions. So an expression like:
>>> expr = or_(
...     User.name == "squidward", and_(Address.user_id == User.id, User.name == "sandy")
... )
won’t include parentheses, because the AND operator takes natural precedence over OR:
>>> print(expr)
user_account.name = :name_1 OR address.user_id = user_account.id AND user_account.name = :name_2
Whereas this one, where OR would otherwise not be evaluated before the AND, does:
>>> expr = and_(
...     Address.user_id == User.id, or_(User.name == "squidward", User.name == "sandy")
... )
>>> print(expr)
address.user_id = user_account.id AND (user_account.name = :name_1 OR user_account.name = :name_2)
The same behavior takes effect for math operators. In the parenthesized Python expression below, the multiplication operator naturally takes precedence over the addition operator, therefore the SQL will not include parentheses:
>>> print(column("q") + (column("x") * column("y")))
q + x * y
Whereas this one, where the addition operator would not otherwise occur before the multiplication operator, does get parentheses:
>>> print(column("q") * (column("x") + column("y")))
q * (x + y)


SELECT and Related Constructs
The term “selectable” refers to any object that represents database rows. In SQLAlchemy, these objects descend from Selectable, the most prominent being Select, which represents a SQL SELECT statement. A subset of Selectable is FromClause, which represents objects that can be within the FROM clause of a Select statement. A distinguishing feature of FromClause is the FromClause.c attribute, which is a namespace of all the columns contained within the FROM clause (these elements are themselves ColumnElement subclasses).
Selectable Foundational Constructors
Top level “FROM clause” and “SELECT” constructors.
Object NameDescriptionexcept_(*selects)Return an EXCEPT of multiple selectables.except_all(*selects)Return an EXCEPT ALL of multiple selectables.exists([__argument])Construct a new Exists construct.intersect(*selects)Return an INTERSECT of multiple selectables.intersect_all(*selects)Return an INTERSECT ALL of multiple selectables.select(*entities, **__kw)Construct a new Select.table(name, *columns, **kw)Produce a new TableClause.union(*selects)Return a UNION of multiple selectables.union_all(*selects)Return a UNION ALL of multiple selectables.values(*columns, [name, literal_binds])Construct a Values construct representing the SQL VALUES clause.function sqlalchemy.sql.expression.except_(*selects: _SelectStatementForCompoundArgument[_TP]) → CompoundSelect[_TP]
Return an EXCEPT of multiple selectables.
The returned object is an instance of CompoundSelect.
Parameters:
*selects – a list of Select instances.
function sqlalchemy.sql.expression.except_all(*selects: _SelectStatementForCompoundArgument[_TP]) → CompoundSelect[_TP]
Return an EXCEPT ALL of multiple selectables.
The returned object is an instance of CompoundSelect.
Parameters:
*selects – a list of Select instances.
function sqlalchemy.sql.expression.exists(__argument: _ColumnsClauseArgument[Any] | SelectBase | ScalarSelect[Any] | None = None) → Exists
Construct a new Exists construct.
The exists() can be invoked by itself to produce an Exists construct, which will accept simple WHERE criteria:
exists_criteria = exists().where(table1.c.col1 == table2.c.col2)
However, for greater flexibility in constructing the SELECT, an existing Select construct may be converted to an Exists, most conveniently by making use of the SelectBase.exists() method:
exists_criteria = (
    select(table2.c.col2).where(table1.c.col1 == table2.c.col2).exists()
)
The EXISTS criteria is then used inside of an enclosing SELECT:
stmt = select(table1.c.col1).where(exists_criteria)
The above statement will then be of the form:
SELECT col1 FROM table1 WHERE EXISTS
(SELECT table2.col2 FROM table2 WHERE table2.col2 = table1.col1)
See also
EXISTS subqueries - in the 2.0 style tutorial.
SelectBase.exists() - method to transform a SELECT to an EXISTS clause.
function sqlalchemy.sql.expression.intersect(*selects: _SelectStatementForCompoundArgument[_TP]) → CompoundSelect[_TP]
Return an INTERSECT of multiple selectables.
The returned object is an instance of CompoundSelect.
Parameters:
*selects – a list of Select instances.
function sqlalchemy.sql.expression.intersect_all(*selects: _SelectStatementForCompoundArgument[_TP]) → CompoundSelect[_TP]
Return an INTERSECT ALL of multiple selectables.
The returned object is an instance of CompoundSelect.
Parameters:
*selects – a list of Select instances.
function sqlalchemy.sql.expression.select(*entities: _ColumnsClauseArgument[Any], **__kw: Any) → Select[Any]
Construct a new Select.
Added in version 1.4: - The select() function now accepts column arguments positionally. The top-level select() function will automatically use the 1.x or 2.x style API based on the incoming arguments; using select() from the sqlalchemy.future module will enforce that only the 2.x style constructor is used.
Similar functionality is also available via the FromClause.select() method on any FromClause.
See also
Using SELECT Statements - in the SQLAlchemy Unified Tutorial
Parameters:
*entities – 
Entities to SELECT from. For Core usage, this is typically a series of ColumnElement and / or FromClause objects which will form the columns clause of the resulting statement. For those objects that are instances of FromClause (typically Table or Alias objects), the FromClause.c collection is extracted to form a collection of ColumnElement objects.
This parameter will also accept TextClause constructs as given, as well as ORM-mapped classes.
function sqlalchemy.sql.expression.table(name: str, *columns: ColumnClause[Any], **kw: Any) → TableClause
Produce a new TableClause.
The object returned is an instance of TableClause, which represents the “syntactical” portion of the schema-level Table object. It may be used to construct lightweight table constructs.
Parameters:
• name – Name of the table.
• columns – A collection of column() constructs.
• schema – 
The schema name for this table.
Added in version 1.3.18: table() can now accept a schema argument.
function sqlalchemy.sql.expression.union(*selects: _SelectStatementForCompoundArgument[_TP]) → CompoundSelect[_TP]
Return a UNION of multiple selectables.
The returned object is an instance of CompoundSelect.
A similar union() method is available on all FromClause subclasses.
Parameters:
• *selects – a list of Select instances.
• **kwargs – available keyword arguments are the same as those of select().
function sqlalchemy.sql.expression.union_all(*selects: _SelectStatementForCompoundArgument[_TP]) → CompoundSelect[_TP]
Return a UNION ALL of multiple selectables.
The returned object is an instance of CompoundSelect.
A similar union_all() method is available on all FromClause subclasses.
Parameters:
*selects – a list of Select instances.
function sqlalchemy.sql.expression.values(*columns: ColumnClause[Any], name: str | None = None, literal_binds: bool = False) → Values
Construct a Values construct representing the SQL VALUES clause.
The column expressions and the actual data for Values are given in two separate steps. The constructor receives the column expressions typically as column() constructs, and the data is then passed via the Values.data() method as a list, which can be called multiple times to add more data, e.g.:
from sqlalchemy import column
from sqlalchemy import values
from sqlalchemy import Integer
from sqlalchemy import String

value_expr = (
    values(
        column("id", Integer),
        column("name", String),
    )
    .data([(1, "name1"), (2, "name2")])
    .data([(3, "name3")])
)
Would represent a SQL fragment like:
VALUES(1, "name1"), (2, "name2"), (3, "name3")
The values construct has an optional values.name field; when using this field, the PostgreSQL-specific “named VALUES” clause may be generated:
value_expr = values(
    column("id", Integer), column("name", String), name="somename"
).data([(1, "name1"), (2, "name2"), (3, "name3")])
When selecting from the above construct, the name and column names will be listed out using a PostgreSQL-specific syntax:
>>> print(value_expr.select())
SELECT somename.id, somename.name
FROM (VALUES (:param_1, :param_2), (:param_3, :param_4),
(:param_5, :param_6)) AS somename (id, name)
For a more database-agnostic means of SELECTing named columns from a VALUES expression, the Values.cte() method may be used, which produces a named CTE with explicit column names against the VALUES construct within; this syntax works on PostgreSQL, SQLite, and MariaDB:
value_expr = (
    values(
        column("id", Integer),
        column("name", String),
    )
    .data([(1, "name1"), (2, "name2"), (3, "name3")])
    .cte()
)
Rendering as:
>>> print(value_expr.select())
WITH anon_1(id, name) AS
(VALUES (:param_1, :param_2), (:param_3, :param_4), (:param_5, :param_6))
SELECT anon_1.id, anon_1.name
FROM anon_1
Added in version 2.0.42: Added the Values.cte() method to Values
Parameters:
• *columns – column expressions, typically composed using column() objects.
• name – the name for this VALUES construct. If omitted, the VALUES construct will be unnamed in a SQL expression. Different backends may have different requirements here.
• literal_binds – Defaults to False. Whether or not to render the data values inline in the SQL output, rather than using bound parameters.
Selectable Modifier Constructors
Functions listed here are more commonly available as methods from FromClause and Selectable elements, for example, the alias() function is usually invoked via the FromClause.alias() method.
Object NameDescriptionalias(selectable[, name, flat])Return a named alias of the given FromClause.cte(selectable[, name, recursive])Return a new CTE, or Common Table Expression instance.join(left, right[, onclause, isouter, ...])Produce a Join object, given two FromClause expressions.lateral(selectable[, name])Return a Lateral object.outerjoin(left, right[, onclause, full])Return an OUTER JOIN clause element.tablesample(selectable, sampling[, name, seed])Return a TableSample object.function sqlalchemy.sql.expression.alias(selectable: FromClause, name: str | None = None, flat: bool = False) → NamedFromClause
Return a named alias of the given FromClause.
For Table and Join objects, the return type is the Alias object. Other kinds of NamedFromClause objects may be returned for other kinds of FromClause objects.
The named alias represents any FromClause with an alternate name assigned within SQL, typically using the AS clause when generated, e.g. SELECT * FROM table AS aliasname.
Equivalent functionality is available via the FromClause.alias() method available on all FromClause objects.
Parameters:
• selectable – any FromClause subclass, such as a table, select statement, etc.
• name – string name to be assigned as the alias. If None, a name will be deterministically generated at compile time. Deterministic means the name is guaranteed to be unique against other constructs used in the same statement, and will also be the same name for each successive compilation of the same statement object.
• flat – Will be passed through to if the given selectable is an instance of Join - see Join.alias() for details.
function sqlalchemy.sql.expression.cte(selectable: HasCTE, name: str | None = None, recursive: bool = False) → CTE
Return a new CTE, or Common Table Expression instance.
Please see HasCTE.cte() for detail on CTE usage.
function sqlalchemy.sql.expression.join(left: _FromClauseArgument, right: _FromClauseArgument, onclause: _OnClauseArgument | None = None, isouter: bool = False, full: bool = False) → Join
Produce a Join object, given two FromClause expressions.
E.g.:
j = join(
    user_table, address_table, user_table.c.id == address_table.c.user_id
)
stmt = select(user_table).select_from(j)
would emit SQL along the lines of:
SELECT user.id, user.name FROM user
JOIN address ON user.id = address.user_id
Similar functionality is available given any FromClause object (e.g. such as a Table) using the FromClause.join() method.
Parameters:
• left – The left side of the join.
• right – the right side of the join; this is any FromClause object such as a Table object, and may also be a selectable-compatible object such as an ORM-mapped class.
• onclause – a SQL expression representing the ON clause of the join. If left at None, FromClause.join() will attempt to join the two tables based on a foreign key relationship.
• isouter – if True, render a LEFT OUTER JOIN, instead of JOIN.
• full – if True, render a FULL OUTER JOIN, instead of JOIN.
See also
FromClause.join() - method form, based on a given left side.
Join - the type of object produced.
function sqlalchemy.sql.expression.lateral(selectable: SelectBase | _FromClauseArgument, name: str | None = None) → LateralFromClause
Return a Lateral object.
Lateral is an Alias subclass that represents a subquery with the LATERAL keyword applied to it.
The special behavior of a LATERAL subquery is that it appears in the FROM clause of an enclosing SELECT, but may correlate to other FROM clauses of that SELECT. It is a special case of subquery only supported by a small number of backends, currently more recent PostgreSQL versions.
See also
LATERAL correlation - overview of usage.
function sqlalchemy.sql.expression.outerjoin(left: _FromClauseArgument, right: _FromClauseArgument, onclause: _OnClauseArgument | None = None, full: bool = False) → Join
Return an OUTER JOIN clause element.
The returned object is an instance of Join.
Similar functionality is also available via the FromClause.outerjoin() method on any FromClause.
Parameters:
• left – The left side of the join.
• right – The right side of the join.
• onclause – Optional criterion for the ON clause, is derived from foreign key relationships established between left and right otherwise.
To chain joins together, use the FromClause.join() or FromClause.outerjoin() methods on the resulting Join object.
function sqlalchemy.sql.expression.tablesample(selectable: _FromClauseArgument, sampling: float | Function[Any], name: str | None = None, seed: roles.ExpressionElementRole[Any] | None = None) → TableSample
Return a TableSample object.
TableSample is an Alias subclass that represents a table with the TABLESAMPLE clause applied to it. tablesample() is also available from the FromClause class via the FromClause.tablesample() method.
The TABLESAMPLE clause allows selecting a randomly selected approximate percentage of rows from a table. It supports multiple sampling methods, most commonly BERNOULLI and SYSTEM.
e.g.:
from sqlalchemy import func

selectable = people.tablesample(
    func.bernoulli(1), name="alias", seed=func.random()
)
stmt = select(selectable.c.people_id)
Assuming people with a column people_id, the above statement would render as:
SELECT alias.people_id FROM
people AS alias TABLESAMPLE bernoulli(:bernoulli_1)
REPEATABLE (random())
Parameters:
• sampling – a float percentage between 0 and 100 or Function.
• name – optional alias name
• seed – any real-valued SQL expression. When specified, the REPEATABLE sub-clause is also rendered.
Selectable Class Documentation
The classes here are generated using the constructors listed at Selectable Foundational Constructors and Selectable Modifier Constructors.
Object NameDescriptionAliasRepresents an table or selectable alias (AS).AliasedReturnsRowsBase class of aliases against tables, subqueries, and other selectables.CompoundSelectForms the basis of UNION, UNION ALL, and other SELECT-based set operations.CTERepresent a Common Table Expression.ExecutableMark a ClauseElement as supporting execution.ExistsRepresent an EXISTS clause.FromClauseRepresent an element that can be used within the FROM clause of a SELECT statement.GenerativeSelectBase class for SELECT statements where additional elements can be added.HasCTEMixin that declares a class to include CTE support.HasPrefixesHasSuffixesJoinRepresent a JOIN construct between two FromClause elements.LateralRepresent a LATERAL subquery.ReturnsRowsThe base-most class for Core constructs that have some concept of columns that can represent rows.ScalarSelectRepresent a scalar subquery.ScalarValuesRepresent a scalar VALUES construct that can be used as a COLUMN element in a statement.SelectRepresents a SELECT statement.SelectableMark a class as being selectable.SelectBaseBase class for SELECT statements.SubqueryRepresent a subquery of a SELECT.TableClauseRepresents a minimal “table” construct.TableSampleRepresent a TABLESAMPLE clause.TableValuedAliasAn alias against a “table valued” SQL function.TextualSelectWrap a TextClause construct within a SelectBase interface.ValuesRepresent a VALUES construct that can be used as a FROM element in a statement.class sqlalchemy.sql.expression.Alias
Represents an table or selectable alias (AS).
Represents an alias, as typically applied to any table or sub-select within a SQL statement using the AS keyword (or without the keyword on certain databases such as Oracle Database).
This object is constructed from the alias() module level function as well as the FromClause.alias() method available on all FromClause subclasses.
See also
FromClause.alias()
Members
inherit_cache
Class signature
class sqlalchemy.sql.expression.Alias (sqlalchemy.sql.roles.DMLTableRole, sqlalchemy.sql.expression.FromClauseAlias)
attribute sqlalchemy.sql.expression.Alias.inherit_cache: bool | None = True
Indicate if this HasCacheKey instance should make use of the cache key generation scheme used by its immediate superclass.
The attribute defaults to None, which indicates that a construct has not yet taken into account whether or not its appropriate for it to participate in caching; this is functionally equivalent to setting the value to False, except that a warning is also emitted.
This flag can be set to True on a particular class, if the SQL that corresponds to the object does not change based on attributes which are local to this class, and not its superclass.
See also
Enabling Caching Support for Custom Constructs - General guideslines for setting the HasCacheKey.inherit_cache attribute for third-party or user defined SQL constructs.
class sqlalchemy.sql.expression.AliasedReturnsRows
Base class of aliases against tables, subqueries, and other selectables.
Members
description, is_derived_from(), original
Class signature
class sqlalchemy.sql.expression.AliasedReturnsRows (sqlalchemy.sql.expression.NoInit, sqlalchemy.sql.expression.NamedFromClause)
attribute sqlalchemy.sql.expression.AliasedReturnsRows.description
method sqlalchemy.sql.expression.AliasedReturnsRows.is_derived_from(fromclause: FromClause | None) → bool
Return True if this FromClause is ‘derived’ from the given FromClause.
An example would be an Alias of a Table is derived from that Table.
attribute sqlalchemy.sql.expression.AliasedReturnsRows.original
Legacy for dialects that are referring to Alias.original.
class sqlalchemy.sql.expression.CompoundSelect
Forms the basis of UNION, UNION ALL, and other SELECT-based set operations.
See also
union()
union_all()
intersect()
intersect_all()
except()
except_all()
Members
add_cte(), alias(), argument_for(), as_scalar(), c, compile(), corresponding_column(), cte(), dialect_kwargs, dialect_options, execution_options(), exists(), exported_columns, fetch(), get_children(), get_execution_options(), get_label_style(), group_by(), inherit_cache, is_derived_from(), kwargs, label(), lateral(), limit(), name_cte_columns, offset(), options(), order_by(), replace_selectable(), scalar_subquery(), select(), selected_columns, self_group(), set_label_style(), slice(), subquery(), with_for_update()
Class signature
class sqlalchemy.sql.expression.CompoundSelect (sqlalchemy.sql.expression.HasCompileState, sqlalchemy.sql.expression.GenerativeSelect, sqlalchemy.sql.expression.TypedReturnsRows)
method sqlalchemy.sql.expression.CompoundSelect.add_cte(*ctes: CTE, nest_here: bool = False) → Self
inherited from the HasCTE.add_cte() method of HasCTE
Add one or more CTE constructs to this statement.
This method will associate the given CTE constructs with the parent statement such that they will each be unconditionally rendered in the WITH clause of the final statement, even if not referenced elsewhere within the statement or any sub-selects.
The optional HasCTE.add_cte.nest_here parameter when set to True will have the effect that each given CTE will render in a WITH clause rendered directly along with this statement, rather than being moved to the top of the ultimate rendered statement, even if this statement is rendered as a subquery within a larger statement.
This method has two general uses. One is to embed CTE statements that serve some purpose without being referenced explicitly, such as the use case of embedding a DML statement such as an INSERT or UPDATE as a CTE inline with a primary statement that may draw from its results indirectly. The other is to provide control over the exact placement of a particular series of CTE constructs that should remain rendered directly in terms of a particular statement that may be nested in a larger statement.
E.g.:
from sqlalchemy import table, column, select

t = table("t", column("c1"), column("c2"))

ins = t.insert().values({"c1": "x", "c2": "y"}).cte()

stmt = select(t).add_cte(ins)
Would render:
WITH anon_1 AS (
    INSERT INTO t (c1, c2) VALUES (:param_1, :param_2)
)
SELECT t.c1, t.c2
FROM t
Above, the “anon_1” CTE is not referenced in the SELECT statement, however still accomplishes the task of running an INSERT statement.
Similarly in a DML-related context, using the PostgreSQL Insert construct to generate an “upsert”:
from sqlalchemy import table, column
from sqlalchemy.dialects.postgresql import insert

t = table("t", column("c1"), column("c2"))

delete_statement_cte = t.delete().where(t.c.c1 < 1).cte("deletions")

insert_stmt = insert(t).values({"c1": 1, "c2": 2})
update_statement = insert_stmt.on_conflict_do_update(
    index_elements=[t.c.c1],
    set_={
        "c1": insert_stmt.excluded.c1,
        "c2": insert_stmt.excluded.c2,
    },
).add_cte(delete_statement_cte)

print(update_statement)
The above statement renders as:
WITH deletions AS (
    DELETE FROM t WHERE t.c1 < %(c1_1)s
)
INSERT INTO t (c1, c2) VALUES (%(c1)s, %(c2)s)
ON CONFLICT (c1) DO UPDATE SET c1 = excluded.c1, c2 = excluded.c2
Added in version 1.4.21.
Parameters:
• *ctes – 
zero or more CTE constructs.
Changed in version 2.0: Multiple CTE instances are accepted
• nest_here – 
if True, the given CTE or CTEs will be rendered as though they specified the HasCTE.cte.nesting flag to True when they were added to this HasCTE. Assuming the given CTEs are not referenced in an outer-enclosing statement as well, the CTEs given should render at the level of this statement when this flag is given.
Added in version 2.0.
See also
HasCTE.cte.nesting
method sqlalchemy.sql.expression.CompoundSelect.alias(name: str | None = None, flat: bool = False) → Subquery
inherited from the SelectBase.alias() method of SelectBase
Return a named subquery against this SelectBase.
For a SelectBase (as opposed to a FromClause), this returns a Subquery object which behaves mostly the same as the Alias object that is used with a FromClause.
Changed in version 1.4: The SelectBase.alias() method is now a synonym for the SelectBase.subquery() method.
classmethod sqlalchemy.sql.expression.CompoundSelect.argument_for(dialect_name, argument_name, default)
inherited from the DialectKWArgs.argument_for() method of DialectKWArgs
Add a new kind of dialect-specific keyword argument for this class.
E.g.:
Index.argument_for("mydialect", "length", None)

some_index = Index("a", "b", mydialect_length=5)
The DialectKWArgs.argument_for() method is a per-argument way adding extra arguments to the DefaultDialect.construct_arguments dictionary. This dictionary provides a list of argument names accepted by various schema-level constructs on behalf of a dialect.
New dialects should typically specify this dictionary all at once as a data member of the dialect class. The use case for ad-hoc addition of argument names is typically for end-user code that is also using a custom compilation scheme which consumes the additional arguments.
Parameters:
• dialect_name – name of a dialect. The dialect must be locatable, else a NoSuchModuleError is raised. The dialect must also include an existing DefaultDialect.construct_arguments collection, indicating that it participates in the keyword-argument validation and default system, else ArgumentError is raised. If the dialect does not include this collection, then any keyword argument can be specified on behalf of this dialect already. All dialects packaged within SQLAlchemy include this collection, however for third party dialects, support may vary.
• argument_name – name of the parameter.
• default – default value of the parameter.
method sqlalchemy.sql.expression.CompoundSelect.as_scalar() → ScalarSelect[Any]
inherited from the SelectBase.as_scalar() method of SelectBase
Deprecated since version 1.4: The SelectBase.as_scalar() method is deprecated and will be removed in a future release. Please refer to SelectBase.scalar_subquery().
attribute sqlalchemy.sql.expression.CompoundSelect.c
inherited from the SelectBase.c attribute of SelectBase
Deprecated since version 1.4: The SelectBase.c and SelectBase.columns attributes are deprecated and will be removed in a future release; these attributes implicitly create a subquery that should be explicit. Please call SelectBase.subquery() first in order to create a subquery, which then contains this attribute. To access the columns that this SELECT object SELECTs from, use the SelectBase.selected_columns attribute.
method sqlalchemy.sql.expression.CompoundSelect.compile(bind: _HasDialect | None = None, dialect: Dialect | None = None, **kw: Any) → Compiled
inherited from the CompilerElement.compile() method of CompilerElement
Compile this SQL expression.
The return value is a Compiled object. Calling str() or unicode() on the returned value will yield a string representation of the result. The Compiled object also can return a dictionary of bind parameter names and values using the params accessor.
Parameters:
• bind – An Connection or Engine which can provide a Dialect in order to generate a Compiled object. If the bind and dialect parameters are both omitted, a default SQL compiler is used.
• column_keys – Used for INSERT and UPDATE statements, a list of column names which should be present in the VALUES clause of the compiled statement. If None, all columns from the target table object are rendered.
• dialect – A Dialect instance which can generate a Compiled object. This argument takes precedence over the bind argument.
• compile_kwargs – 
optional dictionary of additional parameters that will be passed through to the compiler within all “visit” methods. This allows any custom flag to be passed through to a custom compilation construct, for example. It is also used for the case of passing the literal_binds flag through:
from sqlalchemy.sql import table, column, select

t = table("t", column("x"))

s = select(t).where(t.c.x == 5)

print(s.compile(compile_kwargs={"literal_binds": True}))
• 
See also
How do I render SQL expressions as strings, possibly with bound parameters inlined?
method sqlalchemy.sql.expression.CompoundSelect.corresponding_column(column: KeyedColumnElement[Any], require_embedded: bool = False) → KeyedColumnElement[Any] | None
inherited from the Selectable.corresponding_column() method of Selectable
Given a ColumnElement, return the exported ColumnElement object from the Selectable.exported_columns collection of this Selectable which corresponds to that original ColumnElement via a common ancestor column.
Parameters:
• column – the target ColumnElement to be matched.
• require_embedded – only return corresponding columns for the given ColumnElement, if the given ColumnElement is actually present within a sub-element of this Selectable. Normally the column will match if it merely shares a common ancestor with one of the exported columns of this Selectable.
See also
Selectable.exported_columns - the ColumnCollection that is used for the operation.
ColumnCollection.corresponding_column() - implementation method.
method sqlalchemy.sql.expression.CompoundSelect.cte(name: str | None = None, recursive: bool = False, nesting: bool = False) → CTE
inherited from the HasCTE.cte() method of HasCTE
Return a new CTE, or Common Table Expression instance.
Common table expressions are a SQL standard whereby SELECT statements can draw upon secondary statements specified along with the primary statement, using a clause called “WITH”. Special semantics regarding UNION can also be employed to allow “recursive” queries, where a SELECT statement can draw upon the set of rows that have previously been selected.
CTEs can also be applied to DML constructs UPDATE, INSERT and DELETE on some databases, both as a source of CTE rows when combined with RETURNING, as well as a consumer of CTE rows.
SQLAlchemy detects CTE objects, which are treated similarly to Alias objects, as special elements to be delivered to the FROM clause of the statement as well as to a WITH clause at the top of the statement.
For special prefixes such as PostgreSQL “MATERIALIZED” and “NOT MATERIALIZED”, the CTE.prefix_with() method may be used to establish these.
Changed in version 1.3.13: Added support for prefixes. In particular - MATERIALIZED and NOT MATERIALIZED.
Parameters:
• name – name given to the common table expression. Like FromClause.alias(), the name can be left as None in which case an anonymous symbol will be used at query compile time.
• recursive – if True, will render WITH RECURSIVE. A recursive common table expression is intended to be used in conjunction with UNION ALL in order to derive rows from those already selected.
• nesting – 
if True, will render the CTE locally to the statement in which it is referenced. For more complex scenarios, the HasCTE.add_cte() method using the HasCTE.add_cte.nest_here parameter may also be used to more carefully control the exact placement of a particular CTE.
Added in version 1.4.24.
See also
HasCTE.add_cte()
The following examples include two from PostgreSQL’s documentation at https://www.postgresql.org/docs/current/static/queries-with.html, as well as additional examples.
Example 1, non recursive:
from sqlalchemy import (
    Table,
    Column,
    String,
    Integer,
    MetaData,
    select,
    func,
)

metadata = MetaData()

orders = Table(
    "orders",
    metadata,
    Column("region", String),
    Column("amount", Integer),
    Column("product", String),
    Column("quantity", Integer),
)

regional_sales = (
    select(orders.c.region, func.sum(orders.c.amount).label("total_sales"))
    .group_by(orders.c.region)
    .cte("regional_sales")
)


top_regions = (
    select(regional_sales.c.region)
    .where(
        regional_sales.c.total_sales
        > select(func.sum(regional_sales.c.total_sales) / 10)
    )
    .cte("top_regions")
)

statement = (
    select(
        orders.c.region,
        orders.c.product,
        func.sum(orders.c.quantity).label("product_units"),
        func.sum(orders.c.amount).label("product_sales"),
    )
    .where(orders.c.region.in_(select(top_regions.c.region)))
    .group_by(orders.c.region, orders.c.product)
)

result = conn.execute(statement).fetchall()
Example 2, WITH RECURSIVE:
from sqlalchemy import (
    Table,
    Column,
    String,
    Integer,
    MetaData,
    select,
    func,
)

metadata = MetaData()

parts = Table(
    "parts",
    metadata,
    Column("part", String),
    Column("sub_part", String),
    Column("quantity", Integer),
)

included_parts = (
    select(parts.c.sub_part, parts.c.part, parts.c.quantity)
    .where(parts.c.part == "our part")
    .cte(recursive=True)
)


incl_alias = included_parts.alias()
parts_alias = parts.alias()
included_parts = included_parts.union_all(
    select(
        parts_alias.c.sub_part, parts_alias.c.part, parts_alias.c.quantity
    ).where(parts_alias.c.part == incl_alias.c.sub_part)
)

statement = select(
    included_parts.c.sub_part,
    func.sum(included_parts.c.quantity).label("total_quantity"),
).group_by(included_parts.c.sub_part)

result = conn.execute(statement).fetchall()
Example 3, an upsert using UPDATE and INSERT with CTEs:
from datetime import date
from sqlalchemy import (
    MetaData,
    Table,
    Column,
    Integer,
    Date,
    select,
    literal,
    and_,
    exists,
)

metadata = MetaData()

visitors = Table(
    "visitors",
    metadata,
    Column("product_id", Integer, primary_key=True),
    Column("date", Date, primary_key=True),
    Column("count", Integer),
)

# add 5 visitors for the product_id == 1
product_id = 1
day = date.today()
count = 5

update_cte = (
    visitors.update()
    .where(
        and_(visitors.c.product_id == product_id, visitors.c.date == day)
    )
    .values(count=visitors.c.count + count)
    .returning(literal(1))
    .cte("update_cte")
)

upsert = visitors.insert().from_select(
    [visitors.c.product_id, visitors.c.date, visitors.c.count],
    select(literal(product_id), literal(day), literal(count)).where(
        ~exists(update_cte.select())
    ),
)

connection.execute(upsert)
Example 4, Nesting CTE (SQLAlchemy 1.4.24 and above):
value_a = select(literal("root").label("n")).cte("value_a")

# A nested CTE with the same name as the root one
value_a_nested = select(literal("nesting").label("n")).cte(
    "value_a", nesting=True
)

# Nesting CTEs takes ascendency locally
# over the CTEs at a higher level
value_b = select(value_a_nested.c.n).cte("value_b")

value_ab = select(value_a.c.n.label("a"), value_b.c.n.label("b"))
The above query will render the second CTE nested inside the first, shown with inline parameters below as:
WITH
    value_a AS
        (SELECT 'root' AS n),
    value_b AS
        (WITH value_a AS
            (SELECT 'nesting' AS n)
        SELECT value_a.n AS n FROM value_a)
SELECT value_a.n AS a, value_b.n AS b
FROM value_a, value_b
The same CTE can be set up using the HasCTE.add_cte() method as follows (SQLAlchemy 2.0 and above):
value_a = select(literal("root").label("n")).cte("value_a")

# A nested CTE with the same name as the root one
value_a_nested = select(literal("nesting").label("n")).cte("value_a")

# Nesting CTEs takes ascendency locally
# over the CTEs at a higher level
value_b = (
    select(value_a_nested.c.n)
    .add_cte(value_a_nested, nest_here=True)
    .cte("value_b")
)

value_ab = select(value_a.c.n.label("a"), value_b.c.n.label("b"))
Example 5, Non-Linear CTE (SQLAlchemy 1.4.28 and above):
edge = Table(
    "edge",
    metadata,
    Column("id", Integer, primary_key=True),
    Column("left", Integer),
    Column("right", Integer),
)

root_node = select(literal(1).label("node")).cte("nodes", recursive=True)

left_edge = select(edge.c.left).join(
    root_node, edge.c.right == root_node.c.node
)
right_edge = select(edge.c.right).join(
    root_node, edge.c.left == root_node.c.node
)

subgraph_cte = root_node.union(left_edge, right_edge)

subgraph = select(subgraph_cte)
The above query will render 2 UNIONs inside the recursive CTE:
WITH RECURSIVE nodes(node) AS (
        SELECT 1 AS node
    UNION
        SELECT edge."left" AS "left"
        FROM edge JOIN nodes ON edge."right" = nodes.node
    UNION
        SELECT edge."right" AS "right"
        FROM edge JOIN nodes ON edge."left" = nodes.node
)
SELECT nodes.node FROM nodes
See also
Query.cte() - ORM version of HasCTE.cte().
attribute sqlalchemy.sql.expression.CompoundSelect.dialect_kwargs
inherited from the DialectKWArgs.dialect_kwargs attribute of DialectKWArgs
A collection of keyword arguments specified as dialect-specific options to this construct.
The arguments are present here in their original <dialect>_<kwarg> format. Only arguments that were actually passed are included; unlike the DialectKWArgs.dialect_options collection, which contains all options known by this dialect including defaults.
The collection is also writable; keys are accepted of the form <dialect>_<kwarg> where the value will be assembled into the list of options.
See also
DialectKWArgs.dialect_options - nested dictionary form
attribute sqlalchemy.sql.expression.CompoundSelect.dialect_options
inherited from the DialectKWArgs.dialect_options attribute of DialectKWArgs
A collection of keyword arguments specified as dialect-specific options to this construct.
This is a two-level nested registry, keyed to <dialect_name> and <argument_name>. For example, the postgresql_where argument would be locatable as:
arg = my_object.dialect_options["postgresql"]["where"]
Added in version 0.9.2.
See also
DialectKWArgs.dialect_kwargs - flat dictionary form
method sqlalchemy.sql.expression.CompoundSelect.execution_options(**kw: Any) → Self
inherited from the Executable.execution_options() method of Executable
Set non-SQL options for the statement which take effect during execution.
Execution options can be set at many scopes, including per-statement, per-connection, or per execution, using methods such as Connection.execution_options() and parameters which accept a dictionary of options such as Connection.execute.execution_options and Session.execute.execution_options.
The primary characteristic of an execution option, as opposed to other kinds of options such as ORM loader options, is that execution options never affect the compiled SQL of a query, only things that affect how the SQL statement itself is invoked or how results are fetched. That is, execution options are not part of what’s accommodated by SQL compilation nor are they considered part of the cached state of a statement.
The Executable.execution_options() method is generative, as is the case for the method as applied to the Engine and Query objects, which means when the method is called, a copy of the object is returned, which applies the given parameters to that new copy, but leaves the original unchanged:
statement = select(table.c.x, table.c.y)
new_statement = statement.execution_options(my_option=True)
An exception to this behavior is the Connection object, where the Connection.execution_options() method is explicitly not generative.
The kinds of options that may be passed to Executable.execution_options() and other related methods and parameter dictionaries include parameters that are explicitly consumed by SQLAlchemy Core or ORM, as well as arbitrary keyword arguments not defined by SQLAlchemy, which means the methods and/or parameter dictionaries may be used for user-defined parameters that interact with custom code, which may access the parameters using methods such as Executable.get_execution_options() and Connection.get_execution_options(), or within selected event hooks using a dedicated execution_options event parameter such as ConnectionEvents.before_execute.execution_options or ORMExecuteState.execution_options, e.g.:
from sqlalchemy import event


@event.listens_for(some_engine, "before_execute")
def _process_opt(conn, statement, multiparams, params, execution_options):
    "run a SQL function before invoking a statement"

    if execution_options.get("do_special_thing", False):
        conn.exec_driver_sql("run_special_function()")
Within the scope of options that are explicitly recognized by SQLAlchemy, most apply to specific classes of objects and not others. The most common execution options include:
• Connection.execution_options.isolation_level - sets the isolation level for a connection or a class of connections via an Engine. This option is accepted only by Connection or Engine.
• Connection.execution_options.stream_results - indicates results should be fetched using a server side cursor; this option is accepted by Connection, by the Connection.execute.execution_options parameter on Connection.execute(), and additionally by Executable.execution_options() on a SQL statement object, as well as by ORM constructs like Session.execute().
• Connection.execution_options.compiled_cache - indicates a dictionary that will serve as the SQL compilation cache for a Connection or Engine, as well as for ORM methods like Session.execute(). Can be passed as None to disable caching for statements. This option is not accepted by Executable.execution_options() as it is inadvisable to carry along a compilation cache within a statement object.
• Connection.execution_options.schema_translate_map - a mapping of schema names used by the Schema Translate Map feature, accepted by Connection, Engine, Executable, as well as by ORM constructs like Session.execute().
See also
Connection.execution_options()
Connection.execute.execution_options
Session.execute.execution_options
ORM Execution Options - documentation on all ORM-specific execution options
method sqlalchemy.sql.expression.CompoundSelect.exists() → Exists
inherited from the SelectBase.exists() method of SelectBase
Return an Exists representation of this selectable, which can be used as a column expression.
The returned object is an instance of Exists.
See also
exists()
EXISTS subqueries - in the 2.0 style tutorial.
Added in version 1.4.
attribute sqlalchemy.sql.expression.CompoundSelect.exported_columns
inherited from the SelectBase.exported_columns attribute of SelectBase
A ColumnCollection that represents the “exported” columns of this Selectable, not including TextClause constructs.
The “exported” columns for a SelectBase object are synonymous with the SelectBase.selected_columns collection.
Added in version 1.4.
See also
Select.exported_columns
Selectable.exported_columns
FromClause.exported_columns
method sqlalchemy.sql.expression.CompoundSelect.fetch(count: _LimitOffsetType, with_ties: bool = False, percent: bool = False, **dialect_kw: Any) → Self
inherited from the GenerativeSelect.fetch() method of GenerativeSelect
Return a new selectable with the given FETCH FIRST criterion applied.
This is a numeric value which usually renders as FETCH {FIRST | NEXT} [ count ] {ROW | ROWS} {ONLY | WITH TIES} expression in the resulting select. This functionality is is currently implemented for Oracle Database, PostgreSQL, MSSQL.
Use GenerativeSelect.offset() to specify the offset.
Note
The GenerativeSelect.fetch() method will replace any clause applied with GenerativeSelect.limit().
Added in version 1.4.
Parameters:
• count – an integer COUNT parameter, or a SQL expression that provides an integer result. When percent=True this will represent the percentage of rows to return, not the absolute value. Pass None to reset it.
• with_ties – When True, the WITH TIES option is used to return any additional rows that tie for the last place in the result set according to the ORDER BY clause. The ORDER BY may be mandatory in this case. Defaults to False
• percent – When True, count represents the percentage of the total number of selected rows to return. Defaults to False
• **dialect_kw – 
Additional dialect-specific keyword arguments may be accepted by dialects.
Added in version 2.0.41.
See also
GenerativeSelect.limit()
GenerativeSelect.offset()
method sqlalchemy.sql.expression.CompoundSelect.get_children(*, omit_attrs: Tuple[str, ...] = (), **kw: Any) → Iterable[HasTraverseInternals]
inherited from the HasTraverseInternals.get_children() method of HasTraverseInternals
Return immediate child HasTraverseInternals elements of this HasTraverseInternals.
This is used for visit traversal.
**kw may contain flags that change the collection that is returned, for example to return a subset of items in order to cut down on larger traversals, or to return child items from a different context (such as schema-level collections instead of clause-level).
method sqlalchemy.sql.expression.CompoundSelect.get_execution_options() → _ExecuteOptions
inherited from the Executable.get_execution_options() method of Executable
Get the non-SQL options which will take effect during execution.
Added in version 1.3.
See also
Executable.execution_options()
method sqlalchemy.sql.expression.CompoundSelect.get_label_style() → SelectLabelStyle
inherited from the GenerativeSelect.get_label_style() method of GenerativeSelect
Retrieve the current label style.
Added in version 1.4.
method sqlalchemy.sql.expression.CompoundSelect.group_by(_GenerativeSelect__first: Literal[None, _NoArg.NO_ARG] | _ColumnExpressionOrStrLabelArgument[Any] = _NoArg.NO_ARG, *clauses: _ColumnExpressionOrStrLabelArgument[Any]) → Self
inherited from the GenerativeSelect.group_by() method of GenerativeSelect
Return a new selectable with the given list of GROUP BY criterion applied.
All existing GROUP BY settings can be suppressed by passing None.
e.g.:
stmt = select(table.c.name, func.max(table.c.stat)).group_by(table.c.name)
Parameters:
*clauses – a series of ColumnElement constructs which will be used to generate an GROUP BY clause.
See also
Aggregate functions with GROUP BY / HAVING - in the SQLAlchemy Unified Tutorial
Ordering or Grouping by a Label - in the SQLAlchemy Unified Tutorial
attribute sqlalchemy.sql.expression.CompoundSelect.inherit_cache: bool | None = None
inherited from the HasCacheKey.inherit_cache attribute of HasCacheKey
Indicate if this HasCacheKey instance should make use of the cache key generation scheme used by its immediate superclass.
The attribute defaults to None, which indicates that a construct has not yet taken into account whether or not its appropriate for it to participate in caching; this is functionally equivalent to setting the value to False, except that a warning is also emitted.
This flag can be set to True on a particular class, if the SQL that corresponds to the object does not change based on attributes which are local to this class, and not its superclass.
See also
Enabling Caching Support for Custom Constructs - General guideslines for setting the HasCacheKey.inherit_cache attribute for third-party or user defined SQL constructs.
method sqlalchemy.sql.expression.CompoundSelect.is_derived_from(fromclause: FromClause | None) → bool
Return True if this ReturnsRows is ‘derived’ from the given FromClause.
An example would be an Alias of a Table is derived from that Table.
attribute sqlalchemy.sql.expression.CompoundSelect.kwargs
inherited from the DialectKWArgs.kwargs attribute of DialectKWArgs
A synonym for DialectKWArgs.dialect_kwargs.
method sqlalchemy.sql.expression.CompoundSelect.label(name: str | None) → Label[Any]
inherited from the SelectBase.label() method of SelectBase
Return a ‘scalar’ representation of this selectable, embedded as a subquery with a label.
See also
SelectBase.scalar_subquery().
method sqlalchemy.sql.expression.CompoundSelect.lateral(name: str | None = None) → LateralFromClause
inherited from the SelectBase.lateral() method of SelectBase
Return a LATERAL alias of this Selectable.
The return value is the Lateral construct also provided by the top-level lateral() function.
See also
LATERAL correlation - overview of usage.
method sqlalchemy.sql.expression.CompoundSelect.limit(limit: _LimitOffsetType) → Self
inherited from the GenerativeSelect.limit() method of GenerativeSelect
Return a new selectable with the given LIMIT criterion applied.
This is a numerical value which usually renders as a LIMIT expression in the resulting select. Backends that don’t support LIMIT will attempt to provide similar functionality.
Note
The GenerativeSelect.limit() method will replace any clause applied with GenerativeSelect.fetch().
Parameters:
limit – an integer LIMIT parameter, or a SQL expression that provides an integer result. Pass None to reset it.
See also
GenerativeSelect.fetch()
GenerativeSelect.offset()
attribute sqlalchemy.sql.expression.CompoundSelect.name_cte_columns: bool = False
inherited from the HasCTE.name_cte_columns attribute of HasCTE
indicates if this HasCTE as contained within a CTE should compel the CTE to render the column names of this object in the WITH clause.
Added in version 2.0.42.
method sqlalchemy.sql.expression.CompoundSelect.offset(offset: _LimitOffsetType) → Self
inherited from the GenerativeSelect.offset() method of GenerativeSelect
Return a new selectable with the given OFFSET criterion applied.
This is a numeric value which usually renders as an OFFSET expression in the resulting select. Backends that don’t support OFFSET will attempt to provide similar functionality.
Parameters:
offset – an integer OFFSET parameter, or a SQL expression that provides an integer result. Pass None to reset it.
See also
GenerativeSelect.limit()
GenerativeSelect.fetch()
method sqlalchemy.sql.expression.CompoundSelect.options(*options: ExecutableOption) → Self
inherited from the Executable.options() method of Executable
Apply options to this statement.
In the general sense, options are any kind of Python object that can be interpreted by the SQL compiler for the statement. These options can be consumed by specific dialects or specific kinds of compilers.
The most commonly known kind of option are the ORM level options that apply “eager load” and other loading behaviors to an ORM query. However, options can theoretically be used for many other purposes.
For background on specific kinds of options for specific kinds of statements, refer to the documentation for those option objects.
Changed in version 1.4: - added Executable.options() to Core statement objects towards the goal of allowing unified Core / ORM querying capabilities.
See also
Column Loading Options - refers to options specific to the usage of ORM queries
Relationship Loading with Loader Options - refers to options specific to the usage of ORM queries
method sqlalchemy.sql.expression.CompoundSelect.order_by(_GenerativeSelect__first: Literal[None, _NoArg.NO_ARG] | _ColumnExpressionOrStrLabelArgument[Any] = _NoArg.NO_ARG, *clauses: _ColumnExpressionOrStrLabelArgument[Any]) → Self
inherited from the GenerativeSelect.order_by() method of GenerativeSelect
Return a new selectable with the given list of ORDER BY criteria applied.
e.g.:
stmt = select(table).order_by(table.c.id, table.c.name)
Calling this method multiple times is equivalent to calling it once with all the clauses concatenated. All existing ORDER BY criteria may be cancelled by passing None by itself. New ORDER BY criteria may then be added by invoking Query.order_by() again, e.g.:
# will erase all ORDER BY and ORDER BY new_col alone
stmt = stmt.order_by(None).order_by(new_col)
Parameters:
*clauses – a series of ColumnElement constructs which will be used to generate an ORDER BY clause.
See also
ORDER BY - in the SQLAlchemy Unified Tutorial
Ordering or Grouping by a Label - in the SQLAlchemy Unified Tutorial
method sqlalchemy.sql.expression.CompoundSelect.replace_selectable(old: FromClause, alias: Alias) → Self
inherited from the Selectable.replace_selectable() method of Selectable
Replace all occurrences of FromClause ‘old’ with the given Alias object, returning a copy of this FromClause.
Deprecated since version 1.4: The Selectable.replace_selectable() method is deprecated, and will be removed in a future release. Similar functionality is available via the sqlalchemy.sql.visitors module.
method sqlalchemy.sql.expression.CompoundSelect.scalar_subquery() → ScalarSelect[Any]
inherited from the SelectBase.scalar_subquery() method of SelectBase
Return a ‘scalar’ representation of this selectable, which can be used as a column expression.
The returned object is an instance of ScalarSelect.
Typically, a select statement which has only one column in its columns clause is eligible to be used as a scalar expression. The scalar subquery can then be used in the WHERE clause or columns clause of an enclosing SELECT.
Note that the scalar subquery differentiates from the FROM-level subquery that can be produced using the SelectBase.subquery() method.
See also
Scalar and Correlated Subqueries - in the 2.0 tutorial
method sqlalchemy.sql.expression.CompoundSelect.select(*arg: Any, **kw: Any) → Select
inherited from the SelectBase.select() method of SelectBase
Deprecated since version 1.4: The SelectBase.select() method is deprecated and will be removed in a future release; this method implicitly creates a subquery that should be explicit. Please call SelectBase.subquery() first in order to create a subquery, which then can be selected.
attribute sqlalchemy.sql.expression.CompoundSelect.selected_columns
A ColumnCollection representing the columns that this SELECT statement or similar construct returns in its result set, not including TextClause constructs.
For a CompoundSelect, the CompoundSelect.selected_columns attribute returns the selected columns of the first SELECT statement contained within the series of statements within the set operation.
See also
Select.selected_columns
Added in version 1.4.
method sqlalchemy.sql.expression.CompoundSelect.self_group(against: OperatorType | None = None) → GroupedElement
Apply a ‘grouping’ to this ClauseElement.
This method is overridden by subclasses to return a “grouping” construct, i.e. parenthesis. In particular it’s used by “binary” expressions to provide a grouping around themselves when placed into a larger expression, as well as by select() constructs when placed into the FROM clause of another select(). (Note that subqueries should be normally created using the Select.alias() method, as many platforms require nested SELECT statements to be named).
As expressions are composed together, the application of self_group() is automatic - end-user code should never need to use this method directly. Note that SQLAlchemy’s clause constructs take operator precedence into account - so parenthesis might not be needed, for example, in an expression like x OR (y AND z) - AND takes precedence over OR.
The base self_group() method of ClauseElement just returns self.
method sqlalchemy.sql.expression.CompoundSelect.set_label_style(style: SelectLabelStyle) → Self
Return a new selectable with the specified label style.
There are three “label styles” available, SelectLabelStyle.LABEL_STYLE_DISAMBIGUATE_ONLY, SelectLabelStyle.LABEL_STYLE_TABLENAME_PLUS_COL, and SelectLabelStyle.LABEL_STYLE_NONE. The default style is SelectLabelStyle.LABEL_STYLE_DISAMBIGUATE_ONLY.
In modern SQLAlchemy, there is not generally a need to change the labeling style, as per-expression labels are more effectively used by making use of the ColumnElement.label() method. In past versions, LABEL_STYLE_TABLENAME_PLUS_COL was used to disambiguate same-named columns from different tables, aliases, or subqueries; the newer LABEL_STYLE_DISAMBIGUATE_ONLY now applies labels only to names that conflict with an existing name so that the impact of this labeling is minimal.
The rationale for disambiguation is mostly so that all column expressions are available from a given FromClause.c collection when a subquery is created.
Added in version 1.4: - the GenerativeSelect.set_label_style() method replaces the previous combination of .apply_labels(), .with_labels() and use_labels=True methods and/or parameters.
See also
LABEL_STYLE_DISAMBIGUATE_ONLY
LABEL_STYLE_TABLENAME_PLUS_COL
LABEL_STYLE_NONE
LABEL_STYLE_DEFAULT
method sqlalchemy.sql.expression.CompoundSelect.slice(start: int, stop: int) → Self
inherited from the GenerativeSelect.slice() method of GenerativeSelect
Apply LIMIT / OFFSET to this statement based on a slice.
The start and stop indices behave like the argument to Python’s built-in range() function. This method provides an alternative to using LIMIT/OFFSET to get a slice of the query.
For example,
stmt = select(User).order_by(User.id).slice(1, 3)
renders as
SELECT users.id AS users_id,
       users.name AS users_name
FROM users ORDER BY users.id
LIMIT ? OFFSET ?
(2, 1)
Note
The GenerativeSelect.slice() method will replace any clause applied with GenerativeSelect.fetch().
Added in version 1.4: Added the GenerativeSelect.slice() method generalized from the ORM.
See also
GenerativeSelect.limit()
GenerativeSelect.offset()
GenerativeSelect.fetch()
method sqlalchemy.sql.expression.CompoundSelect.subquery(name: str | None = None) → Subquery
inherited from the SelectBase.subquery() method of SelectBase
Return a subquery of this SelectBase.
A subquery is from a SQL perspective a parenthesized, named construct that can be placed in the FROM clause of another SELECT statement.
Given a SELECT statement such as:
stmt = select(table.c.id, table.c.name)
The above statement might look like:
SELECT table.id, table.name FROM table
The subquery form by itself renders the same way, however when embedded into the FROM clause of another SELECT statement, it becomes a named sub-element:
subq = stmt.subquery()
new_stmt = select(subq)
The above renders as:
SELECT anon_1.id, anon_1.name
FROM (SELECT table.id, table.name FROM table) AS anon_1
Historically, SelectBase.subquery() is equivalent to calling the FromClause.alias() method on a FROM object; however, as a SelectBase object is not directly FROM object, the SelectBase.subquery() method provides clearer semantics.
Added in version 1.4.
method sqlalchemy.sql.expression.CompoundSelect.with_for_update(*, nowait: bool = False, read: bool = False, of: _ForUpdateOfArgument | None = None, skip_locked: bool = False, key_share: bool = False) → Self
inherited from the GenerativeSelect.with_for_update() method of GenerativeSelect
Specify a FOR UPDATE clause for this GenerativeSelect.
E.g.:
stmt = select(table).with_for_update(nowait=True)
On a database like PostgreSQL or Oracle Database, the above would render a statement like:
SELECT table.a, table.b FROM table FOR UPDATE NOWAIT
on other backends, the nowait option is ignored and instead would produce:
SELECT table.a, table.b FROM table FOR UPDATE
When called with no arguments, the statement will render with the suffix FOR UPDATE. Additional arguments can then be provided which allow for common database-specific variants.
Parameters:
• nowait – boolean; will render FOR UPDATE NOWAIT on Oracle Database and PostgreSQL dialects.
• read – boolean; will render LOCK IN SHARE MODE on MySQL, FOR SHARE on PostgreSQL. On PostgreSQL, when combined with nowait, will render FOR SHARE NOWAIT.
• of – SQL expression or list of SQL expression elements, (typically Column objects or a compatible expression, for some backends may also be a table expression) which will render into a FOR UPDATE OF clause; supported by PostgreSQL, Oracle Database, some MySQL versions and possibly others. May render as a table or as a column depending on backend.
• skip_locked – boolean, will render FOR UPDATE SKIP LOCKED on Oracle Database and PostgreSQL dialects or FOR SHARE SKIP LOCKED if read=True is also specified.
• key_share – boolean, will render FOR NO KEY UPDATE, or if combined with read=True will render FOR KEY SHARE, on the PostgreSQL dialect.
class sqlalchemy.sql.expression.CTE
Represent a Common Table Expression.
The CTE object is obtained using the SelectBase.cte() method from any SELECT statement. A less often available syntax also allows use of the HasCTE.cte() method present on DML constructs such as Insert, Update and Delete. See the HasCTE.cte() method for usage details on CTEs.
See also
Subqueries and CTEs - in the 2.0 tutorial
HasCTE.cte() - examples of calling styles
Members
alias(), union(), union_all()
Class signature
class sqlalchemy.sql.expression.CTE (sqlalchemy.sql.roles.DMLTableRole, sqlalchemy.sql.roles.IsCTERole, sqlalchemy.sql.expression.Generative, sqlalchemy.sql.expression.HasPrefixes, sqlalchemy.sql.expression.HasSuffixes, sqlalchemy.sql.expression.AliasedReturnsRows)
method sqlalchemy.sql.expression.CTE.alias(name: str | None = None, flat: bool = False) → CTE
Return an Alias of this CTE.
This method is a CTE-specific specialization of the FromClause.alias() method.
See also
Using Aliases
alias()
method sqlalchemy.sql.expression.CTE.union(*other: _SelectStatementForCompoundArgument[Any]) → CTE
Return a new CTE with a SQL UNION of the original CTE against the given selectables provided as positional arguments.
Parameters:
*other – 
one or more elements with which to create a UNION.
Changed in version 1.4.28: multiple elements are now accepted.
See also
HasCTE.cte() - examples of calling styles
method sqlalchemy.sql.expression.CTE.union_all(*other: _SelectStatementForCompoundArgument[Any]) → CTE
Return a new CTE with a SQL UNION ALL of the original CTE against the given selectables provided as positional arguments.
Parameters:
*other – 
one or more elements with which to create a UNION.
Changed in version 1.4.28: multiple elements are now accepted.
See also
HasCTE.cte() - examples of calling styles
class sqlalchemy.sql.expression.Executable
Mark a ClauseElement as supporting execution.
Executable is a superclass for all “statement” types of objects, including select(), delete(), update(), insert(), text().
Members
execution_options(), get_execution_options(), options()
Class signature
class sqlalchemy.sql.expression.Executable (sqlalchemy.sql.roles.StatementRole)
method sqlalchemy.sql.expression.Executable.execution_options(**kw: Any) → Self
Set non-SQL options for the statement which take effect during execution.
Execution options can be set at many scopes, including per-statement, per-connection, or per execution, using methods such as Connection.execution_options() and parameters which accept a dictionary of options such as Connection.execute.execution_options and Session.execute.execution_options.
The primary characteristic of an execution option, as opposed to other kinds of options such as ORM loader options, is that execution options never affect the compiled SQL of a query, only things that affect how the SQL statement itself is invoked or how results are fetched. That is, execution options are not part of what’s accommodated by SQL compilation nor are they considered part of the cached state of a statement.
The Executable.execution_options() method is generative, as is the case for the method as applied to the Engine and Query objects, which means when the method is called, a copy of the object is returned, which applies the given parameters to that new copy, but leaves the original unchanged:
statement = select(table.c.x, table.c.y)
new_statement = statement.execution_options(my_option=True)
An exception to this behavior is the Connection object, where the Connection.execution_options() method is explicitly not generative.
The kinds of options that may be passed to Executable.execution_options() and other related methods and parameter dictionaries include parameters that are explicitly consumed by SQLAlchemy Core or ORM, as well as arbitrary keyword arguments not defined by SQLAlchemy, which means the methods and/or parameter dictionaries may be used for user-defined parameters that interact with custom code, which may access the parameters using methods such as Executable.get_execution_options() and Connection.get_execution_options(), or within selected event hooks using a dedicated execution_options event parameter such as ConnectionEvents.before_execute.execution_options or ORMExecuteState.execution_options, e.g.:
from sqlalchemy import event


@event.listens_for(some_engine, "before_execute")
def _process_opt(conn, statement, multiparams, params, execution_options):
    "run a SQL function before invoking a statement"

    if execution_options.get("do_special_thing", False):
        conn.exec_driver_sql("run_special_function()")
Within the scope of options that are explicitly recognized by SQLAlchemy, most apply to specific classes of objects and not others. The most common execution options include:
• Connection.execution_options.isolation_level - sets the isolation level for a connection or a class of connections via an Engine. This option is accepted only by Connection or Engine.
• Connection.execution_options.stream_results - indicates results should be fetched using a server side cursor; this option is accepted by Connection, by the Connection.execute.execution_options parameter on Connection.execute(), and additionally by Executable.execution_options() on a SQL statement object, as well as by ORM constructs like Session.execute().
• Connection.execution_options.compiled_cache - indicates a dictionary that will serve as the SQL compilation cache for a Connection or Engine, as well as for ORM methods like Session.execute(). Can be passed as None to disable caching for statements. This option is not accepted by Executable.execution_options() as it is inadvisable to carry along a compilation cache within a statement object.
• Connection.execution_options.schema_translate_map - a mapping of schema names used by the Schema Translate Map feature, accepted by Connection, Engine, Executable, as well as by ORM constructs like Session.execute().
See also
Connection.execution_options()
Connection.execute.execution_options
Session.execute.execution_options
ORM Execution Options - documentation on all ORM-specific execution options
method sqlalchemy.sql.expression.Executable.get_execution_options() → _ExecuteOptions
Get the non-SQL options which will take effect during execution.
Added in version 1.3.
See also
Executable.execution_options()
method sqlalchemy.sql.expression.Executable.options(*options: ExecutableOption) → Self
Apply options to this statement.
In the general sense, options are any kind of Python object that can be interpreted by the SQL compiler for the statement. These options can be consumed by specific dialects or specific kinds of compilers.
The most commonly known kind of option are the ORM level options that apply “eager load” and other loading behaviors to an ORM query. However, options can theoretically be used for many other purposes.
For background on specific kinds of options for specific kinds of statements, refer to the documentation for those option objects.
Changed in version 1.4: - added Executable.options() to Core statement objects towards the goal of allowing unified Core / ORM querying capabilities.
See also
Column Loading Options - refers to options specific to the usage of ORM queries
Relationship Loading with Loader Options - refers to options specific to the usage of ORM queries
class sqlalchemy.sql.expression.Exists
Represent an EXISTS clause.
See exists() for a description of usage.
An EXISTS clause can also be constructed from a select() instance by calling SelectBase.exists().
Members
correlate(), correlate_except(), inherit_cache, select(), select_from(), where()
Class signature
class sqlalchemy.sql.expression.Exists (sqlalchemy.sql.expression.UnaryExpression)
method sqlalchemy.sql.expression.Exists.correlate(*fromclauses: Literal[None, False] | _FromClauseArgument) → Self
Apply correlation to the subquery noted by this Exists.
See also
ScalarSelect.correlate()
method sqlalchemy.sql.expression.Exists.correlate_except(*fromclauses: Literal[None, False] | _FromClauseArgument) → Self
Apply correlation to the subquery noted by this Exists.
See also
ScalarSelect.correlate_except()
attribute sqlalchemy.sql.expression.Exists.inherit_cache: bool | None = True
Indicate if this HasCacheKey instance should make use of the cache key generation scheme used by its immediate superclass.
The attribute defaults to None, which indicates that a construct has not yet taken into account whether or not its appropriate for it to participate in caching; this is functionally equivalent to setting the value to False, except that a warning is also emitted.
This flag can be set to True on a particular class, if the SQL that corresponds to the object does not change based on attributes which are local to this class, and not its superclass.
See also
Enabling Caching Support for Custom Constructs - General guideslines for setting the HasCacheKey.inherit_cache attribute for third-party or user defined SQL constructs.
method sqlalchemy.sql.expression.Exists.select() → Select
Return a SELECT of this Exists.
e.g.:
stmt = exists(some_table.c.id).where(some_table.c.id == 5).select()
This will produce a statement resembling:
SELECT EXISTS (SELECT id FROM some_table WHERE some_table = :param) AS anon_1
See also
select() - general purpose method which allows for arbitrary column lists.
method sqlalchemy.sql.expression.Exists.select_from(*froms: _FromClauseArgument) → Self
Return a new Exists construct, applying the given expression to the Select.select_from() method of the select statement contained.
Note
it is typically preferable to build a Select statement first, including the desired WHERE clause, then use the SelectBase.exists() method to produce an Exists object at once.
method sqlalchemy.sql.expression.Exists.where(*clause: _ColumnExpressionArgument[bool]) → Self
Return a new exists() construct with the given expression added to its WHERE clause, joined to the existing clause via AND, if any.
Note
it is typically preferable to build a Select statement first, including the desired WHERE clause, then use the SelectBase.exists() method to produce an Exists object at once.
class sqlalchemy.sql.expression.FromClause
Represent an element that can be used within the FROM clause of a SELECT statement.
The most common forms of FromClause are the Table and the select() constructs. Key features common to all FromClause objects include:
• a c collection, which provides per-name access to a collection of ColumnElement objects.
• a primary_key attribute, which is a collection of all those ColumnElement objects that indicate the primary_key flag.
• Methods to generate various derivations of a “from” clause, including FromClause.alias(), FromClause.join(), FromClause.select().
Members
alias(), c, columns, description, entity_namespace, exported_columns, foreign_keys, is_derived_from(), join(), outerjoin(), primary_key, schema, select(), tablesample()
Class signature
class sqlalchemy.sql.expression.FromClause (sqlalchemy.sql.roles.AnonymizedFromClauseRole, sqlalchemy.sql.expression.Selectable)
method sqlalchemy.sql.expression.FromClause.alias(name: str | None = None, flat: bool = False) → NamedFromClause
Return an alias of this FromClause.
E.g.:
a2 = some_table.alias("a2")
The above code creates an Alias object which can be used as a FROM clause in any SELECT statement.
See also
Using Aliases
alias()
attribute sqlalchemy.sql.expression.FromClause.c
A synonym for FromClause.columns
Returns:
a ColumnCollection
attribute sqlalchemy.sql.expression.FromClause.columns
A named-based collection of ColumnElement objects maintained by this FromClause.
The columns, or c collection, is the gateway to the construction of SQL expressions using table-bound or other selectable-bound columns:
select(mytable).where(mytable.c.somecolumn == 5)
Returns:
a ColumnCollection object.
attribute sqlalchemy.sql.expression.FromClause.description
A brief description of this FromClause.
Used primarily for error message formatting.
attribute sqlalchemy.sql.expression.FromClause.entity_namespace
Return a namespace used for name-based access in SQL expressions.
This is the namespace that is used to resolve “filter_by()” type expressions, such as:
stmt.filter_by(address="some address")
It defaults to the .c collection, however internally it can be overridden using the “entity_namespace” annotation to deliver alternative results.
attribute sqlalchemy.sql.expression.FromClause.exported_columns
A ColumnCollection that represents the “exported” columns of this Selectable.
The “exported” columns for a FromClause object are synonymous with the FromClause.columns collection.
Added in version 1.4.
See also
Selectable.exported_columns
SelectBase.exported_columns
attribute sqlalchemy.sql.expression.FromClause.foreign_keys
Return the collection of ForeignKey marker objects which this FromClause references.
Each ForeignKey is a member of a Table-wide ForeignKeyConstraint.
See also
Table.foreign_key_constraints
method sqlalchemy.sql.expression.FromClause.is_derived_from(fromclause: FromClause | None) → bool
Return True if this FromClause is ‘derived’ from the given FromClause.
An example would be an Alias of a Table is derived from that Table.
method sqlalchemy.sql.expression.FromClause.join(right: _FromClauseArgument, onclause: _ColumnExpressionArgument[bool] | None = None, isouter: bool = False, full: bool = False) → Join
Return a Join from this FromClause to another FromClause.
E.g.:
from sqlalchemy import join

j = user_table.join(
    address_table, user_table.c.id == address_table.c.user_id
)
stmt = select(user_table).select_from(j)
would emit SQL along the lines of:
SELECT user.id, user.name FROM user
JOIN address ON user.id = address.user_id
Parameters:
• right – the right side of the join; this is any FromClause object such as a Table object, and may also be a selectable-compatible object such as an ORM-mapped class.
• onclause – a SQL expression representing the ON clause of the join. If left at None, FromClause.join() will attempt to join the two tables based on a foreign key relationship.
• isouter – if True, render a LEFT OUTER JOIN, instead of JOIN.
• full – if True, render a FULL OUTER JOIN, instead of LEFT OUTER JOIN. Implies FromClause.join.isouter.
See also
join() - standalone function
Join - the type of object produced
method sqlalchemy.sql.expression.FromClause.outerjoin(right: _FromClauseArgument, onclause: _ColumnExpressionArgument[bool] | None = None, full: bool = False) → Join
Return a Join from this FromClause to another FromClause, with the “isouter” flag set to True.
E.g.:
from sqlalchemy import outerjoin

j = user_table.outerjoin(
    address_table, user_table.c.id == address_table.c.user_id
)
The above is equivalent to:
j = user_table.join(
    address_table, user_table.c.id == address_table.c.user_id, isouter=True
)
Parameters:
• right – the right side of the join; this is any FromClause object such as a Table object, and may also be a selectable-compatible object such as an ORM-mapped class.
• onclause – a SQL expression representing the ON clause of the join. If left at None, FromClause.join() will attempt to join the two tables based on a foreign key relationship.
• full – if True, render a FULL OUTER JOIN, instead of LEFT OUTER JOIN.
See also
FromClause.join()
Join
attribute sqlalchemy.sql.expression.FromClause.primary_key
Return the iterable collection of Column objects which comprise the primary key of this _selectable.FromClause.
For a Table object, this collection is represented by the PrimaryKeyConstraint which itself is an iterable collection of Column objects.
attribute sqlalchemy.sql.expression.FromClause.schema: str | None = None
Define the ‘schema’ attribute for this FromClause.
This is typically None for most objects except that of Table, where it is taken as the value of the Table.schema argument.
method sqlalchemy.sql.expression.FromClause.select() → Select
Return a SELECT of this FromClause.
e.g.:
stmt = some_table.select().where(some_table.c.id == 5)
See also
select() - general purpose method which allows for arbitrary column lists.
method sqlalchemy.sql.expression.FromClause.tablesample(sampling: float | Function[Any], name: str | None = None, seed: roles.ExpressionElementRole[Any] | None = None) → TableSample
Return a TABLESAMPLE alias of this FromClause.
The return value is the TableSample construct also provided by the top-level tablesample() function.
See also
tablesample() - usage guidelines and parameters
class sqlalchemy.sql.expression.GenerativeSelect
Base class for SELECT statements where additional elements can be added.
This serves as the base for Select and CompoundSelect where elements such as ORDER BY, GROUP BY can be added and column rendering can be controlled. Compare to TextualSelect, which, while it subclasses SelectBase and is also a SELECT construct, represents a fixed textual string which cannot be altered at this level, only wrapped as a subquery.
Members
fetch(), get_label_style(), group_by(), limit(), offset(), order_by(), set_label_style(), slice(), with_for_update()
Class signature
class sqlalchemy.sql.expression.GenerativeSelect (sqlalchemy.sql.expression.DialectKWArgs, sqlalchemy.sql.expression.SelectBase, sqlalchemy.sql.expression.Generative)
method sqlalchemy.sql.expression.GenerativeSelect.fetch(count: _LimitOffsetType, with_ties: bool = False, percent: bool = False, **dialect_kw: Any) → Self
Return a new selectable with the given FETCH FIRST criterion applied.
This is a numeric value which usually renders as FETCH {FIRST | NEXT} [ count ] {ROW | ROWS} {ONLY | WITH TIES} expression in the resulting select. This functionality is is currently implemented for Oracle Database, PostgreSQL, MSSQL.
Use GenerativeSelect.offset() to specify the offset.
Note
The GenerativeSelect.fetch() method will replace any clause applied with GenerativeSelect.limit().
Added in version 1.4.
Parameters:
• count – an integer COUNT parameter, or a SQL expression that provides an integer result. When percent=True this will represent the percentage of rows to return, not the absolute value. Pass None to reset it.
• with_ties – When True, the WITH TIES option is used to return any additional rows that tie for the last place in the result set according to the ORDER BY clause. The ORDER BY may be mandatory in this case. Defaults to False
• percent – When True, count represents the percentage of the total number of selected rows to return. Defaults to False
• **dialect_kw – 
Additional dialect-specific keyword arguments may be accepted by dialects.
Added in version 2.0.41.
See also
GenerativeSelect.limit()
GenerativeSelect.offset()
method sqlalchemy.sql.expression.GenerativeSelect.get_label_style() → SelectLabelStyle
Retrieve the current label style.
Added in version 1.4.
method sqlalchemy.sql.expression.GenerativeSelect.group_by(_GenerativeSelect__first: Literal[None, _NoArg.NO_ARG] | _ColumnExpressionOrStrLabelArgument[Any] = _NoArg.NO_ARG, *clauses: _ColumnExpressionOrStrLabelArgument[Any]) → Self
Return a new selectable with the given list of GROUP BY criterion applied.
All existing GROUP BY settings can be suppressed by passing None.
e.g.:
stmt = select(table.c.name, func.max(table.c.stat)).group_by(table.c.name)
Parameters:
*clauses – a series of ColumnElement constructs which will be used to generate an GROUP BY clause.
See also
Aggregate functions with GROUP BY / HAVING - in the SQLAlchemy Unified Tutorial
Ordering or Grouping by a Label - in the SQLAlchemy Unified Tutorial
method sqlalchemy.sql.expression.GenerativeSelect.limit(limit: _LimitOffsetType) → Self
Return a new selectable with the given LIMIT criterion applied.
This is a numerical value which usually renders as a LIMIT expression in the resulting select. Backends that don’t support LIMIT will attempt to provide similar functionality.
Note
The GenerativeSelect.limit() method will replace any clause applied with GenerativeSelect.fetch().
Parameters:
limit – an integer LIMIT parameter, or a SQL expression that provides an integer result. Pass None to reset it.
See also
GenerativeSelect.fetch()
GenerativeSelect.offset()
method sqlalchemy.sql.expression.GenerativeSelect.offset(offset: _LimitOffsetType) → Self
Return a new selectable with the given OFFSET criterion applied.
This is a numeric value which usually renders as an OFFSET expression in the resulting select. Backends that don’t support OFFSET will attempt to provide similar functionality.
Parameters:
offset – an integer OFFSET parameter, or a SQL expression that provides an integer result. Pass None to reset it.
See also
GenerativeSelect.limit()
GenerativeSelect.fetch()
method sqlalchemy.sql.expression.GenerativeSelect.order_by(_GenerativeSelect__first: Literal[None, _NoArg.NO_ARG] | _ColumnExpressionOrStrLabelArgument[Any] = _NoArg.NO_ARG, *clauses: _ColumnExpressionOrStrLabelArgument[Any]) → Self
Return a new selectable with the given list of ORDER BY criteria applied.
e.g.:
stmt = select(table).order_by(table.c.id, table.c.name)
Calling this method multiple times is equivalent to calling it once with all the clauses concatenated. All existing ORDER BY criteria may be cancelled by passing None by itself. New ORDER BY criteria may then be added by invoking Query.order_by() again, e.g.:
# will erase all ORDER BY and ORDER BY new_col alone
stmt = stmt.order_by(None).order_by(new_col)
Parameters:
*clauses – a series of ColumnElement constructs which will be used to generate an ORDER BY clause.
See also
ORDER BY - in the SQLAlchemy Unified Tutorial
Ordering or Grouping by a Label - in the SQLAlchemy Unified Tutorial
method sqlalchemy.sql.expression.GenerativeSelect.set_label_style(style: SelectLabelStyle) → Self
Return a new selectable with the specified label style.
There are three “label styles” available, SelectLabelStyle.LABEL_STYLE_DISAMBIGUATE_ONLY, SelectLabelStyle.LABEL_STYLE_TABLENAME_PLUS_COL, and SelectLabelStyle.LABEL_STYLE_NONE. The default style is SelectLabelStyle.LABEL_STYLE_DISAMBIGUATE_ONLY.
In modern SQLAlchemy, there is not generally a need to change the labeling style, as per-expression labels are more effectively used by making use of the ColumnElement.label() method. In past versions, LABEL_STYLE_TABLENAME_PLUS_COL was used to disambiguate same-named columns from different tables, aliases, or subqueries; the newer LABEL_STYLE_DISAMBIGUATE_ONLY now applies labels only to names that conflict with an existing name so that the impact of this labeling is minimal.
The rationale for disambiguation is mostly so that all column expressions are available from a given FromClause.c collection when a subquery is created.
Added in version 1.4: - the GenerativeSelect.set_label_style() method replaces the previous combination of .apply_labels(), .with_labels() and use_labels=True methods and/or parameters.
See also
LABEL_STYLE_DISAMBIGUATE_ONLY
LABEL_STYLE_TABLENAME_PLUS_COL
LABEL_STYLE_NONE
LABEL_STYLE_DEFAULT
method sqlalchemy.sql.expression.GenerativeSelect.slice(start: int, stop: int) → Self
Apply LIMIT / OFFSET to this statement based on a slice.
The start and stop indices behave like the argument to Python’s built-in range() function. This method provides an alternative to using LIMIT/OFFSET to get a slice of the query.
For example,
stmt = select(User).order_by(User.id).slice(1, 3)
renders as
SELECT users.id AS users_id,
       users.name AS users_name
FROM users ORDER BY users.id
LIMIT ? OFFSET ?
(2, 1)
Note
The GenerativeSelect.slice() method will replace any clause applied with GenerativeSelect.fetch().
Added in version 1.4: Added the GenerativeSelect.slice() method generalized from the ORM.
See also
GenerativeSelect.limit()
GenerativeSelect.offset()
GenerativeSelect.fetch()
method sqlalchemy.sql.expression.GenerativeSelect.with_for_update(*, nowait: bool = False, read: bool = False, of: _ForUpdateOfArgument | None = None, skip_locked: bool = False, key_share: bool = False) → Self
Specify a FOR UPDATE clause for this GenerativeSelect.
E.g.:
stmt = select(table).with_for_update(nowait=True)
On a database like PostgreSQL or Oracle Database, the above would render a statement like:
SELECT table.a, table.b FROM table FOR UPDATE NOWAIT
on other backends, the nowait option is ignored and instead would produce:
SELECT table.a, table.b FROM table FOR UPDATE
When called with no arguments, the statement will render with the suffix FOR UPDATE. Additional arguments can then be provided which allow for common database-specific variants.
Parameters:
• nowait – boolean; will render FOR UPDATE NOWAIT on Oracle Database and PostgreSQL dialects.
• read – boolean; will render LOCK IN SHARE MODE on MySQL, FOR SHARE on PostgreSQL. On PostgreSQL, when combined with nowait, will render FOR SHARE NOWAIT.
• of – SQL expression or list of SQL expression elements, (typically Column objects or a compatible expression, for some backends may also be a table expression) which will render into a FOR UPDATE OF clause; supported by PostgreSQL, Oracle Database, some MySQL versions and possibly others. May render as a table or as a column depending on backend.
• skip_locked – boolean, will render FOR UPDATE SKIP LOCKED on Oracle Database and PostgreSQL dialects or FOR SHARE SKIP LOCKED if read=True is also specified.
• key_share – boolean, will render FOR NO KEY UPDATE, or if combined with read=True will render FOR KEY SHARE, on the PostgreSQL dialect.
class sqlalchemy.sql.expression.HasCTE
Mixin that declares a class to include CTE support.
Members
add_cte(), cte(), name_cte_columns
Class signature
class sqlalchemy.sql.expression.HasCTE (sqlalchemy.sql.roles.HasCTERole, sqlalchemy.sql.expression.SelectsRows)
method sqlalchemy.sql.expression.HasCTE.add_cte(*ctes: CTE, nest_here: bool = False) → Self
Add one or more CTE constructs to this statement.
This method will associate the given CTE constructs with the parent statement such that they will each be unconditionally rendered in the WITH clause of the final statement, even if not referenced elsewhere within the statement or any sub-selects.
The optional HasCTE.add_cte.nest_here parameter when set to True will have the effect that each given CTE will render in a WITH clause rendered directly along with this statement, rather than being moved to the top of the ultimate rendered statement, even if this statement is rendered as a subquery within a larger statement.
This method has two general uses. One is to embed CTE statements that serve some purpose without being referenced explicitly, such as the use case of embedding a DML statement such as an INSERT or UPDATE as a CTE inline with a primary statement that may draw from its results indirectly. The other is to provide control over the exact placement of a particular series of CTE constructs that should remain rendered directly in terms of a particular statement that may be nested in a larger statement.
E.g.:
from sqlalchemy import table, column, select

t = table("t", column("c1"), column("c2"))

ins = t.insert().values({"c1": "x", "c2": "y"}).cte()

stmt = select(t).add_cte(ins)
Would render:
WITH anon_1 AS (
    INSERT INTO t (c1, c2) VALUES (:param_1, :param_2)
)
SELECT t.c1, t.c2
FROM t
Above, the “anon_1” CTE is not referenced in the SELECT statement, however still accomplishes the task of running an INSERT statement.
Similarly in a DML-related context, using the PostgreSQL Insert construct to generate an “upsert”:
from sqlalchemy import table, column
from sqlalchemy.dialects.postgresql import insert

t = table("t", column("c1"), column("c2"))

delete_statement_cte = t.delete().where(t.c.c1 < 1).cte("deletions")

insert_stmt = insert(t).values({"c1": 1, "c2": 2})
update_statement = insert_stmt.on_conflict_do_update(
    index_elements=[t.c.c1],
    set_={
        "c1": insert_stmt.excluded.c1,
        "c2": insert_stmt.excluded.c2,
    },
).add_cte(delete_statement_cte)

print(update_statement)
The above statement renders as:
WITH deletions AS (
    DELETE FROM t WHERE t.c1 < %(c1_1)s
)
INSERT INTO t (c1, c2) VALUES (%(c1)s, %(c2)s)
ON CONFLICT (c1) DO UPDATE SET c1 = excluded.c1, c2 = excluded.c2
Added in version 1.4.21.
Parameters:
• *ctes – 
zero or more CTE constructs.
Changed in version 2.0: Multiple CTE instances are accepted
• nest_here – 
if True, the given CTE or CTEs will be rendered as though they specified the HasCTE.cte.nesting flag to True when they were added to this HasCTE. Assuming the given CTEs are not referenced in an outer-enclosing statement as well, the CTEs given should render at the level of this statement when this flag is given.
Added in version 2.0.
See also
HasCTE.cte.nesting
method sqlalchemy.sql.expression.HasCTE.cte(name: str | None = None, recursive: bool = False, nesting: bool = False) → CTE
Return a new CTE, or Common Table Expression instance.
Common table expressions are a SQL standard whereby SELECT statements can draw upon secondary statements specified along with the primary statement, using a clause called “WITH”. Special semantics regarding UNION can also be employed to allow “recursive” queries, where a SELECT statement can draw upon the set of rows that have previously been selected.
CTEs can also be applied to DML constructs UPDATE, INSERT and DELETE on some databases, both as a source of CTE rows when combined with RETURNING, as well as a consumer of CTE rows.
SQLAlchemy detects CTE objects, which are treated similarly to Alias objects, as special elements to be delivered to the FROM clause of the statement as well as to a WITH clause at the top of the statement.
For special prefixes such as PostgreSQL “MATERIALIZED” and “NOT MATERIALIZED”, the CTE.prefix_with() method may be used to establish these.
Changed in version 1.3.13: Added support for prefixes. In particular - MATERIALIZED and NOT MATERIALIZED.
Parameters:
• name – name given to the common table expression. Like FromClause.alias(), the name can be left as None in which case an anonymous symbol will be used at query compile time.
• recursive – if True, will render WITH RECURSIVE. A recursive common table expression is intended to be used in conjunction with UNION ALL in order to derive rows from those already selected.
• nesting – 
if True, will render the CTE locally to the statement in which it is referenced. For more complex scenarios, the HasCTE.add_cte() method using the HasCTE.add_cte.nest_here parameter may also be used to more carefully control the exact placement of a particular CTE.
Added in version 1.4.24.
See also
HasCTE.add_cte()
The following examples include two from PostgreSQL’s documentation at https://www.postgresql.org/docs/current/static/queries-with.html, as well as additional examples.
Example 1, non recursive:
from sqlalchemy import (
    Table,
    Column,
    String,
    Integer,
    MetaData,
    select,
    func,
)

metadata = MetaData()

orders = Table(
    "orders",
    metadata,
    Column("region", String),
    Column("amount", Integer),
    Column("product", String),
    Column("quantity", Integer),
)

regional_sales = (
    select(orders.c.region, func.sum(orders.c.amount).label("total_sales"))
    .group_by(orders.c.region)
    .cte("regional_sales")
)


top_regions = (
    select(regional_sales.c.region)
    .where(
        regional_sales.c.total_sales
        > select(func.sum(regional_sales.c.total_sales) / 10)
    )
    .cte("top_regions")
)

statement = (
    select(
        orders.c.region,
        orders.c.product,
        func.sum(orders.c.quantity).label("product_units"),
        func.sum(orders.c.amount).label("product_sales"),
    )
    .where(orders.c.region.in_(select(top_regions.c.region)))
    .group_by(orders.c.region, orders.c.product)
)

result = conn.execute(statement).fetchall()
Example 2, WITH RECURSIVE:
from sqlalchemy import (
    Table,
    Column,
    String,
    Integer,
    MetaData,
    select,
    func,
)

metadata = MetaData()

parts = Table(
    "parts",
    metadata,
    Column("part", String),
    Column("sub_part", String),
    Column("quantity", Integer),
)

included_parts = (
    select(parts.c.sub_part, parts.c.part, parts.c.quantity)
    .where(parts.c.part == "our part")
    .cte(recursive=True)
)


incl_alias = included_parts.alias()
parts_alias = parts.alias()
included_parts = included_parts.union_all(
    select(
        parts_alias.c.sub_part, parts_alias.c.part, parts_alias.c.quantity
    ).where(parts_alias.c.part == incl_alias.c.sub_part)
)

statement = select(
    included_parts.c.sub_part,
    func.sum(included_parts.c.quantity).label("total_quantity"),
).group_by(included_parts.c.sub_part)

result = conn.execute(statement).fetchall()
Example 3, an upsert using UPDATE and INSERT with CTEs:
from datetime import date
from sqlalchemy import (
    MetaData,
    Table,
    Column,
    Integer,
    Date,
    select,
    literal,
    and_,
    exists,
)

metadata = MetaData()

visitors = Table(
    "visitors",
    metadata,
    Column("product_id", Integer, primary_key=True),
    Column("date", Date, primary_key=True),
    Column("count", Integer),
)

# add 5 visitors for the product_id == 1
product_id = 1
day = date.today()
count = 5

update_cte = (
    visitors.update()
    .where(
        and_(visitors.c.product_id == product_id, visitors.c.date == day)
    )
    .values(count=visitors.c.count + count)
    .returning(literal(1))
    .cte("update_cte")
)

upsert = visitors.insert().from_select(
    [visitors.c.product_id, visitors.c.date, visitors.c.count],
    select(literal(product_id), literal(day), literal(count)).where(
        ~exists(update_cte.select())
    ),
)

connection.execute(upsert)
Example 4, Nesting CTE (SQLAlchemy 1.4.24 and above):
value_a = select(literal("root").label("n")).cte("value_a")

# A nested CTE with the same name as the root one
value_a_nested = select(literal("nesting").label("n")).cte(
    "value_a", nesting=True
)

# Nesting CTEs takes ascendency locally
# over the CTEs at a higher level
value_b = select(value_a_nested.c.n).cte("value_b")

value_ab = select(value_a.c.n.label("a"), value_b.c.n.label("b"))
The above query will render the second CTE nested inside the first, shown with inline parameters below as:
WITH
    value_a AS
        (SELECT 'root' AS n),
    value_b AS
        (WITH value_a AS
            (SELECT 'nesting' AS n)
        SELECT value_a.n AS n FROM value_a)
SELECT value_a.n AS a, value_b.n AS b
FROM value_a, value_b
The same CTE can be set up using the HasCTE.add_cte() method as follows (SQLAlchemy 2.0 and above):
value_a = select(literal("root").label("n")).cte("value_a")

# A nested CTE with the same name as the root one
value_a_nested = select(literal("nesting").label("n")).cte("value_a")

# Nesting CTEs takes ascendency locally
# over the CTEs at a higher level
value_b = (
    select(value_a_nested.c.n)
    .add_cte(value_a_nested, nest_here=True)
    .cte("value_b")
)

value_ab = select(value_a.c.n.label("a"), value_b.c.n.label("b"))
Example 5, Non-Linear CTE (SQLAlchemy 1.4.28 and above):
edge = Table(
    "edge",
    metadata,
    Column("id", Integer, primary_key=True),
    Column("left", Integer),
    Column("right", Integer),
)

root_node = select(literal(1).label("node")).cte("nodes", recursive=True)

left_edge = select(edge.c.left).join(
    root_node, edge.c.right == root_node.c.node
)
right_edge = select(edge.c.right).join(
    root_node, edge.c.left == root_node.c.node
)

subgraph_cte = root_node.union(left_edge, right_edge)

subgraph = select(subgraph_cte)
The above query will render 2 UNIONs inside the recursive CTE:
WITH RECURSIVE nodes(node) AS (
        SELECT 1 AS node
    UNION
        SELECT edge."left" AS "left"
        FROM edge JOIN nodes ON edge."right" = nodes.node
    UNION
        SELECT edge."right" AS "right"
        FROM edge JOIN nodes ON edge."left" = nodes.node
)
SELECT nodes.node FROM nodes
See also
Query.cte() - ORM version of HasCTE.cte().
attribute sqlalchemy.sql.expression.HasCTE.name_cte_columns: bool = False
indicates if this HasCTE as contained within a CTE should compel the CTE to render the column names of this object in the WITH clause.
Added in version 2.0.42.
class sqlalchemy.sql.expression.HasPrefixes
Members
prefix_with()
method sqlalchemy.sql.expression.HasPrefixes.prefix_with(*prefixes: _TextCoercedExpressionArgument[Any], dialect: str = '*') → Self
Add one or more expressions following the statement keyword, i.e. SELECT, INSERT, UPDATE, or DELETE. Generative.
This is used to support backend-specific prefix keywords such as those provided by MySQL.
E.g.:
stmt = table.insert().prefix_with("LOW_PRIORITY", dialect="mysql")

# MySQL 5.7 optimizer hints
stmt = select(table).prefix_with("/*+ BKA(t1) */", dialect="mysql")
Multiple prefixes can be specified by multiple calls to HasPrefixes.prefix_with().
Parameters:
• *prefixes – textual or ClauseElement construct which will be rendered following the INSERT, UPDATE, or DELETE keyword.
• dialect – optional string dialect name which will limit rendering of this prefix to only that dialect.
class sqlalchemy.sql.expression.HasSuffixes
Members
suffix_with()
method sqlalchemy.sql.expression.HasSuffixes.suffix_with(*suffixes: _TextCoercedExpressionArgument[Any], dialect: str = '*') → Self
Add one or more expressions following the statement as a whole.
This is used to support backend-specific suffix keywords on certain constructs.
E.g.:
stmt = (
    select(col1, col2)
    .cte()
    .suffix_with(
        "cycle empno set y_cycle to 1 default 0", dialect="oracle"
    )
)
Multiple suffixes can be specified by multiple calls to HasSuffixes.suffix_with().
Parameters:
• *suffixes – textual or ClauseElement construct which will be rendered following the target clause.
• dialect – Optional string dialect name which will limit rendering of this suffix to only that dialect.
class sqlalchemy.sql.expression.Join
Represent a JOIN construct between two FromClause elements.
The public constructor function for Join is the module-level join() function, as well as the FromClause.join() method of any FromClause (e.g. such as Table).
See also
join()
FromClause.join()
Members
__init__(), description, is_derived_from(), select(), self_group()
Class signature
class sqlalchemy.sql.expression.Join (sqlalchemy.sql.roles.DMLTableRole, sqlalchemy.sql.expression.FromClause)
method sqlalchemy.sql.expression.Join.__init__(left: _FromClauseArgument, right: _FromClauseArgument, onclause: _OnClauseArgument | None = None, isouter: bool = False, full: bool = False)
Construct a new Join.
The usual entrypoint here is the join() function or the FromClause.join() method of any FromClause object.
attribute sqlalchemy.sql.expression.Join.description
method sqlalchemy.sql.expression.Join.is_derived_from(fromclause: FromClause | None) → bool
Return True if this FromClause is ‘derived’ from the given FromClause.
An example would be an Alias of a Table is derived from that Table.
method sqlalchemy.sql.expression.Join.select() → Select
Create a Select from this Join.
E.g.:
stmt = table_a.join(table_b, table_a.c.id == table_b.c.a_id)

stmt = stmt.select()
The above will produce a SQL string resembling:
SELECT table_a.id, table_a.col, table_b.id, table_b.a_id
FROM table_a JOIN table_b ON table_a.id = table_b.a_id
method sqlalchemy.sql.expression.Join.self_group(against: OperatorType | None = None) → FromGrouping
Apply a ‘grouping’ to this ClauseElement.
This method is overridden by subclasses to return a “grouping” construct, i.e. parenthesis. In particular it’s used by “binary” expressions to provide a grouping around themselves when placed into a larger expression, as well as by select() constructs when placed into the FROM clause of another select(). (Note that subqueries should be normally created using the Select.alias() method, as many platforms require nested SELECT statements to be named).
As expressions are composed together, the application of self_group() is automatic - end-user code should never need to use this method directly. Note that SQLAlchemy’s clause constructs take operator precedence into account - so parenthesis might not be needed, for example, in an expression like x OR (y AND z) - AND takes precedence over OR.
The base self_group() method of ClauseElement just returns self.
class sqlalchemy.sql.expression.Lateral
Represent a LATERAL subquery.
This object is constructed from the lateral() module level function as well as the FromClause.lateral() method available on all FromClause subclasses.
While LATERAL is part of the SQL standard, currently only more recent PostgreSQL versions provide support for this keyword.
See also
LATERAL correlation - overview of usage.
Members
inherit_cache
Class signature
class sqlalchemy.sql.expression.Lateral (sqlalchemy.sql.expression.FromClauseAlias, sqlalchemy.sql.expression.LateralFromClause)
attribute sqlalchemy.sql.expression.Lateral.inherit_cache: bool | None = True
Indicate if this HasCacheKey instance should make use of the cache key generation scheme used by its immediate superclass.
The attribute defaults to None, which indicates that a construct has not yet taken into account whether or not its appropriate for it to participate in caching; this is functionally equivalent to setting the value to False, except that a warning is also emitted.
This flag can be set to True on a particular class, if the SQL that corresponds to the object does not change based on attributes which are local to this class, and not its superclass.
See also
Enabling Caching Support for Custom Constructs - General guideslines for setting the HasCacheKey.inherit_cache attribute for third-party or user defined SQL constructs.
class sqlalchemy.sql.expression.ReturnsRows
The base-most class for Core constructs that have some concept of columns that can represent rows.
While the SELECT statement and TABLE are the primary things we think of in this category, DML like INSERT, UPDATE and DELETE can also specify RETURNING which means they can be used in CTEs and other forms, and PostgreSQL has functions that return rows also.
Added in version 1.4.
Members
compile(), exported_columns, get_children(), inherit_cache, is_derived_from()
Class signature
class sqlalchemy.sql.expression.ReturnsRows (sqlalchemy.sql.roles.ReturnsRowsRole, sqlalchemy.sql.expression.DQLDMLClauseElement)
method sqlalchemy.sql.expression.ReturnsRows.compile(bind: _HasDialect | None = None, dialect: Dialect | None = None, **kw: Any) → Compiled
inherited from the CompilerElement.compile() method of CompilerElement
Compile this SQL expression.
The return value is a Compiled object. Calling str() or unicode() on the returned value will yield a string representation of the result. The Compiled object also can return a dictionary of bind parameter names and values using the params accessor.
Parameters:
• bind – An Connection or Engine which can provide a Dialect in order to generate a Compiled object. If the bind and dialect parameters are both omitted, a default SQL compiler is used.
• column_keys – Used for INSERT and UPDATE statements, a list of column names which should be present in the VALUES clause of the compiled statement. If None, all columns from the target table object are rendered.
• dialect – A Dialect instance which can generate a Compiled object. This argument takes precedence over the bind argument.
• compile_kwargs – 
optional dictionary of additional parameters that will be passed through to the compiler within all “visit” methods. This allows any custom flag to be passed through to a custom compilation construct, for example. It is also used for the case of passing the literal_binds flag through:
from sqlalchemy.sql import table, column, select

t = table("t", column("x"))

s = select(t).where(t.c.x == 5)

print(s.compile(compile_kwargs={"literal_binds": True}))
• 
See also
How do I render SQL expressions as strings, possibly with bound parameters inlined?
attribute sqlalchemy.sql.expression.ReturnsRows.exported_columns
A ColumnCollection that represents the “exported” columns of this ReturnsRows.
The “exported” columns represent the collection of ColumnElement expressions that are rendered by this SQL construct. There are primary varieties which are the “FROM clause columns” of a FROM clause, such as a table, join, or subquery, the “SELECTed columns”, which are the columns in the “columns clause” of a SELECT statement, and the RETURNING columns in a DML statement..
Added in version 1.4.
See also
FromClause.exported_columns
SelectBase.exported_columns
method sqlalchemy.sql.expression.ReturnsRows.get_children(*, omit_attrs: Tuple[str, ...] = (), **kw: Any) → Iterable[HasTraverseInternals]
inherited from the HasTraverseInternals.get_children() method of HasTraverseInternals
Return immediate child HasTraverseInternals elements of this HasTraverseInternals.
This is used for visit traversal.
**kw may contain flags that change the collection that is returned, for example to return a subset of items in order to cut down on larger traversals, or to return child items from a different context (such as schema-level collections instead of clause-level).
attribute sqlalchemy.sql.expression.ReturnsRows.inherit_cache: bool | None = None
inherited from the HasCacheKey.inherit_cache attribute of HasCacheKey
Indicate if this HasCacheKey instance should make use of the cache key generation scheme used by its immediate superclass.
The attribute defaults to None, which indicates that a construct has not yet taken into account whether or not its appropriate for it to participate in caching; this is functionally equivalent to setting the value to False, except that a warning is also emitted.
This flag can be set to True on a particular class, if the SQL that corresponds to the object does not change based on attributes which are local to this class, and not its superclass.
See also
Enabling Caching Support for Custom Constructs - General guideslines for setting the HasCacheKey.inherit_cache attribute for third-party or user defined SQL constructs.
method sqlalchemy.sql.expression.ReturnsRows.is_derived_from(fromclause: FromClause | None) → bool
Return True if this ReturnsRows is ‘derived’ from the given FromClause.
An example would be an Alias of a Table is derived from that Table.
class sqlalchemy.sql.expression.ScalarSelect
Represent a scalar subquery.
A ScalarSelect is created by invoking the SelectBase.scalar_subquery() method. The object then participates in other SQL expressions as a SQL column expression within the ColumnElement hierarchy.
See also
SelectBase.scalar_subquery()
Scalar and Correlated Subqueries - in the 2.0 tutorial
Members
correlate(), correlate_except(), inherit_cache, self_group(), where()
Class signature
class sqlalchemy.sql.expression.ScalarSelect (sqlalchemy.sql.roles.InElementRole, sqlalchemy.sql.expression.Generative, sqlalchemy.sql.expression.GroupedElement, sqlalchemy.sql.expression.ColumnElement)
method sqlalchemy.sql.expression.ScalarSelect.correlate(*fromclauses: Literal[None, False] | _FromClauseArgument) → Self
Return a new ScalarSelect which will correlate the given FROM clauses to that of an enclosing Select.
This method is mirrored from the Select.correlate() method of the underlying Select. The method applies the :meth:_sql.Select.correlate` method, then returns a new ScalarSelect against that statement.
Added in version 1.4: Previously, the ScalarSelect.correlate() method was only available from Select.
Parameters:
*fromclauses – a list of one or more FromClause constructs, or other compatible constructs (i.e. ORM-mapped classes) to become part of the correlate collection.
See also
ScalarSelect.correlate_except()
Scalar and Correlated Subqueries - in the 2.0 tutorial
method sqlalchemy.sql.expression.ScalarSelect.correlate_except(*fromclauses: Literal[None, False] | _FromClauseArgument) → Self
Return a new ScalarSelect which will omit the given FROM clauses from the auto-correlation process.
This method is mirrored from the Select.correlate_except() method of the underlying Select. The method applies the :meth:_sql.Select.correlate_except` method, then returns a new ScalarSelect against that statement.
Added in version 1.4: Previously, the ScalarSelect.correlate_except() method was only available from Select.
Parameters:
*fromclauses – a list of one or more FromClause constructs, or other compatible constructs (i.e. ORM-mapped classes) to become part of the correlate-exception collection.
See also
ScalarSelect.correlate()
Scalar and Correlated Subqueries - in the 2.0 tutorial
attribute sqlalchemy.sql.expression.ScalarSelect.inherit_cache: bool | None = True
Indicate if this HasCacheKey instance should make use of the cache key generation scheme used by its immediate superclass.
The attribute defaults to None, which indicates that a construct has not yet taken into account whether or not its appropriate for it to participate in caching; this is functionally equivalent to setting the value to False, except that a warning is also emitted.
This flag can be set to True on a particular class, if the SQL that corresponds to the object does not change based on attributes which are local to this class, and not its superclass.
See also
Enabling Caching Support for Custom Constructs - General guideslines for setting the HasCacheKey.inherit_cache attribute for third-party or user defined SQL constructs.
method sqlalchemy.sql.expression.ScalarSelect.self_group(against: OperatorType | None = None) → Self
Apply a ‘grouping’ to this ClauseElement.
This method is overridden by subclasses to return a “grouping” construct, i.e. parenthesis. In particular it’s used by “binary” expressions to provide a grouping around themselves when placed into a larger expression, as well as by select() constructs when placed into the FROM clause of another select(). (Note that subqueries should be normally created using the Select.alias() method, as many platforms require nested SELECT statements to be named).
As expressions are composed together, the application of self_group() is automatic - end-user code should never need to use this method directly. Note that SQLAlchemy’s clause constructs take operator precedence into account - so parenthesis might not be needed, for example, in an expression like x OR (y AND z) - AND takes precedence over OR.
The base self_group() method of ClauseElement just returns self.
method sqlalchemy.sql.expression.ScalarSelect.where(crit: _ColumnExpressionArgument[bool]) → Self
Apply a WHERE clause to the SELECT statement referred to by this ScalarSelect.
class sqlalchemy.sql.expression.Select
Represents a SELECT statement.
The Select object is normally constructed using the select() function. See that function for details.
See also
select()
Using SELECT Statements - in the 2.0 tutorial
Members
__init__(), __new__(), add_columns(), add_cte(), alias(), argument_for(), as_scalar(), c, column(), column_descriptions, columns_clause_froms, compile(), correlate(), correlate_except(), corresponding_column(), cte(), dialect_kwargs, dialect_options, distinct(), except_(), except_all(), execution_options(), exists(), exported_columns, fetch(), filter(), filter_by(), from_statement(), froms, get_children(), get_execution_options(), get_final_froms(), get_label_style(), group_by(), having(), inherit_cache, inner_columns, intersect(), intersect_all(), is_derived_from(), join(), join_from(), kwargs, label(), lateral(), limit(), name_cte_columns, offset(), options(), order_by(), outerjoin(), outerjoin_from(), prefix_with(), reduce_columns(), replace_selectable(), scalar_subquery(), select(), select_from(), selected_columns, self_group(), set_label_style(), slice(), subquery(), suffix_with(), union(), union_all(), where(), whereclause, with_for_update(), with_hint(), with_only_columns(), with_statement_hint()
Class signature
class sqlalchemy.sql.expression.Select (sqlalchemy.sql.expression.HasPrefixes, sqlalchemy.sql.expression.HasSuffixes, sqlalchemy.sql.expression.HasHints, sqlalchemy.sql.expression.HasCompileState, sqlalchemy.sql.expression._SelectFromElements, sqlalchemy.sql.expression.GenerativeSelect, sqlalchemy.sql.expression.TypedReturnsRows)
method sqlalchemy.sql.expression.Select.__init__(*entities: _ColumnsClauseArgument[Any], **dialect_kw: Any)
Construct a new Select.
The public constructor for Select is the select() function.
classmethod sqlalchemy.sql.expression.Select.__new__(*args, **kwargs)
method sqlalchemy.sql.expression.Select.add_columns(*entities: _ColumnsClauseArgument[Any]) → Select[Any]
Return a new select() construct with the given entities appended to its columns clause.
E.g.:
my_select = my_select.add_columns(table.c.new_column)
The original expressions in the columns clause remain in place. To replace the original expressions with new ones, see the method Select.with_only_columns().
Parameters:
*entities – column, table, or other entity expressions to be added to the columns clause
See also
Select.with_only_columns() - replaces existing expressions rather than appending.
Selecting Multiple ORM Entities Simultaneously - ORM-centric example
method sqlalchemy.sql.expression.Select.add_cte(*ctes: CTE, nest_here: bool = False) → Self
inherited from the HasCTE.add_cte() method of HasCTE
Add one or more CTE constructs to this statement.
This method will associate the given CTE constructs with the parent statement such that they will each be unconditionally rendered in the WITH clause of the final statement, even if not referenced elsewhere within the statement or any sub-selects.
The optional HasCTE.add_cte.nest_here parameter when set to True will have the effect that each given CTE will render in a WITH clause rendered directly along with this statement, rather than being moved to the top of the ultimate rendered statement, even if this statement is rendered as a subquery within a larger statement.
This method has two general uses. One is to embed CTE statements that serve some purpose without being referenced explicitly, such as the use case of embedding a DML statement such as an INSERT or UPDATE as a CTE inline with a primary statement that may draw from its results indirectly. The other is to provide control over the exact placement of a particular series of CTE constructs that should remain rendered directly in terms of a particular statement that may be nested in a larger statement.
E.g.:
from sqlalchemy import table, column, select

t = table("t", column("c1"), column("c2"))

ins = t.insert().values({"c1": "x", "c2": "y"}).cte()

stmt = select(t).add_cte(ins)
Would render:
WITH anon_1 AS (
    INSERT INTO t (c1, c2) VALUES (:param_1, :param_2)
)
SELECT t.c1, t.c2
FROM t
Above, the “anon_1” CTE is not referenced in the SELECT statement, however still accomplishes the task of running an INSERT statement.
Similarly in a DML-related context, using the PostgreSQL Insert construct to generate an “upsert”:
from sqlalchemy import table, column
from sqlalchemy.dialects.postgresql import insert

t = table("t", column("c1"), column("c2"))

delete_statement_cte = t.delete().where(t.c.c1 < 1).cte("deletions")

insert_stmt = insert(t).values({"c1": 1, "c2": 2})
update_statement = insert_stmt.on_conflict_do_update(
    index_elements=[t.c.c1],
    set_={
        "c1": insert_stmt.excluded.c1,
        "c2": insert_stmt.excluded.c2,
    },
).add_cte(delete_statement_cte)

print(update_statement)
The above statement renders as:
WITH deletions AS (
    DELETE FROM t WHERE t.c1 < %(c1_1)s
)
INSERT INTO t (c1, c2) VALUES (%(c1)s, %(c2)s)
ON CONFLICT (c1) DO UPDATE SET c1 = excluded.c1, c2 = excluded.c2
Added in version 1.4.21.
Parameters:
• *ctes – 
zero or more CTE constructs.
Changed in version 2.0: Multiple CTE instances are accepted
• nest_here – 
if True, the given CTE or CTEs will be rendered as though they specified the HasCTE.cte.nesting flag to True when they were added to this HasCTE. Assuming the given CTEs are not referenced in an outer-enclosing statement as well, the CTEs given should render at the level of this statement when this flag is given.
Added in version 2.0.
See also
HasCTE.cte.nesting
method sqlalchemy.sql.expression.Select.alias(name: str | None = None, flat: bool = False) → Subquery
inherited from the SelectBase.alias() method of SelectBase
Return a named subquery against this SelectBase.
For a SelectBase (as opposed to a FromClause), this returns a Subquery object which behaves mostly the same as the Alias object that is used with a FromClause.
Changed in version 1.4: The SelectBase.alias() method is now a synonym for the SelectBase.subquery() method.
classmethod sqlalchemy.sql.expression.Select.argument_for(dialect_name, argument_name, default)
inherited from the DialectKWArgs.argument_for() method of DialectKWArgs
Add a new kind of dialect-specific keyword argument for this class.
E.g.:
Index.argument_for("mydialect", "length", None)

some_index = Index("a", "b", mydialect_length=5)
The DialectKWArgs.argument_for() method is a per-argument way adding extra arguments to the DefaultDialect.construct_arguments dictionary. This dictionary provides a list of argument names accepted by various schema-level constructs on behalf of a dialect.
New dialects should typically specify this dictionary all at once as a data member of the dialect class. The use case for ad-hoc addition of argument names is typically for end-user code that is also using a custom compilation scheme which consumes the additional arguments.
Parameters:
• dialect_name – name of a dialect. The dialect must be locatable, else a NoSuchModuleError is raised. The dialect must also include an existing DefaultDialect.construct_arguments collection, indicating that it participates in the keyword-argument validation and default system, else ArgumentError is raised. If the dialect does not include this collection, then any keyword argument can be specified on behalf of this dialect already. All dialects packaged within SQLAlchemy include this collection, however for third party dialects, support may vary.
• argument_name – name of the parameter.
• default – default value of the parameter.
method sqlalchemy.sql.expression.Select.as_scalar() → ScalarSelect[Any]
inherited from the SelectBase.as_scalar() method of SelectBase
Deprecated since version 1.4: The SelectBase.as_scalar() method is deprecated and will be removed in a future release. Please refer to SelectBase.scalar_subquery().
attribute sqlalchemy.sql.expression.Select.c
inherited from the SelectBase.c attribute of SelectBase
Deprecated since version 1.4: The SelectBase.c and SelectBase.columns attributes are deprecated and will be removed in a future release; these attributes implicitly create a subquery that should be explicit. Please call SelectBase.subquery() first in order to create a subquery, which then contains this attribute. To access the columns that this SELECT object SELECTs from, use the SelectBase.selected_columns attribute.
method sqlalchemy.sql.expression.Select.column(column: _ColumnsClauseArgument[Any]) → Select[Any]
Return a new select() construct with the given column expression added to its columns clause.
Deprecated since version 1.4: The Select.column() method is deprecated and will be removed in a future release. Please use Select.add_columns()
E.g.:
my_select = my_select.column(table.c.new_column)
See the documentation for Select.with_only_columns() for guidelines on adding /replacing the columns of a Select object.
attribute sqlalchemy.sql.expression.Select.column_descriptions
Return a plugin-enabled ‘column descriptions’ structure referring to the columns which are SELECTed by this statement.
This attribute is generally useful when using the ORM, as an extended structure which includes information about mapped entities is returned. The section Inspecting entities and columns from ORM-enabled SELECT and DML statements contains more background.
For a Core-only statement, the structure returned by this accessor is derived from the same objects that are returned by the Select.selected_columns accessor, formatted as a list of dictionaries which contain the keys name, type and expr, which indicate the column expressions to be selected:
>>> stmt = select(user_table)
>>> stmt.column_descriptions
[
    {
        'name': 'id',
        'type': Integer(),
        'expr': Column('id', Integer(), ...)},
    {
        'name': 'name',
        'type': String(length=30),
        'expr': Column('name', String(length=30), ...)}
]
Changed in version 1.4.33: The Select.column_descriptions attribute returns a structure for a Core-only set of entities, not just ORM-only entities.
See also
UpdateBase.entity_description - entity information for an insert(), update(), or delete()
Inspecting entities and columns from ORM-enabled SELECT and DML statements - ORM background
attribute sqlalchemy.sql.expression.Select.columns_clause_froms
Return the set of FromClause objects implied by the columns clause of this SELECT statement.
Added in version 1.4.23.
See also
Select.froms - “final” FROM list taking the full statement into account
Select.with_only_columns() - makes use of this collection to set up a new FROM list
method sqlalchemy.sql.expression.Select.compile(bind: _HasDialect | None = None, dialect: Dialect | None = None, **kw: Any) → Compiled
inherited from the CompilerElement.compile() method of CompilerElement
Compile this SQL expression.
The return value is a Compiled object. Calling str() or unicode() on the returned value will yield a string representation of the result. The Compiled object also can return a dictionary of bind parameter names and values using the params accessor.
Parameters:
• bind – An Connection or Engine which can provide a Dialect in order to generate a Compiled object. If the bind and dialect parameters are both omitted, a default SQL compiler is used.
• column_keys – Used for INSERT and UPDATE statements, a list of column names which should be present in the VALUES clause of the compiled statement. If None, all columns from the target table object are rendered.
• dialect – A Dialect instance which can generate a Compiled object. This argument takes precedence over the bind argument.
• compile_kwargs – 
optional dictionary of additional parameters that will be passed through to the compiler within all “visit” methods. This allows any custom flag to be passed through to a custom compilation construct, for example. It is also used for the case of passing the literal_binds flag through:
from sqlalchemy.sql import table, column, select

t = table("t", column("x"))

s = select(t).where(t.c.x == 5)

print(s.compile(compile_kwargs={"literal_binds": True}))
• 
See also
How do I render SQL expressions as strings, possibly with bound parameters inlined?
method sqlalchemy.sql.expression.Select.correlate(*fromclauses: Literal[None, False] | _FromClauseArgument) → Self
Return a new Select which will correlate the given FROM clauses to that of an enclosing Select.
Calling this method turns off the Select object’s default behavior of “auto-correlation”. Normally, FROM elements which appear in a Select that encloses this one via its WHERE clause, ORDER BY, HAVING or columns clause will be omitted from this Select object’s FROM clause. Setting an explicit correlation collection using the Select.correlate() method provides a fixed list of FROM objects that can potentially take place in this process.
When Select.correlate() is used to apply specific FROM clauses for correlation, the FROM elements become candidates for correlation regardless of how deeply nested this Select object is, relative to an enclosing Select which refers to the same FROM object. This is in contrast to the behavior of “auto-correlation” which only correlates to an immediate enclosing Select. Multi-level correlation ensures that the link between enclosed and enclosing Select is always via at least one WHERE/ORDER BY/HAVING/columns clause in order for correlation to take place.
If None is passed, the Select object will correlate none of its FROM entries, and all will render unconditionally in the local FROM clause.
Parameters:
*fromclauses – one or more FromClause or other FROM-compatible construct such as an ORM mapped entity to become part of the correlate collection; alternatively pass a single value None to remove all existing correlations.
See also
Select.correlate_except()
Scalar and Correlated Subqueries
method sqlalchemy.sql.expression.Select.correlate_except(*fromclauses: Literal[None, False] | _FromClauseArgument) → Self
Return a new Select which will omit the given FROM clauses from the auto-correlation process.
Calling Select.correlate_except() turns off the Select object’s default behavior of “auto-correlation” for the given FROM elements. An element specified here will unconditionally appear in the FROM list, while all other FROM elements remain subject to normal auto-correlation behaviors.
If None is passed, or no arguments are passed, the Select object will correlate all of its FROM entries.
Parameters:
*fromclauses – a list of one or more FromClause constructs, or other compatible constructs (i.e. ORM-mapped classes) to become part of the correlate-exception collection.
See also
Select.correlate()
Scalar and Correlated Subqueries
method sqlalchemy.sql.expression.Select.corresponding_column(column: KeyedColumnElement[Any], require_embedded: bool = False) → KeyedColumnElement[Any] | None
inherited from the Selectable.corresponding_column() method of Selectable
Given a ColumnElement, return the exported ColumnElement object from the Selectable.exported_columns collection of this Selectable which corresponds to that original ColumnElement via a common ancestor column.
Parameters:
• column – the target ColumnElement to be matched.
• require_embedded – only return corresponding columns for the given ColumnElement, if the given ColumnElement is actually present within a sub-element of this Selectable. Normally the column will match if it merely shares a common ancestor with one of the exported columns of this Selectable.
See also
Selectable.exported_columns - the ColumnCollection that is used for the operation.
ColumnCollection.corresponding_column() - implementation method.
method sqlalchemy.sql.expression.Select.cte(name: str | None = None, recursive: bool = False, nesting: bool = False) → CTE
inherited from the HasCTE.cte() method of HasCTE
Return a new CTE, or Common Table Expression instance.
Common table expressions are a SQL standard whereby SELECT statements can draw upon secondary statements specified along with the primary statement, using a clause called “WITH”. Special semantics regarding UNION can also be employed to allow “recursive” queries, where a SELECT statement can draw upon the set of rows that have previously been selected.
CTEs can also be applied to DML constructs UPDATE, INSERT and DELETE on some databases, both as a source of CTE rows when combined with RETURNING, as well as a consumer of CTE rows.
SQLAlchemy detects CTE objects, which are treated similarly to Alias objects, as special elements to be delivered to the FROM clause of the statement as well as to a WITH clause at the top of the statement.
For special prefixes such as PostgreSQL “MATERIALIZED” and “NOT MATERIALIZED”, the CTE.prefix_with() method may be used to establish these.
Changed in version 1.3.13: Added support for prefixes. In particular - MATERIALIZED and NOT MATERIALIZED.
Parameters:
• name – name given to the common table expression. Like FromClause.alias(), the name can be left as None in which case an anonymous symbol will be used at query compile time.
• recursive – if True, will render WITH RECURSIVE. A recursive common table expression is intended to be used in conjunction with UNION ALL in order to derive rows from those already selected.
• nesting – 
if True, will render the CTE locally to the statement in which it is referenced. For more complex scenarios, the HasCTE.add_cte() method using the HasCTE.add_cte.nest_here parameter may also be used to more carefully control the exact placement of a particular CTE.
Added in version 1.4.24.
See also
HasCTE.add_cte()
The following examples include two from PostgreSQL’s documentation at https://www.postgresql.org/docs/current/static/queries-with.html, as well as additional examples.
Example 1, non recursive:
from sqlalchemy import (
    Table,
    Column,
    String,
    Integer,
    MetaData,
    select,
    func,
)

metadata = MetaData()

orders = Table(
    "orders",
    metadata,
    Column("region", String),
    Column("amount", Integer),
    Column("product", String),
    Column("quantity", Integer),
)

regional_sales = (
    select(orders.c.region, func.sum(orders.c.amount).label("total_sales"))
    .group_by(orders.c.region)
    .cte("regional_sales")
)


top_regions = (
    select(regional_sales.c.region)
    .where(
        regional_sales.c.total_sales
        > select(func.sum(regional_sales.c.total_sales) / 10)
    )
    .cte("top_regions")
)

statement = (
    select(
        orders.c.region,
        orders.c.product,
        func.sum(orders.c.quantity).label("product_units"),
        func.sum(orders.c.amount).label("product_sales"),
    )
    .where(orders.c.region.in_(select(top_regions.c.region)))
    .group_by(orders.c.region, orders.c.product)
)

result = conn.execute(statement).fetchall()
Example 2, WITH RECURSIVE:
from sqlalchemy import (
    Table,
    Column,
    String,
    Integer,
    MetaData,
    select,
    func,
)

metadata = MetaData()

parts = Table(
    "parts",
    metadata,
    Column("part", String),
    Column("sub_part", String),
    Column("quantity", Integer),
)

included_parts = (
    select(parts.c.sub_part, parts.c.part, parts.c.quantity)
    .where(parts.c.part == "our part")
    .cte(recursive=True)
)


incl_alias = included_parts.alias()
parts_alias = parts.alias()
included_parts = included_parts.union_all(
    select(
        parts_alias.c.sub_part, parts_alias.c.part, parts_alias.c.quantity
    ).where(parts_alias.c.part == incl_alias.c.sub_part)
)

statement = select(
    included_parts.c.sub_part,
    func.sum(included_parts.c.quantity).label("total_quantity"),
).group_by(included_parts.c.sub_part)

result = conn.execute(statement).fetchall()
Example 3, an upsert using UPDATE and INSERT with CTEs:
from datetime import date
from sqlalchemy import (
    MetaData,
    Table,
    Column,
    Integer,
    Date,
    select,
    literal,
    and_,
    exists,
)

metadata = MetaData()

visitors = Table(
    "visitors",
    metadata,
    Column("product_id", Integer, primary_key=True),
    Column("date", Date, primary_key=True),
    Column("count", Integer),
)

# add 5 visitors for the product_id == 1
product_id = 1
day = date.today()
count = 5

update_cte = (
    visitors.update()
    .where(
        and_(visitors.c.product_id == product_id, visitors.c.date == day)
    )
    .values(count=visitors.c.count + count)
    .returning(literal(1))
    .cte("update_cte")
)

upsert = visitors.insert().from_select(
    [visitors.c.product_id, visitors.c.date, visitors.c.count],
    select(literal(product_id), literal(day), literal(count)).where(
        ~exists(update_cte.select())
    ),
)

connection.execute(upsert)
Example 4, Nesting CTE (SQLAlchemy 1.4.24 and above):
value_a = select(literal("root").label("n")).cte("value_a")

# A nested CTE with the same name as the root one
value_a_nested = select(literal("nesting").label("n")).cte(
    "value_a", nesting=True
)

# Nesting CTEs takes ascendency locally
# over the CTEs at a higher level
value_b = select(value_a_nested.c.n).cte("value_b")

value_ab = select(value_a.c.n.label("a"), value_b.c.n.label("b"))
The above query will render the second CTE nested inside the first, shown with inline parameters below as:
WITH
    value_a AS
        (SELECT 'root' AS n),
    value_b AS
        (WITH value_a AS
            (SELECT 'nesting' AS n)
        SELECT value_a.n AS n FROM value_a)
SELECT value_a.n AS a, value_b.n AS b
FROM value_a, value_b
The same CTE can be set up using the HasCTE.add_cte() method as follows (SQLAlchemy 2.0 and above):
value_a = select(literal("root").label("n")).cte("value_a")

# A nested CTE with the same name as the root one
value_a_nested = select(literal("nesting").label("n")).cte("value_a")

# Nesting CTEs takes ascendency locally
# over the CTEs at a higher level
value_b = (
    select(value_a_nested.c.n)
    .add_cte(value_a_nested, nest_here=True)
    .cte("value_b")
)

value_ab = select(value_a.c.n.label("a"), value_b.c.n.label("b"))
Example 5, Non-Linear CTE (SQLAlchemy 1.4.28 and above):
edge = Table(
    "edge",
    metadata,
    Column("id", Integer, primary_key=True),
    Column("left", Integer),
    Column("right", Integer),
)

root_node = select(literal(1).label("node")).cte("nodes", recursive=True)

left_edge = select(edge.c.left).join(
    root_node, edge.c.right == root_node.c.node
)
right_edge = select(edge.c.right).join(
    root_node, edge.c.left == root_node.c.node
)

subgraph_cte = root_node.union(left_edge, right_edge)

subgraph = select(subgraph_cte)
The above query will render 2 UNIONs inside the recursive CTE:
WITH RECURSIVE nodes(node) AS (
        SELECT 1 AS node
    UNION
        SELECT edge."left" AS "left"
        FROM edge JOIN nodes ON edge."right" = nodes.node
    UNION
        SELECT edge."right" AS "right"
        FROM edge JOIN nodes ON edge."left" = nodes.node
)
SELECT nodes.node FROM nodes
See also
Query.cte() - ORM version of HasCTE.cte().
attribute sqlalchemy.sql.expression.Select.dialect_kwargs
inherited from the DialectKWArgs.dialect_kwargs attribute of DialectKWArgs
A collection of keyword arguments specified as dialect-specific options to this construct.
The arguments are present here in their original <dialect>_<kwarg> format. Only arguments that were actually passed are included; unlike the DialectKWArgs.dialect_options collection, which contains all options known by this dialect including defaults.
The collection is also writable; keys are accepted of the form <dialect>_<kwarg> where the value will be assembled into the list of options.
See also
DialectKWArgs.dialect_options - nested dictionary form
attribute sqlalchemy.sql.expression.Select.dialect_options
inherited from the DialectKWArgs.dialect_options attribute of DialectKWArgs
A collection of keyword arguments specified as dialect-specific options to this construct.
This is a two-level nested registry, keyed to <dialect_name> and <argument_name>. For example, the postgresql_where argument would be locatable as:
arg = my_object.dialect_options["postgresql"]["where"]
Added in version 0.9.2.
See also
DialectKWArgs.dialect_kwargs - flat dictionary form
method sqlalchemy.sql.expression.Select.distinct(*expr: _ColumnExpressionArgument[Any]) → Self
Return a new select() construct which will apply DISTINCT to the SELECT statement overall.
E.g.:
from sqlalchemy import select

stmt = select(users_table.c.id, users_table.c.name).distinct()
The above would produce an statement resembling:
SELECT DISTINCT user.id, user.name FROM user
The method also accepts an *expr parameter which produces the PostgreSQL dialect-specific DISTINCT ON expression. Using this parameter on other backends which don’t support this syntax will raise an error.
Parameters:
*expr – 
optional column expressions. When present, the PostgreSQL dialect will render a DISTINCT ON (<expressions>) construct. A deprecation warning and/or CompileError will be raised on other backends.
Deprecated since version 1.4: Using *expr in other dialects is deprecated and will raise CompileError in a future version.
method sqlalchemy.sql.expression.Select.except_(*other: _SelectStatementForCompoundArgument[_TP]) → CompoundSelect[_TP]
Return a SQL EXCEPT of this select() construct against the given selectable provided as positional arguments.
Parameters:
*other – 
one or more elements with which to create a UNION.
Changed in version 1.4.28: multiple elements are now accepted.
method sqlalchemy.sql.expression.Select.except_all(*other: _SelectStatementForCompoundArgument[_TP]) → CompoundSelect[_TP]
Return a SQL EXCEPT ALL of this select() construct against the given selectables provided as positional arguments.
Parameters:
*other – 
one or more elements with which to create a UNION.
Changed in version 1.4.28: multiple elements are now accepted.
method sqlalchemy.sql.expression.Select.execution_options(**kw: Any) → Self
inherited from the Executable.execution_options() method of Executable
Set non-SQL options for the statement which take effect during execution.
Execution options can be set at many scopes, including per-statement, per-connection, or per execution, using methods such as Connection.execution_options() and parameters which accept a dictionary of options such as Connection.execute.execution_options and Session.execute.execution_options.
The primary characteristic of an execution option, as opposed to other kinds of options such as ORM loader options, is that execution options never affect the compiled SQL of a query, only things that affect how the SQL statement itself is invoked or how results are fetched. That is, execution options are not part of what’s accommodated by SQL compilation nor are they considered part of the cached state of a statement.
The Executable.execution_options() method is generative, as is the case for the method as applied to the Engine and Query objects, which means when the method is called, a copy of the object is returned, which applies the given parameters to that new copy, but leaves the original unchanged:
statement = select(table.c.x, table.c.y)
new_statement = statement.execution_options(my_option=True)
An exception to this behavior is the Connection object, where the Connection.execution_options() method is explicitly not generative.
The kinds of options that may be passed to Executable.execution_options() and other related methods and parameter dictionaries include parameters that are explicitly consumed by SQLAlchemy Core or ORM, as well as arbitrary keyword arguments not defined by SQLAlchemy, which means the methods and/or parameter dictionaries may be used for user-defined parameters that interact with custom code, which may access the parameters using methods such as Executable.get_execution_options() and Connection.get_execution_options(), or within selected event hooks using a dedicated execution_options event parameter such as ConnectionEvents.before_execute.execution_options or ORMExecuteState.execution_options, e.g.:
from sqlalchemy import event


@event.listens_for(some_engine, "before_execute")
def _process_opt(conn, statement, multiparams, params, execution_options):
    "run a SQL function before invoking a statement"

    if execution_options.get("do_special_thing", False):
        conn.exec_driver_sql("run_special_function()")
Within the scope of options that are explicitly recognized by SQLAlchemy, most apply to specific classes of objects and not others. The most common execution options include:
• Connection.execution_options.isolation_level - sets the isolation level for a connection or a class of connections via an Engine. This option is accepted only by Connection or Engine.
• Connection.execution_options.stream_results - indicates results should be fetched using a server side cursor; this option is accepted by Connection, by the Connection.execute.execution_options parameter on Connection.execute(), and additionally by Executable.execution_options() on a SQL statement object, as well as by ORM constructs like Session.execute().
• Connection.execution_options.compiled_cache - indicates a dictionary that will serve as the SQL compilation cache for a Connection or Engine, as well as for ORM methods like Session.execute(). Can be passed as None to disable caching for statements. This option is not accepted by Executable.execution_options() as it is inadvisable to carry along a compilation cache within a statement object.
• Connection.execution_options.schema_translate_map - a mapping of schema names used by the Schema Translate Map feature, accepted by Connection, Engine, Executable, as well as by ORM constructs like Session.execute().
See also
Connection.execution_options()
Connection.execute.execution_options
Session.execute.execution_options
ORM Execution Options - documentation on all ORM-specific execution options
method sqlalchemy.sql.expression.Select.exists() → Exists
inherited from the SelectBase.exists() method of SelectBase
Return an Exists representation of this selectable, which can be used as a column expression.
The returned object is an instance of Exists.
See also
exists()
EXISTS subqueries - in the 2.0 style tutorial.
Added in version 1.4.
attribute sqlalchemy.sql.expression.Select.exported_columns
inherited from the SelectBase.exported_columns attribute of SelectBase
A ColumnCollection that represents the “exported” columns of this Selectable, not including TextClause constructs.
The “exported” columns for a SelectBase object are synonymous with the SelectBase.selected_columns collection.
Added in version 1.4.
See also
Select.exported_columns
Selectable.exported_columns
FromClause.exported_columns
method sqlalchemy.sql.expression.Select.fetch(count: _LimitOffsetType, with_ties: bool = False, percent: bool = False, **dialect_kw: Any) → Self
inherited from the GenerativeSelect.fetch() method of GenerativeSelect
Return a new selectable with the given FETCH FIRST criterion applied.
This is a numeric value which usually renders as FETCH {FIRST | NEXT} [ count ] {ROW | ROWS} {ONLY | WITH TIES} expression in the resulting select. This functionality is is currently implemented for Oracle Database, PostgreSQL, MSSQL.
Use GenerativeSelect.offset() to specify the offset.
Note
The GenerativeSelect.fetch() method will replace any clause applied with GenerativeSelect.limit().
Added in version 1.4.
Parameters:
• count – an integer COUNT parameter, or a SQL expression that provides an integer result. When percent=True this will represent the percentage of rows to return, not the absolute value. Pass None to reset it.
• with_ties – When True, the WITH TIES option is used to return any additional rows that tie for the last place in the result set according to the ORDER BY clause. The ORDER BY may be mandatory in this case. Defaults to False
• percent – When True, count represents the percentage of the total number of selected rows to return. Defaults to False
• **dialect_kw – 
Additional dialect-specific keyword arguments may be accepted by dialects.
Added in version 2.0.41.
See also
GenerativeSelect.limit()
GenerativeSelect.offset()
method sqlalchemy.sql.expression.Select.filter(*criteria: _ColumnExpressionArgument[bool]) → Self
A synonym for the Select.where() method.
method sqlalchemy.sql.expression.Select.filter_by(**kwargs: Any) → Self
apply the given filtering criterion as a WHERE clause to this select.
method sqlalchemy.sql.expression.Select.from_statement(statement: ReturnsRowsRole) → ExecutableReturnsRows
Apply the columns which this Select would select onto another statement.
This operation is plugin-specific and will raise a not supported exception if this Select does not select from plugin-enabled entities.
The statement is typically either a text() or select() construct, and should return the set of columns appropriate to the entities represented by this Select.
See also
Getting ORM Results from Textual Statements - usage examples in the ORM Querying Guide
attribute sqlalchemy.sql.expression.Select.froms
Return the displayed list of FromClause elements.
Deprecated since version 1.4.23: The Select.froms attribute is moved to the Select.get_final_froms() method.
method sqlalchemy.sql.expression.Select.get_children(**kw: Any) → Iterable[ClauseElement]
Return immediate child HasTraverseInternals elements of this HasTraverseInternals.
This is used for visit traversal.
**kw may contain flags that change the collection that is returned, for example to return a subset of items in order to cut down on larger traversals, or to return child items from a different context (such as schema-level collections instead of clause-level).
method sqlalchemy.sql.expression.Select.get_execution_options() → _ExecuteOptions
inherited from the Executable.get_execution_options() method of Executable
Get the non-SQL options which will take effect during execution.
Added in version 1.3.
See also
Executable.execution_options()
method sqlalchemy.sql.expression.Select.get_final_froms() → Sequence[FromClause]
Compute the final displayed list of FromClause elements.
This method will run through the full computation required to determine what FROM elements will be displayed in the resulting SELECT statement, including shadowing individual tables with JOIN objects, as well as full computation for ORM use cases including eager loading clauses.
For ORM use, this accessor returns the post compilation list of FROM objects; this collection will include elements such as eagerly loaded tables and joins. The objects will not be ORM enabled and not work as a replacement for the Select.select_froms() collection; additionally, the method is not well performing for an ORM enabled statement as it will incur the full ORM construction process.
To retrieve the FROM list that’s implied by the “columns” collection passed to the Select originally, use the Select.columns_clause_froms accessor.
To select from an alternative set of columns while maintaining the FROM list, use the Select.with_only_columns() method and pass the Select.with_only_columns.maintain_column_froms parameter.
Added in version 1.4.23: - the Select.get_final_froms() method replaces the previous Select.froms accessor, which is deprecated.
See also
Select.columns_clause_froms
method sqlalchemy.sql.expression.Select.get_label_style() → SelectLabelStyle
inherited from the GenerativeSelect.get_label_style() method of GenerativeSelect
Retrieve the current label style.
Added in version 1.4.
method sqlalchemy.sql.expression.Select.group_by(_GenerativeSelect__first: Literal[None, _NoArg.NO_ARG] | _ColumnExpressionOrStrLabelArgument[Any] = _NoArg.NO_ARG, *clauses: _ColumnExpressionOrStrLabelArgument[Any]) → Self
inherited from the GenerativeSelect.group_by() method of GenerativeSelect
Return a new selectable with the given list of GROUP BY criterion applied.
All existing GROUP BY settings can be suppressed by passing None.
e.g.:
stmt = select(table.c.name, func.max(table.c.stat)).group_by(table.c.name)
Parameters:
*clauses – a series of ColumnElement constructs which will be used to generate an GROUP BY clause.
See also
Aggregate functions with GROUP BY / HAVING - in the SQLAlchemy Unified Tutorial
Ordering or Grouping by a Label - in the SQLAlchemy Unified Tutorial
method sqlalchemy.sql.expression.Select.having(*having: _ColumnExpressionArgument[bool]) → Self
Return a new select() construct with the given expression added to its HAVING clause, joined to the existing clause via AND, if any.
attribute sqlalchemy.sql.expression.Select.inherit_cache: bool | None = None
inherited from the HasCacheKey.inherit_cache attribute of HasCacheKey
Indicate if this HasCacheKey instance should make use of the cache key generation scheme used by its immediate superclass.
The attribute defaults to None, which indicates that a construct has not yet taken into account whether or not its appropriate for it to participate in caching; this is functionally equivalent to setting the value to False, except that a warning is also emitted.
This flag can be set to True on a particular class, if the SQL that corresponds to the object does not change based on attributes which are local to this class, and not its superclass.
See also
Enabling Caching Support for Custom Constructs - General guideslines for setting the HasCacheKey.inherit_cache attribute for third-party or user defined SQL constructs.
attribute sqlalchemy.sql.expression.Select.inner_columns
An iterator of all ColumnElement expressions which would be rendered into the columns clause of the resulting SELECT statement.
This method is legacy as of 1.4 and is superseded by the Select.exported_columns collection.
method sqlalchemy.sql.expression.Select.intersect(*other: _SelectStatementForCompoundArgument[_TP]) → CompoundSelect[_TP]
Return a SQL INTERSECT of this select() construct against the given selectables provided as positional arguments.
Parameters:
• *other – 
one or more elements with which to create a UNION.
Changed in version 1.4.28: multiple elements are now accepted.
• **kwargs – keyword arguments are forwarded to the constructor for the newly created CompoundSelect object.
method sqlalchemy.sql.expression.Select.intersect_all(*other: _SelectStatementForCompoundArgument[_TP]) → CompoundSelect[_TP]
Return a SQL INTERSECT ALL of this select() construct against the given selectables provided as positional arguments.
Parameters:
• *other – 
one or more elements with which to create a UNION.
Changed in version 1.4.28: multiple elements are now accepted.
• **kwargs – keyword arguments are forwarded to the constructor for the newly created CompoundSelect object.
method sqlalchemy.sql.expression.Select.is_derived_from(fromclause: FromClause | None) → bool
Return True if this ReturnsRows is ‘derived’ from the given FromClause.
An example would be an Alias of a Table is derived from that Table.
method sqlalchemy.sql.expression.Select.join(target: _JoinTargetArgument, onclause: _OnClauseArgument | None = None, *, isouter: bool = False, full: bool = False) → Self
Create a SQL JOIN against this Select object’s criterion and apply generatively, returning the newly resulting Select.
E.g.:
stmt = select(user_table).join(
    address_table, user_table.c.id == address_table.c.user_id
)
The above statement generates SQL similar to:
SELECT user.id, user.name
FROM user
JOIN address ON user.id = address.user_id
Changed in version 1.4: Select.join() now creates a Join object between a FromClause source that is within the FROM clause of the existing SELECT, and a given target FromClause, and then adds this Join to the FROM clause of the newly generated SELECT statement. This is completely reworked from the behavior in 1.3, which would instead create a subquery of the entire Select and then join that subquery to the target.
This is a backwards incompatible change as the previous behavior was mostly useless, producing an unnamed subquery rejected by most databases in any case. The new behavior is modeled after that of the very successful Query.join() method in the ORM, in order to support the functionality of Query being available by using a Select object with an Session.
See the notes for this change at select().join() and outerjoin() add JOIN criteria to the current query, rather than creating a subquery.
Parameters:
• target – target table to join towards
• onclause – ON clause of the join. If omitted, an ON clause is generated automatically based on the ForeignKey linkages between the two tables, if one can be unambiguously determined, otherwise an error is raised.
• isouter – if True, generate LEFT OUTER join. Same as Select.outerjoin().
• full – if True, generate FULL OUTER join.
See also
Explicit FROM clauses and JOINs - in the SQLAlchemy Unified Tutorial
Joins - in the ORM Querying Guide
Select.join_from()
Select.outerjoin()
method sqlalchemy.sql.expression.Select.join_from(from_: _FromClauseArgument, target: _JoinTargetArgument, onclause: _OnClauseArgument | None = None, *, isouter: bool = False, full: bool = False) → Self
Create a SQL JOIN against this Select object’s criterion and apply generatively, returning the newly resulting Select.
E.g.:
stmt = select(user_table, address_table).join_from(
    user_table, address_table, user_table.c.id == address_table.c.user_id
)
The above statement generates SQL similar to:
SELECT user.id, user.name, address.id, address.email, address.user_id
FROM user JOIN address ON user.id = address.user_id
Added in version 1.4.
Parameters:
• from_ – the left side of the join, will be rendered in the FROM clause and is roughly equivalent to using the Select.select_from() method.
• target – target table to join towards
• onclause – ON clause of the join.
• isouter – if True, generate LEFT OUTER join. Same as Select.outerjoin().
• full – if True, generate FULL OUTER join.
See also
Explicit FROM clauses and JOINs - in the SQLAlchemy Unified Tutorial
Joins - in the ORM Querying Guide
Select.join()
attribute sqlalchemy.sql.expression.Select.kwargs
inherited from the DialectKWArgs.kwargs attribute of DialectKWArgs
A synonym for DialectKWArgs.dialect_kwargs.
method sqlalchemy.sql.expression.Select.label(name: str | None) → Label[Any]
inherited from the SelectBase.label() method of SelectBase
Return a ‘scalar’ representation of this selectable, embedded as a subquery with a label.
See also
SelectBase.scalar_subquery().
method sqlalchemy.sql.expression.Select.lateral(name: str | None = None) → LateralFromClause
inherited from the SelectBase.lateral() method of SelectBase
Return a LATERAL alias of this Selectable.
The return value is the Lateral construct also provided by the top-level lateral() function.
See also
LATERAL correlation - overview of usage.
method sqlalchemy.sql.expression.Select.limit(limit: _LimitOffsetType) → Self
inherited from the GenerativeSelect.limit() method of GenerativeSelect
Return a new selectable with the given LIMIT criterion applied.
This is a numerical value which usually renders as a LIMIT expression in the resulting select. Backends that don’t support LIMIT will attempt to provide similar functionality.
Note
The GenerativeSelect.limit() method will replace any clause applied with GenerativeSelect.fetch().
Parameters:
limit – an integer LIMIT parameter, or a SQL expression that provides an integer result. Pass None to reset it.
See also
GenerativeSelect.fetch()
GenerativeSelect.offset()
attribute sqlalchemy.sql.expression.Select.name_cte_columns: bool = False
inherited from the HasCTE.name_cte_columns attribute of HasCTE
indicates if this HasCTE as contained within a CTE should compel the CTE to render the column names of this object in the WITH clause.
Added in version 2.0.42.
method sqlalchemy.sql.expression.Select.offset(offset: _LimitOffsetType) → Self
inherited from the GenerativeSelect.offset() method of GenerativeSelect
Return a new selectable with the given OFFSET criterion applied.
This is a numeric value which usually renders as an OFFSET expression in the resulting select. Backends that don’t support OFFSET will attempt to provide similar functionality.
Parameters:
offset – an integer OFFSET parameter, or a SQL expression that provides an integer result. Pass None to reset it.
See also
GenerativeSelect.limit()
GenerativeSelect.fetch()
method sqlalchemy.sql.expression.Select.options(*options: ExecutableOption) → Self
inherited from the Executable.options() method of Executable
Apply options to this statement.
In the general sense, options are any kind of Python object that can be interpreted by the SQL compiler for the statement. These options can be consumed by specific dialects or specific kinds of compilers.
The most commonly known kind of option are the ORM level options that apply “eager load” and other loading behaviors to an ORM query. However, options can theoretically be used for many other purposes.
For background on specific kinds of options for specific kinds of statements, refer to the documentation for those option objects.
Changed in version 1.4: - added Executable.options() to Core statement objects towards the goal of allowing unified Core / ORM querying capabilities.
See also
Column Loading Options - refers to options specific to the usage of ORM queries
Relationship Loading with Loader Options - refers to options specific to the usage of ORM queries
method sqlalchemy.sql.expression.Select.order_by(_GenerativeSelect__first: Literal[None, _NoArg.NO_ARG] | _ColumnExpressionOrStrLabelArgument[Any] = _NoArg.NO_ARG, *clauses: _ColumnExpressionOrStrLabelArgument[Any]) → Self
inherited from the GenerativeSelect.order_by() method of GenerativeSelect
Return a new selectable with the given list of ORDER BY criteria applied.
e.g.:
stmt = select(table).order_by(table.c.id, table.c.name)
Calling this method multiple times is equivalent to calling it once with all the clauses concatenated. All existing ORDER BY criteria may be cancelled by passing None by itself. New ORDER BY criteria may then be added by invoking Query.order_by() again, e.g.:
# will erase all ORDER BY and ORDER BY new_col alone
stmt = stmt.order_by(None).order_by(new_col)
Parameters:
*clauses – a series of ColumnElement constructs which will be used to generate an ORDER BY clause.
See also
ORDER BY - in the SQLAlchemy Unified Tutorial
Ordering or Grouping by a Label - in the SQLAlchemy Unified Tutorial
method sqlalchemy.sql.expression.Select.outerjoin(target: _JoinTargetArgument, onclause: _OnClauseArgument | None = None, *, full: bool = False) → Self
Create a left outer join.
Parameters are the same as that of Select.join().
Changed in version 1.4: Select.outerjoin() now creates a Join object between a FromClause source that is within the FROM clause of the existing SELECT, and a given target FromClause, and then adds this Join to the FROM clause of the newly generated SELECT statement. This is completely reworked from the behavior in 1.3, which would instead create a subquery of the entire Select and then join that subquery to the target.
This is a backwards incompatible change as the previous behavior was mostly useless, producing an unnamed subquery rejected by most databases in any case. The new behavior is modeled after that of the very successful Query.join() method in the ORM, in order to support the functionality of Query being available by using a Select object with an Session.
See the notes for this change at select().join() and outerjoin() add JOIN criteria to the current query, rather than creating a subquery.
See also
Explicit FROM clauses and JOINs - in the SQLAlchemy Unified Tutorial
Joins - in the ORM Querying Guide
Select.join()
method sqlalchemy.sql.expression.Select.outerjoin_from(from_: _FromClauseArgument, target: _JoinTargetArgument, onclause: _OnClauseArgument | None = None, *, full: bool = False) → Self
Create a SQL LEFT OUTER JOIN against this Select object’s criterion and apply generatively, returning the newly resulting Select.
Usage is the same as that of Select.join_from().
method sqlalchemy.sql.expression.Select.prefix_with(*prefixes: _TextCoercedExpressionArgument[Any], dialect: str = '*') → Self
inherited from the HasPrefixes.prefix_with() method of HasPrefixes
Add one or more expressions following the statement keyword, i.e. SELECT, INSERT, UPDATE, or DELETE. Generative.
This is used to support backend-specific prefix keywords such as those provided by MySQL.
E.g.:
stmt = table.insert().prefix_with("LOW_PRIORITY", dialect="mysql")

# MySQL 5.7 optimizer hints
stmt = select(table).prefix_with("/*+ BKA(t1) */", dialect="mysql")
Multiple prefixes can be specified by multiple calls to HasPrefixes.prefix_with().
Parameters:
• *prefixes – textual or ClauseElement construct which will be rendered following the INSERT, UPDATE, or DELETE keyword.
• dialect – optional string dialect name which will limit rendering of this prefix to only that dialect.
method sqlalchemy.sql.expression.Select.reduce_columns(only_synonyms: bool = True) → Select
Return a new select() construct with redundantly named, equivalently-valued columns removed from the columns clause.
“Redundant” here means two columns where one refers to the other either based on foreign key, or via a simple equality comparison in the WHERE clause of the statement. The primary purpose of this method is to automatically construct a select statement with all uniquely-named columns, without the need to use table-qualified labels as Select.set_label_style() does.
When columns are omitted based on foreign key, the referred-to column is the one that’s kept. When columns are omitted based on WHERE equivalence, the first column in the columns clause is the one that’s kept.
Parameters:
only_synonyms – when True, limit the removal of columns to those which have the same name as the equivalent. Otherwise, all columns that are equivalent to another are removed.
method sqlalchemy.sql.expression.Select.replace_selectable(old: FromClause, alias: Alias) → Self
inherited from the Selectable.replace_selectable() method of Selectable
Replace all occurrences of FromClause ‘old’ with the given Alias object, returning a copy of this FromClause.
Deprecated since version 1.4: The Selectable.replace_selectable() method is deprecated, and will be removed in a future release. Similar functionality is available via the sqlalchemy.sql.visitors module.
method sqlalchemy.sql.expression.Select.scalar_subquery() → ScalarSelect[Any]
inherited from the SelectBase.scalar_subquery() method of SelectBase
Return a ‘scalar’ representation of this selectable, which can be used as a column expression.
The returned object is an instance of ScalarSelect.
Typically, a select statement which has only one column in its columns clause is eligible to be used as a scalar expression. The scalar subquery can then be used in the WHERE clause or columns clause of an enclosing SELECT.
Note that the scalar subquery differentiates from the FROM-level subquery that can be produced using the SelectBase.subquery() method.
See also
Scalar and Correlated Subqueries - in the 2.0 tutorial
method sqlalchemy.sql.expression.Select.select(*arg: Any, **kw: Any) → Select
inherited from the SelectBase.select() method of SelectBase
Deprecated since version 1.4: The SelectBase.select() method is deprecated and will be removed in a future release; this method implicitly creates a subquery that should be explicit. Please call SelectBase.subquery() first in order to create a subquery, which then can be selected.
method sqlalchemy.sql.expression.Select.select_from(*froms: _FromClauseArgument) → Self
Return a new select() construct with the given FROM expression(s) merged into its list of FROM objects.
E.g.:
table1 = table("t1", column("a"))
table2 = table("t2", column("b"))
s = select(table1.c.a).select_from(
    table1.join(table2, table1.c.a == table2.c.b)
)
The “from” list is a unique set on the identity of each element, so adding an already present Table or other selectable will have no effect. Passing a Join that refers to an already present Table or other selectable will have the effect of concealing the presence of that selectable as an individual element in the rendered FROM list, instead rendering it into a JOIN clause.
While the typical purpose of Select.select_from() is to replace the default, derived FROM clause with a join, it can also be called with individual table elements, multiple times if desired, in the case that the FROM clause cannot be fully derived from the columns clause:
select(func.count("*")).select_from(table1)
attribute sqlalchemy.sql.expression.Select.selected_columns
A ColumnCollection representing the columns that this SELECT statement or similar construct returns in its result set, not including TextClause constructs.
This collection differs from the FromClause.columns collection of a FromClause in that the columns within this collection cannot be directly nested inside another SELECT statement; a subquery must be applied first which provides for the necessary parenthesization required by SQL.
For a select() construct, the collection here is exactly what would be rendered inside the “SELECT” statement, and the ColumnElement objects are directly present as they were given, e.g.:
col1 = column("q", Integer)
col2 = column("p", Integer)
stmt = select(col1, col2)
Above, stmt.selected_columns would be a collection that contains the col1 and col2 objects directly. For a statement that is against a Table or other FromClause, the collection will use the ColumnElement objects that are in the FromClause.c collection of the from element.
A use case for the Select.selected_columns collection is to allow the existing columns to be referenced when adding additional criteria, e.g.:
def filter_on_id(my_select, id):
    return my_select.where(my_select.selected_columns["id"] == id)


stmt = select(MyModel)

# adds "WHERE id=:param" to the statement
stmt = filter_on_id(stmt, 42)
Note
The Select.selected_columns collection does not include expressions established in the columns clause using the text() construct; these are silently omitted from the collection. To use plain textual column expressions inside of a Select construct, use the literal_column() construct.
Added in version 1.4.
method sqlalchemy.sql.expression.Select.self_group(against: OperatorType | None = None) → SelectStatementGrouping | Self
Return a ‘grouping’ construct as per the ClauseElement specification.
This produces an element that can be embedded in an expression. Note that this method is called automatically as needed when constructing expressions and should not require explicit use.
method sqlalchemy.sql.expression.Select.set_label_style(style: SelectLabelStyle) → Self
inherited from the GenerativeSelect.set_label_style() method of GenerativeSelect
Return a new selectable with the specified label style.
There are three “label styles” available, SelectLabelStyle.LABEL_STYLE_DISAMBIGUATE_ONLY, SelectLabelStyle.LABEL_STYLE_TABLENAME_PLUS_COL, and SelectLabelStyle.LABEL_STYLE_NONE. The default style is SelectLabelStyle.LABEL_STYLE_DISAMBIGUATE_ONLY.
In modern SQLAlchemy, there is not generally a need to change the labeling style, as per-expression labels are more effectively used by making use of the ColumnElement.label() method. In past versions, LABEL_STYLE_TABLENAME_PLUS_COL was used to disambiguate same-named columns from different tables, aliases, or subqueries; the newer LABEL_STYLE_DISAMBIGUATE_ONLY now applies labels only to names that conflict with an existing name so that the impact of this labeling is minimal.
The rationale for disambiguation is mostly so that all column expressions are available from a given FromClause.c collection when a subquery is created.
Added in version 1.4: - the GenerativeSelect.set_label_style() method replaces the previous combination of .apply_labels(), .with_labels() and use_labels=True methods and/or parameters.
See also
LABEL_STYLE_DISAMBIGUATE_ONLY
LABEL_STYLE_TABLENAME_PLUS_COL
LABEL_STYLE_NONE
LABEL_STYLE_DEFAULT
method sqlalchemy.sql.expression.Select.slice(start: int, stop: int) → Self
inherited from the GenerativeSelect.slice() method of GenerativeSelect
Apply LIMIT / OFFSET to this statement based on a slice.
The start and stop indices behave like the argument to Python’s built-in range() function. This method provides an alternative to using LIMIT/OFFSET to get a slice of the query.
For example,
stmt = select(User).order_by(User.id).slice(1, 3)
renders as
SELECT users.id AS users_id,
       users.name AS users_name
FROM users ORDER BY users.id
LIMIT ? OFFSET ?
(2, 1)
Note
The GenerativeSelect.slice() method will replace any clause applied with GenerativeSelect.fetch().
Added in version 1.4: Added the GenerativeSelect.slice() method generalized from the ORM.
See also
GenerativeSelect.limit()
GenerativeSelect.offset()
GenerativeSelect.fetch()
method sqlalchemy.sql.expression.Select.subquery(name: str | None = None) → Subquery
inherited from the SelectBase.subquery() method of SelectBase
Return a subquery of this SelectBase.
A subquery is from a SQL perspective a parenthesized, named construct that can be placed in the FROM clause of another SELECT statement.
Given a SELECT statement such as:
stmt = select(table.c.id, table.c.name)
The above statement might look like:
SELECT table.id, table.name FROM table
The subquery form by itself renders the same way, however when embedded into the FROM clause of another SELECT statement, it becomes a named sub-element:
subq = stmt.subquery()
new_stmt = select(subq)
The above renders as:
SELECT anon_1.id, anon_1.name
FROM (SELECT table.id, table.name FROM table) AS anon_1
Historically, SelectBase.subquery() is equivalent to calling the FromClause.alias() method on a FROM object; however, as a SelectBase object is not directly FROM object, the SelectBase.subquery() method provides clearer semantics.
Added in version 1.4.
method sqlalchemy.sql.expression.Select.suffix_with(*suffixes: _TextCoercedExpressionArgument[Any], dialect: str = '*') → Self
inherited from the HasSuffixes.suffix_with() method of HasSuffixes
Add one or more expressions following the statement as a whole.
This is used to support backend-specific suffix keywords on certain constructs.
E.g.:
stmt = (
    select(col1, col2)
    .cte()
    .suffix_with(
        "cycle empno set y_cycle to 1 default 0", dialect="oracle"
    )
)
Multiple suffixes can be specified by multiple calls to HasSuffixes.suffix_with().
Parameters:
• *suffixes – textual or ClauseElement construct which will be rendered following the target clause.
• dialect – Optional string dialect name which will limit rendering of this suffix to only that dialect.
method sqlalchemy.sql.expression.Select.union(*other: _SelectStatementForCompoundArgument[_TP]) → CompoundSelect[_TP]
Return a SQL UNION of this select() construct against the given selectables provided as positional arguments.
Parameters:
• *other – 
one or more elements with which to create a UNION.
Changed in version 1.4.28: multiple elements are now accepted.
• **kwargs – keyword arguments are forwarded to the constructor for the newly created CompoundSelect object.
method sqlalchemy.sql.expression.Select.union_all(*other: _SelectStatementForCompoundArgument[_TP]) → CompoundSelect[_TP]
Return a SQL UNION ALL of this select() construct against the given selectables provided as positional arguments.
Parameters:
• *other – 
one or more elements with which to create a UNION.
Changed in version 1.4.28: multiple elements are now accepted.
• **kwargs – keyword arguments are forwarded to the constructor for the newly created CompoundSelect object.
method sqlalchemy.sql.expression.Select.where(*whereclause: _ColumnExpressionArgument[bool]) → Self
Return a new select() construct with the given expression added to its WHERE clause, joined to the existing clause via AND, if any.
attribute sqlalchemy.sql.expression.Select.whereclause
Return the completed WHERE clause for this Select statement.
This assembles the current collection of WHERE criteria into a single BooleanClauseList construct.
Added in version 1.4.
method sqlalchemy.sql.expression.Select.with_for_update(*, nowait: bool = False, read: bool = False, of: _ForUpdateOfArgument | None = None, skip_locked: bool = False, key_share: bool = False) → Self
inherited from the GenerativeSelect.with_for_update() method of GenerativeSelect
Specify a FOR UPDATE clause for this GenerativeSelect.
E.g.:
stmt = select(table).with_for_update(nowait=True)
On a database like PostgreSQL or Oracle Database, the above would render a statement like:
SELECT table.a, table.b FROM table FOR UPDATE NOWAIT
on other backends, the nowait option is ignored and instead would produce:
SELECT table.a, table.b FROM table FOR UPDATE
When called with no arguments, the statement will render with the suffix FOR UPDATE. Additional arguments can then be provided which allow for common database-specific variants.
Parameters:
• nowait – boolean; will render FOR UPDATE NOWAIT on Oracle Database and PostgreSQL dialects.
• read – boolean; will render LOCK IN SHARE MODE on MySQL, FOR SHARE on PostgreSQL. On PostgreSQL, when combined with nowait, will render FOR SHARE NOWAIT.
• of – SQL expression or list of SQL expression elements, (typically Column objects or a compatible expression, for some backends may also be a table expression) which will render into a FOR UPDATE OF clause; supported by PostgreSQL, Oracle Database, some MySQL versions and possibly others. May render as a table or as a column depending on backend.
• skip_locked – boolean, will render FOR UPDATE SKIP LOCKED on Oracle Database and PostgreSQL dialects or FOR SHARE SKIP LOCKED if read=True is also specified.
• key_share – boolean, will render FOR NO KEY UPDATE, or if combined with read=True will render FOR KEY SHARE, on the PostgreSQL dialect.
method sqlalchemy.sql.expression.Select.with_hint(selectable: _FromClauseArgument, text: str, dialect_name: str = '*') → Self
inherited from the HasHints.with_hint() method of HasHints
Add an indexing or other executional context hint for the given selectable to this Select or other selectable object.
Tip
The Select.with_hint() method adds hints that are specific to a single table to a statement, in a location that is dialect-specific. To add generic optimizer hints to the beginning of a statement ahead of the SELECT keyword such as for MySQL or Oracle Database, use the Select.prefix_with() method. To add optimizer hints to the end of a statement such as for PostgreSQL, use the Select.with_statement_hint() method.
The text of the hint is rendered in the appropriate location for the database backend in use, relative to the given Table or Alias passed as the selectable argument. The dialect implementation typically uses Python string substitution syntax with the token %(name)s to render the name of the table or alias. E.g. when using Oracle Database, the following:
select(mytable).with_hint(mytable, "index(%(name)s ix_mytable)")
Would render SQL as:
select /*+ index(mytable ix_mytable) */ ... from mytable
The dialect_name option will limit the rendering of a particular hint to a particular backend. Such as, to add hints for both Oracle Database and MSSql simultaneously:
select(mytable).with_hint(
    mytable, "index(%(name)s ix_mytable)", "oracle"
).with_hint(mytable, "WITH INDEX ix_mytable", "mssql")
See also
Select.with_statement_hint()
Select.prefix_with() - generic SELECT prefixing which also can suit some database-specific HINT syntaxes such as MySQL or Oracle Database optimizer hints
method sqlalchemy.sql.expression.Select.with_only_columns(*entities: _ColumnsClauseArgument[Any], maintain_column_froms: bool = False, **_Select__kw: Any) → Select[Any]
Return a new select() construct with its columns clause replaced with the given entities.
By default, this method is exactly equivalent to as if the original select() had been called with the given entities. E.g. a statement:
s = select(table1.c.a, table1.c.b)
s = s.with_only_columns(table1.c.b)
should be exactly equivalent to:
s = select(table1.c.b)
In this mode of operation, Select.with_only_columns() will also dynamically alter the FROM clause of the statement if it is not explicitly stated. To maintain the existing set of FROMs including those implied by the current columns clause, add the Select.with_only_columns.maintain_column_froms parameter:
s = select(table1.c.a, table2.c.b)
s = s.with_only_columns(table1.c.a, maintain_column_froms=True)
The above parameter performs a transfer of the effective FROMs in the columns collection to the Select.select_from() method, as though the following were invoked:
s = select(table1.c.a, table2.c.b)
s = s.select_from(table1, table2).with_only_columns(table1.c.a)
The Select.with_only_columns.maintain_column_froms parameter makes use of the Select.columns_clause_froms collection and performs an operation equivalent to the following:
s = select(table1.c.a, table2.c.b)
s = s.select_from(*s.columns_clause_froms).with_only_columns(table1.c.a)
Parameters:
• *entities – column expressions to be used.
• maintain_column_froms – 
boolean parameter that will ensure the FROM list implied from the current columns clause will be transferred to the Select.select_from() method first.
Added in version 1.4.23.
method sqlalchemy.sql.expression.Select.with_statement_hint(text: str, dialect_name: str = '*') → Self
inherited from the HasHints.with_statement_hint() method of HasHints
Add a statement hint to this Select or other selectable object.
Tip
Select.with_statement_hint() generally adds hints at the trailing end of a SELECT statement. To place dialect-specific hints such as optimizer hints at the front of the SELECT statement after the SELECT keyword, use the Select.prefix_with() method for an open-ended space, or for table-specific hints the Select.with_hint() may be used, which places hints in a dialect-specific location.
This method is similar to Select.with_hint() except that it does not require an individual table, and instead applies to the statement as a whole.
Hints here are specific to the backend database and may include directives such as isolation levels, file directives, fetch directives, etc.
See also
Select.with_hint()
Select.prefix_with() - generic SELECT prefixing which also can suit some database-specific HINT syntaxes such as MySQL or Oracle Database optimizer hints
class sqlalchemy.sql.expression.Selectable
Mark a class as being selectable.
Members
compile(), corresponding_column(), exported_columns, get_children(), inherit_cache, is_derived_from(), lateral(), replace_selectable()
Class signature
class sqlalchemy.sql.expression.Selectable (sqlalchemy.sql.expression.ReturnsRows)
method sqlalchemy.sql.expression.Selectable.compile(bind: _HasDialect | None = None, dialect: Dialect | None = None, **kw: Any) → Compiled
inherited from the CompilerElement.compile() method of CompilerElement
Compile this SQL expression.
The return value is a Compiled object. Calling str() or unicode() on the returned value will yield a string representation of the result. The Compiled object also can return a dictionary of bind parameter names and values using the params accessor.
Parameters:
• bind – An Connection or Engine which can provide a Dialect in order to generate a Compiled object. If the bind and dialect parameters are both omitted, a default SQL compiler is used.
• column_keys – Used for INSERT and UPDATE statements, a list of column names which should be present in the VALUES clause of the compiled statement. If None, all columns from the target table object are rendered.
• dialect – A Dialect instance which can generate a Compiled object. This argument takes precedence over the bind argument.
• compile_kwargs – 
optional dictionary of additional parameters that will be passed through to the compiler within all “visit” methods. This allows any custom flag to be passed through to a custom compilation construct, for example. It is also used for the case of passing the literal_binds flag through:
from sqlalchemy.sql import table, column, select

t = table("t", column("x"))

s = select(t).where(t.c.x == 5)

print(s.compile(compile_kwargs={"literal_binds": True}))
• 
See also
How do I render SQL expressions as strings, possibly with bound parameters inlined?
method sqlalchemy.sql.expression.Selectable.corresponding_column(column: KeyedColumnElement[Any], require_embedded: bool = False) → KeyedColumnElement[Any] | None
Given a ColumnElement, return the exported ColumnElement object from the Selectable.exported_columns collection of this Selectable which corresponds to that original ColumnElement via a common ancestor column.
Parameters:
• column – the target ColumnElement to be matched.
• require_embedded – only return corresponding columns for the given ColumnElement, if the given ColumnElement is actually present within a sub-element of this Selectable. Normally the column will match if it merely shares a common ancestor with one of the exported columns of this Selectable.
See also
Selectable.exported_columns - the ColumnCollection that is used for the operation.
ColumnCollection.corresponding_column() - implementation method.
attribute sqlalchemy.sql.expression.Selectable.exported_columns
inherited from the ReturnsRows.exported_columns attribute of ReturnsRows
A ColumnCollection that represents the “exported” columns of this ReturnsRows.
The “exported” columns represent the collection of ColumnElement expressions that are rendered by this SQL construct. There are primary varieties which are the “FROM clause columns” of a FROM clause, such as a table, join, or subquery, the “SELECTed columns”, which are the columns in the “columns clause” of a SELECT statement, and the RETURNING columns in a DML statement..
Added in version 1.4.
See also
FromClause.exported_columns
SelectBase.exported_columns
method sqlalchemy.sql.expression.Selectable.get_children(*, omit_attrs: Tuple[str, ...] = (), **kw: Any) → Iterable[HasTraverseInternals]
inherited from the HasTraverseInternals.get_children() method of HasTraverseInternals
Return immediate child HasTraverseInternals elements of this HasTraverseInternals.
This is used for visit traversal.
**kw may contain flags that change the collection that is returned, for example to return a subset of items in order to cut down on larger traversals, or to return child items from a different context (such as schema-level collections instead of clause-level).
attribute sqlalchemy.sql.expression.Selectable.inherit_cache: bool | None = None
inherited from the HasCacheKey.inherit_cache attribute of HasCacheKey
Indicate if this HasCacheKey instance should make use of the cache key generation scheme used by its immediate superclass.
The attribute defaults to None, which indicates that a construct has not yet taken into account whether or not its appropriate for it to participate in caching; this is functionally equivalent to setting the value to False, except that a warning is also emitted.
This flag can be set to True on a particular class, if the SQL that corresponds to the object does not change based on attributes which are local to this class, and not its superclass.
See also
Enabling Caching Support for Custom Constructs - General guideslines for setting the HasCacheKey.inherit_cache attribute for third-party or user defined SQL constructs.
method sqlalchemy.sql.expression.Selectable.is_derived_from(fromclause: FromClause | None) → bool
inherited from the ReturnsRows.is_derived_from() method of ReturnsRows
Return True if this ReturnsRows is ‘derived’ from the given FromClause.
An example would be an Alias of a Table is derived from that Table.
method sqlalchemy.sql.expression.Selectable.lateral(name: str | None = None) → LateralFromClause
Return a LATERAL alias of this Selectable.
The return value is the Lateral construct also provided by the top-level lateral() function.
See also
LATERAL correlation - overview of usage.
method sqlalchemy.sql.expression.Selectable.replace_selectable(old: FromClause, alias: Alias) → Self
Replace all occurrences of FromClause ‘old’ with the given Alias object, returning a copy of this FromClause.
Deprecated since version 1.4: The Selectable.replace_selectable() method is deprecated, and will be removed in a future release. Similar functionality is available via the sqlalchemy.sql.visitors module.
class sqlalchemy.sql.expression.SelectBase
Base class for SELECT statements.
This includes Select, CompoundSelect and TextualSelect.
Members
__new__(), add_cte(), alias(), as_scalar(), c, compile(), corresponding_column(), cte(), exists(), exported_columns, get_children(), get_label_style(), inherit_cache, is_derived_from(), label(), lateral(), name_cte_columns, replace_selectable(), scalar_subquery(), select(), selected_columns, set_label_style(), subquery()
Class signature
class sqlalchemy.sql.expression.SelectBase (sqlalchemy.sql.roles.SelectStatementRole, sqlalchemy.sql.roles.DMLSelectRole, sqlalchemy.sql.roles.CompoundElementRole, sqlalchemy.sql.roles.InElementRole, sqlalchemy.sql.expression.HasCTE, sqlalchemy.sql.annotation.SupportsCloneAnnotations, sqlalchemy.sql.expression.Selectable)
classmethod sqlalchemy.sql.expression.SelectBase.__new__(*args, **kwargs)
method sqlalchemy.sql.expression.SelectBase.add_cte(*ctes: CTE, nest_here: bool = False) → Self
inherited from the HasCTE.add_cte() method of HasCTE
Add one or more CTE constructs to this statement.
This method will associate the given CTE constructs with the parent statement such that they will each be unconditionally rendered in the WITH clause of the final statement, even if not referenced elsewhere within the statement or any sub-selects.
The optional HasCTE.add_cte.nest_here parameter when set to True will have the effect that each given CTE will render in a WITH clause rendered directly along with this statement, rather than being moved to the top of the ultimate rendered statement, even if this statement is rendered as a subquery within a larger statement.
This method has two general uses. One is to embed CTE statements that serve some purpose without being referenced explicitly, such as the use case of embedding a DML statement such as an INSERT or UPDATE as a CTE inline with a primary statement that may draw from its results indirectly. The other is to provide control over the exact placement of a particular series of CTE constructs that should remain rendered directly in terms of a particular statement that may be nested in a larger statement.
E.g.:
from sqlalchemy import table, column, select

t = table("t", column("c1"), column("c2"))

ins = t.insert().values({"c1": "x", "c2": "y"}).cte()

stmt = select(t).add_cte(ins)
Would render:
WITH anon_1 AS (
    INSERT INTO t (c1, c2) VALUES (:param_1, :param_2)
)
SELECT t.c1, t.c2
FROM t
Above, the “anon_1” CTE is not referenced in the SELECT statement, however still accomplishes the task of running an INSERT statement.
Similarly in a DML-related context, using the PostgreSQL Insert construct to generate an “upsert”:
from sqlalchemy import table, column
from sqlalchemy.dialects.postgresql import insert

t = table("t", column("c1"), column("c2"))

delete_statement_cte = t.delete().where(t.c.c1 < 1).cte("deletions")

insert_stmt = insert(t).values({"c1": 1, "c2": 2})
update_statement = insert_stmt.on_conflict_do_update(
    index_elements=[t.c.c1],
    set_={
        "c1": insert_stmt.excluded.c1,
        "c2": insert_stmt.excluded.c2,
    },
).add_cte(delete_statement_cte)

print(update_statement)
The above statement renders as:
WITH deletions AS (
    DELETE FROM t WHERE t.c1 < %(c1_1)s
)
INSERT INTO t (c1, c2) VALUES (%(c1)s, %(c2)s)
ON CONFLICT (c1) DO UPDATE SET c1 = excluded.c1, c2 = excluded.c2
Added in version 1.4.21.
Parameters:
• *ctes – 
zero or more CTE constructs.
Changed in version 2.0: Multiple CTE instances are accepted
• nest_here – 
if True, the given CTE or CTEs will be rendered as though they specified the HasCTE.cte.nesting flag to True when they were added to this HasCTE. Assuming the given CTEs are not referenced in an outer-enclosing statement as well, the CTEs given should render at the level of this statement when this flag is given.
Added in version 2.0.
See also
HasCTE.cte.nesting
method sqlalchemy.sql.expression.SelectBase.alias(name: str | None = None, flat: bool = False) → Subquery
Return a named subquery against this SelectBase.
For a SelectBase (as opposed to a FromClause), this returns a Subquery object which behaves mostly the same as the Alias object that is used with a FromClause.
Changed in version 1.4: The SelectBase.alias() method is now a synonym for the SelectBase.subquery() method.
method sqlalchemy.sql.expression.SelectBase.as_scalar() → ScalarSelect[Any]
Deprecated since version 1.4: The SelectBase.as_scalar() method is deprecated and will be removed in a future release. Please refer to SelectBase.scalar_subquery().
attribute sqlalchemy.sql.expression.SelectBase.c
Deprecated since version 1.4: The SelectBase.c and SelectBase.columns attributes are deprecated and will be removed in a future release; these attributes implicitly create a subquery that should be explicit. Please call SelectBase.subquery() first in order to create a subquery, which then contains this attribute. To access the columns that this SELECT object SELECTs from, use the SelectBase.selected_columns attribute.
method sqlalchemy.sql.expression.SelectBase.compile(bind: _HasDialect | None = None, dialect: Dialect | None = None, **kw: Any) → Compiled
inherited from the CompilerElement.compile() method of CompilerElement
Compile this SQL expression.
The return value is a Compiled object. Calling str() or unicode() on the returned value will yield a string representation of the result. The Compiled object also can return a dictionary of bind parameter names and values using the params accessor.
Parameters:
• bind – An Connection or Engine which can provide a Dialect in order to generate a Compiled object. If the bind and dialect parameters are both omitted, a default SQL compiler is used.
• column_keys – Used for INSERT and UPDATE statements, a list of column names which should be present in the VALUES clause of the compiled statement. If None, all columns from the target table object are rendered.
• dialect – A Dialect instance which can generate a Compiled object. This argument takes precedence over the bind argument.
• compile_kwargs – 
optional dictionary of additional parameters that will be passed through to the compiler within all “visit” methods. This allows any custom flag to be passed through to a custom compilation construct, for example. It is also used for the case of passing the literal_binds flag through:
from sqlalchemy.sql import table, column, select

t = table("t", column("x"))

s = select(t).where(t.c.x == 5)

print(s.compile(compile_kwargs={"literal_binds": True}))
• 
See also
How do I render SQL expressions as strings, possibly with bound parameters inlined?
method sqlalchemy.sql.expression.SelectBase.corresponding_column(column: KeyedColumnElement[Any], require_embedded: bool = False) → KeyedColumnElement[Any] | None
inherited from the Selectable.corresponding_column() method of Selectable
Given a ColumnElement, return the exported ColumnElement object from the Selectable.exported_columns collection of this Selectable which corresponds to that original ColumnElement via a common ancestor column.
Parameters:
• column – the target ColumnElement to be matched.
• require_embedded – only return corresponding columns for the given ColumnElement, if the given ColumnElement is actually present within a sub-element of this Selectable. Normally the column will match if it merely shares a common ancestor with one of the exported columns of this Selectable.
See also
Selectable.exported_columns - the ColumnCollection that is used for the operation.
ColumnCollection.corresponding_column() - implementation method.
method sqlalchemy.sql.expression.SelectBase.cte(name: str | None = None, recursive: bool = False, nesting: bool = False) → CTE
inherited from the HasCTE.cte() method of HasCTE
Return a new CTE, or Common Table Expression instance.
Common table expressions are a SQL standard whereby SELECT statements can draw upon secondary statements specified along with the primary statement, using a clause called “WITH”. Special semantics regarding UNION can also be employed to allow “recursive” queries, where a SELECT statement can draw upon the set of rows that have previously been selected.
CTEs can also be applied to DML constructs UPDATE, INSERT and DELETE on some databases, both as a source of CTE rows when combined with RETURNING, as well as a consumer of CTE rows.
SQLAlchemy detects CTE objects, which are treated similarly to Alias objects, as special elements to be delivered to the FROM clause of the statement as well as to a WITH clause at the top of the statement.
For special prefixes such as PostgreSQL “MATERIALIZED” and “NOT MATERIALIZED”, the CTE.prefix_with() method may be used to establish these.
Changed in version 1.3.13: Added support for prefixes. In particular - MATERIALIZED and NOT MATERIALIZED.
Parameters:
• name – name given to the common table expression. Like FromClause.alias(), the name can be left as None in which case an anonymous symbol will be used at query compile time.
• recursive – if True, will render WITH RECURSIVE. A recursive common table expression is intended to be used in conjunction with UNION ALL in order to derive rows from those already selected.
• nesting – 
if True, will render the CTE locally to the statement in which it is referenced. For more complex scenarios, the HasCTE.add_cte() method using the HasCTE.add_cte.nest_here parameter may also be used to more carefully control the exact placement of a particular CTE.
Added in version 1.4.24.
See also
HasCTE.add_cte()
The following examples include two from PostgreSQL’s documentation at https://www.postgresql.org/docs/current/static/queries-with.html, as well as additional examples.
Example 1, non recursive:
from sqlalchemy import (
    Table,
    Column,
    String,
    Integer,
    MetaData,
    select,
    func,
)

metadata = MetaData()

orders = Table(
    "orders",
    metadata,
    Column("region", String),
    Column("amount", Integer),
    Column("product", String),
    Column("quantity", Integer),
)

regional_sales = (
    select(orders.c.region, func.sum(orders.c.amount).label("total_sales"))
    .group_by(orders.c.region)
    .cte("regional_sales")
)


top_regions = (
    select(regional_sales.c.region)
    .where(
        regional_sales.c.total_sales
        > select(func.sum(regional_sales.c.total_sales) / 10)
    )
    .cte("top_regions")
)

statement = (
    select(
        orders.c.region,
        orders.c.product,
        func.sum(orders.c.quantity).label("product_units"),
        func.sum(orders.c.amount).label("product_sales"),
    )
    .where(orders.c.region.in_(select(top_regions.c.region)))
    .group_by(orders.c.region, orders.c.product)
)

result = conn.execute(statement).fetchall()
Example 2, WITH RECURSIVE:
from sqlalchemy import (
    Table,
    Column,
    String,
    Integer,
    MetaData,
    select,
    func,
)

metadata = MetaData()

parts = Table(
    "parts",
    metadata,
    Column("part", String),
    Column("sub_part", String),
    Column("quantity", Integer),
)

included_parts = (
    select(parts.c.sub_part, parts.c.part, parts.c.quantity)
    .where(parts.c.part == "our part")
    .cte(recursive=True)
)


incl_alias = included_parts.alias()
parts_alias = parts.alias()
included_parts = included_parts.union_all(
    select(
        parts_alias.c.sub_part, parts_alias.c.part, parts_alias.c.quantity
    ).where(parts_alias.c.part == incl_alias.c.sub_part)
)

statement = select(
    included_parts.c.sub_part,
    func.sum(included_parts.c.quantity).label("total_quantity"),
).group_by(included_parts.c.sub_part)

result = conn.execute(statement).fetchall()
Example 3, an upsert using UPDATE and INSERT with CTEs:
from datetime import date
from sqlalchemy import (
    MetaData,
    Table,
    Column,
    Integer,
    Date,
    select,
    literal,
    and_,
    exists,
)

metadata = MetaData()

visitors = Table(
    "visitors",
    metadata,
    Column("product_id", Integer, primary_key=True),
    Column("date", Date, primary_key=True),
    Column("count", Integer),
)

# add 5 visitors for the product_id == 1
product_id = 1
day = date.today()
count = 5

update_cte = (
    visitors.update()
    .where(
        and_(visitors.c.product_id == product_id, visitors.c.date == day)
    )
    .values(count=visitors.c.count + count)
    .returning(literal(1))
    .cte("update_cte")
)

upsert = visitors.insert().from_select(
    [visitors.c.product_id, visitors.c.date, visitors.c.count],
    select(literal(product_id), literal(day), literal(count)).where(
        ~exists(update_cte.select())
    ),
)

connection.execute(upsert)
Example 4, Nesting CTE (SQLAlchemy 1.4.24 and above):
value_a = select(literal("root").label("n")).cte("value_a")

# A nested CTE with the same name as the root one
value_a_nested = select(literal("nesting").label("n")).cte(
    "value_a", nesting=True
)

# Nesting CTEs takes ascendency locally
# over the CTEs at a higher level
value_b = select(value_a_nested.c.n).cte("value_b")

value_ab = select(value_a.c.n.label("a"), value_b.c.n.label("b"))
The above query will render the second CTE nested inside the first, shown with inline parameters below as:
WITH
    value_a AS
        (SELECT 'root' AS n),
    value_b AS
        (WITH value_a AS
            (SELECT 'nesting' AS n)
        SELECT value_a.n AS n FROM value_a)
SELECT value_a.n AS a, value_b.n AS b
FROM value_a, value_b
The same CTE can be set up using the HasCTE.add_cte() method as follows (SQLAlchemy 2.0 and above):
value_a = select(literal("root").label("n")).cte("value_a")

# A nested CTE with the same name as the root one
value_a_nested = select(literal("nesting").label("n")).cte("value_a")

# Nesting CTEs takes ascendency locally
# over the CTEs at a higher level
value_b = (
    select(value_a_nested.c.n)
    .add_cte(value_a_nested, nest_here=True)
    .cte("value_b")
)

value_ab = select(value_a.c.n.label("a"), value_b.c.n.label("b"))
Example 5, Non-Linear CTE (SQLAlchemy 1.4.28 and above):
edge = Table(
    "edge",
    metadata,
    Column("id", Integer, primary_key=True),
    Column("left", Integer),
    Column("right", Integer),
)

root_node = select(literal(1).label("node")).cte("nodes", recursive=True)

left_edge = select(edge.c.left).join(
    root_node, edge.c.right == root_node.c.node
)
right_edge = select(edge.c.right).join(
    root_node, edge.c.left == root_node.c.node
)

subgraph_cte = root_node.union(left_edge, right_edge)

subgraph = select(subgraph_cte)
The above query will render 2 UNIONs inside the recursive CTE:
WITH RECURSIVE nodes(node) AS (
        SELECT 1 AS node
    UNION
        SELECT edge."left" AS "left"
        FROM edge JOIN nodes ON edge."right" = nodes.node
    UNION
        SELECT edge."right" AS "right"
        FROM edge JOIN nodes ON edge."left" = nodes.node
)
SELECT nodes.node FROM nodes
See also
Query.cte() - ORM version of HasCTE.cte().
method sqlalchemy.sql.expression.SelectBase.exists() → Exists
Return an Exists representation of this selectable, which can be used as a column expression.
The returned object is an instance of Exists.
See also
exists()
EXISTS subqueries - in the 2.0 style tutorial.
Added in version 1.4.
attribute sqlalchemy.sql.expression.SelectBase.exported_columns
A ColumnCollection that represents the “exported” columns of this Selectable, not including TextClause constructs.
The “exported” columns for a SelectBase object are synonymous with the SelectBase.selected_columns collection.
Added in version 1.4.
See also
Select.exported_columns
Selectable.exported_columns
FromClause.exported_columns
method sqlalchemy.sql.expression.SelectBase.get_children(*, omit_attrs: Tuple[str, ...] = (), **kw: Any) → Iterable[HasTraverseInternals]
inherited from the HasTraverseInternals.get_children() method of HasTraverseInternals
Return immediate child HasTraverseInternals elements of this HasTraverseInternals.
This is used for visit traversal.
**kw may contain flags that change the collection that is returned, for example to return a subset of items in order to cut down on larger traversals, or to return child items from a different context (such as schema-level collections instead of clause-level).
method sqlalchemy.sql.expression.SelectBase.get_label_style() → SelectLabelStyle
Retrieve the current label style.
Implemented by subclasses.
attribute sqlalchemy.sql.expression.SelectBase.inherit_cache: bool | None = None
inherited from the HasCacheKey.inherit_cache attribute of HasCacheKey
Indicate if this HasCacheKey instance should make use of the cache key generation scheme used by its immediate superclass.
The attribute defaults to None, which indicates that a construct has not yet taken into account whether or not its appropriate for it to participate in caching; this is functionally equivalent to setting the value to False, except that a warning is also emitted.
This flag can be set to True on a particular class, if the SQL that corresponds to the object does not change based on attributes which are local to this class, and not its superclass.
See also
Enabling Caching Support for Custom Constructs - General guideslines for setting the HasCacheKey.inherit_cache attribute for third-party or user defined SQL constructs.
method sqlalchemy.sql.expression.SelectBase.is_derived_from(fromclause: FromClause | None) → bool
inherited from the ReturnsRows.is_derived_from() method of ReturnsRows
Return True if this ReturnsRows is ‘derived’ from the given FromClause.
An example would be an Alias of a Table is derived from that Table.
method sqlalchemy.sql.expression.SelectBase.label(name: str | None) → Label[Any]
Return a ‘scalar’ representation of this selectable, embedded as a subquery with a label.
See also
SelectBase.scalar_subquery().
method sqlalchemy.sql.expression.SelectBase.lateral(name: str | None = None) → LateralFromClause
Return a LATERAL alias of this Selectable.
The return value is the Lateral construct also provided by the top-level lateral() function.
See also
LATERAL correlation - overview of usage.
attribute sqlalchemy.sql.expression.SelectBase.name_cte_columns: bool = False
inherited from the HasCTE.name_cte_columns attribute of HasCTE
indicates if this HasCTE as contained within a CTE should compel the CTE to render the column names of this object in the WITH clause.
Added in version 2.0.42.
method sqlalchemy.sql.expression.SelectBase.replace_selectable(old: FromClause, alias: Alias) → Self
inherited from the Selectable.replace_selectable() method of Selectable
Replace all occurrences of FromClause ‘old’ with the given Alias object, returning a copy of this FromClause.
Deprecated since version 1.4: The Selectable.replace_selectable() method is deprecated, and will be removed in a future release. Similar functionality is available via the sqlalchemy.sql.visitors module.
method sqlalchemy.sql.expression.SelectBase.scalar_subquery() → ScalarSelect[Any]
Return a ‘scalar’ representation of this selectable, which can be used as a column expression.
The returned object is an instance of ScalarSelect.
Typically, a select statement which has only one column in its columns clause is eligible to be used as a scalar expression. The scalar subquery can then be used in the WHERE clause or columns clause of an enclosing SELECT.
Note that the scalar subquery differentiates from the FROM-level subquery that can be produced using the SelectBase.subquery() method.
See also
Scalar and Correlated Subqueries - in the 2.0 tutorial
method sqlalchemy.sql.expression.SelectBase.select(*arg: Any, **kw: Any) → Select
Deprecated since version 1.4: The SelectBase.select() method is deprecated and will be removed in a future release; this method implicitly creates a subquery that should be explicit. Please call SelectBase.subquery() first in order to create a subquery, which then can be selected.
attribute sqlalchemy.sql.expression.SelectBase.selected_columns
A ColumnCollection representing the columns that this SELECT statement or similar construct returns in its result set.
This collection differs from the FromClause.columns collection of a FromClause in that the columns within this collection cannot be directly nested inside another SELECT statement; a subquery must be applied first which provides for the necessary parenthesization required by SQL.
Note
The SelectBase.selected_columns collection does not include expressions established in the columns clause using the text() construct; these are silently omitted from the collection. To use plain textual column expressions inside of a Select construct, use the literal_column() construct.
See also
Select.selected_columns
Added in version 1.4.
method sqlalchemy.sql.expression.SelectBase.set_label_style(style: SelectLabelStyle) → Self
Return a new selectable with the specified label style.
Implemented by subclasses.
method sqlalchemy.sql.expression.SelectBase.subquery(name: str | None = None) → Subquery
Return a subquery of this SelectBase.
A subquery is from a SQL perspective a parenthesized, named construct that can be placed in the FROM clause of another SELECT statement.
Given a SELECT statement such as:
stmt = select(table.c.id, table.c.name)
The above statement might look like:
SELECT table.id, table.name FROM table
The subquery form by itself renders the same way, however when embedded into the FROM clause of another SELECT statement, it becomes a named sub-element:
subq = stmt.subquery()
new_stmt = select(subq)
The above renders as:
SELECT anon_1.id, anon_1.name
FROM (SELECT table.id, table.name FROM table) AS anon_1
Historically, SelectBase.subquery() is equivalent to calling the FromClause.alias() method on a FROM object; however, as a SelectBase object is not directly FROM object, the SelectBase.subquery() method provides clearer semantics.
Added in version 1.4.
class sqlalchemy.sql.expression.Subquery
Represent a subquery of a SELECT.
A Subquery is created by invoking the SelectBase.subquery() method, or for convenience the SelectBase.alias() method, on any SelectBase subclass which includes Select, CompoundSelect, and TextualSelect. As rendered in a FROM clause, it represents the body of the SELECT statement inside of parenthesis, followed by the usual “AS <somename>” that defines all “alias” objects.
The Subquery object is very similar to the Alias object and can be used in an equivalent way. The difference between Alias and Subquery is that Alias always contains a FromClause object whereas Subquery always contains a SelectBase object.
Added in version 1.4: The Subquery class was added which now serves the purpose of providing an aliased version of a SELECT statement.
Members
as_scalar(), inherit_cache
Class signature
class sqlalchemy.sql.expression.Subquery (sqlalchemy.sql.expression.AliasedReturnsRows)
method sqlalchemy.sql.expression.Subquery.as_scalar() → ScalarSelect[Any]
Deprecated since version 1.4: The Subquery.as_scalar() method, which was previously Alias.as_scalar() prior to version 1.4, is deprecated and will be removed in a future release; Please use the Select.scalar_subquery() method of the select() construct before constructing a subquery object, or with the ORM use the Query.scalar_subquery() method.
attribute sqlalchemy.sql.expression.Subquery.inherit_cache: bool | None = True
Indicate if this HasCacheKey instance should make use of the cache key generation scheme used by its immediate superclass.
The attribute defaults to None, which indicates that a construct has not yet taken into account whether or not its appropriate for it to participate in caching; this is functionally equivalent to setting the value to False, except that a warning is also emitted.
This flag can be set to True on a particular class, if the SQL that corresponds to the object does not change based on attributes which are local to this class, and not its superclass.
See also
Enabling Caching Support for Custom Constructs - General guideslines for setting the HasCacheKey.inherit_cache attribute for third-party or user defined SQL constructs.
class sqlalchemy.sql.expression.TableClause
Represents a minimal “table” construct.
This is a lightweight table object that has only a name, a collection of columns, which are typically produced by the column() function, and a schema:
from sqlalchemy import table, column

user = table(
    "user",
    column("id"),
    column("name"),
    column("description"),
)
The TableClause construct serves as the base for the more commonly used Table object, providing the usual set of FromClause services including the .c. collection and statement generation methods.
It does not provide all the additional schema-level services of Table, including constraints, references to other tables, or support for MetaData-level services. It’s useful on its own as an ad-hoc construct used to generate quick SQL statements when a more fully fledged Table is not on hand.
Members
alias(), c, columns, compare(), compile(), corresponding_column(), delete(), description, entity_namespace, exported_columns, foreign_keys, get_children(), implicit_returning, inherit_cache, insert(), is_derived_from(), join(), lateral(), outerjoin(), params(), primary_key, replace_selectable(), schema, select(), self_group(), table_valued(), tablesample(), unique_params(), update()
Class signature
class sqlalchemy.sql.expression.TableClause (sqlalchemy.sql.roles.DMLTableRole, sqlalchemy.sql.expression.Immutable, sqlalchemy.sql.expression.NamedFromClause)
method sqlalchemy.sql.expression.TableClause.alias(name: str | None = None, flat: bool = False) → NamedFromClause
inherited from the FromClause.alias() method of FromClause
Return an alias of this FromClause.
E.g.:
a2 = some_table.alias("a2")
The above code creates an Alias object which can be used as a FROM clause in any SELECT statement.
See also
Using Aliases
alias()
attribute sqlalchemy.sql.expression.TableClause.c
inherited from the FromClause.c attribute of FromClause
A synonym for FromClause.columns
Returns:
a ColumnCollection
attribute sqlalchemy.sql.expression.TableClause.columns
inherited from the FromClause.columns attribute of FromClause
A named-based collection of ColumnElement objects maintained by this FromClause.
The columns, or c collection, is the gateway to the construction of SQL expressions using table-bound or other selectable-bound columns:
select(mytable).where(mytable.c.somecolumn == 5)
Returns:
a ColumnCollection object.
method sqlalchemy.sql.expression.TableClause.compare(other: ClauseElement, **kw: Any) → bool
inherited from the ClauseElement.compare() method of ClauseElement
Compare this ClauseElement to the given ClauseElement.
Subclasses should override the default behavior, which is a straight identity comparison.
**kw are arguments consumed by subclass compare() methods and may be used to modify the criteria for comparison (see ColumnElement).
method sqlalchemy.sql.expression.TableClause.compile(bind: _HasDialect | None = None, dialect: Dialect | None = None, **kw: Any) → Compiled
inherited from the CompilerElement.compile() method of CompilerElement
Compile this SQL expression.
The return value is a Compiled object. Calling str() or unicode() on the returned value will yield a string representation of the result. The Compiled object also can return a dictionary of bind parameter names and values using the params accessor.
Parameters:
• bind – An Connection or Engine which can provide a Dialect in order to generate a Compiled object. If the bind and dialect parameters are both omitted, a default SQL compiler is used.
• column_keys – Used for INSERT and UPDATE statements, a list of column names which should be present in the VALUES clause of the compiled statement. If None, all columns from the target table object are rendered.
• dialect – A Dialect instance which can generate a Compiled object. This argument takes precedence over the bind argument.
• compile_kwargs – 
optional dictionary of additional parameters that will be passed through to the compiler within all “visit” methods. This allows any custom flag to be passed through to a custom compilation construct, for example. It is also used for the case of passing the literal_binds flag through:
from sqlalchemy.sql import table, column, select

t = table("t", column("x"))

s = select(t).where(t.c.x == 5)

print(s.compile(compile_kwargs={"literal_binds": True}))
• 
See also
How do I render SQL expressions as strings, possibly with bound parameters inlined?
method sqlalchemy.sql.expression.TableClause.corresponding_column(column: KeyedColumnElement[Any], require_embedded: bool = False) → KeyedColumnElement[Any] | None
inherited from the Selectable.corresponding_column() method of Selectable
Given a ColumnElement, return the exported ColumnElement object from the Selectable.exported_columns collection of this Selectable which corresponds to that original ColumnElement via a common ancestor column.
Parameters:
• column – the target ColumnElement to be matched.
• require_embedded – only return corresponding columns for the given ColumnElement, if the given ColumnElement is actually present within a sub-element of this Selectable. Normally the column will match if it merely shares a common ancestor with one of the exported columns of this Selectable.
See also
Selectable.exported_columns - the ColumnCollection that is used for the operation.
ColumnCollection.corresponding_column() - implementation method.
method sqlalchemy.sql.expression.TableClause.delete() → Delete
Generate a delete() construct against this TableClause.
E.g.:
table.delete().where(table.c.id == 7)
See delete() for argument and usage information.
attribute sqlalchemy.sql.expression.TableClause.description
attribute sqlalchemy.sql.expression.TableClause.entity_namespace
inherited from the FromClause.entity_namespace attribute of FromClause
Return a namespace used for name-based access in SQL expressions.
This is the namespace that is used to resolve “filter_by()” type expressions, such as:
stmt.filter_by(address="some address")
It defaults to the .c collection, however internally it can be overridden using the “entity_namespace” annotation to deliver alternative results.
attribute sqlalchemy.sql.expression.TableClause.exported_columns
inherited from the FromClause.exported_columns attribute of FromClause
A ColumnCollection that represents the “exported” columns of this Selectable.
The “exported” columns for a FromClause object are synonymous with the FromClause.columns collection.
Added in version 1.4.
See also
Selectable.exported_columns
SelectBase.exported_columns
attribute sqlalchemy.sql.expression.TableClause.foreign_keys
inherited from the FromClause.foreign_keys attribute of FromClause
Return the collection of ForeignKey marker objects which this FromClause references.
Each ForeignKey is a member of a Table-wide ForeignKeyConstraint.
See also
Table.foreign_key_constraints
method sqlalchemy.sql.expression.TableClause.get_children(*, omit_attrs: Tuple[str, ...] = (), **kw: Any) → Iterable[HasTraverseInternals]
inherited from the HasTraverseInternals.get_children() method of HasTraverseInternals
Return immediate child HasTraverseInternals elements of this HasTraverseInternals.
This is used for visit traversal.
**kw may contain flags that change the collection that is returned, for example to return a subset of items in order to cut down on larger traversals, or to return child items from a different context (such as schema-level collections instead of clause-level).
attribute sqlalchemy.sql.expression.TableClause.implicit_returning = False
TableClause doesn’t support having a primary key or column -level defaults, so implicit returning doesn’t apply.
attribute sqlalchemy.sql.expression.TableClause.inherit_cache: bool | None = None
inherited from the HasCacheKey.inherit_cache attribute of HasCacheKey
Indicate if this HasCacheKey instance should make use of the cache key generation scheme used by its immediate superclass.
The attribute defaults to None, which indicates that a construct has not yet taken into account whether or not its appropriate for it to participate in caching; this is functionally equivalent to setting the value to False, except that a warning is also emitted.
This flag can be set to True on a particular class, if the SQL that corresponds to the object does not change based on attributes which are local to this class, and not its superclass.
See also
Enabling Caching Support for Custom Constructs - General guideslines for setting the HasCacheKey.inherit_cache attribute for third-party or user defined SQL constructs.
method sqlalchemy.sql.expression.TableClause.insert() → Insert
Generate an Insert construct against this TableClause.
E.g.:
table.insert().values(name="foo")
See insert() for argument and usage information.
method sqlalchemy.sql.expression.TableClause.is_derived_from(fromclause: FromClause | None) → bool
inherited from the FromClause.is_derived_from() method of FromClause
Return True if this FromClause is ‘derived’ from the given FromClause.
An example would be an Alias of a Table is derived from that Table.
method sqlalchemy.sql.expression.TableClause.join(right: _FromClauseArgument, onclause: _ColumnExpressionArgument[bool] | None = None, isouter: bool = False, full: bool = False) → Join
inherited from the FromClause.join() method of FromClause
Return a Join from this FromClause to another FromClause.
E.g.:
from sqlalchemy import join

j = user_table.join(
    address_table, user_table.c.id == address_table.c.user_id
)
stmt = select(user_table).select_from(j)
would emit SQL along the lines of:
SELECT user.id, user.name FROM user
JOIN address ON user.id = address.user_id
Parameters:
• right – the right side of the join; this is any FromClause object such as a Table object, and may also be a selectable-compatible object such as an ORM-mapped class.
• onclause – a SQL expression representing the ON clause of the join. If left at None, FromClause.join() will attempt to join the two tables based on a foreign key relationship.
• isouter – if True, render a LEFT OUTER JOIN, instead of JOIN.
• full – if True, render a FULL OUTER JOIN, instead of LEFT OUTER JOIN. Implies FromClause.join.isouter.
See also
join() - standalone function
Join - the type of object produced
method sqlalchemy.sql.expression.TableClause.lateral(name: str | None = None) → LateralFromClause
inherited from the Selectable.lateral() method of Selectable
Return a LATERAL alias of this Selectable.
The return value is the Lateral construct also provided by the top-level lateral() function.
See also
LATERAL correlation - overview of usage.
method sqlalchemy.sql.expression.TableClause.outerjoin(right: _FromClauseArgument, onclause: _ColumnExpressionArgument[bool] | None = None, full: bool = False) → Join
inherited from the FromClause.outerjoin() method of FromClause
Return a Join from this FromClause to another FromClause, with the “isouter” flag set to True.
E.g.:
from sqlalchemy import outerjoin

j = user_table.outerjoin(
    address_table, user_table.c.id == address_table.c.user_id
)
The above is equivalent to:
j = user_table.join(
    address_table, user_table.c.id == address_table.c.user_id, isouter=True
)
Parameters:
• right – the right side of the join; this is any FromClause object such as a Table object, and may also be a selectable-compatible object such as an ORM-mapped class.
• onclause – a SQL expression representing the ON clause of the join. If left at None, FromClause.join() will attempt to join the two tables based on a foreign key relationship.
• full – if True, render a FULL OUTER JOIN, instead of LEFT OUTER JOIN.
See also
FromClause.join()
Join
method sqlalchemy.sql.expression.TableClause.params(*optionaldict, **kwargs)
inherited from the Immutable.params() method of Immutable
Return a copy with bindparam() elements replaced.
Returns a copy of this ClauseElement with bindparam() elements replaced with values taken from the given dictionary:
>>> clause = column("x") + bindparam("foo")
>>> print(clause.compile().params)
{'foo':None}
>>> print(clause.params({"foo": 7}).compile().params)
{'foo':7}
attribute sqlalchemy.sql.expression.TableClause.primary_key
inherited from the FromClause.primary_key attribute of FromClause
Return the iterable collection of Column objects which comprise the primary key of this _selectable.FromClause.
For a Table object, this collection is represented by the PrimaryKeyConstraint which itself is an iterable collection of Column objects.
method sqlalchemy.sql.expression.TableClause.replace_selectable(old: FromClause, alias: Alias) → Self
inherited from the Selectable.replace_selectable() method of Selectable
Replace all occurrences of FromClause ‘old’ with the given Alias object, returning a copy of this FromClause.
Deprecated since version 1.4: The Selectable.replace_selectable() method is deprecated, and will be removed in a future release. Similar functionality is available via the sqlalchemy.sql.visitors module.
attribute sqlalchemy.sql.expression.TableClause.schema: str | None = None
inherited from the FromClause.schema attribute of FromClause
Define the ‘schema’ attribute for this FromClause.
This is typically None for most objects except that of Table, where it is taken as the value of the Table.schema argument.
method sqlalchemy.sql.expression.TableClause.select() → Select
inherited from the FromClause.select() method of FromClause
Return a SELECT of this FromClause.
e.g.:
stmt = some_table.select().where(some_table.c.id == 5)
See also
select() - general purpose method which allows for arbitrary column lists.
method sqlalchemy.sql.expression.TableClause.self_group(against: OperatorType | None = None) → ClauseElement
inherited from the ClauseElement.self_group() method of ClauseElement
Apply a ‘grouping’ to this ClauseElement.
This method is overridden by subclasses to return a “grouping” construct, i.e. parenthesis. In particular it’s used by “binary” expressions to provide a grouping around themselves when placed into a larger expression, as well as by select() constructs when placed into the FROM clause of another select(). (Note that subqueries should be normally created using the Select.alias() method, as many platforms require nested SELECT statements to be named).
As expressions are composed together, the application of self_group() is automatic - end-user code should never need to use this method directly. Note that SQLAlchemy’s clause constructs take operator precedence into account - so parenthesis might not be needed, for example, in an expression like x OR (y AND z) - AND takes precedence over OR.
The base self_group() method of ClauseElement just returns self.
method sqlalchemy.sql.expression.TableClause.table_valued() → TableValuedColumn[Any]
inherited from the NamedFromClause.table_valued() method of NamedFromClause
Return a TableValuedColumn object for this FromClause.
A TableValuedColumn is a ColumnElement that represents a complete row in a table. Support for this construct is backend dependent, and is supported in various forms by backends such as PostgreSQL, Oracle Database and SQL Server.
E.g.:
>>> from sqlalchemy import select, column, func, table
>>> a = table("a", column("id"), column("x"), column("y"))
>>> stmt = select(func.row_to_json(a.table_valued()))
>>> print(stmt)
SELECT row_to_json(a) AS row_to_json_1
FROM a
Added in version 1.4.0b2.
See also
Working with SQL Functions - in the SQLAlchemy Unified Tutorial
method sqlalchemy.sql.expression.TableClause.tablesample(sampling: float | Function[Any], name: str | None = None, seed: roles.ExpressionElementRole[Any] | None = None) → TableSample
inherited from the FromClause.tablesample() method of FromClause
Return a TABLESAMPLE alias of this FromClause.
The return value is the TableSample construct also provided by the top-level tablesample() function.
See also
tablesample() - usage guidelines and parameters
method sqlalchemy.sql.expression.TableClause.unique_params(*optionaldict, **kwargs)
inherited from the Immutable.unique_params() method of Immutable
Return a copy with bindparam() elements replaced.
Same functionality as ClauseElement.params(), except adds unique=True to affected bind parameters so that multiple statements can be used.
method sqlalchemy.sql.expression.TableClause.update() → Update
Generate an update() construct against this TableClause.
E.g.:
table.update().where(table.c.id == 7).values(name="foo")
See update() for argument and usage information.
class sqlalchemy.sql.expression.TableSample
Represent a TABLESAMPLE clause.
This object is constructed from the tablesample() module level function as well as the FromClause.tablesample() method available on all FromClause subclasses.
See also
tablesample()
Class signature
class sqlalchemy.sql.expression.TableSample (sqlalchemy.sql.expression.FromClauseAlias)
class sqlalchemy.sql.expression.TableValuedAlias
An alias against a “table valued” SQL function.
This construct provides for a SQL function that returns columns to be used in the FROM clause of a SELECT statement. The object is generated using the FunctionElement.table_valued() method, e.g.:
>>> from sqlalchemy import select, func
>>> fn = func.json_array_elements_text('["one", "two", "three"]').table_valued(
...     "value"
... )
>>> print(select(fn.c.value))
SELECT anon_1.value
FROM json_array_elements_text(:json_array_elements_text_1) AS anon_1
Added in version 1.4.0b2.
See also
Table-Valued Functions - in the SQLAlchemy Unified Tutorial
Members
alias(), column, lateral(), render_derived()
Class signature
class sqlalchemy.sql.expression.TableValuedAlias (sqlalchemy.sql.expression.LateralFromClause, sqlalchemy.sql.expression.Alias)
method sqlalchemy.sql.expression.TableValuedAlias.alias(name: str | None = None, flat: bool = False) → TableValuedAlias
Return a new alias of this TableValuedAlias.
This creates a distinct FROM object that will be distinguished from the original one when used in a SQL statement.
attribute sqlalchemy.sql.expression.TableValuedAlias.column
Return a column expression representing this TableValuedAlias.
This accessor is used to implement the FunctionElement.column_valued() method. See that method for further details.
E.g.:
>>> print(select(func.some_func().table_valued("value").column))
SELECT anon_1 FROM some_func() AS anon_1
See also
FunctionElement.column_valued()
method sqlalchemy.sql.expression.TableValuedAlias.lateral(name: str | None = None) → LateralFromClause
Return a new TableValuedAlias with the lateral flag set, so that it renders as LATERAL.
See also
lateral()
method sqlalchemy.sql.expression.TableValuedAlias.render_derived(name: str | None = None, with_types: bool = False) → TableValuedAlias
Apply “render derived” to this TableValuedAlias.
This has the effect of the individual column names listed out after the alias name in the “AS” sequence, e.g.:
>>> print(
...     select(
...         func.unnest(array(["one", "two", "three"]))
...         .table_valued("x", with_ordinality="o")
...         .render_derived()
...     )
... )
SELECT anon_1.x, anon_1.o
FROM unnest(ARRAY[%(param_1)s, %(param_2)s, %(param_3)s]) WITH ORDINALITY AS anon_1(x, o)
The with_types keyword will render column types inline within the alias expression (this syntax currently applies to the PostgreSQL database):
>>> print(
...     select(
...         func.json_to_recordset('[{"a":1,"b":"foo"},{"a":"2","c":"bar"}]')
...         .table_valued(column("a", Integer), column("b", String))
...         .render_derived(with_types=True)
...     )
... )
SELECT anon_1.a, anon_1.b FROM json_to_recordset(:json_to_recordset_1)
AS anon_1(a INTEGER, b VARCHAR)
Parameters:
• name – optional string name that will be applied to the alias generated. If left as None, a unique anonymizing name will be used.
• with_types – if True, the derived columns will include the datatype specification with each column. This is a special syntax currently known to be required by PostgreSQL for some SQL functions.
class sqlalchemy.sql.expression.TextualSelect
Wrap a TextClause construct within a SelectBase interface.
This allows the TextClause object to gain a .c collection and other FROM-like capabilities such as FromClause.alias(), SelectBase.cte(), etc.
The TextualSelect construct is produced via the TextClause.columns() method - see that method for details.
Changed in version 1.4: the TextualSelect class was renamed from TextAsFrom, to more correctly suit its role as a SELECT-oriented object and not a FROM clause.
See also
text()
TextClause.columns() - primary creation interface.
Members
add_cte(), alias(), as_scalar(), c, compare(), compile(), corresponding_column(), cte(), execution_options(), exists(), exported_columns, get_children(), get_execution_options(), get_label_style(), inherit_cache, is_derived_from(), label(), lateral(), name_cte_columns, options(), params(), replace_selectable(), scalar_subquery(), select(), selected_columns, self_group(), set_label_style(), subquery(), unique_params()
Class signature
class sqlalchemy.sql.expression.TextualSelect (sqlalchemy.sql.expression.SelectBase, sqlalchemy.sql.expression.ExecutableReturnsRows, sqlalchemy.sql.expression.Generative)
method sqlalchemy.sql.expression.TextualSelect.add_cte(*ctes: CTE, nest_here: bool = False) → Self
inherited from the HasCTE.add_cte() method of HasCTE
Add one or more CTE constructs to this statement.
This method will associate the given CTE constructs with the parent statement such that they will each be unconditionally rendered in the WITH clause of the final statement, even if not referenced elsewhere within the statement or any sub-selects.
The optional HasCTE.add_cte.nest_here parameter when set to True will have the effect that each given CTE will render in a WITH clause rendered directly along with this statement, rather than being moved to the top of the ultimate rendered statement, even if this statement is rendered as a subquery within a larger statement.
This method has two general uses. One is to embed CTE statements that serve some purpose without being referenced explicitly, such as the use case of embedding a DML statement such as an INSERT or UPDATE as a CTE inline with a primary statement that may draw from its results indirectly. The other is to provide control over the exact placement of a particular series of CTE constructs that should remain rendered directly in terms of a particular statement that may be nested in a larger statement.
E.g.:
from sqlalchemy import table, column, select

t = table("t", column("c1"), column("c2"))

ins = t.insert().values({"c1": "x", "c2": "y"}).cte()

stmt = select(t).add_cte(ins)
Would render:
WITH anon_1 AS (
    INSERT INTO t (c1, c2) VALUES (:param_1, :param_2)
)
SELECT t.c1, t.c2
FROM t
Above, the “anon_1” CTE is not referenced in the SELECT statement, however still accomplishes the task of running an INSERT statement.
Similarly in a DML-related context, using the PostgreSQL Insert construct to generate an “upsert”:
from sqlalchemy import table, column
from sqlalchemy.dialects.postgresql import insert

t = table("t", column("c1"), column("c2"))

delete_statement_cte = t.delete().where(t.c.c1 < 1).cte("deletions")

insert_stmt = insert(t).values({"c1": 1, "c2": 2})
update_statement = insert_stmt.on_conflict_do_update(
    index_elements=[t.c.c1],
    set_={
        "c1": insert_stmt.excluded.c1,
        "c2": insert_stmt.excluded.c2,
    },
).add_cte(delete_statement_cte)

print(update_statement)
The above statement renders as:
WITH deletions AS (
    DELETE FROM t WHERE t.c1 < %(c1_1)s
)
INSERT INTO t (c1, c2) VALUES (%(c1)s, %(c2)s)
ON CONFLICT (c1) DO UPDATE SET c1 = excluded.c1, c2 = excluded.c2
Added in version 1.4.21.
Parameters:
• *ctes – 
zero or more CTE constructs.
Changed in version 2.0: Multiple CTE instances are accepted
• nest_here – 
if True, the given CTE or CTEs will be rendered as though they specified the HasCTE.cte.nesting flag to True when they were added to this HasCTE. Assuming the given CTEs are not referenced in an outer-enclosing statement as well, the CTEs given should render at the level of this statement when this flag is given.
Added in version 2.0.
See also
HasCTE.cte.nesting
method sqlalchemy.sql.expression.TextualSelect.alias(name: str | None = None, flat: bool = False) → Subquery
inherited from the SelectBase.alias() method of SelectBase
Return a named subquery against this SelectBase.
For a SelectBase (as opposed to a FromClause), this returns a Subquery object which behaves mostly the same as the Alias object that is used with a FromClause.
Changed in version 1.4: The SelectBase.alias() method is now a synonym for the SelectBase.subquery() method.
method sqlalchemy.sql.expression.TextualSelect.as_scalar() → ScalarSelect[Any]
inherited from the SelectBase.as_scalar() method of SelectBase
Deprecated since version 1.4: The SelectBase.as_scalar() method is deprecated and will be removed in a future release. Please refer to SelectBase.scalar_subquery().
attribute sqlalchemy.sql.expression.TextualSelect.c
inherited from the SelectBase.c attribute of SelectBase
Deprecated since version 1.4: The SelectBase.c and SelectBase.columns attributes are deprecated and will be removed in a future release; these attributes implicitly create a subquery that should be explicit. Please call SelectBase.subquery() first in order to create a subquery, which then contains this attribute. To access the columns that this SELECT object SELECTs from, use the SelectBase.selected_columns attribute.
method sqlalchemy.sql.expression.TextualSelect.compare(other: ClauseElement, **kw: Any) → bool
inherited from the ClauseElement.compare() method of ClauseElement
Compare this ClauseElement to the given ClauseElement.
Subclasses should override the default behavior, which is a straight identity comparison.
**kw are arguments consumed by subclass compare() methods and may be used to modify the criteria for comparison (see ColumnElement).
method sqlalchemy.sql.expression.TextualSelect.compile(bind: _HasDialect | None = None, dialect: Dialect | None = None, **kw: Any) → Compiled
inherited from the CompilerElement.compile() method of CompilerElement
Compile this SQL expression.
The return value is a Compiled object. Calling str() or unicode() on the returned value will yield a string representation of the result. The Compiled object also can return a dictionary of bind parameter names and values using the params accessor.
Parameters:
• bind – An Connection or Engine which can provide a Dialect in order to generate a Compiled object. If the bind and dialect parameters are both omitted, a default SQL compiler is used.
• column_keys – Used for INSERT and UPDATE statements, a list of column names which should be present in the VALUES clause of the compiled statement. If None, all columns from the target table object are rendered.
• dialect – A Dialect instance which can generate a Compiled object. This argument takes precedence over the bind argument.
• compile_kwargs – 
optional dictionary of additional parameters that will be passed through to the compiler within all “visit” methods. This allows any custom flag to be passed through to a custom compilation construct, for example. It is also used for the case of passing the literal_binds flag through:
from sqlalchemy.sql import table, column, select

t = table("t", column("x"))

s = select(t).where(t.c.x == 5)

print(s.compile(compile_kwargs={"literal_binds": True}))
• 
See also
How do I render SQL expressions as strings, possibly with bound parameters inlined?
method sqlalchemy.sql.expression.TextualSelect.corresponding_column(column: KeyedColumnElement[Any], require_embedded: bool = False) → KeyedColumnElement[Any] | None
inherited from the Selectable.corresponding_column() method of Selectable
Given a ColumnElement, return the exported ColumnElement object from the Selectable.exported_columns collection of this Selectable which corresponds to that original ColumnElement via a common ancestor column.
Parameters:
• column – the target ColumnElement to be matched.
• require_embedded – only return corresponding columns for the given ColumnElement, if the given ColumnElement is actually present within a sub-element of this Selectable. Normally the column will match if it merely shares a common ancestor with one of the exported columns of this Selectable.
See also
Selectable.exported_columns - the ColumnCollection that is used for the operation.
ColumnCollection.corresponding_column() - implementation method.
method sqlalchemy.sql.expression.TextualSelect.cte(name: str | None = None, recursive: bool = False, nesting: bool = False) → CTE
inherited from the HasCTE.cte() method of HasCTE
Return a new CTE, or Common Table Expression instance.
Common table expressions are a SQL standard whereby SELECT statements can draw upon secondary statements specified along with the primary statement, using a clause called “WITH”. Special semantics regarding UNION can also be employed to allow “recursive” queries, where a SELECT statement can draw upon the set of rows that have previously been selected.
CTEs can also be applied to DML constructs UPDATE, INSERT and DELETE on some databases, both as a source of CTE rows when combined with RETURNING, as well as a consumer of CTE rows.
SQLAlchemy detects CTE objects, which are treated similarly to Alias objects, as special elements to be delivered to the FROM clause of the statement as well as to a WITH clause at the top of the statement.
For special prefixes such as PostgreSQL “MATERIALIZED” and “NOT MATERIALIZED”, the CTE.prefix_with() method may be used to establish these.
Changed in version 1.3.13: Added support for prefixes. In particular - MATERIALIZED and NOT MATERIALIZED.
Parameters:
• name – name given to the common table expression. Like FromClause.alias(), the name can be left as None in which case an anonymous symbol will be used at query compile time.
• recursive – if True, will render WITH RECURSIVE. A recursive common table expression is intended to be used in conjunction with UNION ALL in order to derive rows from those already selected.
• nesting – 
if True, will render the CTE locally to the statement in which it is referenced. For more complex scenarios, the HasCTE.add_cte() method using the HasCTE.add_cte.nest_here parameter may also be used to more carefully control the exact placement of a particular CTE.
Added in version 1.4.24.
See also
HasCTE.add_cte()
The following examples include two from PostgreSQL’s documentation at https://www.postgresql.org/docs/current/static/queries-with.html, as well as additional examples.
Example 1, non recursive:
from sqlalchemy import (
    Table,
    Column,
    String,
    Integer,
    MetaData,
    select,
    func,
)

metadata = MetaData()

orders = Table(
    "orders",
    metadata,
    Column("region", String),
    Column("amount", Integer),
    Column("product", String),
    Column("quantity", Integer),
)

regional_sales = (
    select(orders.c.region, func.sum(orders.c.amount).label("total_sales"))
    .group_by(orders.c.region)
    .cte("regional_sales")
)


top_regions = (
    select(regional_sales.c.region)
    .where(
        regional_sales.c.total_sales
        > select(func.sum(regional_sales.c.total_sales) / 10)
    )
    .cte("top_regions")
)

statement = (
    select(
        orders.c.region,
        orders.c.product,
        func.sum(orders.c.quantity).label("product_units"),
        func.sum(orders.c.amount).label("product_sales"),
    )
    .where(orders.c.region.in_(select(top_regions.c.region)))
    .group_by(orders.c.region, orders.c.product)
)

result = conn.execute(statement).fetchall()
Example 2, WITH RECURSIVE:
from sqlalchemy import (
    Table,
    Column,
    String,
    Integer,
    MetaData,
    select,
    func,
)

metadata = MetaData()

parts = Table(
    "parts",
    metadata,
    Column("part", String),
    Column("sub_part", String),
    Column("quantity", Integer),
)

included_parts = (
    select(parts.c.sub_part, parts.c.part, parts.c.quantity)
    .where(parts.c.part == "our part")
    .cte(recursive=True)
)


incl_alias = included_parts.alias()
parts_alias = parts.alias()
included_parts = included_parts.union_all(
    select(
        parts_alias.c.sub_part, parts_alias.c.part, parts_alias.c.quantity
    ).where(parts_alias.c.part == incl_alias.c.sub_part)
)

statement = select(
    included_parts.c.sub_part,
    func.sum(included_parts.c.quantity).label("total_quantity"),
).group_by(included_parts.c.sub_part)

result = conn.execute(statement).fetchall()
Example 3, an upsert using UPDATE and INSERT with CTEs:
from datetime import date
from sqlalchemy import (
    MetaData,
    Table,
    Column,
    Integer,
    Date,
    select,
    literal,
    and_,
    exists,
)

metadata = MetaData()

visitors = Table(
    "visitors",
    metadata,
    Column("product_id", Integer, primary_key=True),
    Column("date", Date, primary_key=True),
    Column("count", Integer),
)

# add 5 visitors for the product_id == 1
product_id = 1
day = date.today()
count = 5

update_cte = (
    visitors.update()
    .where(
        and_(visitors.c.product_id == product_id, visitors.c.date == day)
    )
    .values(count=visitors.c.count + count)
    .returning(literal(1))
    .cte("update_cte")
)

upsert = visitors.insert().from_select(
    [visitors.c.product_id, visitors.c.date, visitors.c.count],
    select(literal(product_id), literal(day), literal(count)).where(
        ~exists(update_cte.select())
    ),
)

connection.execute(upsert)
Example 4, Nesting CTE (SQLAlchemy 1.4.24 and above):
value_a = select(literal("root").label("n")).cte("value_a")

# A nested CTE with the same name as the root one
value_a_nested = select(literal("nesting").label("n")).cte(
    "value_a", nesting=True
)

# Nesting CTEs takes ascendency locally
# over the CTEs at a higher level
value_b = select(value_a_nested.c.n).cte("value_b")

value_ab = select(value_a.c.n.label("a"), value_b.c.n.label("b"))
The above query will render the second CTE nested inside the first, shown with inline parameters below as:
WITH
    value_a AS
        (SELECT 'root' AS n),
    value_b AS
        (WITH value_a AS
            (SELECT 'nesting' AS n)
        SELECT value_a.n AS n FROM value_a)
SELECT value_a.n AS a, value_b.n AS b
FROM value_a, value_b
The same CTE can be set up using the HasCTE.add_cte() method as follows (SQLAlchemy 2.0 and above):
value_a = select(literal("root").label("n")).cte("value_a")

# A nested CTE with the same name as the root one
value_a_nested = select(literal("nesting").label("n")).cte("value_a")

# Nesting CTEs takes ascendency locally
# over the CTEs at a higher level
value_b = (
    select(value_a_nested.c.n)
    .add_cte(value_a_nested, nest_here=True)
    .cte("value_b")
)

value_ab = select(value_a.c.n.label("a"), value_b.c.n.label("b"))
Example 5, Non-Linear CTE (SQLAlchemy 1.4.28 and above):
edge = Table(
    "edge",
    metadata,
    Column("id", Integer, primary_key=True),
    Column("left", Integer),
    Column("right", Integer),
)

root_node = select(literal(1).label("node")).cte("nodes", recursive=True)

left_edge = select(edge.c.left).join(
    root_node, edge.c.right == root_node.c.node
)
right_edge = select(edge.c.right).join(
    root_node, edge.c.left == root_node.c.node
)

subgraph_cte = root_node.union(left_edge, right_edge)

subgraph = select(subgraph_cte)
The above query will render 2 UNIONs inside the recursive CTE:
WITH RECURSIVE nodes(node) AS (
        SELECT 1 AS node
    UNION
        SELECT edge."left" AS "left"
        FROM edge JOIN nodes ON edge."right" = nodes.node
    UNION
        SELECT edge."right" AS "right"
        FROM edge JOIN nodes ON edge."left" = nodes.node
)
SELECT nodes.node FROM nodes
See also
Query.cte() - ORM version of HasCTE.cte().
method sqlalchemy.sql.expression.TextualSelect.execution_options(**kw: Any) → Self
inherited from the Executable.execution_options() method of Executable
Set non-SQL options for the statement which take effect during execution.
Execution options can be set at many scopes, including per-statement, per-connection, or per execution, using methods such as Connection.execution_options() and parameters which accept a dictionary of options such as Connection.execute.execution_options and Session.execute.execution_options.
The primary characteristic of an execution option, as opposed to other kinds of options such as ORM loader options, is that execution options never affect the compiled SQL of a query, only things that affect how the SQL statement itself is invoked or how results are fetched. That is, execution options are not part of what’s accommodated by SQL compilation nor are they considered part of the cached state of a statement.
The Executable.execution_options() method is generative, as is the case for the method as applied to the Engine and Query objects, which means when the method is called, a copy of the object is returned, which applies the given parameters to that new copy, but leaves the original unchanged:
statement = select(table.c.x, table.c.y)
new_statement = statement.execution_options(my_option=True)
An exception to this behavior is the Connection object, where the Connection.execution_options() method is explicitly not generative.
The kinds of options that may be passed to Executable.execution_options() and other related methods and parameter dictionaries include parameters that are explicitly consumed by SQLAlchemy Core or ORM, as well as arbitrary keyword arguments not defined by SQLAlchemy, which means the methods and/or parameter dictionaries may be used for user-defined parameters that interact with custom code, which may access the parameters using methods such as Executable.get_execution_options() and Connection.get_execution_options(), or within selected event hooks using a dedicated execution_options event parameter such as ConnectionEvents.before_execute.execution_options or ORMExecuteState.execution_options, e.g.:
from sqlalchemy import event


@event.listens_for(some_engine, "before_execute")
def _process_opt(conn, statement, multiparams, params, execution_options):
    "run a SQL function before invoking a statement"

    if execution_options.get("do_special_thing", False):
        conn.exec_driver_sql("run_special_function()")
Within the scope of options that are explicitly recognized by SQLAlchemy, most apply to specific classes of objects and not others. The most common execution options include:
• Connection.execution_options.isolation_level - sets the isolation level for a connection or a class of connections via an Engine. This option is accepted only by Connection or Engine.
• Connection.execution_options.stream_results - indicates results should be fetched using a server side cursor; this option is accepted by Connection, by the Connection.execute.execution_options parameter on Connection.execute(), and additionally by Executable.execution_options() on a SQL statement object, as well as by ORM constructs like Session.execute().
• Connection.execution_options.compiled_cache - indicates a dictionary that will serve as the SQL compilation cache for a Connection or Engine, as well as for ORM methods like Session.execute(). Can be passed as None to disable caching for statements. This option is not accepted by Executable.execution_options() as it is inadvisable to carry along a compilation cache within a statement object.
• Connection.execution_options.schema_translate_map - a mapping of schema names used by the Schema Translate Map feature, accepted by Connection, Engine, Executable, as well as by ORM constructs like Session.execute().
See also
Connection.execution_options()
Connection.execute.execution_options
Session.execute.execution_options
ORM Execution Options - documentation on all ORM-specific execution options
method sqlalchemy.sql.expression.TextualSelect.exists() → Exists
inherited from the SelectBase.exists() method of SelectBase
Return an Exists representation of this selectable, which can be used as a column expression.
The returned object is an instance of Exists.
See also
exists()
EXISTS subqueries - in the 2.0 style tutorial.
Added in version 1.4.
attribute sqlalchemy.sql.expression.TextualSelect.exported_columns
inherited from the SelectBase.exported_columns attribute of SelectBase
A ColumnCollection that represents the “exported” columns of this Selectable, not including TextClause constructs.
The “exported” columns for a SelectBase object are synonymous with the SelectBase.selected_columns collection.
Added in version 1.4.
See also
Select.exported_columns
Selectable.exported_columns
FromClause.exported_columns
method sqlalchemy.sql.expression.TextualSelect.get_children(*, omit_attrs: Tuple[str, ...] = (), **kw: Any) → Iterable[HasTraverseInternals]
inherited from the HasTraverseInternals.get_children() method of HasTraverseInternals
Return immediate child HasTraverseInternals elements of this HasTraverseInternals.
This is used for visit traversal.
**kw may contain flags that change the collection that is returned, for example to return a subset of items in order to cut down on larger traversals, or to return child items from a different context (such as schema-level collections instead of clause-level).
method sqlalchemy.sql.expression.TextualSelect.get_execution_options() → _ExecuteOptions
inherited from the Executable.get_execution_options() method of Executable
Get the non-SQL options which will take effect during execution.
Added in version 1.3.
See also
Executable.execution_options()
method sqlalchemy.sql.expression.TextualSelect.get_label_style() → SelectLabelStyle
inherited from the SelectBase.get_label_style() method of SelectBase
Retrieve the current label style.
Implemented by subclasses.
attribute sqlalchemy.sql.expression.TextualSelect.inherit_cache: bool | None = None
inherited from the HasCacheKey.inherit_cache attribute of HasCacheKey
Indicate if this HasCacheKey instance should make use of the cache key generation scheme used by its immediate superclass.
The attribute defaults to None, which indicates that a construct has not yet taken into account whether or not its appropriate for it to participate in caching; this is functionally equivalent to setting the value to False, except that a warning is also emitted.
This flag can be set to True on a particular class, if the SQL that corresponds to the object does not change based on attributes which are local to this class, and not its superclass.
See also
Enabling Caching Support for Custom Constructs - General guideslines for setting the HasCacheKey.inherit_cache attribute for third-party or user defined SQL constructs.
method sqlalchemy.sql.expression.TextualSelect.is_derived_from(fromclause: FromClause | None) → bool
inherited from the ReturnsRows.is_derived_from() method of ReturnsRows
Return True if this ReturnsRows is ‘derived’ from the given FromClause.
An example would be an Alias of a Table is derived from that Table.
method sqlalchemy.sql.expression.TextualSelect.label(name: str | None) → Label[Any]
inherited from the SelectBase.label() method of SelectBase
Return a ‘scalar’ representation of this selectable, embedded as a subquery with a label.
See also
SelectBase.scalar_subquery().
method sqlalchemy.sql.expression.TextualSelect.lateral(name: str | None = None) → LateralFromClause
inherited from the SelectBase.lateral() method of SelectBase
Return a LATERAL alias of this Selectable.
The return value is the Lateral construct also provided by the top-level lateral() function.
See also
LATERAL correlation - overview of usage.
attribute sqlalchemy.sql.expression.TextualSelect.name_cte_columns: bool = False
inherited from the HasCTE.name_cte_columns attribute of HasCTE
indicates if this HasCTE as contained within a CTE should compel the CTE to render the column names of this object in the WITH clause.
Added in version 2.0.42.
method sqlalchemy.sql.expression.TextualSelect.options(*options: ExecutableOption) → Self
inherited from the Executable.options() method of Executable
Apply options to this statement.
In the general sense, options are any kind of Python object that can be interpreted by the SQL compiler for the statement. These options can be consumed by specific dialects or specific kinds of compilers.
The most commonly known kind of option are the ORM level options that apply “eager load” and other loading behaviors to an ORM query. However, options can theoretically be used for many other purposes.
For background on specific kinds of options for specific kinds of statements, refer to the documentation for those option objects.
Changed in version 1.4: - added Executable.options() to Core statement objects towards the goal of allowing unified Core / ORM querying capabilities.
See also
Column Loading Options - refers to options specific to the usage of ORM queries
Relationship Loading with Loader Options - refers to options specific to the usage of ORM queries
method sqlalchemy.sql.expression.TextualSelect.params(_ClauseElement__optionaldict: Mapping[str, Any] | None = None, **kwargs: Any) → Self
inherited from the ClauseElement.params() method of ClauseElement
Return a copy with bindparam() elements replaced.
Returns a copy of this ClauseElement with bindparam() elements replaced with values taken from the given dictionary:
>>> clause = column("x") + bindparam("foo")
>>> print(clause.compile().params)
{'foo':None}
>>> print(clause.params({"foo": 7}).compile().params)
{'foo':7}
method sqlalchemy.sql.expression.TextualSelect.replace_selectable(old: FromClause, alias: Alias) → Self
inherited from the Selectable.replace_selectable() method of Selectable
Replace all occurrences of FromClause ‘old’ with the given Alias object, returning a copy of this FromClause.
Deprecated since version 1.4: The Selectable.replace_selectable() method is deprecated, and will be removed in a future release. Similar functionality is available via the sqlalchemy.sql.visitors module.
method sqlalchemy.sql.expression.TextualSelect.scalar_subquery() → ScalarSelect[Any]
inherited from the SelectBase.scalar_subquery() method of SelectBase
Return a ‘scalar’ representation of this selectable, which can be used as a column expression.
The returned object is an instance of ScalarSelect.
Typically, a select statement which has only one column in its columns clause is eligible to be used as a scalar expression. The scalar subquery can then be used in the WHERE clause or columns clause of an enclosing SELECT.
Note that the scalar subquery differentiates from the FROM-level subquery that can be produced using the SelectBase.subquery() method.
See also
Scalar and Correlated Subqueries - in the 2.0 tutorial
method sqlalchemy.sql.expression.TextualSelect.select(*arg: Any, **kw: Any) → Select
inherited from the SelectBase.select() method of SelectBase
Deprecated since version 1.4: The SelectBase.select() method is deprecated and will be removed in a future release; this method implicitly creates a subquery that should be explicit. Please call SelectBase.subquery() first in order to create a subquery, which then can be selected.
attribute sqlalchemy.sql.expression.TextualSelect.selected_columns
A ColumnCollection representing the columns that this SELECT statement or similar construct returns in its result set, not including TextClause constructs.
This collection differs from the FromClause.columns collection of a FromClause in that the columns within this collection cannot be directly nested inside another SELECT statement; a subquery must be applied first which provides for the necessary parenthesization required by SQL.
For a TextualSelect construct, the collection contains the ColumnElement objects that were passed to the constructor, typically via the TextClause.columns() method.
Added in version 1.4.
method sqlalchemy.sql.expression.TextualSelect.self_group(against: OperatorType | None = None) → ClauseElement
inherited from the ClauseElement.self_group() method of ClauseElement
Apply a ‘grouping’ to this ClauseElement.
This method is overridden by subclasses to return a “grouping” construct, i.e. parenthesis. In particular it’s used by “binary” expressions to provide a grouping around themselves when placed into a larger expression, as well as by select() constructs when placed into the FROM clause of another select(). (Note that subqueries should be normally created using the Select.alias() method, as many platforms require nested SELECT statements to be named).
As expressions are composed together, the application of self_group() is automatic - end-user code should never need to use this method directly. Note that SQLAlchemy’s clause constructs take operator precedence into account - so parenthesis might not be needed, for example, in an expression like x OR (y AND z) - AND takes precedence over OR.
The base self_group() method of ClauseElement just returns self.
method sqlalchemy.sql.expression.TextualSelect.set_label_style(style: SelectLabelStyle) → TextualSelect
Return a new selectable with the specified label style.
Implemented by subclasses.
method sqlalchemy.sql.expression.TextualSelect.subquery(name: str | None = None) → Subquery
inherited from the SelectBase.subquery() method of SelectBase
Return a subquery of this SelectBase.
A subquery is from a SQL perspective a parenthesized, named construct that can be placed in the FROM clause of another SELECT statement.
Given a SELECT statement such as:
stmt = select(table.c.id, table.c.name)
The above statement might look like:
SELECT table.id, table.name FROM table
The subquery form by itself renders the same way, however when embedded into the FROM clause of another SELECT statement, it becomes a named sub-element:
subq = stmt.subquery()
new_stmt = select(subq)
The above renders as:
SELECT anon_1.id, anon_1.name
FROM (SELECT table.id, table.name FROM table) AS anon_1
Historically, SelectBase.subquery() is equivalent to calling the FromClause.alias() method on a FROM object; however, as a SelectBase object is not directly FROM object, the SelectBase.subquery() method provides clearer semantics.
Added in version 1.4.
method sqlalchemy.sql.expression.TextualSelect.unique_params(_ClauseElement__optionaldict: Dict[str, Any] | None = None, **kwargs: Any) → Self
inherited from the ClauseElement.unique_params() method of ClauseElement
Return a copy with bindparam() elements replaced.
Same functionality as ClauseElement.params(), except adds unique=True to affected bind parameters so that multiple statements can be used.
class sqlalchemy.sql.expression.Values
Represent a VALUES construct that can be used as a FROM element in a statement.
The Values object is created from the values() function.
Added in version 1.4.
Members
add_cte(), alias(), compile(), cte(), data(), inherit_cache, lateral(), name_cte_columns, scalar_values(), table_valued()
Class signature
class sqlalchemy.sql.expression.Values (sqlalchemy.sql.roles.InElementRole, sqlalchemy.sql.expression.HasCTE, sqlalchemy.sql.expression.Generative, sqlalchemy.sql.expression.LateralFromClause)
method sqlalchemy.sql.expression.Values.add_cte(*ctes: CTE, nest_here: bool = False) → Self
inherited from the HasCTE.add_cte() method of HasCTE
Add one or more CTE constructs to this statement.
This method will associate the given CTE constructs with the parent statement such that they will each be unconditionally rendered in the WITH clause of the final statement, even if not referenced elsewhere within the statement or any sub-selects.
The optional HasCTE.add_cte.nest_here parameter when set to True will have the effect that each given CTE will render in a WITH clause rendered directly along with this statement, rather than being moved to the top of the ultimate rendered statement, even if this statement is rendered as a subquery within a larger statement.
This method has two general uses. One is to embed CTE statements that serve some purpose without being referenced explicitly, such as the use case of embedding a DML statement such as an INSERT or UPDATE as a CTE inline with a primary statement that may draw from its results indirectly. The other is to provide control over the exact placement of a particular series of CTE constructs that should remain rendered directly in terms of a particular statement that may be nested in a larger statement.
E.g.:
from sqlalchemy import table, column, select

t = table("t", column("c1"), column("c2"))

ins = t.insert().values({"c1": "x", "c2": "y"}).cte()

stmt = select(t).add_cte(ins)
Would render:
WITH anon_1 AS (
    INSERT INTO t (c1, c2) VALUES (:param_1, :param_2)
)
SELECT t.c1, t.c2
FROM t
Above, the “anon_1” CTE is not referenced in the SELECT statement, however still accomplishes the task of running an INSERT statement.
Similarly in a DML-related context, using the PostgreSQL Insert construct to generate an “upsert”:
from sqlalchemy import table, column
from sqlalchemy.dialects.postgresql import insert

t = table("t", column("c1"), column("c2"))

delete_statement_cte = t.delete().where(t.c.c1 < 1).cte("deletions")

insert_stmt = insert(t).values({"c1": 1, "c2": 2})
update_statement = insert_stmt.on_conflict_do_update(
    index_elements=[t.c.c1],
    set_={
        "c1": insert_stmt.excluded.c1,
        "c2": insert_stmt.excluded.c2,
    },
).add_cte(delete_statement_cte)

print(update_statement)
The above statement renders as:
WITH deletions AS (
    DELETE FROM t WHERE t.c1 < %(c1_1)s
)
INSERT INTO t (c1, c2) VALUES (%(c1)s, %(c2)s)
ON CONFLICT (c1) DO UPDATE SET c1 = excluded.c1, c2 = excluded.c2
Added in version 1.4.21.
Parameters:
• *ctes – 
zero or more CTE constructs.
Changed in version 2.0: Multiple CTE instances are accepted
• nest_here – 
if True, the given CTE or CTEs will be rendered as though they specified the HasCTE.cte.nesting flag to True when they were added to this HasCTE. Assuming the given CTEs are not referenced in an outer-enclosing statement as well, the CTEs given should render at the level of this statement when this flag is given.
Added in version 2.0.
See also
HasCTE.cte.nesting
method sqlalchemy.sql.expression.Values.alias(name: str | None = None, flat: bool = False) → Self
Return a new Values construct that is a copy of this one with the given name.
This method is a VALUES-specific specialization of the FromClause.alias() method.
See also
Using Aliases
alias()
method sqlalchemy.sql.expression.Values.compile(bind: _HasDialect | None = None, dialect: Dialect | None = None, **kw: Any) → Compiled
inherited from the CompilerElement.compile() method of CompilerElement
Compile this SQL expression.
The return value is a Compiled object. Calling str() or unicode() on the returned value will yield a string representation of the result. The Compiled object also can return a dictionary of bind parameter names and values using the params accessor.
Parameters:
• bind – An Connection or Engine which can provide a Dialect in order to generate a Compiled object. If the bind and dialect parameters are both omitted, a default SQL compiler is used.
• column_keys – Used for INSERT and UPDATE statements, a list of column names which should be present in the VALUES clause of the compiled statement. If None, all columns from the target table object are rendered.
• dialect – A Dialect instance which can generate a Compiled object. This argument takes precedence over the bind argument.
• compile_kwargs – 
optional dictionary of additional parameters that will be passed through to the compiler within all “visit” methods. This allows any custom flag to be passed through to a custom compilation construct, for example. It is also used for the case of passing the literal_binds flag through:
from sqlalchemy.sql import table, column, select

t = table("t", column("x"))

s = select(t).where(t.c.x == 5)

print(s.compile(compile_kwargs={"literal_binds": True}))
• 
See also
How do I render SQL expressions as strings, possibly with bound parameters inlined?
method sqlalchemy.sql.expression.Values.cte(name: str | None = None, recursive: bool = False, nesting: bool = False) → CTE
inherited from the HasCTE.cte() method of HasCTE
Return a new CTE, or Common Table Expression instance.
Common table expressions are a SQL standard whereby SELECT statements can draw upon secondary statements specified along with the primary statement, using a clause called “WITH”. Special semantics regarding UNION can also be employed to allow “recursive” queries, where a SELECT statement can draw upon the set of rows that have previously been selected.
CTEs can also be applied to DML constructs UPDATE, INSERT and DELETE on some databases, both as a source of CTE rows when combined with RETURNING, as well as a consumer of CTE rows.
SQLAlchemy detects CTE objects, which are treated similarly to Alias objects, as special elements to be delivered to the FROM clause of the statement as well as to a WITH clause at the top of the statement.
For special prefixes such as PostgreSQL “MATERIALIZED” and “NOT MATERIALIZED”, the CTE.prefix_with() method may be used to establish these.
Changed in version 1.3.13: Added support for prefixes. In particular - MATERIALIZED and NOT MATERIALIZED.
Parameters:
• name – name given to the common table expression. Like FromClause.alias(), the name can be left as None in which case an anonymous symbol will be used at query compile time.
• recursive – if True, will render WITH RECURSIVE. A recursive common table expression is intended to be used in conjunction with UNION ALL in order to derive rows from those already selected.
• nesting – 
if True, will render the CTE locally to the statement in which it is referenced. For more complex scenarios, the HasCTE.add_cte() method using the HasCTE.add_cte.nest_here parameter may also be used to more carefully control the exact placement of a particular CTE.
Added in version 1.4.24.
See also
HasCTE.add_cte()
The following examples include two from PostgreSQL’s documentation at https://www.postgresql.org/docs/current/static/queries-with.html, as well as additional examples.
Example 1, non recursive:
from sqlalchemy import (
    Table,
    Column,
    String,
    Integer,
    MetaData,
    select,
    func,
)

metadata = MetaData()

orders = Table(
    "orders",
    metadata,
    Column("region", String),
    Column("amount", Integer),
    Column("product", String),
    Column("quantity", Integer),
)

regional_sales = (
    select(orders.c.region, func.sum(orders.c.amount).label("total_sales"))
    .group_by(orders.c.region)
    .cte("regional_sales")
)


top_regions = (
    select(regional_sales.c.region)
    .where(
        regional_sales.c.total_sales
        > select(func.sum(regional_sales.c.total_sales) / 10)
    )
    .cte("top_regions")
)

statement = (
    select(
        orders.c.region,
        orders.c.product,
        func.sum(orders.c.quantity).label("product_units"),
        func.sum(orders.c.amount).label("product_sales"),
    )
    .where(orders.c.region.in_(select(top_regions.c.region)))
    .group_by(orders.c.region, orders.c.product)
)

result = conn.execute(statement).fetchall()
Example 2, WITH RECURSIVE:
from sqlalchemy import (
    Table,
    Column,
    String,
    Integer,
    MetaData,
    select,
    func,
)

metadata = MetaData()

parts = Table(
    "parts",
    metadata,
    Column("part", String),
    Column("sub_part", String),
    Column("quantity", Integer),
)

included_parts = (
    select(parts.c.sub_part, parts.c.part, parts.c.quantity)
    .where(parts.c.part == "our part")
    .cte(recursive=True)
)


incl_alias = included_parts.alias()
parts_alias = parts.alias()
included_parts = included_parts.union_all(
    select(
        parts_alias.c.sub_part, parts_alias.c.part, parts_alias.c.quantity
    ).where(parts_alias.c.part == incl_alias.c.sub_part)
)

statement = select(
    included_parts.c.sub_part,
    func.sum(included_parts.c.quantity).label("total_quantity"),
).group_by(included_parts.c.sub_part)

result = conn.execute(statement).fetchall()
Example 3, an upsert using UPDATE and INSERT with CTEs:
from datetime import date
from sqlalchemy import (
    MetaData,
    Table,
    Column,
    Integer,
    Date,
    select,
    literal,
    and_,
    exists,
)

metadata = MetaData()

visitors = Table(
    "visitors",
    metadata,
    Column("product_id", Integer, primary_key=True),
    Column("date", Date, primary_key=True),
    Column("count", Integer),
)

# add 5 visitors for the product_id == 1
product_id = 1
day = date.today()
count = 5

update_cte = (
    visitors.update()
    .where(
        and_(visitors.c.product_id == product_id, visitors.c.date == day)
    )
    .values(count=visitors.c.count + count)
    .returning(literal(1))
    .cte("update_cte")
)

upsert = visitors.insert().from_select(
    [visitors.c.product_id, visitors.c.date, visitors.c.count],
    select(literal(product_id), literal(day), literal(count)).where(
        ~exists(update_cte.select())
    ),
)

connection.execute(upsert)
Example 4, Nesting CTE (SQLAlchemy 1.4.24 and above):
value_a = select(literal("root").label("n")).cte("value_a")

# A nested CTE with the same name as the root one
value_a_nested = select(literal("nesting").label("n")).cte(
    "value_a", nesting=True
)

# Nesting CTEs takes ascendency locally
# over the CTEs at a higher level
value_b = select(value_a_nested.c.n).cte("value_b")

value_ab = select(value_a.c.n.label("a"), value_b.c.n.label("b"))
The above query will render the second CTE nested inside the first, shown with inline parameters below as:
WITH
    value_a AS
        (SELECT 'root' AS n),
    value_b AS
        (WITH value_a AS
            (SELECT 'nesting' AS n)
        SELECT value_a.n AS n FROM value_a)
SELECT value_a.n AS a, value_b.n AS b
FROM value_a, value_b
The same CTE can be set up using the HasCTE.add_cte() method as follows (SQLAlchemy 2.0 and above):
value_a = select(literal("root").label("n")).cte("value_a")

# A nested CTE with the same name as the root one
value_a_nested = select(literal("nesting").label("n")).cte("value_a")

# Nesting CTEs takes ascendency locally
# over the CTEs at a higher level
value_b = (
    select(value_a_nested.c.n)
    .add_cte(value_a_nested, nest_here=True)
    .cte("value_b")
)

value_ab = select(value_a.c.n.label("a"), value_b.c.n.label("b"))
Example 5, Non-Linear CTE (SQLAlchemy 1.4.28 and above):
edge = Table(
    "edge",
    metadata,
    Column("id", Integer, primary_key=True),
    Column("left", Integer),
    Column("right", Integer),
)

root_node = select(literal(1).label("node")).cte("nodes", recursive=True)

left_edge = select(edge.c.left).join(
    root_node, edge.c.right == root_node.c.node
)
right_edge = select(edge.c.right).join(
    root_node, edge.c.left == root_node.c.node
)

subgraph_cte = root_node.union(left_edge, right_edge)

subgraph = select(subgraph_cte)
The above query will render 2 UNIONs inside the recursive CTE:
WITH RECURSIVE nodes(node) AS (
        SELECT 1 AS node
    UNION
        SELECT edge."left" AS "left"
        FROM edge JOIN nodes ON edge."right" = nodes.node
    UNION
        SELECT edge."right" AS "right"
        FROM edge JOIN nodes ON edge."left" = nodes.node
)
SELECT nodes.node FROM nodes
See also
Query.cte() - ORM version of HasCTE.cte().
method sqlalchemy.sql.expression.Values.data(values: Sequence[Tuple[Any, ...]]) → Self
Return a new Values construct, adding the given data to the data list.
E.g.:
my_values = my_values.data([(1, "value 1"), (2, "value2")])
Parameters:
values – a sequence (i.e. list) of tuples that map to the column expressions given in the Values constructor.
attribute sqlalchemy.sql.expression.Values.inherit_cache: bool | None = None
inherited from the HasCacheKey.inherit_cache attribute of HasCacheKey
Indicate if this HasCacheKey instance should make use of the cache key generation scheme used by its immediate superclass.
The attribute defaults to None, which indicates that a construct has not yet taken into account whether or not its appropriate for it to participate in caching; this is functionally equivalent to setting the value to False, except that a warning is also emitted.
This flag can be set to True on a particular class, if the SQL that corresponds to the object does not change based on attributes which are local to this class, and not its superclass.
See also
Enabling Caching Support for Custom Constructs - General guideslines for setting the HasCacheKey.inherit_cache attribute for third-party or user defined SQL constructs.
method sqlalchemy.sql.expression.Values.lateral(name: str | None = None) → Self
Return a new Values with the lateral flag set, so that it renders as LATERAL.
See also
lateral()
attribute sqlalchemy.sql.expression.Values.name_cte_columns: bool = True
indicates if this HasCTE as contained within a CTE should compel the CTE to render the column names of this object in the WITH clause.
Added in version 2.0.42.
method sqlalchemy.sql.expression.Values.scalar_values() → ScalarValues
Returns a scalar VALUES construct that can be used as a COLUMN element in a statement.
Added in version 2.0.0b4.
method sqlalchemy.sql.expression.Values.table_valued() → TableValuedColumn[Any]
inherited from the NamedFromClause.table_valued() method of NamedFromClause
Return a TableValuedColumn object for this FromClause.
A TableValuedColumn is a ColumnElement that represents a complete row in a table. Support for this construct is backend dependent, and is supported in various forms by backends such as PostgreSQL, Oracle Database and SQL Server.
E.g.:
>>> from sqlalchemy import select, column, func, table
>>> a = table("a", column("id"), column("x"), column("y"))
>>> stmt = select(func.row_to_json(a.table_valued()))
>>> print(stmt)
SELECT row_to_json(a) AS row_to_json_1
FROM a
Added in version 1.4.0b2.
See also
Working with SQL Functions - in the SQLAlchemy Unified Tutorial
class sqlalchemy.sql.expression.ScalarValues
Represent a scalar VALUES construct that can be used as a COLUMN element in a statement.
The ScalarValues object is created from the Values.scalar_values() method. It’s also automatically generated when a Values is used in an IN or NOT IN condition.
Added in version 2.0.0b4.
Class signature
class sqlalchemy.sql.expression.ScalarValues (sqlalchemy.sql.roles.InElementRole, sqlalchemy.sql.expression.GroupedElement, sqlalchemy.sql.expression.ColumnElement)
Label Style Constants
Constants used with the GenerativeSelect.set_label_style() method.
Object NameDescriptionSelectLabelStyleLabel style constants that may be passed to Select.set_label_style().class sqlalchemy.sql.expression.SelectLabelStyle
Label style constants that may be passed to Select.set_label_style().
Members
LABEL_STYLE_DEFAULT, LABEL_STYLE_DISAMBIGUATE_ONLY, LABEL_STYLE_NONE, LABEL_STYLE_TABLENAME_PLUS_COL
Class signature
class sqlalchemy.sql.expression.SelectLabelStyle (enum.Enum)
attribute sqlalchemy.sql.expression.SelectLabelStyle.LABEL_STYLE_DEFAULT = 2
The default label style, refers to LABEL_STYLE_DISAMBIGUATE_ONLY.
Added in version 1.4.
attribute sqlalchemy.sql.expression.SelectLabelStyle.LABEL_STYLE_DISAMBIGUATE_ONLY = 2
Label style indicating that columns with a name that conflicts with an existing name should be labeled with a semi-anonymizing label when generating the columns clause of a SELECT statement.
Below, most column names are left unaffected, except for the second occurrence of the name columna, which is labeled using the label columna_1 to disambiguate it from that of tablea.columna:
>>> from sqlalchemy import (
...     table,
...     column,
...     select,
...     true,
...     LABEL_STYLE_DISAMBIGUATE_ONLY,
... )
>>> table1 = table("table1", column("columna"), column("columnb"))
>>> table2 = table("table2", column("columna"), column("columnc"))
>>> print(
...     select(table1, table2)
...     .join(table2, true())
...     .set_label_style(LABEL_STYLE_DISAMBIGUATE_ONLY)
... )
SELECT table1.columna, table1.columnb, table2.columna AS columna_1, table2.columnc
FROM table1 JOIN table2 ON true
Used with the GenerativeSelect.set_label_style() method, LABEL_STYLE_DISAMBIGUATE_ONLY is the default labeling style for all SELECT statements outside of 1.x style ORM queries.
Added in version 1.4.
attribute sqlalchemy.sql.expression.SelectLabelStyle.LABEL_STYLE_NONE = 0
Label style indicating no automatic labeling should be applied to the columns clause of a SELECT statement.
Below, the columns named columna are both rendered as is, meaning that the name columna can only refer to the first occurrence of this name within a result set, as well as if the statement were used as a subquery:
>>> from sqlalchemy import table, column, select, true, LABEL_STYLE_NONE
>>> table1 = table("table1", column("columna"), column("columnb"))
>>> table2 = table("table2", column("columna"), column("columnc"))
>>> print(
...     select(table1, table2)
...     .join(table2, true())
...     .set_label_style(LABEL_STYLE_NONE)
... )
SELECT table1.columna, table1.columnb, table2.columna, table2.columnc
FROM table1 JOIN table2 ON true
Used with the Select.set_label_style() method.
Added in version 1.4.
attribute sqlalchemy.sql.expression.SelectLabelStyle.LABEL_STYLE_TABLENAME_PLUS_COL = 1
Label style indicating all columns should be labeled as <tablename>_<columnname> when generating the columns clause of a SELECT statement, to disambiguate same-named columns referenced from different tables, aliases, or subqueries.
Below, all column names are given a label so that the two same-named columns columna are disambiguated as table1_columna and table2_columna:
>>> from sqlalchemy import (
...     table,
...     column,
...     select,
...     true,
...     LABEL_STYLE_TABLENAME_PLUS_COL,
... )
>>> table1 = table("table1", column("columna"), column("columnb"))
>>> table2 = table("table2", column("columna"), column("columnc"))
>>> print(
...     select(table1, table2)
...     .join(table2, true())
...     .set_label_style(LABEL_STYLE_TABLENAME_PLUS_COL)
... )
SELECT table1.columna AS table1_columna, table1.columnb AS table1_columnb, table2.columna AS table2_columna, table2.columnc AS table2_columnc
FROM table1 JOIN table2 ON true
Used with the GenerativeSelect.set_label_style() method. Equivalent to the legacy method Select.apply_labels(); LABEL_STYLE_TABLENAME_PLUS_COL is SQLAlchemy’s legacy auto-labeling style. LABEL_STYLE_DISAMBIGUATE_ONLY provides a less intrusive approach to disambiguation of same-named column expressions.
Added in version 1.4.
See also
Select.set_label_style()
Select.get_label_style()


Insert, Updates, Deletes
INSERT, UPDATE and DELETE statements build on a hierarchy starting with UpdateBase. The Insert and Update constructs build on the intermediary ValuesBase.
DML Foundational Constructors
Top level “INSERT”, “UPDATE”, “DELETE” constructors.
Object NameDescriptiondelete(table)Construct Delete object.insert(table)Construct an Insert object.update(table)Construct an Update object.function sqlalchemy.sql.expression.delete(table: _DMLTableArgument) → Delete
Construct Delete object.
E.g.:
from sqlalchemy import delete

stmt = delete(user_table).where(user_table.c.id == 5)
Similar functionality is available via the TableClause.delete() method on Table.
Parameters:
table – The table to delete rows from.
See also
Using UPDATE and DELETE Statements - in the SQLAlchemy Unified Tutorial
function sqlalchemy.sql.expression.insert(table: _DMLTableArgument) → Insert
Construct an Insert object.
E.g.:
from sqlalchemy import insert

stmt = insert(user_table).values(name="username", fullname="Full Username")
Similar functionality is available via the TableClause.insert() method on Table.
See also
Using INSERT Statements - in the SQLAlchemy Unified Tutorial
Parameters:
• table – TableClause which is the subject of the insert.
• values – collection of values to be inserted; see Insert.values() for a description of allowed formats here. Can be omitted entirely; a Insert construct will also dynamically render the VALUES clause at execution time based on the parameters passed to Connection.execute().
• inline – if True, no attempt will be made to retrieve the SQL-generated default values to be provided within the statement; in particular, this allows SQL expressions to be rendered ‘inline’ within the statement without the need to pre-execute them beforehand; for backends that support “returning”, this turns off the “implicit returning” feature for the statement.
If both insert.values and compile-time bind parameters are present, the compile-time bind parameters override the information specified within insert.values on a per-key basis.
The keys within Insert.values can be either Column objects or their string identifiers. Each key may reference one of:
• a literal data value (i.e. string, number, etc.);
• a Column object;
• a SELECT statement.
If a SELECT statement is specified which references this INSERT statement’s table, the statement will be correlated against the INSERT statement.
See also
Using INSERT Statements - in the SQLAlchemy Unified Tutorial
function sqlalchemy.sql.expression.update(table: _DMLTableArgument) → Update
Construct an Update object.
E.g.:
from sqlalchemy import update

stmt = (
    update(user_table).where(user_table.c.id == 5).values(name="user #5")
)
Similar functionality is available via the TableClause.update() method on Table.
Parameters:
table – A Table object representing the database table to be updated.
See also
Using UPDATE and DELETE Statements - in the SQLAlchemy Unified Tutorial
DML Class Documentation Constructors
Class documentation for the constructors listed at DML Foundational Constructors.
Object NameDescriptionDeleteRepresent a DELETE construct.InsertRepresent an INSERT construct.UpdateRepresent an Update construct.UpdateBaseForm the base for INSERT, UPDATE, and DELETE statements.ValuesBaseSupplies support for ValuesBase.values() to INSERT and UPDATE constructs.class sqlalchemy.sql.expression.Delete
Represent a DELETE construct.
The Delete object is created using the delete() function.
Members
where(), with_dialect_options(), returning()
Class signature
class sqlalchemy.sql.expression.Delete (sqlalchemy.sql.expression.DMLWhereBase, sqlalchemy.sql.expression.UpdateBase)
method sqlalchemy.sql.expression.Delete.where(*whereclause: _ColumnExpressionArgument[bool]) → Self
inherited from the DMLWhereBase.where() method of DMLWhereBase
Return a new construct with the given expression(s) added to its WHERE clause, joined to the existing clause via AND, if any.
Both Update.where() and Delete.where() support multiple-table forms, including database-specific UPDATE...FROM as well as DELETE..USING. For backends that don’t have multiple-table support, a backend agnostic approach to using multiple tables is to make use of correlated subqueries. See the linked tutorial sections below for examples.
See also
Correlated Updates
UPDATE..FROM
Multiple Table Deletes
method sqlalchemy.sql.expression.Delete.with_dialect_options(**opt: Any) → Self
inherited from the UpdateBase.with_dialect_options() method of UpdateBase
Add dialect options to this INSERT/UPDATE/DELETE object.
e.g.:
upd = table.update().dialect_options(mysql_limit=10)
method sqlalchemy.sql.expression.Delete.returning(*cols: _ColumnsClauseArgument[Any], sort_by_parameter_order: bool = False, **_UpdateBase__kw: Any) → UpdateBase
inherited from the UpdateBase.returning() method of UpdateBase
Add a RETURNING or equivalent clause to this statement.
e.g.:
>>> stmt = (
...     table.update()
...     .where(table.c.data == "value")
...     .values(status="X")
...     .returning(table.c.server_flag, table.c.updated_timestamp)
... )
>>> print(stmt)
UPDATE some_table SET status=:status
WHERE some_table.data = :data_1
RETURNING some_table.server_flag, some_table.updated_timestamp
The method may be invoked multiple times to add new entries to the list of expressions to be returned.
Added in version 1.4.0b2: The method may be invoked multiple times to add new entries to the list of expressions to be returned.
The given collection of column expressions should be derived from the table that is the target of the INSERT, UPDATE, or DELETE. While Column objects are typical, the elements can also be expressions:
>>> stmt = table.insert().returning(
...     (table.c.first_name + " " + table.c.last_name).label("fullname")
... )
>>> print(stmt)
INSERT INTO some_table (first_name, last_name)
VALUES (:first_name, :last_name)
RETURNING some_table.first_name || :first_name_1 || some_table.last_name AS fullname
Upon compilation, a RETURNING clause, or database equivalent, will be rendered within the statement. For INSERT and UPDATE, the values are the newly inserted/updated values. For DELETE, the values are those of the rows which were deleted.
Upon execution, the values of the columns to be returned are made available via the result set and can be iterated using CursorResult.fetchone() and similar. For DBAPIs which do not natively support returning values (i.e. cx_oracle), SQLAlchemy will approximate this behavior at the result level so that a reasonable amount of behavioral neutrality is provided.
Note that not all databases/DBAPIs support RETURNING. For those backends with no support, an exception is raised upon compilation and/or execution. For those who do support it, the functionality across backends varies greatly, including restrictions on executemany() and other statements which return multiple rows. Please read the documentation notes for the database in use in order to determine the availability of RETURNING.
Parameters:
• *cols – series of columns, SQL expressions, or whole tables entities to be returned.
• sort_by_parameter_order – 
for a batch INSERT that is being executed against multiple parameter sets, organize the results of RETURNING so that the returned rows correspond to the order of parameter sets passed in. This applies only to an executemany execution for supporting dialects and typically makes use of the insertmanyvalues feature.
Added in version 2.0.10.
See also
Correlating RETURNING rows to parameter sets - background on sorting of RETURNING rows for bulk INSERT (Core level discussion)
Correlating RETURNING records with input data order - example of use with ORM Bulk INSERT Statements (ORM level discussion)
See also
UpdateBase.return_defaults() - an alternative method tailored towards efficient fetching of server-side defaults and triggers for single-row INSERTs or UPDATEs.
INSERT…RETURNING - in the SQLAlchemy Unified Tutorial
class sqlalchemy.sql.expression.Insert
Represent an INSERT construct.
The Insert object is created using the insert() function.
Members
with_dialect_options(), values(), returning(), from_select(), inline(), select
Class signature
class sqlalchemy.sql.expression.Insert (sqlalchemy.sql.expression.ValuesBase)
method sqlalchemy.sql.expression.Insert.with_dialect_options(**opt: Any) → Self
inherited from the UpdateBase.with_dialect_options() method of UpdateBase
Add dialect options to this INSERT/UPDATE/DELETE object.
e.g.:
upd = table.update().dialect_options(mysql_limit=10)
method sqlalchemy.sql.expression.Insert.values(*args: _DMLColumnKeyMapping[Any] | Sequence[Any], **kwargs: Any) → Self
inherited from the ValuesBase.values() method of ValuesBase
Specify a fixed VALUES clause for an INSERT statement, or the SET clause for an UPDATE.
Note that the Insert and Update constructs support per-execution time formatting of the VALUES and/or SET clauses, based on the arguments passed to Connection.execute(). However, the ValuesBase.values() method can be used to “fix” a particular set of parameters into the statement.
Multiple calls to ValuesBase.values() will produce a new construct, each one with the parameter list modified to include the new parameters sent. In the typical case of a single dictionary of parameters, the newly passed keys will replace the same keys in the previous construct. In the case of a list-based “multiple values” construct, each new list of values is extended onto the existing list of values.
Parameters:
• **kwargs – 
key value pairs representing the string key of a Column mapped to the value to be rendered into the VALUES or SET clause:
users.insert().values(name="some name")

users.update().where(users.c.id == 5).values(name="some name")
•  •  *args – 
As an alternative to passing key/value parameters, a dictionary, tuple, or list of dictionaries or tuples can be passed as a single positional argument in order to form the VALUES or SET clause of the statement. The forms that are accepted vary based on whether this is an Insert or an Update construct.
For either an Insert or Update construct, a single dictionary can be passed, which works the same as that of the kwargs form:
users.insert().values({"name": "some name"})

users.update().values({"name": "some new name"})
Also for either form but more typically for the Insert construct, a tuple that contains an entry for every column in the table is also accepted:
users.insert().values((5, "some name"))
The Insert construct also supports being passed a list of dictionaries or full-table-tuples, which on the server will render the less common SQL syntax of “multiple values” - this syntax is supported on backends such as SQLite, PostgreSQL, MySQL, but not necessarily others:
users.insert().values(
    [
        {"name": "some name"},
        {"name": "some other name"},
        {"name": "yet another name"},
    ]
)
The above form would render a multiple VALUES statement similar to:
INSERT INTO users (name) VALUES
                (:name_1),
                (:name_2),
                (:name_3)
• It is essential to note that passing multiple values is NOT the same as using traditional executemany() form. The above syntax is a special syntax not typically used. To emit an INSERT statement against multiple rows, the normal method is to pass a multiple values list to the Connection.execute() method, which is supported by all database backends and is generally more efficient for a very large number of parameters.
See also
Sending Multiple Parameters - an introduction to the traditional Core method of multiple parameter set invocation for INSERTs and other statements.
The UPDATE construct also supports rendering the SET parameters in a specific order. For this feature refer to the Update.ordered_values() method.
See also
Update.ordered_values()
method sqlalchemy.sql.expression.Insert.returning(*cols: _ColumnsClauseArgument[Any], sort_by_parameter_order: bool = False, **_UpdateBase__kw: Any) → UpdateBase
inherited from the UpdateBase.returning() method of UpdateBase
Add a RETURNING or equivalent clause to this statement.
e.g.:
>>> stmt = (
...     table.update()
...     .where(table.c.data == "value")
...     .values(status="X")
...     .returning(table.c.server_flag, table.c.updated_timestamp)
... )
>>> print(stmt)
UPDATE some_table SET status=:status
WHERE some_table.data = :data_1
RETURNING some_table.server_flag, some_table.updated_timestamp
The method may be invoked multiple times to add new entries to the list of expressions to be returned.
Added in version 1.4.0b2: The method may be invoked multiple times to add new entries to the list of expressions to be returned.
The given collection of column expressions should be derived from the table that is the target of the INSERT, UPDATE, or DELETE. While Column objects are typical, the elements can also be expressions:
>>> stmt = table.insert().returning(
...     (table.c.first_name + " " + table.c.last_name).label("fullname")
... )
>>> print(stmt)
INSERT INTO some_table (first_name, last_name)
VALUES (:first_name, :last_name)
RETURNING some_table.first_name || :first_name_1 || some_table.last_name AS fullname
Upon compilation, a RETURNING clause, or database equivalent, will be rendered within the statement. For INSERT and UPDATE, the values are the newly inserted/updated values. For DELETE, the values are those of the rows which were deleted.
Upon execution, the values of the columns to be returned are made available via the result set and can be iterated using CursorResult.fetchone() and similar. For DBAPIs which do not natively support returning values (i.e. cx_oracle), SQLAlchemy will approximate this behavior at the result level so that a reasonable amount of behavioral neutrality is provided.
Note that not all databases/DBAPIs support RETURNING. For those backends with no support, an exception is raised upon compilation and/or execution. For those who do support it, the functionality across backends varies greatly, including restrictions on executemany() and other statements which return multiple rows. Please read the documentation notes for the database in use in order to determine the availability of RETURNING.
Parameters:
• *cols – series of columns, SQL expressions, or whole tables entities to be returned.
• sort_by_parameter_order – 
for a batch INSERT that is being executed against multiple parameter sets, organize the results of RETURNING so that the returned rows correspond to the order of parameter sets passed in. This applies only to an executemany execution for supporting dialects and typically makes use of the insertmanyvalues feature.
Added in version 2.0.10.
See also
Correlating RETURNING rows to parameter sets - background on sorting of RETURNING rows for bulk INSERT (Core level discussion)
Correlating RETURNING records with input data order - example of use with ORM Bulk INSERT Statements (ORM level discussion)
See also
UpdateBase.return_defaults() - an alternative method tailored towards efficient fetching of server-side defaults and triggers for single-row INSERTs or UPDATEs.
INSERT…RETURNING - in the SQLAlchemy Unified Tutorial
method sqlalchemy.sql.expression.Insert.from_select(names: Sequence[_DMLColumnArgument], select: Selectable, include_defaults: bool = True) → Self
Return a new Insert construct which represents an INSERT...FROM SELECT statement.
e.g.:
sel = select(table1.c.a, table1.c.b).where(table1.c.c > 5)
ins = table2.insert().from_select(["a", "b"], sel)
Parameters:
• names – a sequence of string column names or Column objects representing the target columns.
• select – a select() construct, FromClause or other construct which resolves into a FromClause, such as an ORM Query object, etc. The order of columns returned from this FROM clause should correspond to the order of columns sent as the names parameter; while this is not checked before passing along to the database, the database would normally raise an exception if these column lists don’t correspond.
• include_defaults – 
if True, non-server default values and SQL expressions as specified on Column objects (as documented in Column INSERT/UPDATE Defaults) not otherwise specified in the list of names will be rendered into the INSERT and SELECT statements, so that these values are also included in the data to be inserted.
Note
A Python-side default that uses a Python callable function will only be invoked once for the whole statement, and not per row.
method sqlalchemy.sql.expression.Insert.inline() → Self
Make this Insert construct “inline” .
When set, no attempt will be made to retrieve the SQL-generated default values to be provided within the statement; in particular, this allows SQL expressions to be rendered ‘inline’ within the statement without the need to pre-execute them beforehand; for backends that support “returning”, this turns off the “implicit returning” feature for the statement.
Changed in version 1.4: the Insert.inline parameter is now superseded by the Insert.inline() method.
attribute sqlalchemy.sql.expression.Insert.select: Select[Any] | None = None
SELECT statement for INSERT .. FROM SELECT
class sqlalchemy.sql.expression.Update
Represent an Update construct.
The Update object is created using the update() function.
Members
returning(), where(), with_dialect_options(), values(), inline(), ordered_values()
Class signature
class sqlalchemy.sql.expression.Update (sqlalchemy.sql.expression.DMLWhereBase, sqlalchemy.sql.expression.ValuesBase)
method sqlalchemy.sql.expression.Update.returning(*cols: _ColumnsClauseArgument[Any], sort_by_parameter_order: bool = False, **_UpdateBase__kw: Any) → UpdateBase
inherited from the UpdateBase.returning() method of UpdateBase
Add a RETURNING or equivalent clause to this statement.
e.g.:
>>> stmt = (
...     table.update()
...     .where(table.c.data == "value")
...     .values(status="X")
...     .returning(table.c.server_flag, table.c.updated_timestamp)
... )
>>> print(stmt)
UPDATE some_table SET status=:status
WHERE some_table.data = :data_1
RETURNING some_table.server_flag, some_table.updated_timestamp
The method may be invoked multiple times to add new entries to the list of expressions to be returned.
Added in version 1.4.0b2: The method may be invoked multiple times to add new entries to the list of expressions to be returned.
The given collection of column expressions should be derived from the table that is the target of the INSERT, UPDATE, or DELETE. While Column objects are typical, the elements can also be expressions:
>>> stmt = table.insert().returning(
...     (table.c.first_name + " " + table.c.last_name).label("fullname")
... )
>>> print(stmt)
INSERT INTO some_table (first_name, last_name)
VALUES (:first_name, :last_name)
RETURNING some_table.first_name || :first_name_1 || some_table.last_name AS fullname
Upon compilation, a RETURNING clause, or database equivalent, will be rendered within the statement. For INSERT and UPDATE, the values are the newly inserted/updated values. For DELETE, the values are those of the rows which were deleted.
Upon execution, the values of the columns to be returned are made available via the result set and can be iterated using CursorResult.fetchone() and similar. For DBAPIs which do not natively support returning values (i.e. cx_oracle), SQLAlchemy will approximate this behavior at the result level so that a reasonable amount of behavioral neutrality is provided.
Note that not all databases/DBAPIs support RETURNING. For those backends with no support, an exception is raised upon compilation and/or execution. For those who do support it, the functionality across backends varies greatly, including restrictions on executemany() and other statements which return multiple rows. Please read the documentation notes for the database in use in order to determine the availability of RETURNING.
Parameters:
• *cols – series of columns, SQL expressions, or whole tables entities to be returned.
• sort_by_parameter_order – 
for a batch INSERT that is being executed against multiple parameter sets, organize the results of RETURNING so that the returned rows correspond to the order of parameter sets passed in. This applies only to an executemany execution for supporting dialects and typically makes use of the insertmanyvalues feature.
Added in version 2.0.10.
See also
Correlating RETURNING rows to parameter sets - background on sorting of RETURNING rows for bulk INSERT (Core level discussion)
Correlating RETURNING records with input data order - example of use with ORM Bulk INSERT Statements (ORM level discussion)
See also
UpdateBase.return_defaults() - an alternative method tailored towards efficient fetching of server-side defaults and triggers for single-row INSERTs or UPDATEs.
INSERT…RETURNING - in the SQLAlchemy Unified Tutorial
method sqlalchemy.sql.expression.Update.where(*whereclause: _ColumnExpressionArgument[bool]) → Self
inherited from the DMLWhereBase.where() method of DMLWhereBase
Return a new construct with the given expression(s) added to its WHERE clause, joined to the existing clause via AND, if any.
Both Update.where() and Delete.where() support multiple-table forms, including database-specific UPDATE...FROM as well as DELETE..USING. For backends that don’t have multiple-table support, a backend agnostic approach to using multiple tables is to make use of correlated subqueries. See the linked tutorial sections below for examples.
See also
Correlated Updates
UPDATE..FROM
Multiple Table Deletes
method sqlalchemy.sql.expression.Update.with_dialect_options(**opt: Any) → Self
inherited from the UpdateBase.with_dialect_options() method of UpdateBase
Add dialect options to this INSERT/UPDATE/DELETE object.
e.g.:
upd = table.update().dialect_options(mysql_limit=10)
method sqlalchemy.sql.expression.Update.values(*args: _DMLColumnKeyMapping[Any] | Sequence[Any], **kwargs: Any) → Self
inherited from the ValuesBase.values() method of ValuesBase
Specify a fixed VALUES clause for an INSERT statement, or the SET clause for an UPDATE.
Note that the Insert and Update constructs support per-execution time formatting of the VALUES and/or SET clauses, based on the arguments passed to Connection.execute(). However, the ValuesBase.values() method can be used to “fix” a particular set of parameters into the statement.
Multiple calls to ValuesBase.values() will produce a new construct, each one with the parameter list modified to include the new parameters sent. In the typical case of a single dictionary of parameters, the newly passed keys will replace the same keys in the previous construct. In the case of a list-based “multiple values” construct, each new list of values is extended onto the existing list of values.
Parameters:
• **kwargs – 
key value pairs representing the string key of a Column mapped to the value to be rendered into the VALUES or SET clause:
users.insert().values(name="some name")

users.update().where(users.c.id == 5).values(name="some name")
•  •  *args – 
As an alternative to passing key/value parameters, a dictionary, tuple, or list of dictionaries or tuples can be passed as a single positional argument in order to form the VALUES or SET clause of the statement. The forms that are accepted vary based on whether this is an Insert or an Update construct.
For either an Insert or Update construct, a single dictionary can be passed, which works the same as that of the kwargs form:
users.insert().values({"name": "some name"})

users.update().values({"name": "some new name"})
Also for either form but more typically for the Insert construct, a tuple that contains an entry for every column in the table is also accepted:
users.insert().values((5, "some name"))
The Insert construct also supports being passed a list of dictionaries or full-table-tuples, which on the server will render the less common SQL syntax of “multiple values” - this syntax is supported on backends such as SQLite, PostgreSQL, MySQL, but not necessarily others:
users.insert().values(
    [
        {"name": "some name"},
        {"name": "some other name"},
        {"name": "yet another name"},
    ]
)
The above form would render a multiple VALUES statement similar to:
INSERT INTO users (name) VALUES
                (:name_1),
                (:name_2),
                (:name_3)
• It is essential to note that passing multiple values is NOT the same as using traditional executemany() form. The above syntax is a special syntax not typically used. To emit an INSERT statement against multiple rows, the normal method is to pass a multiple values list to the Connection.execute() method, which is supported by all database backends and is generally more efficient for a very large number of parameters.
See also
Sending Multiple Parameters - an introduction to the traditional Core method of multiple parameter set invocation for INSERTs and other statements.
The UPDATE construct also supports rendering the SET parameters in a specific order. For this feature refer to the Update.ordered_values() method.
See also
Update.ordered_values()
method sqlalchemy.sql.expression.Update.inline() → Self
Make this Update construct “inline” .
When set, SQL defaults present on Column objects via the default keyword will be compiled ‘inline’ into the statement and not pre-executed. This means that their values will not be available in the dictionary returned from CursorResult.last_updated_params().
Changed in version 1.4: the update.inline parameter is now superseded by the Update.inline() method.
method sqlalchemy.sql.expression.Update.ordered_values(*args: Tuple[_DMLColumnArgument, Any]) → Self
Specify the VALUES clause of this UPDATE statement with an explicit parameter ordering that will be maintained in the SET clause of the resulting UPDATE statement.
E.g.:
stmt = table.update().ordered_values(("name", "ed"), ("ident", "foo"))
See also
Parameter Ordered Updates - full example of the Update.ordered_values() method.
Changed in version 1.4: The Update.ordered_values() method supersedes the update.preserve_parameter_order parameter, which will be removed in SQLAlchemy 2.0.
class sqlalchemy.sql.expression.UpdateBase
Form the base for INSERT, UPDATE, and DELETE statements.
Members
entity_description, exported_columns, is_derived_from(), params(), return_defaults(), returning(), returning_column_descriptions, with_dialect_options(), with_hint()
Class signature
class sqlalchemy.sql.expression.UpdateBase (sqlalchemy.sql.roles.DMLRole, sqlalchemy.sql.expression.HasCTE, sqlalchemy.sql.expression.HasCompileState, sqlalchemy.sql.expression.DialectKWArgs, sqlalchemy.sql.expression.HasPrefixes, sqlalchemy.sql.expression.Generative, sqlalchemy.sql.expression.ExecutableReturnsRows, sqlalchemy.sql.expression.ClauseElement)
attribute sqlalchemy.sql.expression.UpdateBase.entity_description
Return a plugin-enabled description of the table and/or entity which this DML construct is operating against.
This attribute is generally useful when using the ORM, as an extended structure which includes information about mapped entities is returned. The section Inspecting entities and columns from ORM-enabled SELECT and DML statements contains more background.
For a Core statement, the structure returned by this accessor is derived from the UpdateBase.table attribute, and refers to the Table being inserted, updated, or deleted:
>>> stmt = insert(user_table)
>>> stmt.entity_description
{
    "name": "user_table",
    "table": Table("user_table", ...)
}
Added in version 1.4.33.
See also
UpdateBase.returning_column_descriptions
Select.column_descriptions - entity information for a select() construct
Inspecting entities and columns from ORM-enabled SELECT and DML statements - ORM background
attribute sqlalchemy.sql.expression.UpdateBase.exported_columns
Return the RETURNING columns as a column collection for this statement.
Added in version 1.4.
method sqlalchemy.sql.expression.UpdateBase.is_derived_from(fromclause: FromClause | None) → bool
Return True if this ReturnsRows is ‘derived’ from the given FromClause.
Since these are DMLs, we dont want such statements ever being adapted so we return False for derives.
method sqlalchemy.sql.expression.UpdateBase.params(*arg: Any, **kw: Any) → NoReturn
Set the parameters for the statement.
This method raises NotImplementedError on the base class, and is overridden by ValuesBase to provide the SET/VALUES clause of UPDATE and INSERT.
method sqlalchemy.sql.expression.UpdateBase.return_defaults(*cols: _DMLColumnArgument, supplemental_cols: Iterable[_DMLColumnArgument] | None = None, sort_by_parameter_order: bool = False) → Self
Make use of a RETURNING clause for the purpose of fetching server-side expressions and defaults, for supporting backends only.
Deep Alchemy
The UpdateBase.return_defaults() method is used by the ORM for its internal work in fetching newly generated primary key and server default values, in particular to provide the underyling implementation of the Mapper.eager_defaults ORM feature as well as to allow RETURNING support with bulk ORM inserts. Its behavior is fairly idiosyncratic and is not really intended for general use. End users should stick with using UpdateBase.returning() in order to add RETURNING clauses to their INSERT, UPDATE and DELETE statements.
Normally, a single row INSERT statement will automatically populate the CursorResult.inserted_primary_key attribute when executed, which stores the primary key of the row that was just inserted in the form of a Row object with column names as named tuple keys (and the Row._mapping view fully populated as well). The dialect in use chooses the strategy to use in order to populate this data; if it was generated using server-side defaults and / or SQL expressions, dialect-specific approaches such as cursor.lastrowid or RETURNING are typically used to acquire the new primary key value.
However, when the statement is modified by calling UpdateBase.return_defaults() before executing the statement, additional behaviors take place only for backends that support RETURNING and for Table objects that maintain the Table.implicit_returning parameter at its default value of True. In these cases, when the CursorResult is returned from the statement’s execution, not only will CursorResult.inserted_primary_key be populated as always, the CursorResult.returned_defaults attribute will also be populated with a Row named-tuple representing the full range of server generated values from that single row, including values for any columns that specify Column.server_default or which make use of Column.default using a SQL expression.
When invoking INSERT statements with multiple rows using insertmanyvalues, the UpdateBase.return_defaults() modifier will have the effect of the CursorResult.inserted_primary_key_rows and CursorResult.returned_defaults_rows attributes being fully populated with lists of Row objects representing newly inserted primary key values as well as newly inserted server generated values for each row inserted. The CursorResult.inserted_primary_key and CursorResult.returned_defaults attributes will also continue to be populated with the first row of these two collections.
If the backend does not support RETURNING or the Table in use has disabled Table.implicit_returning, then no RETURNING clause is added and no additional data is fetched, however the INSERT, UPDATE or DELETE statement proceeds normally.
E.g.:
stmt = table.insert().values(data="newdata").return_defaults()

result = connection.execute(stmt)

server_created_at = result.returned_defaults["created_at"]
When used against an UPDATE statement UpdateBase.return_defaults() instead looks for columns that include Column.onupdate or Column.server_onupdate parameters assigned, when constructing the columns that will be included in the RETURNING clause by default if explicit columns were not specified. When used against a DELETE statement, no columns are included in RETURNING by default, they instead must be specified explicitly as there are no columns that normally change values when a DELETE statement proceeds.
Added in version 2.0: UpdateBase.return_defaults() is supported for DELETE statements also and has been moved from ValuesBase to UpdateBase.
The UpdateBase.return_defaults() method is mutually exclusive against the UpdateBase.returning() method and errors will be raised during the SQL compilation process if both are used at the same time on one statement. The RETURNING clause of the INSERT, UPDATE or DELETE statement is therefore controlled by only one of these methods at a time.
The UpdateBase.return_defaults() method differs from UpdateBase.returning() in these ways:
1. UpdateBase.return_defaults() method causes the CursorResult.returned_defaults collection to be populated with the first row from the RETURNING result. This attribute is not populated when using UpdateBase.returning().
2. UpdateBase.return_defaults() is compatible with existing logic used to fetch auto-generated primary key values that are then populated into the CursorResult.inserted_primary_key attribute. By contrast, using UpdateBase.returning() will have the effect of the CursorResult.inserted_primary_key attribute being left unpopulated.
3. UpdateBase.return_defaults() can be called against any backend. Backends that don’t support RETURNING will skip the usage of the feature, rather than raising an exception, unless supplemental_cols is passed. The return value of CursorResult.returned_defaults will be None for backends that don’t support RETURNING or for which the target Table sets Table.implicit_returning to False.
4. An INSERT statement invoked with executemany() is supported if the backend database driver supports the insertmanyvalues feature which is now supported by most SQLAlchemy-included backends. When executemany is used, the CursorResult.returned_defaults_rows and CursorResult.inserted_primary_key_rows accessors will return the inserted defaults and primary keys.
Added in version 1.4: Added CursorResult.returned_defaults_rows and CursorResult.inserted_primary_key_rows accessors. In version 2.0, the underlying implementation which fetches and populates the data for these attributes was generalized to be supported by most backends, whereas in 1.4 they were only supported by the psycopg2 driver.
Parameters:
• cols – optional list of column key names or Column that acts as a filter for those columns that will be fetched.
• supplemental_cols – 
optional list of RETURNING expressions, in the same form as one would pass to the UpdateBase.returning() method. When present, the additional columns will be included in the RETURNING clause, and the CursorResult object will be “rewound” when returned, so that methods like CursorResult.all() will return new rows mostly as though the statement used UpdateBase.returning() directly. However, unlike when using UpdateBase.returning() directly, the order of the columns is undefined, so can only be targeted using names or Row._mapping keys; they cannot reliably be targeted positionally.
Added in version 2.0.
• sort_by_parameter_order – 
for a batch INSERT that is being executed against multiple parameter sets, organize the results of RETURNING so that the returned rows correspond to the order of parameter sets passed in. This applies only to an executemany execution for supporting dialects and typically makes use of the insertmanyvalues feature.
Added in version 2.0.10.
See also
Correlating RETURNING rows to parameter sets - background on sorting of RETURNING rows for bulk INSERT
See also
UpdateBase.returning()
CursorResult.returned_defaults
CursorResult.returned_defaults_rows
CursorResult.inserted_primary_key
CursorResult.inserted_primary_key_rows
method sqlalchemy.sql.expression.UpdateBase.returning(*cols: _ColumnsClauseArgument[Any], sort_by_parameter_order: bool = False, **_UpdateBase__kw: Any) → UpdateBase
Add a RETURNING or equivalent clause to this statement.
e.g.:
>>> stmt = (
...     table.update()
...     .where(table.c.data == "value")
...     .values(status="X")
...     .returning(table.c.server_flag, table.c.updated_timestamp)
... )
>>> print(stmt)
UPDATE some_table SET status=:status
WHERE some_table.data = :data_1
RETURNING some_table.server_flag, some_table.updated_timestamp
The method may be invoked multiple times to add new entries to the list of expressions to be returned.
Added in version 1.4.0b2: The method may be invoked multiple times to add new entries to the list of expressions to be returned.
The given collection of column expressions should be derived from the table that is the target of the INSERT, UPDATE, or DELETE. While Column objects are typical, the elements can also be expressions:
>>> stmt = table.insert().returning(
...     (table.c.first_name + " " + table.c.last_name).label("fullname")
... )
>>> print(stmt)
INSERT INTO some_table (first_name, last_name)
VALUES (:first_name, :last_name)
RETURNING some_table.first_name || :first_name_1 || some_table.last_name AS fullname
Upon compilation, a RETURNING clause, or database equivalent, will be rendered within the statement. For INSERT and UPDATE, the values are the newly inserted/updated values. For DELETE, the values are those of the rows which were deleted.
Upon execution, the values of the columns to be returned are made available via the result set and can be iterated using CursorResult.fetchone() and similar. For DBAPIs which do not natively support returning values (i.e. cx_oracle), SQLAlchemy will approximate this behavior at the result level so that a reasonable amount of behavioral neutrality is provided.
Note that not all databases/DBAPIs support RETURNING. For those backends with no support, an exception is raised upon compilation and/or execution. For those who do support it, the functionality across backends varies greatly, including restrictions on executemany() and other statements which return multiple rows. Please read the documentation notes for the database in use in order to determine the availability of RETURNING.
Parameters:
• *cols – series of columns, SQL expressions, or whole tables entities to be returned.
• sort_by_parameter_order – 
for a batch INSERT that is being executed against multiple parameter sets, organize the results of RETURNING so that the returned rows correspond to the order of parameter sets passed in. This applies only to an executemany execution for supporting dialects and typically makes use of the insertmanyvalues feature.
Added in version 2.0.10.
See also
Correlating RETURNING rows to parameter sets - background on sorting of RETURNING rows for bulk INSERT (Core level discussion)
Correlating RETURNING records with input data order - example of use with ORM Bulk INSERT Statements (ORM level discussion)
See also
UpdateBase.return_defaults() - an alternative method tailored towards efficient fetching of server-side defaults and triggers for single-row INSERTs or UPDATEs.
INSERT…RETURNING - in the SQLAlchemy Unified Tutorial
attribute sqlalchemy.sql.expression.UpdateBase.returning_column_descriptions
Return a plugin-enabled description of the columns which this DML construct is RETURNING against, in other words the expressions established as part of UpdateBase.returning().
This attribute is generally useful when using the ORM, as an extended structure which includes information about mapped entities is returned. The section Inspecting entities and columns from ORM-enabled SELECT and DML statements contains more background.
For a Core statement, the structure returned by this accessor is derived from the same objects that are returned by the UpdateBase.exported_columns accessor:
>>> stmt = insert(user_table).returning(user_table.c.id, user_table.c.name)
>>> stmt.entity_description
[
    {
        "name": "id",
        "type": Integer,
        "expr": Column("id", Integer(), table=<user>, ...)
    },
    {
        "name": "name",
        "type": String(),
        "expr": Column("name", String(), table=<user>, ...)
    },
]
Added in version 1.4.33.
See also
UpdateBase.entity_description
Select.column_descriptions - entity information for a select() construct
Inspecting entities and columns from ORM-enabled SELECT and DML statements - ORM background
method sqlalchemy.sql.expression.UpdateBase.with_dialect_options(**opt: Any) → Self
Add dialect options to this INSERT/UPDATE/DELETE object.
e.g.:
upd = table.update().dialect_options(mysql_limit=10)
method sqlalchemy.sql.expression.UpdateBase.with_hint(text: str, selectable: _DMLTableArgument | None = None, dialect_name: str = '*') → Self
Add a table hint for a single table to this INSERT/UPDATE/DELETE statement.
Note
UpdateBase.with_hint() currently applies only to Microsoft SQL Server. For MySQL INSERT/UPDATE/DELETE hints, use UpdateBase.prefix_with().
The text of the hint is rendered in the appropriate location for the database backend in use, relative to the Table that is the subject of this statement, or optionally to that of the given Table passed as the selectable argument.
The dialect_name option will limit the rendering of a particular hint to a particular backend. Such as, to add a hint that only takes effect for SQL Server:
mytable.insert().with_hint("WITH (PAGLOCK)", dialect_name="mssql")
Parameters:
• text – Text of the hint.
• selectable – optional Table that specifies an element of the FROM clause within an UPDATE or DELETE to be the subject of the hint - applies only to certain backends.
• dialect_name – defaults to *, if specified as the name of a particular dialect, will apply these hints only when that dialect is in use.
class sqlalchemy.sql.expression.ValuesBase
Supplies support for ValuesBase.values() to INSERT and UPDATE constructs.
Members
select, values()
Class signature
class sqlalchemy.sql.expression.ValuesBase (sqlalchemy.sql.expression.UpdateBase)
attribute sqlalchemy.sql.expression.ValuesBase.select: Select[Any] | None = None
SELECT statement for INSERT .. FROM SELECT
method sqlalchemy.sql.expression.ValuesBase.values(*args: _DMLColumnKeyMapping[Any] | Sequence[Any], **kwargs: Any) → Self
Specify a fixed VALUES clause for an INSERT statement, or the SET clause for an UPDATE.
Note that the Insert and Update constructs support per-execution time formatting of the VALUES and/or SET clauses, based on the arguments passed to Connection.execute(). However, the ValuesBase.values() method can be used to “fix” a particular set of parameters into the statement.
Multiple calls to ValuesBase.values() will produce a new construct, each one with the parameter list modified to include the new parameters sent. In the typical case of a single dictionary of parameters, the newly passed keys will replace the same keys in the previous construct. In the case of a list-based “multiple values” construct, each new list of values is extended onto the existing list of values.
Parameters:
• **kwargs – 
key value pairs representing the string key of a Column mapped to the value to be rendered into the VALUES or SET clause:
users.insert().values(name="some name")

users.update().where(users.c.id == 5).values(name="some name")
•  •  *args – 
As an alternative to passing key/value parameters, a dictionary, tuple, or list of dictionaries or tuples can be passed as a single positional argument in order to form the VALUES or SET clause of the statement. The forms that are accepted vary based on whether this is an Insert or an Update construct.
For either an Insert or Update construct, a single dictionary can be passed, which works the same as that of the kwargs form:
users.insert().values({"name": "some name"})

users.update().values({"name": "some new name"})
Also for either form but more typically for the Insert construct, a tuple that contains an entry for every column in the table is also accepted:
users.insert().values((5, "some name"))
The Insert construct also supports being passed a list of dictionaries or full-table-tuples, which on the server will render the less common SQL syntax of “multiple values” - this syntax is supported on backends such as SQLite, PostgreSQL, MySQL, but not necessarily others:
users.insert().values(
    [
        {"name": "some name"},
        {"name": "some other name"},
        {"name": "yet another name"},
    ]
)
The above form would render a multiple VALUES statement similar to:
INSERT INTO users (name) VALUES
                (:name_1),
                (:name_2),
                (:name_3)
• It is essential to note that passing multiple values is NOT the same as using traditional executemany() form. The above syntax is a special syntax not typically used. To emit an INSERT statement against multiple rows, the normal method is to pass a multiple values list to the Connection.execute() method, which is supported by all database backends and is generally more efficient for a very large number of parameters.
See also
Sending Multiple Parameters - an introduction to the traditional Core method of multiple parameter set invocation for INSERTs and other statements.
The UPDATE construct also supports rendering the SET parameters in a specific order. For this feature refer to the Update.ordered_values() method.
See also
Update.ordered_values()


SQL and Generic Functions
SQL functions are invoked by using the func namespace. See the tutorial at Working with SQL Functions for background on how to use the func object to render SQL functions in statements.
See also
Working with SQL Functions - in the SQLAlchemy Unified Tutorial
Function API
The base API for SQL functions, which provides for the func namespace as well as classes that may be used for extensibility.
Object NameDescriptionAnsiFunctionDefine a function in “ansi” format, which doesn’t render parenthesis.FunctionDescribe a named SQL function.FunctionElementBase for SQL function-oriented constructs.GenericFunctionDefine a ‘generic’ function.register_function(identifier, fn[, package])Associate a callable with a particular func. name.class sqlalchemy.sql.functions.AnsiFunction
Define a function in “ansi” format, which doesn’t render parenthesis.
Class signature
class sqlalchemy.sql.functions.AnsiFunction (sqlalchemy.sql.functions.GenericFunction)
class sqlalchemy.sql.functions.Function
Describe a named SQL function.
The Function object is typically generated from the func generation object.
Parameters:
• *clauses – list of column expressions that form the arguments of the SQL function call.
• type_ – optional TypeEngine datatype object that will be used as the return value of the column expression generated by this function call.
• packagenames – 
a string which indicates package prefix names to be prepended to the function name when the SQL is generated. The func generator creates these when it is called using dotted format, e.g.:
func.mypackage.some_function(col1, col2)
• 
See also
Working with SQL Functions - in the SQLAlchemy Unified Tutorial
func - namespace which produces registered or ad-hoc Function instances.
GenericFunction - allows creation of registered function types.
Members
__init__()
Class signature
class sqlalchemy.sql.functions.Function (sqlalchemy.sql.functions.FunctionElement)
method sqlalchemy.sql.functions.Function.__init__(name: str, *clauses: _ColumnExpressionOrLiteralArgument[Any], type_: _TypeEngineArgument[_T] | None = None, packagenames: Tuple[str, ...] | None = None) → None
Construct a Function.
The func construct is normally used to construct new Function instances.
class sqlalchemy.sql.functions.FunctionElement
Base for SQL function-oriented constructs.
This is a generic type, meaning that type checkers and IDEs can be instructed on the types to expect in a Result for this function. See GenericFunction for an example of how this is done.
See also
Working with SQL Functions - in the SQLAlchemy Unified Tutorial
Function - named SQL function.
func - namespace which produces registered or ad-hoc Function instances.
GenericFunction - allows creation of registered function types.
Members
__init__(), alias(), as_comparison(), c, clauses, column_valued(), columns, entity_namespace, exported_columns, filter(), over(), scalar_table_valued(), select(), self_group(), table_valued(), within_group(), within_group_type()
Class signature
class sqlalchemy.sql.functions.FunctionElement (sqlalchemy.sql.expression.Executable, sqlalchemy.sql.expression.ColumnElement, sqlalchemy.sql.expression.FromClause, sqlalchemy.sql.expression.Generative)
method sqlalchemy.sql.functions.FunctionElement.__init__(*clauses: _ColumnExpressionOrLiteralArgument[Any]) → None
Construct a FunctionElement.
Parameters:
• *clauses – list of column expressions that form the arguments of the SQL function call.
• **kwargs – additional kwargs are typically consumed by subclasses.
See also
func
Function
method sqlalchemy.sql.functions.FunctionElement.alias(name: str | None = None, joins_implicitly: bool = False) → TableValuedAlias
Produce a Alias construct against this FunctionElement.
Tip
The FunctionElement.alias() method is part of the mechanism by which “table valued” SQL functions are created. However, most use cases are covered by higher level methods on FunctionElement including FunctionElement.table_valued(), and FunctionElement.column_valued().
This construct wraps the function in a named alias which is suitable for the FROM clause, in the style accepted for example by PostgreSQL. A column expression is also provided using the special .column attribute, which may be used to refer to the output of the function as a scalar value in the columns or where clause, for a backend such as PostgreSQL.
For a full table-valued expression, use the FunctionElement.table_valued() method first to establish named columns.
e.g.:
>>> from sqlalchemy import func, select, column
>>> data_view = func.unnest([1, 2, 3]).alias("data_view")
>>> print(select(data_view.column))
SELECT data_view
FROM unnest(:unnest_1) AS data_view
The FunctionElement.column_valued() method provides a shortcut for the above pattern:
>>> data_view = func.unnest([1, 2, 3]).column_valued("data_view")
>>> print(select(data_view))
SELECT data_view
FROM unnest(:unnest_1) AS data_view
Added in version 1.4.0b2: Added the .column accessor
Parameters:
• name – alias name, will be rendered as AS <name> in the FROM clause
• joins_implicitly – 
when True, the table valued function may be used in the FROM clause without any explicit JOIN to other tables in the SQL query, and no “cartesian product” warning will be generated. May be useful for SQL functions such as func.json_each().
Added in version 1.4.33.
See also
Table-Valued Functions - in the SQLAlchemy Unified Tutorial
FunctionElement.table_valued()
FunctionElement.scalar_table_valued()
FunctionElement.column_valued()
method sqlalchemy.sql.functions.FunctionElement.as_comparison(left_index: int, right_index: int) → FunctionAsBinary
Interpret this expression as a boolean comparison between two values.
This method is used for an ORM use case described at Custom operators based on SQL functions.
A hypothetical SQL function “is_equal()” which compares to values for equality would be written in the Core expression language as:
expr = func.is_equal("a", "b")
If “is_equal()” above is comparing “a” and “b” for equality, the FunctionElement.as_comparison() method would be invoked as:
expr = func.is_equal("a", "b").as_comparison(1, 2)
Where above, the integer value “1” refers to the first argument of the “is_equal()” function and the integer value “2” refers to the second.
This would create a BinaryExpression that is equivalent to:
BinaryExpression("a", "b", operator=op.eq)
However, at the SQL level it would still render as “is_equal(‘a’, ‘b’)”.
The ORM, when it loads a related object or collection, needs to be able to manipulate the “left” and “right” sides of the ON clause of a JOIN expression. The purpose of this method is to provide a SQL function construct that can also supply this information to the ORM, when used with the relationship.primaryjoin parameter. The return value is a containment object called FunctionAsBinary.
An ORM example is as follows:
class Venue(Base):
    __tablename__ = "venue"
    id = Column(Integer, primary_key=True)
    name = Column(String)

    descendants = relationship(
        "Venue",
        primaryjoin=func.instr(
            remote(foreign(name)), name + "/"
        ).as_comparison(1, 2)
        == 1,
        viewonly=True,
        order_by=name,
    )
Above, the “Venue” class can load descendant “Venue” objects by determining if the name of the parent Venue is contained within the start of the hypothetical descendant value’s name, e.g. “parent1” would match up to “parent1/child1”, but not to “parent2/child1”.
Possible use cases include the “materialized path” example given above, as well as making use of special SQL functions such as geometric functions to create join conditions.
Parameters:
• left_index – the integer 1-based index of the function argument that serves as the “left” side of the expression.
• right_index – the integer 1-based index of the function argument that serves as the “right” side of the expression.
Added in version 1.3.
See also
Custom operators based on SQL functions - example use within the ORM
attribute sqlalchemy.sql.functions.FunctionElement.c
synonym for FunctionElement.columns.
attribute sqlalchemy.sql.functions.FunctionElement.clauses
Return the underlying ClauseList which contains the arguments for this FunctionElement.
method sqlalchemy.sql.functions.FunctionElement.column_valued(name: str | None = None, joins_implicitly: bool = False) → TableValuedColumn[_T]
Return this FunctionElement as a column expression that selects from itself as a FROM clause.
E.g.:
>>> from sqlalchemy import select, func
>>> gs = func.generate_series(1, 5, -1).column_valued()
>>> print(select(gs))
SELECT anon_1
FROM generate_series(:generate_series_1, :generate_series_2, :generate_series_3) AS anon_1
This is shorthand for:
gs = func.generate_series(1, 5, -1).alias().column
Parameters:
• name – optional name to assign to the alias name that’s generated. If omitted, a unique anonymizing name is used.
• joins_implicitly – 
when True, the “table” portion of the column valued function may be a member of the FROM clause without any explicit JOIN to other tables in the SQL query, and no “cartesian product” warning will be generated. May be useful for SQL functions such as func.json_array_elements().
Added in version 1.4.46.
See also
Column Valued Functions - Table Valued Function as a Scalar Column - in the SQLAlchemy Unified Tutorial
Column Valued Functions - in the PostgreSQL documentation
FunctionElement.table_valued()
attribute sqlalchemy.sql.functions.FunctionElement.columns
The set of columns exported by this FunctionElement.
This is a placeholder collection that allows the function to be placed in the FROM clause of a statement:
>>> from sqlalchemy import column, select, func
>>> stmt = select(column("x"), column("y")).select_from(func.myfunction())
>>> print(stmt)
SELECT x, y FROM myfunction()
The above form is a legacy feature that is now superseded by the fully capable FunctionElement.table_valued() method; see that method for details.
See also
FunctionElement.table_valued() - generates table-valued SQL function expressions.
attribute sqlalchemy.sql.functions.FunctionElement.entity_namespace
overrides FromClause.entity_namespace as functions are generally column expressions and not FromClauses.
attribute sqlalchemy.sql.functions.FunctionElement.exported_columns
method sqlalchemy.sql.functions.FunctionElement.filter(*criterion: _ColumnExpressionArgument[bool]) → Self | FunctionFilter[_T]
Produce a FILTER clause against this function.
Used against aggregate and window functions, for database backends that support the “FILTER” clause.
The expression:
func.count(1).filter(True)
is shorthand for:
from sqlalchemy import funcfilter

funcfilter(func.count(1), True)
See also
Special Modifiers WITHIN GROUP, FILTER - in the SQLAlchemy Unified Tutorial
FunctionFilter
funcfilter()
method sqlalchemy.sql.functions.FunctionElement.over(*, partition_by: _ByArgument | None = None, order_by: _ByArgument | None = None, rows: Tuple[int | None, int | None] | None = None, range_: Tuple[int | None, int | None] | None = None, groups: Tuple[int | None, int | None] | None = None) → Over[_T]
Produce an OVER clause against this function.
Used against aggregate or so-called “window” functions, for database backends that support window functions.
The expression:
func.row_number().over(order_by="x")
is shorthand for:
from sqlalchemy import over

over(func.row_number(), order_by="x")
See over() for a full description.
See also
over()
Using Window Functions - in the SQLAlchemy Unified Tutorial
method sqlalchemy.sql.functions.FunctionElement.scalar_table_valued(name: str, type_: _TypeEngineArgument[_T] | None = None) → ScalarFunctionColumn[_T]
Return a column expression that’s against this FunctionElement as a scalar table-valued expression.
The returned expression is similar to that returned by a single column accessed off of a FunctionElement.table_valued() construct, except no FROM clause is generated; the function is rendered in the similar way as a scalar subquery.
E.g.:
>>> from sqlalchemy import func, select
>>> fn = func.jsonb_each("{'k', 'v'}").scalar_table_valued("key")
>>> print(select(fn))
SELECT (jsonb_each(:jsonb_each_1)).key
Added in version 1.4.0b2.
See also
FunctionElement.table_valued()
FunctionElement.alias()
FunctionElement.column_valued()
method sqlalchemy.sql.functions.FunctionElement.select() → Select
Produce a select() construct against this FunctionElement.
This is shorthand for:
s = select(function_element)
method sqlalchemy.sql.functions.FunctionElement.self_group(against: OperatorType | None = None) → ClauseElement
Apply a ‘grouping’ to this ClauseElement.
This method is overridden by subclasses to return a “grouping” construct, i.e. parenthesis. In particular it’s used by “binary” expressions to provide a grouping around themselves when placed into a larger expression, as well as by select() constructs when placed into the FROM clause of another select(). (Note that subqueries should be normally created using the Select.alias() method, as many platforms require nested SELECT statements to be named).
As expressions are composed together, the application of self_group() is automatic - end-user code should never need to use this method directly. Note that SQLAlchemy’s clause constructs take operator precedence into account - so parenthesis might not be needed, for example, in an expression like x OR (y AND z) - AND takes precedence over OR.
The base self_group() method of ClauseElement just returns self.
method sqlalchemy.sql.functions.FunctionElement.table_valued(*expr: _ColumnExpressionOrStrLabelArgument[Any], **kw: Any) → TableValuedAlias
Return a TableValuedAlias representation of this FunctionElement with table-valued expressions added.
e.g.:
>>> fn = func.generate_series(1, 5).table_valued(
...     "value", "start", "stop", "step"
... )

>>> print(select(fn))
SELECT anon_1.value, anon_1.start, anon_1.stop, anon_1.step
FROM generate_series(:generate_series_1, :generate_series_2) AS anon_1
>>> print(select(fn.c.value, fn.c.stop).where(fn.c.value > 2))
SELECT anon_1.value, anon_1.stop
FROM generate_series(:generate_series_1, :generate_series_2) AS anon_1
WHERE anon_1.value > :value_1
A WITH ORDINALITY expression may be generated by passing the keyword argument “with_ordinality”:
>>> fn = func.generate_series(4, 1, -1).table_valued(
...     "gen", with_ordinality="ordinality"
... )
>>> print(select(fn))
SELECT anon_1.gen, anon_1.ordinality
FROM generate_series(:generate_series_1, :generate_series_2, :generate_series_3) WITH ORDINALITY AS anon_1
Parameters:
• *expr – A series of string column names that will be added to the .c collection of the resulting TableValuedAlias construct as columns. column() objects with or without datatypes may also be used.
• name – optional name to assign to the alias name that’s generated. If omitted, a unique anonymizing name is used.
• with_ordinality – string name that when present results in the WITH ORDINALITY clause being added to the alias, and the given string name will be added as a column to the .c collection of the resulting TableValuedAlias.
• joins_implicitly – 
when True, the table valued function may be used in the FROM clause without any explicit JOIN to other tables in the SQL query, and no “cartesian product” warning will be generated. May be useful for SQL functions such as func.json_each().
Added in version 1.4.33.
Added in version 1.4.0b2.
See also
Table-Valued Functions - in the SQLAlchemy Unified Tutorial
Table-Valued Functions - in the PostgreSQL documentation
FunctionElement.scalar_table_valued() - variant of FunctionElement.table_valued() which delivers the complete table valued expression as a scalar column expression
FunctionElement.column_valued()
TableValuedAlias.render_derived() - renders the alias using a derived column clause, e.g. AS name(col1, col2, ...)
method sqlalchemy.sql.functions.FunctionElement.within_group(*order_by: _ColumnExpressionArgument[Any]) → WithinGroup[_T]
Produce a WITHIN GROUP (ORDER BY expr) clause against this function.
Used against so-called “ordered set aggregate” and “hypothetical set aggregate” functions, including percentile_cont, rank, dense_rank, etc.
See within_group() for a full description.
See also
Special Modifiers WITHIN GROUP, FILTER - in the SQLAlchemy Unified Tutorial
method sqlalchemy.sql.functions.FunctionElement.within_group_type(within_group: WithinGroup[_S]) → TypeEngine | None
For types that define their return type as based on the criteria within a WITHIN GROUP (ORDER BY) expression, called by the WithinGroup construct.
Returns None by default, in which case the function’s normal .type is used.
class sqlalchemy.sql.functions.GenericFunction
Define a ‘generic’ function.
A generic function is a pre-established Function class that is instantiated automatically when called by name from the func attribute. Note that calling any name from func has the effect that a new Function instance is created automatically, given that name. The primary use case for defining a GenericFunction class is so that a function of a particular name may be given a fixed return type. It can also include custom argument parsing schemes as well as additional methods.
Subclasses of GenericFunction are automatically registered under the name of the class. For example, a user-defined function as_utc() would be available immediately:
from sqlalchemy.sql.functions import GenericFunction
from sqlalchemy.types import DateTime


class as_utc(GenericFunction):
    type = DateTime()
    inherit_cache = True


print(select(func.as_utc()))
User-defined generic functions can be organized into packages by specifying the “package” attribute when defining GenericFunction. Third party libraries containing many functions may want to use this in order to avoid name conflicts with other systems. For example, if our as_utc() function were part of a package “time”:
class as_utc(GenericFunction):
    type = DateTime()
    package = "time"
    inherit_cache = True
The above function would be available from func using the package name time:
print(select(func.time.as_utc()))
A final option is to allow the function to be accessed from one name in func but to render as a different name. The identifier attribute will override the name used to access the function as loaded from func, but will retain the usage of name as the rendered name:
class GeoBuffer(GenericFunction):
    type = Geometry()
    package = "geo"
    name = "ST_Buffer"
    identifier = "buffer"
    inherit_cache = True
The above function will render as follows:
>>> print(func.geo.buffer())
ST_Buffer()
The name will be rendered as is, however without quoting unless the name contains special characters that require quoting. To force quoting on or off for the name, use the quoted_name construct:
from sqlalchemy.sql import quoted_name


class GeoBuffer(GenericFunction):
    type = Geometry()
    package = "geo"
    name = quoted_name("ST_Buffer", True)
    identifier = "buffer"
    inherit_cache = True
The above function will render as:
>>> print(func.geo.buffer())
"ST_Buffer"()
Type parameters for this class as a generic type can be passed and should match the type seen in a Result. For example:
class as_utc(GenericFunction[datetime.datetime]):
    type = DateTime()
    inherit_cache = True
The above indicates that the following expression returns a datetime object:
connection.scalar(select(func.as_utc()))
Added in version 1.3.13: The quoted_name construct is now recognized for quoting when used with the “name” attribute of the object, so that quoting can be forced on or off for the function name.
Class signature
class sqlalchemy.sql.functions.GenericFunction (sqlalchemy.sql.functions.Function)
function sqlalchemy.sql.functions.register_function(identifier: str, fn: Type[Function[Any]], package: str = '_default') → None
Associate a callable with a particular func. name.
This is normally called by GenericFunction, but is also available by itself so that a non-Function construct can be associated with the func accessor (i.e. CAST, EXTRACT).
Selected “Known” Functions
These are GenericFunction implementations for a selected set of common SQL functions that set up the expected return type for each function automatically. The are invoked in the same way as any other member of the func namespace:
select(func.count("*")).select_from(some_table)
Note that any name not known to func generates the function name as is - there is no restriction on what SQL functions can be called, known or unknown to SQLAlchemy, built-in or user defined. The section here only describes those functions where SQLAlchemy already knows what argument and return types are in use.
Object NameDescriptionaggregate_stringsImplement a generic string aggregation function.array_aggSupport for the ARRAY_AGG function.char_lengthThe CHAR_LENGTH() SQL function.coalesceconcatThe SQL CONCAT() function, which concatenates strings.countThe ANSI COUNT aggregate function. With no arguments, emits COUNT *.cubeImplement the CUBE grouping operation.cume_distImplement the cume_dist hypothetical-set aggregate function.current_dateThe CURRENT_DATE() SQL function.current_timeThe CURRENT_TIME() SQL function.current_timestampThe CURRENT_TIMESTAMP() SQL function.current_userThe CURRENT_USER() SQL function.dense_rankImplement the dense_rank hypothetical-set aggregate function.grouping_setsImplement the GROUPING SETS grouping operation.localtimeThe localtime() SQL function.localtimestampThe localtimestamp() SQL function.maxThe SQL MAX() aggregate function.minThe SQL MIN() aggregate function.modeImplement the mode ordered-set aggregate function.next_valueRepresent the ‘next value’, given a Sequence as its single argument.nowThe SQL now() datetime function.percent_rankImplement the percent_rank hypothetical-set aggregate function.percentile_contImplement the percentile_cont ordered-set aggregate function.percentile_discImplement the percentile_disc ordered-set aggregate function.randomThe RANDOM() SQL function.rankImplement the rank hypothetical-set aggregate function.rollupImplement the ROLLUP grouping operation.session_userThe SESSION_USER() SQL function.sumThe SQL SUM() aggregate function.sysdateThe SYSDATE() SQL function.userThe USER() SQL function.class sqlalchemy.sql.functions.aggregate_strings
Implement a generic string aggregation function.
This function will concatenate non-null values into a string and separate the values by a delimiter.
This function is compiled on a per-backend basis, into functions such as group_concat(), string_agg(), or LISTAGG().
e.g. Example usage with delimiter ‘.’:
stmt = select(func.aggregate_strings(table.c.str_col, "."))
The return type of this function is String.
Class signature
class sqlalchemy.sql.functions.aggregate_strings (sqlalchemy.sql.functions.GenericFunction)
class sqlalchemy.sql.functions.array_agg
Support for the ARRAY_AGG function.
The func.array_agg(expr) construct returns an expression of type ARRAY.
e.g.:
stmt = select(func.array_agg(table.c.values)[2:5])
See also
array_agg() - PostgreSQL-specific version that returns ARRAY, which has PG-specific operators added.
Class signature
class sqlalchemy.sql.functions.array_agg (sqlalchemy.sql.functions.ReturnTypeFromArgs)
class sqlalchemy.sql.functions.char_length
The CHAR_LENGTH() SQL function.
Class signature
class sqlalchemy.sql.functions.char_length (sqlalchemy.sql.functions.GenericFunction)
class sqlalchemy.sql.functions.coalesce
Class signature
class sqlalchemy.sql.functions.coalesce (sqlalchemy.sql.functions.ReturnTypeFromArgs)
class sqlalchemy.sql.functions.concat
The SQL CONCAT() function, which concatenates strings.
E.g.:
>>> print(select(func.concat("a", "b")))
SELECT concat(:concat_2, :concat_3) AS concat_1
String concatenation in SQLAlchemy is more commonly available using the Python + operator with string datatypes, which will render a backend-specific concatenation operator, such as :
>>> print(select(literal("a") + "b"))
SELECT :param_1 || :param_2 AS anon_1
Class signature
class sqlalchemy.sql.functions.concat (sqlalchemy.sql.functions.GenericFunction)
class sqlalchemy.sql.functions.count
The ANSI COUNT aggregate function. With no arguments, emits COUNT *.
E.g.:
from sqlalchemy import func
from sqlalchemy import select
from sqlalchemy import table, column

my_table = table("some_table", column("id"))

stmt = select(func.count()).select_from(my_table)
Executing stmt would emit:
SELECT count(*) AS count_1
FROM some_table
Class signature
class sqlalchemy.sql.functions.count (sqlalchemy.sql.functions.GenericFunction)
class sqlalchemy.sql.functions.cube
Implement the CUBE grouping operation.
This function is used as part of the GROUP BY of a statement, e.g. Select.group_by():
stmt = select(
    func.sum(table.c.value), table.c.col_1, table.c.col_2
).group_by(func.cube(table.c.col_1, table.c.col_2))
Added in version 1.2.
Class signature
class sqlalchemy.sql.functions.cube (sqlalchemy.sql.functions.GenericFunction)
class sqlalchemy.sql.functions.cume_dist
Implement the cume_dist hypothetical-set aggregate function.
This function must be used with the FunctionElement.within_group() modifier to supply a sort expression to operate upon.
The return type of this function is Numeric.
Class signature
class sqlalchemy.sql.functions.cume_dist (sqlalchemy.sql.functions.GenericFunction)
class sqlalchemy.sql.functions.current_date
The CURRENT_DATE() SQL function.
Class signature
class sqlalchemy.sql.functions.current_date (sqlalchemy.sql.functions.AnsiFunction)
class sqlalchemy.sql.functions.current_time
The CURRENT_TIME() SQL function.
Class signature
class sqlalchemy.sql.functions.current_time (sqlalchemy.sql.functions.AnsiFunction)
class sqlalchemy.sql.functions.current_timestamp
The CURRENT_TIMESTAMP() SQL function.
Class signature
class sqlalchemy.sql.functions.current_timestamp (sqlalchemy.sql.functions.AnsiFunction)
class sqlalchemy.sql.functions.current_user
The CURRENT_USER() SQL function.
Class signature
class sqlalchemy.sql.functions.current_user (sqlalchemy.sql.functions.AnsiFunction)
class sqlalchemy.sql.functions.dense_rank
Implement the dense_rank hypothetical-set aggregate function.
This function must be used with the FunctionElement.within_group() modifier to supply a sort expression to operate upon.
The return type of this function is Integer.
Class signature
class sqlalchemy.sql.functions.dense_rank (sqlalchemy.sql.functions.GenericFunction)
class sqlalchemy.sql.functions.grouping_sets
Implement the GROUPING SETS grouping operation.
This function is used as part of the GROUP BY of a statement, e.g. Select.group_by():
stmt = select(
    func.sum(table.c.value), table.c.col_1, table.c.col_2
).group_by(func.grouping_sets(table.c.col_1, table.c.col_2))
In order to group by multiple sets, use the tuple_() construct:
from sqlalchemy import tuple_

stmt = select(
    func.sum(table.c.value), table.c.col_1, table.c.col_2, table.c.col_3
).group_by(
    func.grouping_sets(
        tuple_(table.c.col_1, table.c.col_2),
        tuple_(table.c.value, table.c.col_3),
    )
)
Added in version 1.2.
Class signature
class sqlalchemy.sql.functions.grouping_sets (sqlalchemy.sql.functions.GenericFunction)
class sqlalchemy.sql.functions.localtime
The localtime() SQL function.
Class signature
class sqlalchemy.sql.functions.localtime (sqlalchemy.sql.functions.AnsiFunction)
class sqlalchemy.sql.functions.localtimestamp
The localtimestamp() SQL function.
Class signature
class sqlalchemy.sql.functions.localtimestamp (sqlalchemy.sql.functions.AnsiFunction)
class sqlalchemy.sql.functions.max
The SQL MAX() aggregate function.
Class signature
class sqlalchemy.sql.functions.max (sqlalchemy.sql.functions.ReturnTypeFromArgs)
class sqlalchemy.sql.functions.min
The SQL MIN() aggregate function.
Class signature
class sqlalchemy.sql.functions.min (sqlalchemy.sql.functions.ReturnTypeFromArgs)
class sqlalchemy.sql.functions.mode
Implement the mode ordered-set aggregate function.
This function must be used with the FunctionElement.within_group() modifier to supply a sort expression to operate upon.
The return type of this function is the same as the sort expression.
Class signature
class sqlalchemy.sql.functions.mode (sqlalchemy.sql.functions.OrderedSetAgg)
class sqlalchemy.sql.functions.next_value
Represent the ‘next value’, given a Sequence as its single argument.
Compiles into the appropriate function on each backend, or will raise NotImplementedError if used on a backend that does not provide support for sequences.
Class signature
class sqlalchemy.sql.functions.next_value (sqlalchemy.sql.functions.GenericFunction)
class sqlalchemy.sql.functions.now
The SQL now() datetime function.
SQLAlchemy dialects will usually render this particular function in a backend-specific way, such as rendering it as CURRENT_TIMESTAMP.
Class signature
class sqlalchemy.sql.functions.now (sqlalchemy.sql.functions.GenericFunction)
class sqlalchemy.sql.functions.percent_rank
Implement the percent_rank hypothetical-set aggregate function.
This function must be used with the FunctionElement.within_group() modifier to supply a sort expression to operate upon.
The return type of this function is Numeric.
Class signature
class sqlalchemy.sql.functions.percent_rank (sqlalchemy.sql.functions.GenericFunction)
class sqlalchemy.sql.functions.percentile_cont
Implement the percentile_cont ordered-set aggregate function.
This function must be used with the FunctionElement.within_group() modifier to supply a sort expression to operate upon.
The return type of this function is the same as the sort expression, or if the arguments are an array, an ARRAY of the sort expression’s type.
Class signature
class sqlalchemy.sql.functions.percentile_cont (sqlalchemy.sql.functions.OrderedSetAgg)
class sqlalchemy.sql.functions.percentile_disc
Implement the percentile_disc ordered-set aggregate function.
This function must be used with the FunctionElement.within_group() modifier to supply a sort expression to operate upon.
The return type of this function is the same as the sort expression, or if the arguments are an array, an ARRAY of the sort expression’s type.
Class signature
class sqlalchemy.sql.functions.percentile_disc (sqlalchemy.sql.functions.OrderedSetAgg)
class sqlalchemy.sql.functions.random
The RANDOM() SQL function.
Class signature
class sqlalchemy.sql.functions.random (sqlalchemy.sql.functions.GenericFunction)
class sqlalchemy.sql.functions.rank
Implement the rank hypothetical-set aggregate function.
This function must be used with the FunctionElement.within_group() modifier to supply a sort expression to operate upon.
The return type of this function is Integer.
Class signature
class sqlalchemy.sql.functions.rank (sqlalchemy.sql.functions.GenericFunction)
class sqlalchemy.sql.functions.rollup
Implement the ROLLUP grouping operation.
This function is used as part of the GROUP BY of a statement, e.g. Select.group_by():
stmt = select(
    func.sum(table.c.value), table.c.col_1, table.c.col_2
).group_by(func.rollup(table.c.col_1, table.c.col_2))
Added in version 1.2.
Class signature
class sqlalchemy.sql.functions.rollup (sqlalchemy.sql.functions.GenericFunction)
class sqlalchemy.sql.functions.session_user
The SESSION_USER() SQL function.
Class signature
class sqlalchemy.sql.functions.session_user (sqlalchemy.sql.functions.AnsiFunction)
class sqlalchemy.sql.functions.sum
The SQL SUM() aggregate function.
Class signature
class sqlalchemy.sql.functions.sum (sqlalchemy.sql.functions.ReturnTypeFromArgs)
class sqlalchemy.sql.functions.sysdate
The SYSDATE() SQL function.
Class signature
class sqlalchemy.sql.functions.sysdate (sqlalchemy.sql.functions.AnsiFunction)
class sqlalchemy.sql.functions.user
The USER() SQL function.
Class signature
class sqlalchemy.sql.functions.user (sqlalchemy.sql.functions.AnsiFunction)


Custom SQL Constructs and Compilation Extension
Provides an API for creation of custom ClauseElements and compilers.
Synopsis
Usage involves the creation of one or more ClauseElement subclasses and one or more callables defining its compilation:
from sqlalchemy.ext.compiler import compiles
from sqlalchemy.sql.expression import ColumnClause


class MyColumn(ColumnClause):
    inherit_cache = True


@compiles(MyColumn)
def compile_mycolumn(element, compiler, **kw):
    return "[%s]" % element.name
Above, MyColumn extends ColumnClause, the base expression element for named column objects. The compiles decorator registers itself with the MyColumn class so that it is invoked when the object is compiled to a string:
from sqlalchemy import select

s = select(MyColumn("x"), MyColumn("y"))
print(str(s))
Produces:
SELECT [x], [y]
Dialect-specific compilation rules
Compilers can also be made dialect-specific. The appropriate compiler will be invoked for the dialect in use:
from sqlalchemy.schema import DDLElement


class AlterColumn(DDLElement):
    inherit_cache = False

    def __init__(self, column, cmd):
        self.column = column
        self.cmd = cmd


@compiles(AlterColumn)
def visit_alter_column(element, compiler, **kw):
    return "ALTER COLUMN %s ..." % element.column.name


@compiles(AlterColumn, "postgresql")
def visit_alter_column(element, compiler, **kw):
    return "ALTER TABLE %s ALTER COLUMN %s ..." % (
        element.table.name,
        element.column.name,
    )
The second visit_alter_table will be invoked when any postgresql dialect is used.
Compiling sub-elements of a custom expression construct
The compiler argument is the Compiled object in use. This object can be inspected for any information about the in-progress compilation, including compiler.dialect, compiler.statement etc. The SQLCompiler and DDLCompiler both include a process() method which can be used for compilation of embedded attributes:
from sqlalchemy.sql.expression import Executable, ClauseElement


class InsertFromSelect(Executable, ClauseElement):
    inherit_cache = False

    def __init__(self, table, select):
        self.table = table
        self.select = select


@compiles(InsertFromSelect)
def visit_insert_from_select(element, compiler, **kw):
    return "INSERT INTO %s (%s)" % (
        compiler.process(element.table, asfrom=True, **kw),
        compiler.process(element.select, **kw),
    )


insert = InsertFromSelect(t1, select(t1).where(t1.c.x > 5))
print(insert)
Produces (formatted for readability):
INSERT INTO mytable (
    SELECT mytable.x, mytable.y, mytable.z
    FROM mytable
    WHERE mytable.x > :x_1
)
Note
The above InsertFromSelect construct is only an example, this actual functionality is already available using the Insert.from_select() method.
Cross Compiling between SQL and DDL compilers
SQL and DDL constructs are each compiled using different base compilers - SQLCompiler and DDLCompiler. A common need is to access the compilation rules of SQL expressions from within a DDL expression. The DDLCompiler includes an accessor sql_compiler for this reason, such as below where we generate a CHECK constraint that embeds a SQL expression:
@compiles(MyConstraint)
def compile_my_constraint(constraint, ddlcompiler, **kw):
    kw["literal_binds"] = True
    return "CONSTRAINT %s CHECK (%s)" % (
        constraint.name,
        ddlcompiler.sql_compiler.process(constraint.expression, **kw),
    )
Above, we add an additional flag to the process step as called by SQLCompiler.process(), which is the literal_binds flag. This indicates that any SQL expression which refers to a BindParameter object or other “literal” object such as those which refer to strings or integers should be rendered in-place, rather than being referred to as a bound parameter; when emitting DDL, bound parameters are typically not supported.
Changing the default compilation of existing constructs
The compiler extension applies just as well to the existing constructs. When overriding the compilation of a built in SQL construct, the @compiles decorator is invoked upon the appropriate class (be sure to use the class, i.e. Insert or Select, instead of the creation function such as insert() or select()).
Within the new compilation function, to get at the “original” compilation routine, use the appropriate visit_XXX method - this because compiler.process() will call upon the overriding routine and cause an endless loop. Such as, to add “prefix” to all insert statements:
from sqlalchemy.sql.expression import Insert


@compiles(Insert)
def prefix_inserts(insert, compiler, **kw):
    return compiler.visit_insert(insert.prefix_with("some prefix"), **kw)
The above compiler will prefix all INSERT statements with “some prefix” when compiled.
Changing Compilation of Types
compiler works for types, too, such as below where we implement the MS-SQL specific ‘max’ keyword for String/VARCHAR:
@compiles(String, "mssql")
@compiles(VARCHAR, "mssql")
def compile_varchar(element, compiler, **kw):
    if element.length == "max":
        return "VARCHAR('max')"
    else:
        return compiler.visit_VARCHAR(element, **kw)


foo = Table("foo", metadata, Column("data", VARCHAR("max")))
Subclassing Guidelines
A big part of using the compiler extension is subclassing SQLAlchemy expression constructs. To make this easier, the expression and schema packages feature a set of “bases” intended for common tasks. A synopsis is as follows:
• ClauseElement - This is the root expression class. Any SQL expression can be derived from this base, and is probably the best choice for longer constructs such as specialized INSERT statements.
• ColumnElement - The root of all “column-like” elements. Anything that you’d place in the “columns” clause of a SELECT statement (as well as order by and group by) can derive from this - the object will automatically have Python “comparison” behavior.
ColumnElement classes want to have a type member which is expression’s return type. This can be established at the instance level in the constructor, or at the class level if its generally constant:
class timestamp(ColumnElement):
    type = TIMESTAMP()
    inherit_cache = True
•  •  FunctionElement - This is a hybrid of a ColumnElement and a “from clause” like object, and represents a SQL function or stored procedure type of call. Since most databases support statements along the line of “SELECT FROM <some function>” FunctionElement adds in the ability to be used in the FROM clause of a select() construct:
from sqlalchemy.sql.expression import FunctionElement


class coalesce(FunctionElement):
    name = "coalesce"
    inherit_cache = True


@compiles(coalesce)
def compile(element, compiler, **kw):
    return "coalesce(%s)" % compiler.process(element.clauses, **kw)


@compiles(coalesce, "oracle")
def compile(element, compiler, **kw):
    if len(element.clauses) > 2:
        raise TypeError(
            "coalesce only supports two arguments on " "Oracle Database"
        )
    return "nvl(%s)" % compiler.process(element.clauses, **kw)
• 
• ExecutableDDLElement - The root of all DDL expressions, like CREATE TABLE, ALTER TABLE, etc. Compilation of ExecutableDDLElement subclasses is issued by a DDLCompiler instead of a SQLCompiler. ExecutableDDLElement can also be used as an event hook in conjunction with event hooks like DDLEvents.before_create() and DDLEvents.after_create(), allowing the construct to be invoked automatically during CREATE TABLE and DROP TABLE sequences.
See also
Customizing DDL - contains examples of associating DDL objects (which are themselves ExecutableDDLElement instances) with DDLEvents event hooks.
• Executable - This is a mixin which should be used with any expression class that represents a “standalone” SQL statement that can be passed directly to an execute() method. It is already implicit within DDLElement and FunctionElement.
Most of the above constructs also respond to SQL statement caching. A subclassed construct will want to define the caching behavior for the object, which usually means setting the flag inherit_cache to the value of False or True. See the next section Enabling Caching Support for Custom Constructs for background.
Enabling Caching Support for Custom Constructs
SQLAlchemy as of version 1.4 includes a SQL compilation caching facility which will allow equivalent SQL constructs to cache their stringified form, along with other structural information used to fetch results from the statement.
For reasons discussed at Object will not produce a cache key, Performance Implications, the implementation of this caching system takes a conservative approach towards including custom SQL constructs and/or subclasses within the caching system. This includes that any user-defined SQL constructs, including all the examples for this extension, will not participate in caching by default unless they positively assert that they are able to do so. The HasCacheKey.inherit_cache attribute when set to True at the class level of a specific subclass will indicate that instances of this class may be safely cached, using the cache key generation scheme of the immediate superclass. This applies for example to the “synopsis” example indicated previously:
class MyColumn(ColumnClause):
    inherit_cache = True


@compiles(MyColumn)
def compile_mycolumn(element, compiler, **kw):
    return "[%s]" % element.name
Above, the MyColumn class does not include any new state that affects its SQL compilation; the cache key of MyColumn instances will make use of that of the ColumnClause superclass, meaning it will take into account the class of the object (MyColumn), the string name and datatype of the object:
>>> MyColumn("some_name", String())._generate_cache_key()
CacheKey(
    key=('0', <class '__main__.MyColumn'>,
    'name', 'some_name',
    'type', (<class 'sqlalchemy.sql.sqltypes.String'>,
             ('length', None), ('collation', None))
), bindparams=[])
For objects that are likely to be used liberally as components within many larger statements, such as Column subclasses and custom SQL datatypes, it’s important that caching be enabled as much as possible, as this may otherwise negatively affect performance.
An example of an object that does contain state which affects its SQL compilation is the one illustrated at Compiling sub-elements of a custom expression construct; this is an “INSERT FROM SELECT” construct that combines together a Table as well as a Select construct, each of which independently affect the SQL string generation of the construct. For this class, the example illustrates that it simply does not participate in caching:
class InsertFromSelect(Executable, ClauseElement):
    inherit_cache = False

    def __init__(self, table, select):
        self.table = table
        self.select = select


@compiles(InsertFromSelect)
def visit_insert_from_select(element, compiler, **kw):
    return "INSERT INTO %s (%s)" % (
        compiler.process(element.table, asfrom=True, **kw),
        compiler.process(element.select, **kw),
    )
While it is also possible that the above InsertFromSelect could be made to produce a cache key that is composed of that of the Table and Select components together, the API for this is not at the moment fully public. However, for an “INSERT FROM SELECT” construct, which is only used by itself for specific operations, caching is not as critical as in the previous example.
For objects that are used in relative isolation and are generally standalone, such as custom DML constructs like an “INSERT FROM SELECT”, caching is generally less critical as the lack of caching for such a construct will have only localized implications for that specific operation.
Further Examples
“UTC timestamp” function
A function that works like “CURRENT_TIMESTAMP” except applies the appropriate conversions so that the time is in UTC time. Timestamps are best stored in relational databases as UTC, without time zones. UTC so that your database doesn’t think time has gone backwards in the hour when daylight savings ends, without timezones because timezones are like character encodings - they’re best applied only at the endpoints of an application (i.e. convert to UTC upon user input, re-apply desired timezone upon display).
For PostgreSQL and Microsoft SQL Server:
from sqlalchemy.sql import expression
from sqlalchemy.ext.compiler import compiles
from sqlalchemy.types import DateTime


class utcnow(expression.FunctionElement):
    type = DateTime()
    inherit_cache = True


@compiles(utcnow, "postgresql")
def pg_utcnow(element, compiler, **kw):
    return "TIMEZONE('utc', CURRENT_TIMESTAMP)"


@compiles(utcnow, "mssql")
def ms_utcnow(element, compiler, **kw):
    return "GETUTCDATE()"
Example usage:
from sqlalchemy import Table, Column, Integer, String, DateTime, MetaData

metadata = MetaData()
event = Table(
    "event",
    metadata,
    Column("id", Integer, primary_key=True),
    Column("description", String(50), nullable=False),
    Column("timestamp", DateTime, server_default=utcnow()),
)
“GREATEST” function
The “GREATEST” function is given any number of arguments and returns the one that is of the highest value - its equivalent to Python’s max function. A SQL standard version versus a CASE based version which only accommodates two arguments:
from sqlalchemy.sql import expression, case
from sqlalchemy.ext.compiler import compiles
from sqlalchemy.types import Numeric


class greatest(expression.FunctionElement):
    type = Numeric()
    name = "greatest"
    inherit_cache = True


@compiles(greatest)
def default_greatest(element, compiler, **kw):
    return compiler.visit_function(element)


@compiles(greatest, "sqlite")
@compiles(greatest, "mssql")
@compiles(greatest, "oracle")
def case_greatest(element, compiler, **kw):
    arg1, arg2 = list(element.clauses)
    return compiler.process(case((arg1 > arg2, arg1), else_=arg2), **kw)
Example usage:
Session.query(Account).filter(
    greatest(Account.checking_balance, Account.savings_balance) > 10000
)
“false” expression
Render a “false” constant expression, rendering as “0” on platforms that don’t have a “false” constant:
from sqlalchemy.sql import expression
from sqlalchemy.ext.compiler import compiles


class sql_false(expression.ColumnElement):
    inherit_cache = True


@compiles(sql_false)
def default_false(element, compiler, **kw):
    return "false"


@compiles(sql_false, "mssql")
@compiles(sql_false, "mysql")
@compiles(sql_false, "oracle")
def int_false(element, compiler, **kw):
    return "0"
Example usage:
from sqlalchemy import select, union_all

exp = union_all(
    select(users.c.name, sql_false().label("enrolled")),
    select(customers.c.name, customers.c.enrolled),
)
Object NameDescriptioncompiles(class_, *specs)Register a function as a compiler for a given ClauseElement type.deregister(class_)Remove all custom compilers associated with a given ClauseElement type.function sqlalchemy.ext.compiler.compiles(class_: Type[Any], *specs: str) → Callable[[_F], _F]
Register a function as a compiler for a given ClauseElement type.
function sqlalchemy.ext.compiler.deregister(class_: Type[Any]) → None
Remove all custom compilers associated with a given ClauseElement type.


Expression Serializer Extension
Serializer/Deserializer objects for usage with SQLAlchemy query structures, allowing “contextual” deserialization.
Legacy Feature
The serializer extension is legacy and should not be used for new development.
Any SQLAlchemy query structure, either based on sqlalchemy.sql.* or sqlalchemy.orm.* can be used. The mappers, Tables, Columns, Session etc. which are referenced by the structure are not persisted in serialized form, but are instead re-associated with the query structure when it is deserialized.
Warning
The serializer extension uses pickle to serialize and deserialize objects, so the same security consideration mentioned in the python documentation apply.
Usage is nearly the same as that of the standard Python pickle module:
from sqlalchemy.ext.serializer import loads, dumps

metadata = MetaData(bind=some_engine)
Session = scoped_session(sessionmaker())

# ... define mappers

query = (
    Session.query(MyClass)
    .filter(MyClass.somedata == "foo")
    .order_by(MyClass.sortkey)
)

# pickle the query
serialized = dumps(query)

# unpickle.  Pass in metadata + scoped_session
query2 = loads(serialized, metadata, Session)

print(query2.all())
Similar restrictions as when using raw pickle apply; mapped classes must be themselves be pickleable, meaning they are importable from a module-level namespace.
The serializer module is only appropriate for query structures. It is not needed for:
• instances of user-defined classes. These contain no references to engines, sessions or expression constructs in the typical case and can be serialized directly.
• Table metadata that is to be loaded entirely from the serialized structure (i.e. is not already declared in the application). Regular pickle.loads()/dumps() can be used to fully dump any MetaData object, typically one which was reflected from an existing database at some previous point in time. The serializer module is specifically for the opposite case, where the Table metadata is already present in memory.
Object NameDescriptionDeserializerdumps(obj[, protocol])loads(data[, metadata, scoped_session, engine])Serializerclass sqlalchemy.ext.serializer.Deserializer
Members
get_engine(), persistent_load()
Class signature
class sqlalchemy.ext.serializer.Deserializer (_pickle.Unpickler)
method sqlalchemy.ext.serializer.Deserializer.get_engine()
method sqlalchemy.ext.serializer.Deserializer.persistent_load(id_)
class sqlalchemy.ext.serializer.Serializer
Members
persistent_id()
Class signature
class sqlalchemy.ext.serializer.Serializer (_pickle.Pickler)
method sqlalchemy.ext.serializer.Serializer.persistent_id(obj)
function sqlalchemy.ext.serializer.dumps(obj, protocol=5)
function sqlalchemy.ext.serializer.loads(data, metadata=None, scoped_session=None, engine=None)


SQL Expression Language Foundational Constructs
Base classes and mixins that are used to compose SQL Expression Language elements.
Object NameDescriptionCacheKeyThe key used to identify a SQL statement construct in the SQL compilation cache.ClauseElementBase class for elements of a programmatically constructed SQL expression.DialectKWArgsEstablish the ability for a class to have dialect-specific arguments with defaults and constructor validation.HasCacheKeyMixin for objects which can produce a cache key.LambdaElementA SQL construct where the state is stored as an un-invoked lambda.StatementLambdaElementRepresent a composable SQL statement as a LambdaElement.class sqlalchemy.sql.expression.CacheKey
The key used to identify a SQL statement construct in the SQL compilation cache.
See also
SQL Compilation Caching
Members
bindparams, key, to_offline_string()
Class signature
class sqlalchemy.sql.expression.CacheKey (builtins.tuple)
attribute sqlalchemy.sql.expression.CacheKey.bindparams: Sequence[BindParameter[Any]]
Alias for field number 1
attribute sqlalchemy.sql.expression.CacheKey.key: Tuple[Any, ...]
Alias for field number 0
method sqlalchemy.sql.expression.CacheKey.to_offline_string(statement_cache: MutableMapping[Any, str], statement: ClauseElement, parameters: _CoreSingleExecuteParams) → str
Generate an “offline string” form of this CacheKey
The “offline string” is basically the string SQL for the statement plus a repr of the bound parameter values in series. Whereas the CacheKey object is dependent on in-memory identities in order to work as a cache key, the “offline” version is suitable for a cache that will work for other processes as well.
The given statement_cache is a dictionary-like object where the string form of the statement itself will be cached. This dictionary should be in a longer lived scope in order to reduce the time spent stringifying statements.
class sqlalchemy.sql.expression.ClauseElement
Base class for elements of a programmatically constructed SQL expression.
Members
compare(), compile(), get_children(), inherit_cache, params(), self_group(), unique_params()
Class signature
class sqlalchemy.sql.expression.ClauseElement (sqlalchemy.sql.annotation.SupportsWrappingAnnotations, sqlalchemy.sql.cache_key.MemoizedHasCacheKey, sqlalchemy.sql.traversals.HasCopyInternals, sqlalchemy.sql.visitors.ExternallyTraversible, sqlalchemy.sql.expression.CompilerElement)
method sqlalchemy.sql.expression.ClauseElement.compare(other: ClauseElement, **kw: Any) → bool
Compare this ClauseElement to the given ClauseElement.
Subclasses should override the default behavior, which is a straight identity comparison.
**kw are arguments consumed by subclass compare() methods and may be used to modify the criteria for comparison (see ColumnElement).
method sqlalchemy.sql.expression.ClauseElement.compile(bind: _HasDialect | None = None, dialect: Dialect | None = None, **kw: Any) → Compiled
inherited from the CompilerElement.compile() method of CompilerElement
Compile this SQL expression.
The return value is a Compiled object. Calling str() or unicode() on the returned value will yield a string representation of the result. The Compiled object also can return a dictionary of bind parameter names and values using the params accessor.
Parameters:
• bind – An Connection or Engine which can provide a Dialect in order to generate a Compiled object. If the bind and dialect parameters are both omitted, a default SQL compiler is used.
• column_keys – Used for INSERT and UPDATE statements, a list of column names which should be present in the VALUES clause of the compiled statement. If None, all columns from the target table object are rendered.
• dialect – A Dialect instance which can generate a Compiled object. This argument takes precedence over the bind argument.
• compile_kwargs – 
optional dictionary of additional parameters that will be passed through to the compiler within all “visit” methods. This allows any custom flag to be passed through to a custom compilation construct, for example. It is also used for the case of passing the literal_binds flag through:
from sqlalchemy.sql import table, column, select

t = table("t", column("x"))

s = select(t).where(t.c.x == 5)

print(s.compile(compile_kwargs={"literal_binds": True}))
• 
See also
How do I render SQL expressions as strings, possibly with bound parameters inlined?
method sqlalchemy.sql.expression.ClauseElement.get_children(*, omit_attrs: Tuple[str, ...] = (), **kw: Any) → Iterable[HasTraverseInternals]
inherited from the HasTraverseInternals.get_children() method of HasTraverseInternals
Return immediate child HasTraverseInternals elements of this HasTraverseInternals.
This is used for visit traversal.
**kw may contain flags that change the collection that is returned, for example to return a subset of items in order to cut down on larger traversals, or to return child items from a different context (such as schema-level collections instead of clause-level).
attribute sqlalchemy.sql.expression.ClauseElement.inherit_cache: bool | None = None
inherited from the HasCacheKey.inherit_cache attribute of HasCacheKey
Indicate if this HasCacheKey instance should make use of the cache key generation scheme used by its immediate superclass.
The attribute defaults to None, which indicates that a construct has not yet taken into account whether or not its appropriate for it to participate in caching; this is functionally equivalent to setting the value to False, except that a warning is also emitted.
This flag can be set to True on a particular class, if the SQL that corresponds to the object does not change based on attributes which are local to this class, and not its superclass.
See also
Enabling Caching Support for Custom Constructs - General guideslines for setting the HasCacheKey.inherit_cache attribute for third-party or user defined SQL constructs.
method sqlalchemy.sql.expression.ClauseElement.params(_ClauseElement__optionaldict: Mapping[str, Any] | None = None, **kwargs: Any) → Self
Return a copy with bindparam() elements replaced.
Returns a copy of this ClauseElement with bindparam() elements replaced with values taken from the given dictionary:
>>> clause = column("x") + bindparam("foo")
>>> print(clause.compile().params)
{'foo':None}
>>> print(clause.params({"foo": 7}).compile().params)
{'foo':7}
method sqlalchemy.sql.expression.ClauseElement.self_group(against: OperatorType | None = None) → ClauseElement
Apply a ‘grouping’ to this ClauseElement.
This method is overridden by subclasses to return a “grouping” construct, i.e. parenthesis. In particular it’s used by “binary” expressions to provide a grouping around themselves when placed into a larger expression, as well as by select() constructs when placed into the FROM clause of another select(). (Note that subqueries should be normally created using the Select.alias() method, as many platforms require nested SELECT statements to be named).
As expressions are composed together, the application of self_group() is automatic - end-user code should never need to use this method directly. Note that SQLAlchemy’s clause constructs take operator precedence into account - so parenthesis might not be needed, for example, in an expression like x OR (y AND z) - AND takes precedence over OR.
The base self_group() method of ClauseElement just returns self.
method sqlalchemy.sql.expression.ClauseElement.unique_params(_ClauseElement__optionaldict: Dict[str, Any] | None = None, **kwargs: Any) → Self
Return a copy with bindparam() elements replaced.
Same functionality as ClauseElement.params(), except adds unique=True to affected bind parameters so that multiple statements can be used.
class sqlalchemy.sql.base.DialectKWArgs
Establish the ability for a class to have dialect-specific arguments with defaults and constructor validation.
The DialectKWArgs interacts with the DefaultDialect.construct_arguments present on a dialect.
Members
argument_for(), dialect_kwargs, dialect_options, kwargs
See also
DefaultDialect.construct_arguments
classmethod sqlalchemy.sql.base.DialectKWArgs.argument_for(dialect_name, argument_name, default)
Add a new kind of dialect-specific keyword argument for this class.
E.g.:
Index.argument_for("mydialect", "length", None)

some_index = Index("a", "b", mydialect_length=5)
The DialectKWArgs.argument_for() method is a per-argument way adding extra arguments to the DefaultDialect.construct_arguments dictionary. This dictionary provides a list of argument names accepted by various schema-level constructs on behalf of a dialect.
New dialects should typically specify this dictionary all at once as a data member of the dialect class. The use case for ad-hoc addition of argument names is typically for end-user code that is also using a custom compilation scheme which consumes the additional arguments.
Parameters:
• dialect_name – name of a dialect. The dialect must be locatable, else a NoSuchModuleError is raised. The dialect must also include an existing DefaultDialect.construct_arguments collection, indicating that it participates in the keyword-argument validation and default system, else ArgumentError is raised. If the dialect does not include this collection, then any keyword argument can be specified on behalf of this dialect already. All dialects packaged within SQLAlchemy include this collection, however for third party dialects, support may vary.
• argument_name – name of the parameter.
• default – default value of the parameter.
attribute sqlalchemy.sql.base.DialectKWArgs.dialect_kwargs
A collection of keyword arguments specified as dialect-specific options to this construct.
The arguments are present here in their original <dialect>_<kwarg> format. Only arguments that were actually passed are included; unlike the DialectKWArgs.dialect_options collection, which contains all options known by this dialect including defaults.
The collection is also writable; keys are accepted of the form <dialect>_<kwarg> where the value will be assembled into the list of options.
See also
DialectKWArgs.dialect_options - nested dictionary form
attribute sqlalchemy.sql.base.DialectKWArgs.dialect_options
A collection of keyword arguments specified as dialect-specific options to this construct.
This is a two-level nested registry, keyed to <dialect_name> and <argument_name>. For example, the postgresql_where argument would be locatable as:
arg = my_object.dialect_options["postgresql"]["where"]
Added in version 0.9.2.
See also
DialectKWArgs.dialect_kwargs - flat dictionary form
attribute sqlalchemy.sql.base.DialectKWArgs.kwargs
A synonym for DialectKWArgs.dialect_kwargs.
class sqlalchemy.sql.traversals.HasCacheKey
Mixin for objects which can produce a cache key.
This class is usually in a hierarchy that starts with the HasTraverseInternals base, but this is optional. Currently, the class should be able to work on its own without including HasTraverseInternals.
Members
inherit_cache
See also
CacheKey
SQL Compilation Caching
attribute sqlalchemy.sql.traversals.HasCacheKey.inherit_cache: bool | None = None
Indicate if this HasCacheKey instance should make use of the cache key generation scheme used by its immediate superclass.
The attribute defaults to None, which indicates that a construct has not yet taken into account whether or not its appropriate for it to participate in caching; this is functionally equivalent to setting the value to False, except that a warning is also emitted.
This flag can be set to True on a particular class, if the SQL that corresponds to the object does not change based on attributes which are local to this class, and not its superclass.
See also
Enabling Caching Support for Custom Constructs - General guideslines for setting the HasCacheKey.inherit_cache attribute for third-party or user defined SQL constructs.
class sqlalchemy.sql.expression.LambdaElement
A SQL construct where the state is stored as an un-invoked lambda.
The LambdaElement is produced transparently whenever passing lambda expressions into SQL constructs, such as:
stmt = select(table).where(lambda: table.c.col == parameter)
The LambdaElement is the base of the StatementLambdaElement which represents a full statement within a lambda.
Added in version 1.4.
See also
Using Lambdas to add significant speed gains to statement production
Class signature
class sqlalchemy.sql.expression.LambdaElement (sqlalchemy.sql.expression.ClauseElement)
class sqlalchemy.sql.expression.StatementLambdaElement
Represent a composable SQL statement as a LambdaElement.
The StatementLambdaElement is constructed using the lambda_stmt() function:
from sqlalchemy import lambda_stmt

stmt = lambda_stmt(lambda: select(table))
Once constructed, additional criteria can be built onto the statement by adding subsequent lambdas, which accept the existing statement object as a single parameter:
stmt += lambda s: s.where(table.c.col == parameter)
Added in version 1.4.
See also
Using Lambdas to add significant speed gains to statement production
Members
add_criteria(), is_delete, is_dml, is_insert, is_select, is_text, is_update, spoil()
Class signature
class sqlalchemy.sql.expression.StatementLambdaElement (sqlalchemy.sql.roles.AllowsLambdaRole, sqlalchemy.sql.lambdas.LambdaElement, sqlalchemy.sql.expression.Executable)
method sqlalchemy.sql.expression.StatementLambdaElement.add_criteria(other: Callable[[Any], Any], enable_tracking: bool = True, track_on: Any | None = None, track_closure_variables: bool = True, track_bound_values: bool = True) → StatementLambdaElement
Add new criteria to this StatementLambdaElement.
E.g.:
>>> def my_stmt(parameter):
...     stmt = lambda_stmt(
...         lambda: select(table.c.x, table.c.y),
...     )
...     stmt = stmt.add_criteria(lambda: table.c.x > parameter)
...     return stmt
The StatementLambdaElement.add_criteria() method is equivalent to using the Python addition operator to add a new lambda, except that additional arguments may be added including track_closure_values and track_on:
>>> def my_stmt(self, foo):
...     stmt = lambda_stmt(
...         lambda: select(func.max(foo.x, foo.y)),
...         track_closure_variables=False,
...     )
...     stmt = stmt.add_criteria(lambda: self.where_criteria, track_on=[self])
...     return stmt
See lambda_stmt() for a description of the parameters accepted.
attribute sqlalchemy.sql.expression.StatementLambdaElement.is_delete
attribute sqlalchemy.sql.expression.StatementLambdaElement.is_dml
attribute sqlalchemy.sql.expression.StatementLambdaElement.is_insert
attribute sqlalchemy.sql.expression.StatementLambdaElement.is_select
attribute sqlalchemy.sql.expression.StatementLambdaElement.is_text
attribute sqlalchemy.sql.expression.StatementLambdaElement.is_update
method sqlalchemy.sql.expression.StatementLambdaElement.spoil() → NullLambdaStatement
Return a new StatementLambdaElement that will run all lambdas unconditionally each time.


Visitor and Traversal Utilities
The sqlalchemy.sql.visitors module consists of classes and functions that serve the purpose of generically traversing a Core SQL expression structure. This is not unlike the Python ast module in that is presents a system by which a program can operate upon each component of a SQL expression. Common purposes this serves are locating various kinds of elements such as Table or BindParameter objects, as well as altering the state of the structure such as replacing certain FROM clauses with others.
Note
the sqlalchemy.sql.visitors module is an internal API and is not fully public. It is subject to change and may additionally not function as expected for use patterns that aren’t considered within SQLAlchemy’s own internals.
The sqlalchemy.sql.visitors module is part of the internals of SQLAlchemy and it is not usually used by calling application code. It is however used in certain edge cases such as when constructing caching routines as well as when building out custom SQL expressions using the Custom SQL Constructs and Compilation Extension.
Visitor/traversal interface and library functions.
Object NameDescriptionanon_mapalias of cache_anon_mapcloned_traverse(obj, opts, visitors)Clone the given expression structure, allowing modifications by visitors for mutable objects.ExternalTraversalBase class for visitor objects which can traverse externally using the traverse() function.InternalTraversalDefines visitor symbols used for internal traversal.iterate(obj[, opts])Traverse the given expression structure, returning an iterator.replacement_traverse(obj, opts, replace)Clone the given expression structure, allowing element replacement by a given replacement function.traverse(obj, opts, visitors)Traverse and visit the given expression structure using the default iterator.traverse_using(iterator, obj, visitors)Visit the given expression structure using the given iterator of objects.VisitableBase class for visitable objects.class sqlalchemy.sql.visitors.ExternalTraversal
Base class for visitor objects which can traverse externally using the traverse() function.
Direct usage of the traverse() function is usually preferred.
Members
chain(), iterate(), traverse(), visitor_iterator
Class signature
class sqlalchemy.sql.visitors.ExternalTraversal (sqlalchemy.util.langhelpers.MemoizedSlots)
method sqlalchemy.sql.visitors.ExternalTraversal.chain(visitor: ExternalTraversal) → _ExtT
‘Chain’ an additional ExternalTraversal onto this ExternalTraversal
The chained visitor will receive all visit events after this one.
method sqlalchemy.sql.visitors.ExternalTraversal.iterate(obj: ExternallyTraversible | None) → Iterator[ExternallyTraversible]
Traverse the given expression structure, returning an iterator of all elements.
method sqlalchemy.sql.visitors.ExternalTraversal.traverse(obj: ExternallyTraversible | None) → ExternallyTraversible | None
Traverse and visit the given expression structure.
attribute sqlalchemy.sql.visitors.ExternalTraversal.visitor_iterator
Iterate through this visitor and each ‘chained’ visitor.
class sqlalchemy.sql.visitors.InternalTraversal
Defines visitor symbols used for internal traversal.
The InternalTraversal class is used in two ways. One is that it can serve as the superclass for an object that implements the various visit methods of the class. The other is that the symbols themselves of InternalTraversal are used within the _traverse_internals collection. Such as, the Case object defines _traverse_internals as
class Case(ColumnElement[_T]):
    _traverse_internals = [
        ("value", InternalTraversal.dp_clauseelement),
        ("whens", InternalTraversal.dp_clauseelement_tuples),
        ("else_", InternalTraversal.dp_clauseelement),
    ]
Above, the Case class indicates its internal state as the attributes named value, whens, and else_. They each link to an InternalTraversal method which indicates the type of datastructure to which each attribute refers.
Using the _traverse_internals structure, objects of type InternalTraversible will have the following methods automatically implemented:
• HasTraverseInternals.get_children()
• HasTraverseInternals._copy_internals()
• HasCacheKey._gen_cache_key()
Subclasses can also implement these methods directly, particularly for the HasTraverseInternals._copy_internals() method, when special steps are needed.
Added in version 1.4.
Members
dp_annotations_key, dp_anon_name, dp_boolean, dp_clauseelement, dp_clauseelement_list, dp_clauseelement_tuple, dp_clauseelement_tuples, dp_dialect_options, dp_dml_multi_values, dp_dml_ordered_values, dp_dml_values, dp_fromclause_canonical_column_collection, dp_fromclause_ordered_set, dp_has_cache_key, dp_has_cache_key_list, dp_has_cache_key_tuples, dp_ignore, dp_inspectable, dp_inspectable_list, dp_multi, dp_multi_list, dp_named_ddl_element, dp_operator, dp_plain_dict, dp_plain_obj, dp_prefix_sequence, dp_propagate_attrs, dp_statement_hint_list, dp_string, dp_string_clauseelement_dict, dp_string_list, dp_string_multi_dict, dp_table_hint_list, dp_type, dp_unknown_structure
Class signature
class sqlalchemy.sql.visitors.InternalTraversal (enum.Enum)
attribute sqlalchemy.sql.visitors.InternalTraversal.dp_annotations_key = 'AK'
Visit the _annotations_cache_key element.
This is a dictionary of additional information about a ClauseElement that modifies its role. It should be included when comparing or caching objects, however generating this key is relatively expensive. Visitors should check the “_annotations” dict for non-None first before creating this key.
attribute sqlalchemy.sql.visitors.InternalTraversal.dp_anon_name = 'AN'
Visit a potentially “anonymized” string value.
The string value is considered to be significant for cache key generation.
attribute sqlalchemy.sql.visitors.InternalTraversal.dp_boolean = 'B'
Visit a boolean value.
The boolean value is considered to be significant for cache key generation.
attribute sqlalchemy.sql.visitors.InternalTraversal.dp_clauseelement = 'CE'
Visit a ClauseElement object.
attribute sqlalchemy.sql.visitors.InternalTraversal.dp_clauseelement_list = 'CL'
Visit a list of ClauseElement objects.
attribute sqlalchemy.sql.visitors.InternalTraversal.dp_clauseelement_tuple = 'CT'
Visit a tuple of ClauseElement objects.
attribute sqlalchemy.sql.visitors.InternalTraversal.dp_clauseelement_tuples = 'CTS'
Visit a list of tuples which contain ClauseElement objects.
attribute sqlalchemy.sql.visitors.InternalTraversal.dp_dialect_options = 'DO'
Visit a dialect options structure.
attribute sqlalchemy.sql.visitors.InternalTraversal.dp_dml_multi_values = 'DML_MV'
Visit the values() multi-valued list of dictionaries of an Insert object.
attribute sqlalchemy.sql.visitors.InternalTraversal.dp_dml_ordered_values = 'DML_OV'
Visit the values() ordered tuple list of an Update object.
attribute sqlalchemy.sql.visitors.InternalTraversal.dp_dml_values = 'DML_V'
Visit the values() dictionary of a ValuesBase (e.g. Insert or Update) object.
attribute sqlalchemy.sql.visitors.InternalTraversal.dp_fromclause_canonical_column_collection = 'FC'
Visit a FromClause object in the context of the columns attribute.
The column collection is “canonical”, meaning it is the originally defined location of the ColumnClause objects. Right now this means that the object being visited is a TableClause or Table object only.
attribute sqlalchemy.sql.visitors.InternalTraversal.dp_fromclause_ordered_set = 'CO'
Visit an ordered set of FromClause objects.
attribute sqlalchemy.sql.visitors.InternalTraversal.dp_has_cache_key = 'HC'
Visit a HasCacheKey object.
attribute sqlalchemy.sql.visitors.InternalTraversal.dp_has_cache_key_list = 'HL'
Visit a list of HasCacheKey objects.
attribute sqlalchemy.sql.visitors.InternalTraversal.dp_has_cache_key_tuples = 'HT'
Visit a list of tuples which contain HasCacheKey objects.
attribute sqlalchemy.sql.visitors.InternalTraversal.dp_ignore = 'IG'
Specify an object that should be ignored entirely.
This currently applies function call argument caching where some arguments should not be considered to be part of a cache key.
attribute sqlalchemy.sql.visitors.InternalTraversal.dp_inspectable = 'IS'
Visit an inspectable object where the return value is a HasCacheKey object.
attribute sqlalchemy.sql.visitors.InternalTraversal.dp_inspectable_list = 'IL'
Visit a list of inspectable objects which upon inspection are HasCacheKey objects.
attribute sqlalchemy.sql.visitors.InternalTraversal.dp_multi = 'M'
Visit an object that may be a HasCacheKey or may be a plain hashable object.
attribute sqlalchemy.sql.visitors.InternalTraversal.dp_multi_list = 'MT'
Visit a tuple containing elements that may be HasCacheKey or may be a plain hashable object.
attribute sqlalchemy.sql.visitors.InternalTraversal.dp_named_ddl_element = 'DD'
Visit a simple named DDL element.
The current object used by this method is the Sequence.
The object is only considered to be important for cache key generation as far as its name, but not any other aspects of it.
attribute sqlalchemy.sql.visitors.InternalTraversal.dp_operator = 'O'
Visit an operator.
The operator is a function from the sqlalchemy.sql.operators module.
The operator value is considered to be significant for cache key generation.
attribute sqlalchemy.sql.visitors.InternalTraversal.dp_plain_dict = 'PD'
Visit a dictionary with string keys.
The keys of the dictionary should be strings, the values should be immutable and hashable. The dictionary is considered to be significant for cache key generation.
attribute sqlalchemy.sql.visitors.InternalTraversal.dp_plain_obj = 'PO'
Visit a plain python object.
The value should be immutable and hashable, such as an integer. The value is considered to be significant for cache key generation.
attribute sqlalchemy.sql.visitors.InternalTraversal.dp_prefix_sequence = 'PS'
Visit the sequence represented by HasPrefixes or HasSuffixes.
attribute sqlalchemy.sql.visitors.InternalTraversal.dp_propagate_attrs = 'PA'
Visit the propagate attrs dict. This hardcodes to the particular elements we care about right now.
attribute sqlalchemy.sql.visitors.InternalTraversal.dp_statement_hint_list = 'SH'
Visit the _statement_hints collection of a Select object.
attribute sqlalchemy.sql.visitors.InternalTraversal.dp_string = 'S'
Visit a plain string value.
Examples include table and column names, bound parameter keys, special keywords such as “UNION”, “UNION ALL”.
The string value is considered to be significant for cache key generation.
attribute sqlalchemy.sql.visitors.InternalTraversal.dp_string_clauseelement_dict = 'CD'
Visit a dictionary of string keys to ClauseElement objects.
attribute sqlalchemy.sql.visitors.InternalTraversal.dp_string_list = 'SL'
Visit a list of strings.
attribute sqlalchemy.sql.visitors.InternalTraversal.dp_string_multi_dict = 'MD'
Visit a dictionary of string keys to values which may either be plain immutable/hashable or HasCacheKey objects.
attribute sqlalchemy.sql.visitors.InternalTraversal.dp_table_hint_list = 'TH'
Visit the _hints collection of a Select object.
attribute sqlalchemy.sql.visitors.InternalTraversal.dp_type = 'T'
Visit a TypeEngine object
The type object is considered to be significant for cache key generation.
attribute sqlalchemy.sql.visitors.InternalTraversal.dp_unknown_structure = 'UK'
Visit an unknown structure.
class sqlalchemy.sql.visitors.Visitable
Base class for visitable objects.
Visitable is used to implement the SQL compiler dispatch functions. Other forms of traversal such as for cache key generation are implemented separately using the HasTraverseInternals interface.
Changed in version 2.0: The Visitable class was named Traversible in the 1.4 series; the name is changed back to Visitable in 2.0 which is what it was prior to 1.4.
Both names remain importable in both 1.4 and 2.0 versions.
attribute sqlalchemy.sql.visitors..sqlalchemy.sql.visitors.anon_map
alias of cache_anon_map
function sqlalchemy.sql.visitors.cloned_traverse(obj: ExternallyTraversible | None, opts: Mapping[str, Any], visitors: Mapping[str, Callable[[Any], None]]) → ExternallyTraversible | None
Clone the given expression structure, allowing modifications by visitors for mutable objects.
Traversal usage is the same as that of traverse(). The visitor functions present in the visitors dictionary may also modify the internals of the given structure as the traversal proceeds.
The cloned_traverse() function does not provide objects that are part of the Immutable interface to the visit methods (this primarily includes ColumnClause, Column, TableClause and Table objects). As this traversal is only intended to allow in-place mutation of objects, Immutable objects are skipped. The Immutable._clone() method is still called on each object to allow for objects to replace themselves with a different object based on a clone of their sub-internals (e.g. a ColumnClause that clones its subquery to return a new ColumnClause).
Changed in version 2.0: The cloned_traverse() function omits objects that are part of the Immutable interface.
The central API feature used by the cloned_traverse() and replacement_traverse() functions, in addition to the ClauseElement.get_children() function that is used to achieve the iteration, is the ClauseElement._copy_internals() method. For a ClauseElement structure to support cloning and replacement traversals correctly, it needs to be able to pass a cloning function into its internal members in order to make copies of them.
See also
traverse()
replacement_traverse()
function sqlalchemy.sql.visitors.iterate(obj: ExternallyTraversible | None, opts: Mapping[str, Any] = {}) → Iterator[ExternallyTraversible]
Traverse the given expression structure, returning an iterator.
Traversal is configured to be breadth-first.
The central API feature used by the iterate() function is the ClauseElement.get_children() method of ClauseElement objects. This method should return all the ClauseElement objects which are associated with a particular ClauseElement object. For example, a Case structure will refer to a series of ColumnElement objects within its “whens” and “else_” member variables.
Parameters:
• obj – ClauseElement structure to be traversed
• opts – dictionary of iteration options. This dictionary is usually empty in modern usage.
function sqlalchemy.sql.visitors.replacement_traverse(obj: ExternallyTraversible | None, opts: Mapping[str, Any], replace: _TraverseTransformCallableType[Any]) → ExternallyTraversible | None
Clone the given expression structure, allowing element replacement by a given replacement function.
This function is very similar to the cloned_traverse() function, except instead of being passed a dictionary of visitors, all elements are unconditionally passed into the given replace function. The replace function then has the option to return an entirely new object which will replace the one given. If it returns None, then the object is kept in place.
The difference in usage between cloned_traverse() and replacement_traverse() is that in the former case, an already-cloned object is passed to the visitor function, and the visitor function can then manipulate the internal state of the object. In the case of the latter, the visitor function should only return an entirely different object, or do nothing.
The use case for replacement_traverse() is that of replacing a FROM clause inside of a SQL structure with a different one, as is a common use case within the ORM.
function sqlalchemy.sql.visitors.traverse(obj: ExternallyTraversible | None, opts: Mapping[str, Any], visitors: Mapping[str, Callable[[Any], None]]) → ExternallyTraversible | None
Traverse and visit the given expression structure using the default iterator.
e.g.:
from sqlalchemy.sql import visitors

stmt = select(some_table).where(some_table.c.foo == "bar")


def visit_bindparam(bind_param):
    print("found bound value: %s" % bind_param.value)


visitors.traverse(stmt, {}, {"bindparam": visit_bindparam})
The iteration of objects uses the iterate() function, which does a breadth-first traversal using a stack.
Parameters:
• obj – ClauseElement structure to be traversed
• opts – dictionary of iteration options. This dictionary is usually empty in modern usage.
• visitors – dictionary of visit functions. The dictionary should have strings as keys, each of which would correspond to the __visit_name__ of a particular kind of SQL expression object, and callable functions as values, each of which represents a visitor function for that kind of object.
function sqlalchemy.sql.visitors.traverse_using(iterator: Iterable[ExternallyTraversible], obj: ExternallyTraversible | None, visitors: Mapping[str, Callable[[Any], None]]) → ExternallyTraversible | None
Visit the given expression structure using the given iterator of objects.
traverse_using() is usually called internally as the result of the traverse() function.
Parameters:
• iterator – an iterable or sequence which will yield ClauseElement structures; the iterator is assumed to be the product of the iterate() function.
• obj – the ClauseElement that was used as the target of the iterate() function.
• visitors – dictionary of visit functions. See traverse() for details on this dictionary.
See also
traverse()


Schema Definition Language
This section references SQLAlchemy schema metadata, a comprehensive system of describing and inspecting database schemas.
The core of SQLAlchemy’s query and object mapping operations are supported by database metadata, which is comprised of Python objects that describe tables and other schema-level objects. These objects are at the core of three major types of operations - issuing CREATE and DROP statements (known as DDL), constructing SQL queries, and expressing information about structures that already exist within the database.
Database metadata can be expressed by explicitly naming the various components and their properties, using constructs such as Table, Column, ForeignKey and Sequence, all of which are imported from the sqlalchemy.schema package. It can also be generated by SQLAlchemy using a process called reflection, which means you start with a single object such as Table, assign it a name, and then instruct SQLAlchemy to load all the additional information related to that name from a particular engine source.
A key feature of SQLAlchemy’s database metadata constructs is that they are designed to be used in a declarative style which closely resembles that of real DDL. They are therefore most intuitive to those who have some background in creating real schema generation scripts.
• Describing Databases with MetaData
o Accessing Tables and Columns
o Creating and Dropping Database Tables
o Altering Database Objects through Migrations
o Specifying the Schema Name
• Specifying a Default Schema Name with MetaData
• Applying Dynamic Schema Naming Conventions
• Setting a Default Schema for New Connections
• Schemas and Reflection
o Backend-Specific Options
o Column, Table, MetaData API
• Column
• MetaData
• SchemaConst
• SchemaItem
• insert_sentinel()
• Table
• Reflecting Database Objects
o Overriding Reflected Columns
o Reflecting Views
o Reflecting All Tables at Once
o Reflecting Tables from Other Schemas
• Interaction of Schema-qualified Reflection with the Default Schema
o Fine Grained Reflection with Inspector
• Inspector
• ReflectedColumn
• ReflectedComputed
• ReflectedCheckConstraint
• ReflectedForeignKeyConstraint
• ReflectedIdentity
• ReflectedIndex
• ReflectedPrimaryKeyConstraint
• ReflectedUniqueConstraint
• ReflectedTableComment
o Reflecting with Database-Agnostic Types
o Limitations of Reflection
• Column INSERT/UPDATE Defaults
o Scalar Defaults
o Python-Executed Functions
• Context-Sensitive Default Functions
o Client-Invoked SQL Expressions
o Server-invoked DDL-Explicit Default Expressions
o Marking Implicitly Generated Values, timestamps, and Triggered Columns
o Defining Sequences
• Associating a Sequence on a SERIAL column
• Executing a Sequence Standalone
• Associating a Sequence with the MetaData
• Associating a Sequence as the Server Side Default
o Computed Columns (GENERATED ALWAYS AS)
o Identity Columns (GENERATED { ALWAYS | BY DEFAULT } AS IDENTITY)
o Default Objects API
• Computed
• ColumnDefault
• DefaultClause
• DefaultGenerator
• FetchedValue
• Sequence
• Identity
• Defining Constraints and Indexes
o Defining Foreign Keys
• Creating/Dropping Foreign Key Constraints via ALTER
• ON UPDATE and ON DELETE
o UNIQUE Constraint
o CHECK Constraint
o PRIMARY KEY Constraint
o Setting up Constraints when using the Declarative ORM Extension
o Configuring Constraint Naming Conventions
• Configuring a Naming Convention for a MetaData Collection
• The Default Naming Convention
• Truncation of Long Names
• Creating Custom Tokens for Naming Conventions
• Naming CHECK Constraints
• Configuring Naming for Boolean, Enum, and other schema types
• Using Naming Conventions with ORM Declarative Mixins
o Constraints API
• Constraint
• ColumnCollectionMixin
• ColumnCollectionConstraint
• CheckConstraint
• ForeignKey
• ForeignKeyConstraint
• HasConditionalDDL
• PrimaryKeyConstraint
• UniqueConstraint
• conv()
o Indexes
• Functional Indexes
o Index API
• Index
• Customizing DDL
o Custom DDL
o Controlling DDL Sequences
o Using the built-in DDLElement Classes
o Controlling DDL Generation of Constraints and Indexes
o DDL Expression Constructs API
• sort_tables()
• sort_tables_and_constraints()
• BaseDDLElement
• ExecutableDDLElement
• DDL
• _CreateDropBase
• CreateTable
• DropTable
• CreateColumn
• CreateSequence
• DropSequence
• CreateIndex
• DropIndex
• AddConstraint
• DropConstraint
• CreateSchema
• DropSchema


Describing Databases with MetaData
This section discusses the fundamental Table, Column and MetaData objects.
See also
Working with Database Metadata - tutorial introduction to SQLAlchemy’s database metadata concept in the SQLAlchemy Unified Tutorial
A collection of metadata entities is stored in an object aptly named MetaData:
from sqlalchemy import MetaData

metadata_obj = MetaData()
MetaData is a container object that keeps together many different features of a database (or multiple databases) being described.
To represent a table, use the Table class. Its two primary arguments are the table name, then the MetaData object which it will be associated with. The remaining positional arguments are mostly Column objects describing each column:
from sqlalchemy import Table, Column, Integer, String

user = Table(
    "user",
    metadata_obj,
    Column("user_id", Integer, primary_key=True),
    Column("user_name", String(16), nullable=False),
    Column("email_address", String(60)),
    Column("nickname", String(50), nullable=False),
)
Above, a table called user is described, which contains four columns. The primary key of the table consists of the user_id column. Multiple columns may be assigned the primary_key=True flag which denotes a multi-column primary key, known as a composite primary key.
Note also that each column describes its datatype using objects corresponding to genericized types, such as Integer and String. SQLAlchemy features dozens of types of varying levels of specificity as well as the ability to create custom types. Documentation on the type system can be found at SQL Datatype Objects.
Accessing Tables and Columns
The MetaData object contains all of the schema constructs we’ve associated with it. It supports a few methods of accessing these table objects, such as the sorted_tables accessor which returns a list of each Table object in order of foreign key dependency (that is, each table is preceded by all tables which it references):
>>> for t in metadata_obj.sorted_tables:
...     print(t.name)
user
user_preference
invoice
invoice_item
In most cases, individual Table objects have been explicitly declared, and these objects are typically accessed directly as module-level variables in an application. Once a Table has been defined, it has a full set of accessors which allow inspection of its properties. Given the following Table definition:
employees = Table(
    "employees",
    metadata_obj,
    Column("employee_id", Integer, primary_key=True),
    Column("employee_name", String(60), nullable=False),
    Column("employee_dept", Integer, ForeignKey("departments.department_id")),
)
Note the ForeignKey object used in this table - this construct defines a reference to a remote table, and is fully described in Defining Foreign Keys. Methods of accessing information about this table include:
# access the column "employee_id":
employees.columns.employee_id

# or just
employees.c.employee_id

# via string
employees.c["employee_id"]

# a tuple of columns may be returned using multiple strings
# (new in 2.0)
emp_id, name, type = employees.c["employee_id", "name", "type"]

# iterate through all columns
for c in employees.c:
    print(c)

# get the table's primary key columns
for primary_key in employees.primary_key:
    print(primary_key)

# get the table's foreign key objects:
for fkey in employees.foreign_keys:
    print(fkey)

# access the table's MetaData:
employees.metadata

# access a column's name, type, nullable, primary key, foreign key
employees.c.employee_id.name
employees.c.employee_id.type
employees.c.employee_id.nullable
employees.c.employee_id.primary_key
employees.c.employee_dept.foreign_keys

# get the "key" of a column, which defaults to its name, but can
# be any user-defined string:
employees.c.employee_name.key

# access a column's table:
employees.c.employee_id.table is employees

# get the table related by a foreign key
list(employees.c.employee_dept.foreign_keys)[0].column.table
Tip
The FromClause.c collection, synonymous with the FromClause.columns collection, is an instance of ColumnCollection, which provides a dictionary-like interface to the collection of columns. Names are ordinarily accessed like attribute names, e.g. employees.c.employee_name. However for special names with spaces or those that match the names of dictionary methods such as ColumnCollection.keys() or ColumnCollection.values(), indexed access must be used, such as employees.c['values'] or employees.c["some column"]. See ColumnCollection for further information.
Creating and Dropping Database Tables
Once you’ve defined some Table objects, assuming you’re working with a brand new database one thing you might want to do is issue CREATE statements for those tables and their related constructs (as an aside, it’s also quite possible that you don’t want to do this, if you already have some preferred methodology such as tools included with your database or an existing scripting system - if that’s the case, feel free to skip this section - SQLAlchemy has no requirement that it be used to create your tables).
The usual way to issue CREATE is to use create_all() on the MetaData object. This method will issue queries that first check for the existence of each individual table, and if not found will issue the CREATE statements:
engine = create_engine("sqlite:///:memory:")

metadata_obj = MetaData()

user = Table(
    "user",
    metadata_obj,
    Column("user_id", Integer, primary_key=True),
    Column("user_name", String(16), nullable=False),
    Column("email_address", String(60), key="email"),
    Column("nickname", String(50), nullable=False),
)

user_prefs = Table(
    "user_prefs",
    metadata_obj,
    Column("pref_id", Integer, primary_key=True),
    Column("user_id", Integer, ForeignKey("user.user_id"), nullable=False),
    Column("pref_name", String(40), nullable=False),
    Column("pref_value", String(100)),
)

metadata_obj.create_all(engine)
PRAGMA table_info(user){}
CREATE TABLE user(
        user_id INTEGER NOT NULL PRIMARY KEY,
        user_name VARCHAR(16) NOT NULL,
        email_address VARCHAR(60),
        nickname VARCHAR(50) NOT NULL
)
PRAGMA table_info(user_prefs){}
CREATE TABLE user_prefs(
        pref_id INTEGER NOT NULL PRIMARY KEY,
        user_id INTEGER NOT NULL REFERENCES user(user_id),
        pref_name VARCHAR(40) NOT NULL,
        pref_value VARCHAR(100)
)
create_all() creates foreign key constraints between tables usually inline with the table definition itself, and for this reason it also generates the tables in order of their dependency. There are options to change this behavior such that ALTER TABLE is used instead.
Dropping all tables is similarly achieved using the drop_all() method. This method does the exact opposite of create_all() - the presence of each table is checked first, and tables are dropped in reverse order of dependency.
Creating and dropping individual tables can be done via the create() and drop() methods of Table. These methods by default issue the CREATE or DROP regardless of the table being present:
engine = create_engine("sqlite:///:memory:")

metadata_obj = MetaData()

employees = Table(
    "employees",
    metadata_obj,
    Column("employee_id", Integer, primary_key=True),
    Column("employee_name", String(60), nullable=False, key="name"),
    Column("employee_dept", Integer, ForeignKey("departments.department_id")),
)
employees.create(engine)
CREATE TABLE employees(
    employee_id SERIAL NOT NULL PRIMARY KEY,
    employee_name VARCHAR(60) NOT NULL,
    employee_dept INTEGER REFERENCES departments(department_id)
)
{}
drop() method:
employees.drop(engine)
DROP TABLE employees
{}
To enable the “check first for the table existing” logic, add the checkfirst=True argument to create() or drop():
employees.create(engine, checkfirst=True)
employees.drop(engine, checkfirst=False)
Altering Database Objects through Migrations
While SQLAlchemy directly supports emitting CREATE and DROP statements for schema constructs, the ability to alter those constructs, usually via the ALTER statement as well as other database-specific constructs, is outside of the scope of SQLAlchemy itself. While it’s easy enough to emit ALTER statements and similar by hand, such as by passing a text() construct to Connection.execute() or by using the DDL construct, it’s a common practice to automate the maintenance of database schemas in relation to application code using schema migration tools.
The SQLAlchemy project offers the Alembic migration tool for this purpose. Alembic features a highly customizable environment and a minimalistic usage pattern, supporting such features as transactional DDL, automatic generation of “candidate” migrations, an “offline” mode which generates SQL scripts, and support for branch resolution.
Alembic supersedes the SQLAlchemy-Migrate project, which is the original migration tool for SQLAlchemy and is now considered legacy.
Specifying the Schema Name
Most databases support the concept of multiple “schemas” - namespaces that refer to alternate sets of tables and other constructs. The server-side geometry of a “schema” takes many forms, including names of “schemas” under the scope of a particular database (e.g. PostgreSQL schemas), named sibling databases (e.g. MySQL / MariaDB access to other databases on the same server), as well as other concepts like tables owned by other usernames (Oracle Database, SQL Server) or even names that refer to alternate database files (SQLite ATTACH) or remote servers (Oracle Database DBLINK with synonyms).
What all of the above approaches have (mostly) in common is that there’s a way of referencing this alternate set of tables using a string name. SQLAlchemy refers to this name as the schema name. Within SQLAlchemy, this is nothing more than a string name which is associated with a Table object, and is then rendered into SQL statements in a manner appropriate to the target database such that the table is referenced in its remote “schema”, whatever mechanism that is on the target database.
The “schema” name may be associated directly with a Table using the Table.schema argument; when using the ORM with declarative table configuration, the parameter is passed using the __table_args__ parameter dictionary.
The “schema” name may also be associated with the MetaData object where it will take effect automatically for all Table objects associated with that MetaData that don’t otherwise specify their own name. Finally, SQLAlchemy also supports a “dynamic” schema name system that is often used for multi-tenant applications such that a single set of Table metadata may refer to a dynamically configured set of schema names on a per-connection or per-statement basis.
What’s “schema” ?
SQLAlchemy’s support for database “schema” was designed with first party support for PostgreSQL-style schemas. In this style, there is first a “database” that typically has a single “owner”. Within this database there can be any number of “schemas” which then contain the actual table objects.
A table within a specific schema is referenced explicitly using the syntax “<schemaname>.<tablename>”. Contrast this to an architecture such as that of MySQL, where there are only “databases”, however SQL statements can refer to multiple databases at once, using the same syntax except it is “<database>.<tablename>”. On Oracle Database, this syntax refers to yet another concept, the “owner” of a table. Regardless of which kind of database is in use, SQLAlchemy uses the phrase “schema” to refer to the qualifying identifier within the general syntax of “<qualifier>.<tablename>”.
See also
Explicit Schema Name with Declarative Table - schema name specification when using the ORM declarative table configuration
The most basic example is that of the Table.schema argument using a Core Table object as follows:
metadata_obj = MetaData()

financial_info = Table(
    "financial_info",
    metadata_obj,
    Column("id", Integer, primary_key=True),
    Column("value", String(100), nullable=False),
    schema="remote_banks",
)
SQL that is rendered using this Table, such as the SELECT statement below, will explicitly qualify the table name financial_info with the remote_banks schema name:
>>> print(select(financial_info))
SELECT remote_banks.financial_info.id, remote_banks.financial_info.value
FROM remote_banks.financial_info
When a Table object is declared with an explicit schema name, it is stored in the internal MetaData namespace using the combination of the schema and table name. We can view this in the MetaData.tables collection by searching for the key 'remote_banks.financial_info':
>>> metadata_obj.tables["remote_banks.financial_info"]
Table('financial_info', MetaData(),
Column('id', Integer(), table=<financial_info>, primary_key=True, nullable=False),
Column('value', String(length=100), table=<financial_info>, nullable=False),
schema='remote_banks')
This dotted name is also what must be used when referring to the table for use with the ForeignKey or ForeignKeyConstraint objects, even if the referring table is also in that same schema:
customer = Table(
    "customer",
    metadata_obj,
    Column("id", Integer, primary_key=True),
    Column("financial_info_id", ForeignKey("remote_banks.financial_info.id")),
    schema="remote_banks",
)
The Table.schema argument may also be used with certain dialects to indicate a multiple-token (e.g. dotted) path to a particular table. This is particularly important on a database such as Microsoft SQL Server where there are often dotted “database/owner” tokens. The tokens may be placed directly in the name at once, such as:
schema = "dbo.scott"
See also
Multipart Schema Names - describes use of dotted schema names with the SQL Server dialect.
Reflecting Tables from Other Schemas
Specifying a Default Schema Name with MetaData
The MetaData object may also set up an explicit default option for all Table.schema parameters by passing the MetaData.schema argument to the top level MetaData construct:
metadata_obj = MetaData(schema="remote_banks")

financial_info = Table(
    "financial_info",
    metadata_obj,
    Column("id", Integer, primary_key=True),
    Column("value", String(100), nullable=False),
)
Above, for any Table object (or Sequence object directly associated with the MetaData) which leaves the Table.schema parameter at its default of None will instead act as though the parameter were set to the value "remote_banks". This includes that the Table is cataloged in the MetaData using the schema-qualified name, that is:
metadata_obj.tables["remote_banks.financial_info"]
When using the ForeignKey or ForeignKeyConstraint objects to refer to this table, either the schema-qualified name or the non-schema-qualified name may be used to refer to the remote_banks.financial_info table:
# either will work:

refers_to_financial_info = Table(
    "refers_to_financial_info",
    metadata_obj,
    Column("id", Integer, primary_key=True),
    Column("fiid", ForeignKey("financial_info.id")),
)


# or

refers_to_financial_info = Table(
    "refers_to_financial_info",
    metadata_obj,
    Column("id", Integer, primary_key=True),
    Column("fiid", ForeignKey("remote_banks.financial_info.id")),
)
When using a MetaData object that sets MetaData.schema, a Table that wishes to specify that it should not be schema qualified may use the special symbol BLANK_SCHEMA:
from sqlalchemy import BLANK_SCHEMA

metadata_obj = MetaData(schema="remote_banks")

financial_info = Table(
    "financial_info",
    metadata_obj,
    Column("id", Integer, primary_key=True),
    Column("value", String(100), nullable=False),
    schema=BLANK_SCHEMA,  # will not use "remote_banks"
)
See also
MetaData.schema
Applying Dynamic Schema Naming Conventions
The names used by the Table.schema parameter may also be applied against a lookup that is dynamic on a per-connection or per-execution basis, so that for example in multi-tenant situations, each transaction or statement may be targeted at a specific set of schema names that change. The section Translation of Schema Names describes how this feature is used.
See also
Translation of Schema Names
Setting a Default Schema for New Connections
The above approaches all refer to methods of including an explicit schema-name within SQL statements. Database connections in fact feature the concept of a “default” schema, which is the name of the “schema” (or database, owner, etc.) that takes place if a table name is not explicitly schema-qualified. These names are usually configured at the login level, such as when connecting to a PostgreSQL database, the default “schema” is called “public”.
There are often cases where the default “schema” cannot be set via the login itself and instead would usefully be configured each time a connection is made, using a statement such as “SET SEARCH_PATH” on PostgreSQL or “ALTER SESSION” on Oracle Database. These approaches may be achieved by using the PoolEvents.connect() event, which allows access to the DBAPI connection when it is first created. For example, to set the Oracle Database CURRENT_SCHEMA variable to an alternate name:
from sqlalchemy import event
from sqlalchemy import create_engine

engine = create_engine(
    "oracle+oracledb://scott:tiger@localhost:1521?service_name=freepdb1"
)


@event.listens_for(engine, "connect", insert=True)
def set_current_schema(dbapi_connection, connection_record):
    cursor_obj = dbapi_connection.cursor()
    cursor_obj.execute("ALTER SESSION SET CURRENT_SCHEMA=%s" % schema_name)
    cursor_obj.close()
Above, the set_current_schema() event handler will take place immediately when the above Engine first connects; as the event is “inserted” into the beginning of the handler list, it will also take place before the dialect’s own event handlers are run, in particular including the one that will determine the “default schema” for the connection.
For other databases, consult the database and/or dialect documentation for specific information regarding how default schemas are configured.
Changed in version 1.4.0b2: The above recipe now works without the need to establish additional event handlers.
See also
Setting Alternate Search Paths on Connect - in the PostgreSQL dialect documentation.
Schemas and Reflection
The schema feature of SQLAlchemy interacts with the table reflection feature introduced at Reflecting Database Objects. See the section Reflecting Tables from Other Schemas for additional details on how this works.
Backend-Specific Options
Table supports database-specific options. For example, MySQL has different table backend types, including “MyISAM” and “InnoDB”. This can be expressed with Table using mysql_engine:
addresses = Table(
    "engine_email_addresses",
    metadata_obj,
    Column("address_id", Integer, primary_key=True),
    Column("remote_user_id", Integer, ForeignKey(users.c.user_id)),
    Column("email_address", String(20)),
    mysql_engine="InnoDB",
)
Other backends may support table-level options as well - these would be described in the individual documentation sections for each dialect.
Column, Table, MetaData API
Object NameDescriptionColumnRepresents a column in a database table.insert_sentinel([name, type_], *, [default, omit_from_statements])Provides a surrogate Column that will act as a dedicated insert sentinel column, allowing efficient bulk inserts with deterministic RETURNING sorting for tables that don’t otherwise have qualifying primary key configurations.MetaDataA collection of Table objects and their associated schema constructs.SchemaConstSchemaItemBase class for items that define a database schema.TableRepresent a table in a database.attribute sqlalchemy.schema.sqlalchemy.schema.sqlalchemy.schema.BLANK_SCHEMA
Refers to SchemaConst.BLANK_SCHEMA.
attribute sqlalchemy.schema.sqlalchemy.schema.sqlalchemy.schema.RETAIN_SCHEMA
Refers to SchemaConst.RETAIN_SCHEMA
class sqlalchemy.schema.Column
Represents a column in a database table.
Members
__eq__(), __init__(), __le__(), __lt__(), __ne__(), all_(), anon_key_label, anon_label, any_(), argument_for(), asc(), between(), bitwise_and(), bitwise_lshift(), bitwise_not(), bitwise_or(), bitwise_rshift(), bitwise_xor(), bool_op(), cast(), collate(), compare(), compile(), concat(), contains(), copy(), desc(), dialect_kwargs, dialect_options, distinct(), endswith(), expression, foreign_keys, get_children(), icontains(), iendswith(), ilike(), in_(), index, info, inherit_cache, is_(), is_distinct_from(), is_not(), is_not_distinct_from(), isnot(), isnot_distinct_from(), istartswith(), key, kwargs, label(), like(), match(), not_ilike(), not_in(), not_like(), notilike(), notin_(), notlike(), nulls_first(), nulls_last(), nullsfirst(), nullslast(), op(), operate(), params(), proxy_set, references(), regexp_match(), regexp_replace(), reverse_operate(), self_group(), shares_lineage(), startswith(), timetuple, unique, unique_params()
Class signature
class sqlalchemy.schema.Column (sqlalchemy.sql.expression.DialectKWArgs, sqlalchemy.schema.SchemaItem, sqlalchemy.sql.expression.ColumnClause)
method sqlalchemy.schema.Column.__eq__(other: Any) → ColumnOperators
inherited from the sqlalchemy.sql.expression.ColumnOperators.__eq__ method of ColumnOperators
Implement the == operator.
In a column context, produces the clause a = b. If the target is None, produces a IS NULL.
method sqlalchemy.schema.Column.__init__(_Column__name_pos: str | _TypeEngineArgument[_T] | SchemaEventTarget | None = None, _Column__type_pos: _TypeEngineArgument[_T] | SchemaEventTarget | None = None, *args: SchemaEventTarget, name: str | None = None, type_: _TypeEngineArgument[_T] | None = None, autoincrement: _AutoIncrementType = 'auto', default: Any | None = _NoArg.NO_ARG, insert_default: Any | None = _NoArg.NO_ARG, doc: str | None = None, key: str | None = None, index: bool | None = None, unique: bool | None = None, info: _InfoType | None = None, nullable: bool | Literal[SchemaConst.NULL_UNSPECIFIED] | None = SchemaConst.NULL_UNSPECIFIED, onupdate: Any | None = None, primary_key: bool = False, server_default: _ServerDefaultArgument | None = None, server_onupdate: _ServerOnUpdateArgument | None = None, quote: bool | None = None, system: bool = False, comment: str | None = None, insert_sentinel: bool = False, _omit_from_statements: bool = False, _proxies: Any | None = None, **dialect_kwargs: Any)
Construct a new Column object.
Parameters:
• name – 
The name of this column as represented in the database. This argument may be the first positional argument, or specified via keyword.
Names which contain no upper case characters will be treated as case insensitive names, and will not be quoted unless they are a reserved word. Names with any number of upper case characters will be quoted and sent exactly. Note that this behavior applies even for databases which standardize upper case names as case insensitive such as Oracle Database.
The name field may be omitted at construction time and applied later, at any time before the Column is associated with a Table. This is to support convenient usage within the declarative extension.
• type_ – 
The column’s type, indicated using an instance which subclasses TypeEngine. If no arguments are required for the type, the class of the type can be sent as well, e.g.:
# use a type with arguments
Column("data", String(50))

# use no arguments
Column("level", Integer)
•  The type argument may be the second positional argument or specified by keyword.
If the type is None or is omitted, it will first default to the special type NullType. If and when this Column is made to refer to another column using ForeignKey and/or ForeignKeyConstraint, the type of the remote-referenced column will be copied to this column as well, at the moment that the foreign key is resolved against that remote Column object.
•  *args – Additional positional arguments include various SchemaItem derived constructs which will be applied as options to the column. These include instances of Constraint, ForeignKey, ColumnDefault, Sequence, Computed Identity. In some cases an equivalent keyword argument is available such as server_default, default and unique.
•  autoincrement – 
Set up “auto increment” semantics for an integer primary key column with no foreign key dependencies (see later in this docstring for a more specific definition). This may influence the DDL that will be emitted for this column during a table create, as well as how the column will be considered when INSERT statements are compiled and executed.
The default value is the string "auto", which indicates that a single-column (i.e. non-composite) primary key that is of an INTEGER type with no other client-side or server-side default constructs indicated should receive auto increment semantics automatically. Other values include True (force this column to have auto-increment semantics for a composite primary key as well), False (this column should never have auto-increment semantics), and the string "ignore_fk" (special-case for foreign key columns, see below).
The term “auto increment semantics” refers both to the kind of DDL that will be emitted for the column within a CREATE TABLE statement, when methods such as MetaData.create_all() and Table.create() are invoked, as well as how the column will be considered when an INSERT statement is compiled and emitted to the database:
• DDL rendering (i.e. MetaData.create_all(), Table.create()): When used on a Column that has no other default-generating construct associated with it (such as a Sequence or Identity construct), the parameter will imply that database-specific keywords such as PostgreSQL SERIAL, MySQL AUTO_INCREMENT, or IDENTITY on SQL Server should also be rendered. Not every database backend has an “implied” default generator available; for example the Oracle Database backends alway needs an explicit construct such as Identity to be included with a Column in order for the DDL rendered to include auto-generating constructs to also be produced in the database.
• INSERT semantics (i.e. when a insert() construct is compiled into a SQL string and is then executed on a database using Connection.execute() or equivalent): A single-row INSERT statement will be known to produce a new integer primary key value automatically for this column, which will be accessible after the statement is invoked via the CursorResult.inserted_primary_key attribute upon the Result object. This also applies towards use of the ORM when ORM-mapped objects are persisted to the database, indicating that a new integer primary key will be available to become part of the identity key for that object. This behavior takes place regardless of what DDL constructs are associated with the Column and is independent of the “DDL Rendering” behavior discussed in the previous note above.
The parameter may be set to True to indicate that a column which is part of a composite (i.e. multi-column) primary key should have autoincrement semantics, though note that only one column within a primary key may have this setting. It can also be set to True to indicate autoincrement semantics on a column that has a client-side or server-side default configured, however note that not all dialects can accommodate all styles of default as an “autoincrement”. It can also be set to False on a single-column primary key that has a datatype of INTEGER in order to disable auto increment semantics for that column.
The setting only has an effect for columns which are:
• Integer derived (i.e. INT, SMALLINT, BIGINT).
• Part of the primary key
• Not referring to another column via ForeignKey, unless the value is specified as 'ignore_fk':
• # turn on autoincrement for this column despite
• # the ForeignKey()
• Column(
•     "id",
•     ForeignKey("other.id"),
•     primary_key=True,
•     autoincrement="ignore_fk",
)
•  It is typically not desirable to have “autoincrement” enabled on a column that refers to another via foreign key, as such a column is required to refer to a value that originates from elsewhere.
The setting has these effects on columns that meet the above criteria:
• DDL issued for the column, if the column does not already include a default generating construct supported by the backend such as Identity, will include database-specific keywords intended to signify this column as an “autoincrement” column for specific backends. Behavior for primary SQLAlchemy dialects includes:
o AUTO INCREMENT on MySQL and MariaDB
o SERIAL on PostgreSQL
o IDENTITY on MS-SQL - this occurs even without the Identity construct as the Column.autoincrement parameter pre-dates this construct.
o SQLite - SQLite integer primary key columns are implicitly “auto incrementing” and no additional keywords are rendered; to render the special SQLite keyword AUTOINCREMENT is not included as this is unnecessary and not recommended by the database vendor. See the section SQLite Auto Incrementing Behavior for more background.
o Oracle Database - The Oracle Database dialects have no default “autoincrement” feature available at this time, instead the Identity construct is recommended to achieve this (the Sequence construct may also be used).
o Third-party dialects - consult those dialects’ documentation for details on their specific behaviors.
• When a single-row insert() construct is compiled and executed, which does not set the Insert.inline() modifier, newly generated primary key values for this column will be automatically retrieved upon statement execution using a method specific to the database driver in use:
o MySQL, SQLite - calling upon cursor.lastrowid() (see https://www.python.org/dev/peps/pep-0249/#lastrowid)
o PostgreSQL, SQL Server, Oracle Database - use RETURNING or an equivalent construct when rendering an INSERT statement, and then retrieving the newly generated primary key values after execution
o PostgreSQL, Oracle Database for Table objects that set Table.implicit_returning to False - for a Sequence only, the Sequence is invoked explicitly before the INSERT statement takes place so that the newly generated primary key value is available to the client
o SQL Server for Table objects that set Table.implicit_returning to False - the SELECT scope_identity() construct is used after the INSERT statement is invoked to retrieve the newly generated primary key value.
o Third-party dialects - consult those dialects’ documentation for details on their specific behaviors.
• For multiple-row insert() constructs invoked with a list of parameters (i.e. “executemany” semantics), primary-key retrieving behaviors are generally disabled, however there may be special APIs that may be used to retrieve lists of new primary key values for an “executemany”, such as the psycopg2 “fast insertmany” feature. Such features are very new and may not yet be well covered in documentation.
•  default – 
A scalar, Python callable, or ColumnElement expression representing the default value for this column, which will be invoked upon insert if this column is otherwise not specified in the VALUES clause of the insert. This is a shortcut to using ColumnDefault as a positional argument; see that class for full detail on the structure of the argument.
Contrast this argument to Column.server_default which creates a default generator on the database side.
See also
Column INSERT/UPDATE Defaults
•  insert_default – 
An alias of Column.default for compatibility with mapped_column().
•  doc – optional String that can be used by the ORM or similar to document attributes on the Python side. This attribute does not render SQL comments; use the Column.comment parameter for this purpose.
•  key – An optional string identifier which will identify this Column object on the Table. When a key is provided, this is the only identifier referencing the Column within the application, including ORM attribute mapping; the name field is used only when rendering SQL.
•  index – 
When True, indicates that a Index construct will be automatically generated for this Column, which will result in a “CREATE INDEX” statement being emitted for the Table when the DDL create operation is invoked.
Using this flag is equivalent to making use of the Index construct explicitly at the level of the Table construct itself:
Table(
    "some_table",
    metadata,
    Column("x", Integer),
    Index("ix_some_table_x", "x"),
)
•  To add the Index.unique flag to the Index, set both the Column.unique and Column.index flags to True simultaneously, which will have the effect of rendering the “CREATE UNIQUE INDEX” DDL instruction instead of “CREATE INDEX”.
The name of the index is generated using the default naming convention which for the Index construct is of the form ix_<tablename>_<columnname>.
As this flag is intended only as a convenience for the common case of adding a single-column, default configured index to a table definition, explicit use of the Index construct should be preferred for most use cases, including composite indexes that encompass more than one column, indexes with SQL expressions or ordering, backend-specific index configuration options, and indexes that use a specific name.
Note
the Column.index attribute on Column does not indicate if this column is indexed or not, only if this flag was explicitly set here. To view indexes on a column, view the Table.indexes collection or use Inspector.get_indexes().
See also
Indexes
Configuring Constraint Naming Conventions
Column.unique
•  info – Optional data dictionary which will be populated into the SchemaItem.info attribute of this object.
•  nullable – 
When set to False, will cause the “NOT NULL” phrase to be added when generating DDL for the column. When True, will normally generate nothing (in SQL this defaults to “NULL”), except in some very specific backend-specific edge cases where “NULL” may render explicitly. Defaults to True unless Column.primary_key is also True or the column specifies a Identity, in which case it defaults to False. This parameter is only used when issuing CREATE TABLE statements.
Note
When the column specifies a Identity this parameter is in general ignored by the DDL compiler. The PostgreSQL database allows nullable identity column by setting this parameter to True explicitly.
•  onupdate – 
A scalar, Python callable, or ClauseElement representing a default value to be applied to the column within UPDATE statements, which will be invoked upon update if this column is not present in the SET clause of the update. This is a shortcut to using ColumnDefault as a positional argument with for_update=True.
See also
Column INSERT/UPDATE Defaults - complete discussion of onupdate
•  primary_key – If True, marks this column as a primary key column. Multiple columns can have this flag set to specify composite primary keys. As an alternative, the primary key of a Table can be specified via an explicit PrimaryKeyConstraint object.
•  server_default – 
A FetchedValue instance, str, Unicode or text() construct representing the DDL DEFAULT value for the column.
String types will be emitted as-is, surrounded by single quotes:
Column("x", Text, server_default="val")
will render:
x TEXT DEFAULT 'val'
A text() expression will be rendered as-is, without quotes:
Column("y", DateTime, server_default=text("NOW()"))
will render:
y DATETIME DEFAULT NOW()
Strings and text() will be converted into a DefaultClause object upon initialization.
This parameter can also accept complex combinations of contextually valid SQLAlchemy expressions or constructs:
from sqlalchemy import create_engine
from sqlalchemy import Table, Column, MetaData, ARRAY, Text
from sqlalchemy.dialects.postgresql import array

engine = create_engine(
    "postgresql+psycopg2://scott:tiger@localhost/mydatabase"
)
metadata_obj = MetaData()
tbl = Table(
    "foo",
    metadata_obj,
    Column(
        "bar", ARRAY(Text), server_default=array(["biz", "bang", "bash"])
    ),
)
metadata_obj.create_all(engine)
The above results in a table created with the following SQL:
CREATE TABLE foo (
    bar TEXT[] DEFAULT ARRAY['biz', 'bang', 'bash']
)
•  Use FetchedValue to indicate that an already-existing column will generate a default value on the database side which will be available to SQLAlchemy for post-fetch after inserts. This construct does not specify any DDL and the implementation is left to the database, such as via a trigger.
See also
Server-invoked DDL-Explicit Default Expressions - complete discussion of server side defaults
•  server_onupdate – 
A FetchedValue instance representing a database-side default generation function, such as a trigger. This indicates to SQLAlchemy that a newly generated value will be available after updates. This construct does not actually implement any kind of generation function within the database, which instead must be specified separately.
Warning
This directive does not currently produce MySQL’s “ON UPDATE CURRENT_TIMESTAMP()” clause. See Rendering ON UPDATE CURRENT TIMESTAMP for MySQL / MariaDB’s explicit_defaults_for_timestamp for background on how to produce this clause.
See also
Marking Implicitly Generated Values, timestamps, and Triggered Columns
•  quote – Force quoting of this column’s name on or off, corresponding to True or False. When left at its default of None, the column identifier will be quoted according to whether the name is case sensitive (identifiers with at least one upper case character are treated as case sensitive), or if it’s a reserved word. This flag is only needed to force quoting of a reserved word which is not known by the SQLAlchemy dialect.
•  unique – 
When True, and the Column.index parameter is left at its default value of False, indicates that a UniqueConstraint construct will be automatically generated for this Column, which will result in a “UNIQUE CONSTRAINT” clause referring to this column being included in the CREATE TABLE statement emitted, when the DDL create operation for the Table object is invoked.
When this flag is True while the Column.index parameter is simultaneously set to True, the effect instead is that a Index construct which includes the Index.unique parameter set to True is generated. See the documentation for Column.index for additional detail.
Using this flag is equivalent to making use of the UniqueConstraint construct explicitly at the level of the Table construct itself:
Table("some_table", metadata, Column("x", Integer), UniqueConstraint("x"))
• The UniqueConstraint.name parameter of the unique constraint object is left at its default value of None; in the absence of a naming convention for the enclosing MetaData, the UNIQUE CONSTRAINT construct will be emitted as unnamed, which typically invokes a database-specific naming convention to take place.
As this flag is intended only as a convenience for the common case of adding a single-column, default configured unique constraint to a table definition, explicit use of the UniqueConstraint construct should be preferred for most use cases, including composite constraints that encompass more than one column, backend-specific index configuration options, and constraints that use a specific name.
Note
the Column.unique attribute on Column does not indicate if this column has a unique constraint or not, only if this flag was explicitly set here. To view indexes and unique constraints that may involve this column, view the Table.indexes and/or Table.constraints collections or use Inspector.get_indexes() and/or Inspector.get_unique_constraints()
See also
UNIQUE Constraint
Configuring Constraint Naming Conventions
Column.index
• system – 
When True, indicates this is a “system” column, that is a column which is automatically made available by the database, and should not be included in the columns list for a CREATE TABLE statement.
For more elaborate scenarios where columns should be conditionally rendered differently on different backends, consider custom compilation rules for CreateColumn.
• comment – 
Optional string that will render an SQL comment on table creation.
Added in version 1.2: Added the Column.comment parameter to Column.
• insert_sentinel – 
Marks this Column as an insert sentinel used for optimizing the performance of the insertmanyvalues feature for tables that don’t otherwise have qualifying primary key configurations.
Added in version 2.0.10.
See also
insert_sentinel() - all in one helper for declaring sentinel columns
“Insert Many Values” Behavior for INSERT statements
Configuring Sentinel Columns
method sqlalchemy.schema.Column.__le__(other: Any) → ColumnOperators
inherited from the sqlalchemy.sql.expression.ColumnOperators.__le__ method of ColumnOperators
Implement the <= operator.
In a column context, produces the clause a <= b.
method sqlalchemy.schema.Column.__lt__(other: Any) → ColumnOperators
inherited from the sqlalchemy.sql.expression.ColumnOperators.__lt__ method of ColumnOperators
Implement the < operator.
In a column context, produces the clause a < b.
method sqlalchemy.schema.Column.__ne__(other: Any) → ColumnOperators
inherited from the sqlalchemy.sql.expression.ColumnOperators.__ne__ method of ColumnOperators
Implement the != operator.
In a column context, produces the clause a != b. If the target is None, produces a IS NOT NULL.
method sqlalchemy.schema.Column.all_() → ColumnOperators
inherited from the ColumnOperators.all_() method of ColumnOperators
Produce an all_() clause against the parent object.
See the documentation for all_() for examples.
Note
be sure to not confuse the newer ColumnOperators.all_() method with the legacy version of this method, the Comparator.all() method that’s specific to ARRAY, which uses a different calling style.
attribute sqlalchemy.schema.Column.anon_key_label
inherited from the ColumnElement.anon_key_label attribute of ColumnElement
Deprecated since version 1.4: The ColumnElement.anon_key_label attribute is now private, and the public accessor is deprecated.
attribute sqlalchemy.schema.Column.anon_label
inherited from the ColumnElement.anon_label attribute of ColumnElement
Deprecated since version 1.4: The ColumnElement.anon_label attribute is now private, and the public accessor is deprecated.
method sqlalchemy.schema.Column.any_() → ColumnOperators
inherited from the ColumnOperators.any_() method of ColumnOperators
Produce an any_() clause against the parent object.
See the documentation for any_() for examples.
Note
be sure to not confuse the newer ColumnOperators.any_() method with the legacy version of this method, the Comparator.any() method that’s specific to ARRAY, which uses a different calling style.
classmethod sqlalchemy.schema.Column.argument_for(dialect_name, argument_name, default)
inherited from the DialectKWArgs.argument_for() method of DialectKWArgs
Add a new kind of dialect-specific keyword argument for this class.
E.g.:
Index.argument_for("mydialect", "length", None)

some_index = Index("a", "b", mydialect_length=5)
The DialectKWArgs.argument_for() method is a per-argument way adding extra arguments to the DefaultDialect.construct_arguments dictionary. This dictionary provides a list of argument names accepted by various schema-level constructs on behalf of a dialect.
New dialects should typically specify this dictionary all at once as a data member of the dialect class. The use case for ad-hoc addition of argument names is typically for end-user code that is also using a custom compilation scheme which consumes the additional arguments.
Parameters:
• dialect_name – name of a dialect. The dialect must be locatable, else a NoSuchModuleError is raised. The dialect must also include an existing DefaultDialect.construct_arguments collection, indicating that it participates in the keyword-argument validation and default system, else ArgumentError is raised. If the dialect does not include this collection, then any keyword argument can be specified on behalf of this dialect already. All dialects packaged within SQLAlchemy include this collection, however for third party dialects, support may vary.
• argument_name – name of the parameter.
• default – default value of the parameter.
method sqlalchemy.schema.Column.asc() → ColumnOperators
inherited from the ColumnOperators.asc() method of ColumnOperators
Produce a asc() clause against the parent object.
method sqlalchemy.schema.Column.between(cleft: Any, cright: Any, symmetric: bool = False) → ColumnOperators
inherited from the ColumnOperators.between() method of ColumnOperators
Produce a between() clause against the parent object, given the lower and upper range.
method sqlalchemy.schema.Column.bitwise_and(other: Any) → ColumnOperators
inherited from the ColumnOperators.bitwise_and() method of ColumnOperators
Produce a bitwise AND operation, typically via the & operator.
Added in version 2.0.2.
See also
Bitwise Operators
method sqlalchemy.schema.Column.bitwise_lshift(other: Any) → ColumnOperators
inherited from the ColumnOperators.bitwise_lshift() method of ColumnOperators
Produce a bitwise LSHIFT operation, typically via the << operator.
Added in version 2.0.2.
See also
Bitwise Operators
method sqlalchemy.schema.Column.bitwise_not() → ColumnOperators
inherited from the ColumnOperators.bitwise_not() method of ColumnOperators
Produce a bitwise NOT operation, typically via the ~ operator.
Added in version 2.0.2.
See also
Bitwise Operators
method sqlalchemy.schema.Column.bitwise_or(other: Any) → ColumnOperators
inherited from the ColumnOperators.bitwise_or() method of ColumnOperators
Produce a bitwise OR operation, typically via the | operator.
Added in version 2.0.2.
See also
Bitwise Operators
method sqlalchemy.schema.Column.bitwise_rshift(other: Any) → ColumnOperators
inherited from the ColumnOperators.bitwise_rshift() method of ColumnOperators
Produce a bitwise RSHIFT operation, typically via the >> operator.
Added in version 2.0.2.
See also
Bitwise Operators
method sqlalchemy.schema.Column.bitwise_xor(other: Any) → ColumnOperators
inherited from the ColumnOperators.bitwise_xor() method of ColumnOperators
Produce a bitwise XOR operation, typically via the ^ operator, or # for PostgreSQL.
Added in version 2.0.2.
See also
Bitwise Operators
method sqlalchemy.schema.Column.bool_op(opstring: str, precedence: int = 0, python_impl: Callable[[...], Any] | None = None) → Callable[[Any], Operators]
inherited from the Operators.bool_op() method of Operators
Return a custom boolean operator.
This method is shorthand for calling Operators.op() and passing the Operators.op.is_comparison flag with True. A key advantage to using Operators.bool_op() is that when using column constructs, the “boolean” nature of the returned expression will be present for PEP 484 purposes.
See also
Operators.op()
method sqlalchemy.schema.Column.cast(type_: _TypeEngineArgument[_OPT]) → Cast[_OPT]
inherited from the ColumnElement.cast() method of ColumnElement
Produce a type cast, i.e. CAST(<expression> AS <type>).
This is a shortcut to the cast() function.
See also
Data Casts and Type Coercion
cast()
type_coerce()
method sqlalchemy.schema.Column.collate(collation: str) → ColumnOperators
inherited from the ColumnOperators.collate() method of ColumnOperators
Produce a collate() clause against the parent object, given the collation string.
See also
collate()
method sqlalchemy.schema.Column.compare(other: ClauseElement, **kw: Any) → bool
inherited from the ClauseElement.compare() method of ClauseElement
Compare this ClauseElement to the given ClauseElement.
Subclasses should override the default behavior, which is a straight identity comparison.
**kw are arguments consumed by subclass compare() methods and may be used to modify the criteria for comparison (see ColumnElement).
method sqlalchemy.schema.Column.compile(bind: _HasDialect | None = None, dialect: Dialect | None = None, **kw: Any) → Compiled
inherited from the CompilerElement.compile() method of CompilerElement
Compile this SQL expression.
The return value is a Compiled object. Calling str() or unicode() on the returned value will yield a string representation of the result. The Compiled object also can return a dictionary of bind parameter names and values using the params accessor.
Parameters:
• bind – An Connection or Engine which can provide a Dialect in order to generate a Compiled object. If the bind and dialect parameters are both omitted, a default SQL compiler is used.
• column_keys – Used for INSERT and UPDATE statements, a list of column names which should be present in the VALUES clause of the compiled statement. If None, all columns from the target table object are rendered.
• dialect – A Dialect instance which can generate a Compiled object. This argument takes precedence over the bind argument.
• compile_kwargs – 
optional dictionary of additional parameters that will be passed through to the compiler within all “visit” methods. This allows any custom flag to be passed through to a custom compilation construct, for example. It is also used for the case of passing the literal_binds flag through:
from sqlalchemy.sql import table, column, select

t = table("t", column("x"))

s = select(t).where(t.c.x == 5)

print(s.compile(compile_kwargs={"literal_binds": True}))
• 
See also
How do I render SQL expressions as strings, possibly with bound parameters inlined?
method sqlalchemy.schema.Column.concat(other: Any) → ColumnOperators
inherited from the ColumnOperators.concat() method of ColumnOperators
Implement the ‘concat’ operator.
In a column context, produces the clause a || b, or uses the concat() operator on MySQL.
method sqlalchemy.schema.Column.contains(other: Any, **kw: Any) → ColumnOperators
inherited from the ColumnOperators.contains() method of ColumnOperators
Implement the ‘contains’ operator.
Produces a LIKE expression that tests against a match for the middle of a string value:
column LIKE '%' || <other> || '%'
E.g.:
stmt = select(sometable).where(sometable.c.column.contains("foobar"))
Since the operator uses LIKE, wildcard characters "%" and "_" that are present inside the <other> expression will behave like wildcards as well. For literal string values, the ColumnOperators.contains.autoescape flag may be set to True to apply escaping to occurrences of these characters within the string value so that they match as themselves and not as wildcard characters. Alternatively, the ColumnOperators.contains.escape parameter will establish a given character as an escape character which can be of use when the target expression is not a literal string.
Parameters:
• other – expression to be compared. This is usually a plain string value, but can also be an arbitrary SQL expression. LIKE wildcard characters % and _ are not escaped by default unless the ColumnOperators.contains.autoescape flag is set to True.
• autoescape – 
boolean; when True, establishes an escape character within the LIKE expression, then applies it to all occurrences of "%", "_" and the escape character itself within the comparison value, which is assumed to be a literal string and not a SQL expression.
An expression such as:
somecolumn.contains("foo%bar", autoescape=True)
Will render as:
somecolumn LIKE '%' || :param || '%' ESCAPE '/'
•  With the value of :param as "foo/%bar".
•  escape – 
a character which when given will render with the ESCAPE keyword to establish that character as the escape character. This character can then be placed preceding occurrences of % and _ to allow them to act as themselves and not wildcard characters.
An expression such as:
somecolumn.contains("foo/%bar", escape="^")
Will render as:
somecolumn LIKE '%' || :param || '%' ESCAPE '^'
The parameter may also be combined with ColumnOperators.contains.autoescape:
somecolumn.contains("foo%bar^bat", escape="^", autoescape=True)
• Where above, the given literal parameter will be converted to "foo^%bar^^bat" before being passed to the database.
See also
ColumnOperators.startswith()
ColumnOperators.endswith()
ColumnOperators.like()
method sqlalchemy.schema.Column.copy(**kw: Any) → Column[Any]
Deprecated since version 1.4: The Column.copy() method is deprecated and will be removed in a future release.
method sqlalchemy.schema.Column.desc() → ColumnOperators
inherited from the ColumnOperators.desc() method of ColumnOperators
Produce a desc() clause against the parent object.
attribute sqlalchemy.schema.Column.dialect_kwargs
inherited from the DialectKWArgs.dialect_kwargs attribute of DialectKWArgs
A collection of keyword arguments specified as dialect-specific options to this construct.
The arguments are present here in their original <dialect>_<kwarg> format. Only arguments that were actually passed are included; unlike the DialectKWArgs.dialect_options collection, which contains all options known by this dialect including defaults.
The collection is also writable; keys are accepted of the form <dialect>_<kwarg> where the value will be assembled into the list of options.
See also
DialectKWArgs.dialect_options - nested dictionary form
attribute sqlalchemy.schema.Column.dialect_options
inherited from the DialectKWArgs.dialect_options attribute of DialectKWArgs
A collection of keyword arguments specified as dialect-specific options to this construct.
This is a two-level nested registry, keyed to <dialect_name> and <argument_name>. For example, the postgresql_where argument would be locatable as:
arg = my_object.dialect_options["postgresql"]["where"]
Added in version 0.9.2.
See also
DialectKWArgs.dialect_kwargs - flat dictionary form
method sqlalchemy.schema.Column.distinct() → ColumnOperators
inherited from the ColumnOperators.distinct() method of ColumnOperators
Produce a distinct() clause against the parent object.
method sqlalchemy.schema.Column.endswith(other: Any, escape: str | None = None, autoescape: bool = False) → ColumnOperators
inherited from the ColumnOperators.endswith() method of ColumnOperators
Implement the ‘endswith’ operator.
Produces a LIKE expression that tests against a match for the end of a string value:
column LIKE '%' || <other>
E.g.:
stmt = select(sometable).where(sometable.c.column.endswith("foobar"))
Since the operator uses LIKE, wildcard characters "%" and "_" that are present inside the <other> expression will behave like wildcards as well. For literal string values, the ColumnOperators.endswith.autoescape flag may be set to True to apply escaping to occurrences of these characters within the string value so that they match as themselves and not as wildcard characters. Alternatively, the ColumnOperators.endswith.escape parameter will establish a given character as an escape character which can be of use when the target expression is not a literal string.
Parameters:
• other – expression to be compared. This is usually a plain string value, but can also be an arbitrary SQL expression. LIKE wildcard characters % and _ are not escaped by default unless the ColumnOperators.endswith.autoescape flag is set to True.
• autoescape – 
boolean; when True, establishes an escape character within the LIKE expression, then applies it to all occurrences of "%", "_" and the escape character itself within the comparison value, which is assumed to be a literal string and not a SQL expression.
An expression such as:
somecolumn.endswith("foo%bar", autoescape=True)
Will render as:
somecolumn LIKE '%' || :param ESCAPE '/'
•  With the value of :param as "foo/%bar".
•  escape – 
a character which when given will render with the ESCAPE keyword to establish that character as the escape character. This character can then be placed preceding occurrences of % and _ to allow them to act as themselves and not wildcard characters.
An expression such as:
somecolumn.endswith("foo/%bar", escape="^")
Will render as:
somecolumn LIKE '%' || :param ESCAPE '^'
The parameter may also be combined with ColumnOperators.endswith.autoescape:
somecolumn.endswith("foo%bar^bat", escape="^", autoescape=True)
• Where above, the given literal parameter will be converted to "foo^%bar^^bat" before being passed to the database.
See also
ColumnOperators.startswith()
ColumnOperators.contains()
ColumnOperators.like()
attribute sqlalchemy.schema.Column.expression
inherited from the ColumnElement.expression attribute of ColumnElement
Return a column expression.
Part of the inspection interface; returns self.
attribute sqlalchemy.schema.Column.foreign_keys: Set[ForeignKey] = frozenset({})
inherited from the ColumnElement.foreign_keys attribute of ColumnElement
A collection of all ForeignKey marker objects associated with this Column.
Each object is a member of a Table-wide ForeignKeyConstraint.
See also
Table.foreign_keys
method sqlalchemy.schema.Column.get_children(*, column_tables=False, **kw)
inherited from the ColumnClause.get_children() method of ColumnClause
Return immediate child HasTraverseInternals elements of this HasTraverseInternals.
This is used for visit traversal.
**kw may contain flags that change the collection that is returned, for example to return a subset of items in order to cut down on larger traversals, or to return child items from a different context (such as schema-level collections instead of clause-level).
method sqlalchemy.schema.Column.icontains(other: Any, **kw: Any) → ColumnOperators
inherited from the ColumnOperators.icontains() method of ColumnOperators
Implement the icontains operator, e.g. case insensitive version of ColumnOperators.contains().
Produces a LIKE expression that tests against an insensitive match for the middle of a string value:
lower(column) LIKE '%' || lower(<other>) || '%'
E.g.:
stmt = select(sometable).where(sometable.c.column.icontains("foobar"))
Since the operator uses LIKE, wildcard characters "%" and "_" that are present inside the <other> expression will behave like wildcards as well. For literal string values, the ColumnOperators.icontains.autoescape flag may be set to True to apply escaping to occurrences of these characters within the string value so that they match as themselves and not as wildcard characters. Alternatively, the ColumnOperators.icontains.escape parameter will establish a given character as an escape character which can be of use when the target expression is not a literal string.
Parameters:
• other – expression to be compared. This is usually a plain string value, but can also be an arbitrary SQL expression. LIKE wildcard characters % and _ are not escaped by default unless the ColumnOperators.icontains.autoescape flag is set to True.
• autoescape – 
boolean; when True, establishes an escape character within the LIKE expression, then applies it to all occurrences of "%", "_" and the escape character itself within the comparison value, which is assumed to be a literal string and not a SQL expression.
An expression such as:
somecolumn.icontains("foo%bar", autoescape=True)
Will render as:
lower(somecolumn) LIKE '%' || lower(:param) || '%' ESCAPE '/'
•  With the value of :param as "foo/%bar".
•  escape – 
a character which when given will render with the ESCAPE keyword to establish that character as the escape character. This character can then be placed preceding occurrences of % and _ to allow them to act as themselves and not wildcard characters.
An expression such as:
somecolumn.icontains("foo/%bar", escape="^")
Will render as:
lower(somecolumn) LIKE '%' || lower(:param) || '%' ESCAPE '^'
The parameter may also be combined with ColumnOperators.contains.autoescape:
somecolumn.icontains("foo%bar^bat", escape="^", autoescape=True)
• Where above, the given literal parameter will be converted to "foo^%bar^^bat" before being passed to the database.
See also
ColumnOperators.contains()
method sqlalchemy.schema.Column.iendswith(other: Any, escape: str | None = None, autoescape: bool = False) → ColumnOperators
inherited from the ColumnOperators.iendswith() method of ColumnOperators
Implement the iendswith operator, e.g. case insensitive version of ColumnOperators.endswith().
Produces a LIKE expression that tests against an insensitive match for the end of a string value:
lower(column) LIKE '%' || lower(<other>)
E.g.:
stmt = select(sometable).where(sometable.c.column.iendswith("foobar"))
Since the operator uses LIKE, wildcard characters "%" and "_" that are present inside the <other> expression will behave like wildcards as well. For literal string values, the ColumnOperators.iendswith.autoescape flag may be set to True to apply escaping to occurrences of these characters within the string value so that they match as themselves and not as wildcard characters. Alternatively, the ColumnOperators.iendswith.escape parameter will establish a given character as an escape character which can be of use when the target expression is not a literal string.
Parameters:
• other – expression to be compared. This is usually a plain string value, but can also be an arbitrary SQL expression. LIKE wildcard characters % and _ are not escaped by default unless the ColumnOperators.iendswith.autoescape flag is set to True.
• autoescape – 
boolean; when True, establishes an escape character within the LIKE expression, then applies it to all occurrences of "%", "_" and the escape character itself within the comparison value, which is assumed to be a literal string and not a SQL expression.
An expression such as:
somecolumn.iendswith("foo%bar", autoescape=True)
Will render as:
lower(somecolumn) LIKE '%' || lower(:param) ESCAPE '/'
•  With the value of :param as "foo/%bar".
•  escape – 
a character which when given will render with the ESCAPE keyword to establish that character as the escape character. This character can then be placed preceding occurrences of % and _ to allow them to act as themselves and not wildcard characters.
An expression such as:
somecolumn.iendswith("foo/%bar", escape="^")
Will render as:
lower(somecolumn) LIKE '%' || lower(:param) ESCAPE '^'
The parameter may also be combined with ColumnOperators.iendswith.autoescape:
somecolumn.endswith("foo%bar^bat", escape="^", autoescape=True)
• Where above, the given literal parameter will be converted to "foo^%bar^^bat" before being passed to the database.
See also
ColumnOperators.endswith()
method sqlalchemy.schema.Column.ilike(other: Any, escape: str | None = None) → ColumnOperators
inherited from the ColumnOperators.ilike() method of ColumnOperators
Implement the ilike operator, e.g. case insensitive LIKE.
In a column context, produces an expression either of the form:
lower(a) LIKE lower(other)
Or on backends that support the ILIKE operator:
a ILIKE other
E.g.:
stmt = select(sometable).where(sometable.c.column.ilike("%foobar%"))
Parameters:
• other – expression to be compared
• escape – 
optional escape character, renders the ESCAPE keyword, e.g.:
somecolumn.ilike("foo/%bar", escape="/")
• 
See also
ColumnOperators.like()
method sqlalchemy.schema.Column.in_(other: Any) → ColumnOperators
inherited from the ColumnOperators.in_() method of ColumnOperators
Implement the in operator.
In a column context, produces the clause column IN <other>.
The given parameter other may be:
• A list of literal values, e.g.:
stmt.where(column.in_([1, 2, 3]))
In this calling form, the list of items is converted to a set of bound parameters the same length as the list given:
WHERE COL IN (?, ?, ?)
A list of tuples may be provided if the comparison is against a tuple_() containing multiple expressions:
from sqlalchemy import tuple_

stmt.where(tuple_(col1, col2).in_([(1, 10), (2, 20), (3, 30)]))
An empty list, e.g.:
stmt.where(column.in_([]))
In this calling form, the expression renders an “empty set” expression. These expressions are tailored to individual backends and are generally trying to get an empty SELECT statement as a subquery. Such as on SQLite, the expression is:
WHERE col IN (SELECT 1 FROM (SELECT 1) WHERE 1!=1)
•  Changed in version 1.4: empty IN expressions now use an execution-time generated SELECT subquery in all cases.
•  A bound parameter, e.g. bindparam(), may be used if it includes the bindparam.expanding flag:
stmt.where(column.in_(bindparam("value", expanding=True)))
In this calling form, the expression renders a special non-SQL placeholder expression that looks like:
WHERE COL IN ([EXPANDING_value])
This placeholder expression is intercepted at statement execution time to be converted into the variable number of bound parameter form illustrated earlier. If the statement were executed as:
connection.execute(stmt, {"value": [1, 2, 3]})
The database would be passed a bound parameter for each value:
WHERE COL IN (?, ?, ?)
Added in version 1.2: added “expanding” bound parameters
If an empty list is passed, a special “empty list” expression, which is specific to the database in use, is rendered. On SQLite this would be:
WHERE COL IN (SELECT 1 FROM (SELECT 1) WHERE 1!=1)
•  Added in version 1.3: “expanding” bound parameters now support empty lists
•  a select() construct, which is usually a correlated scalar select:
stmt.where(
    column.in_(select(othertable.c.y).where(table.c.x == othertable.c.x))
)
In this calling form, ColumnOperators.in_() renders as given:
WHERE COL IN (SELECT othertable.y
FROM othertable WHERE othertable.x = table.x)
Parameters:
other – a list of literals, a select() construct, or a bindparam() construct that includes the bindparam.expanding flag set to True.
attribute sqlalchemy.schema.Column.index: bool | None
The value of the Column.index parameter.
Does not indicate if this Column is actually indexed or not; use Table.indexes.
See also
Table.indexes
attribute sqlalchemy.schema.Column.info
inherited from the SchemaItem.info attribute of SchemaItem
Info dictionary associated with the object, allowing user-defined data to be associated with this SchemaItem.
The dictionary is automatically generated when first accessed. It can also be specified in the constructor of some objects, such as Table and Column.
attribute sqlalchemy.schema.Column.inherit_cache: bool | None = True
Indicate if this HasCacheKey instance should make use of the cache key generation scheme used by its immediate superclass.
The attribute defaults to None, which indicates that a construct has not yet taken into account whether or not its appropriate for it to participate in caching; this is functionally equivalent to setting the value to False, except that a warning is also emitted.
This flag can be set to True on a particular class, if the SQL that corresponds to the object does not change based on attributes which are local to this class, and not its superclass.
See also
Enabling Caching Support for Custom Constructs - General guideslines for setting the HasCacheKey.inherit_cache attribute for third-party or user defined SQL constructs.
method sqlalchemy.schema.Column.is_(other: Any) → ColumnOperators
inherited from the ColumnOperators.is_() method of ColumnOperators
Implement the IS operator.
Normally, IS is generated automatically when comparing to a value of None, which resolves to NULL. However, explicit usage of IS may be desirable if comparing to boolean values on certain platforms.
See also
ColumnOperators.is_not()
method sqlalchemy.schema.Column.is_distinct_from(other: Any) → ColumnOperators
inherited from the ColumnOperators.is_distinct_from() method of ColumnOperators
Implement the IS DISTINCT FROM operator.
Renders “a IS DISTINCT FROM b” on most platforms; on some such as SQLite may render “a IS NOT b”.
method sqlalchemy.schema.Column.is_not(other: Any) → ColumnOperators
inherited from the ColumnOperators.is_not() method of ColumnOperators
Implement the IS NOT operator.
Normally, IS NOT is generated automatically when comparing to a value of None, which resolves to NULL. However, explicit usage of IS NOT may be desirable if comparing to boolean values on certain platforms.
Changed in version 1.4: The is_not() operator is renamed from isnot() in previous releases. The previous name remains available for backwards compatibility.
See also
ColumnOperators.is_()
method sqlalchemy.schema.Column.is_not_distinct_from(other: Any) → ColumnOperators
inherited from the ColumnOperators.is_not_distinct_from() method of ColumnOperators
Implement the IS NOT DISTINCT FROM operator.
Renders “a IS NOT DISTINCT FROM b” on most platforms; on some such as SQLite may render “a IS b”.
Changed in version 1.4: The is_not_distinct_from() operator is renamed from isnot_distinct_from() in previous releases. The previous name remains available for backwards compatibility.
method sqlalchemy.schema.Column.isnot(other: Any) → ColumnOperators
inherited from the ColumnOperators.isnot() method of ColumnOperators
Implement the IS NOT operator.
Normally, IS NOT is generated automatically when comparing to a value of None, which resolves to NULL. However, explicit usage of IS NOT may be desirable if comparing to boolean values on certain platforms.
Changed in version 1.4: The is_not() operator is renamed from isnot() in previous releases. The previous name remains available for backwards compatibility.
See also
ColumnOperators.is_()
method sqlalchemy.schema.Column.isnot_distinct_from(other: Any) → ColumnOperators
inherited from the ColumnOperators.isnot_distinct_from() method of ColumnOperators
Implement the IS NOT DISTINCT FROM operator.
Renders “a IS NOT DISTINCT FROM b” on most platforms; on some such as SQLite may render “a IS b”.
Changed in version 1.4: The is_not_distinct_from() operator is renamed from isnot_distinct_from() in previous releases. The previous name remains available for backwards compatibility.
method sqlalchemy.schema.Column.istartswith(other: Any, escape: str | None = None, autoescape: bool = False) → ColumnOperators
inherited from the ColumnOperators.istartswith() method of ColumnOperators
Implement the istartswith operator, e.g. case insensitive version of ColumnOperators.startswith().
Produces a LIKE expression that tests against an insensitive match for the start of a string value:
lower(column) LIKE lower(<other>) || '%'
E.g.:
stmt = select(sometable).where(sometable.c.column.istartswith("foobar"))
Since the operator uses LIKE, wildcard characters "%" and "_" that are present inside the <other> expression will behave like wildcards as well. For literal string values, the ColumnOperators.istartswith.autoescape flag may be set to True to apply escaping to occurrences of these characters within the string value so that they match as themselves and not as wildcard characters. Alternatively, the ColumnOperators.istartswith.escape parameter will establish a given character as an escape character which can be of use when the target expression is not a literal string.
Parameters:
• other – expression to be compared. This is usually a plain string value, but can also be an arbitrary SQL expression. LIKE wildcard characters % and _ are not escaped by default unless the ColumnOperators.istartswith.autoescape flag is set to True.
• autoescape – 
boolean; when True, establishes an escape character within the LIKE expression, then applies it to all occurrences of "%", "_" and the escape character itself within the comparison value, which is assumed to be a literal string and not a SQL expression.
An expression such as:
somecolumn.istartswith("foo%bar", autoescape=True)
Will render as:
lower(somecolumn) LIKE lower(:param) || '%' ESCAPE '/'
•  With the value of :param as "foo/%bar".
•  escape – 
a character which when given will render with the ESCAPE keyword to establish that character as the escape character. This character can then be placed preceding occurrences of % and _ to allow them to act as themselves and not wildcard characters.
An expression such as:
somecolumn.istartswith("foo/%bar", escape="^")
Will render as:
lower(somecolumn) LIKE lower(:param) || '%' ESCAPE '^'
The parameter may also be combined with ColumnOperators.istartswith.autoescape:
somecolumn.istartswith("foo%bar^bat", escape="^", autoescape=True)
• Where above, the given literal parameter will be converted to "foo^%bar^^bat" before being passed to the database.
See also
ColumnOperators.startswith()
attribute sqlalchemy.schema.Column.key: str = None
inherited from the ColumnElement.key attribute of ColumnElement
The ‘key’ that in some circumstances refers to this object in a Python namespace.
This typically refers to the “key” of the column as present in the .c collection of a selectable, e.g. sometable.c["somekey"] would return a Column with a .key of “somekey”.
attribute sqlalchemy.schema.Column.kwargs
inherited from the DialectKWArgs.kwargs attribute of DialectKWArgs
A synonym for DialectKWArgs.dialect_kwargs.
method sqlalchemy.schema.Column.label(name: str | None) → Label[_T]
inherited from the ColumnElement.label() method of ColumnElement
Produce a column label, i.e. <columnname> AS <name>.
This is a shortcut to the label() function.
If ‘name’ is None, an anonymous label name will be generated.
method sqlalchemy.schema.Column.like(other: Any, escape: str | None = None) → ColumnOperators
inherited from the ColumnOperators.like() method of ColumnOperators
Implement the like operator.
In a column context, produces the expression:
a LIKE other
E.g.:
stmt = select(sometable).where(sometable.c.column.like("%foobar%"))
Parameters:
• other – expression to be compared
• escape – 
optional escape character, renders the ESCAPE keyword, e.g.:
somecolumn.like("foo/%bar", escape="/")
• 
See also
ColumnOperators.ilike()
method sqlalchemy.schema.Column.match(other: Any, **kwargs: Any) → ColumnOperators
inherited from the ColumnOperators.match() method of ColumnOperators
Implements a database-specific ‘match’ operator.
ColumnOperators.match() attempts to resolve to a MATCH-like function or operator provided by the backend. Examples include:
• PostgreSQL - renders x @@ plainto_tsquery(y)
Changed in version 2.0: plainto_tsquery() is used instead of to_tsquery() for PostgreSQL now; for compatibility with other forms, see Full Text Search.
• MySQL - renders MATCH (x) AGAINST (y IN BOOLEAN MODE)
See also
match - MySQL specific construct with additional features.
• Oracle Database - renders CONTAINS(x, y)
• other backends may provide special implementations.
• Backends without any special implementation will emit the operator as “MATCH”. This is compatible with SQLite, for example.
method sqlalchemy.schema.Column.not_ilike(other: Any, escape: str | None = None) → ColumnOperators
inherited from the ColumnOperators.not_ilike() method of ColumnOperators
implement the NOT ILIKE operator.
This is equivalent to using negation with ColumnOperators.ilike(), i.e. ~x.ilike(y).
Changed in version 1.4: The not_ilike() operator is renamed from notilike() in previous releases. The previous name remains available for backwards compatibility.
See also
ColumnOperators.ilike()
method sqlalchemy.schema.Column.not_in(other: Any) → ColumnOperators
inherited from the ColumnOperators.not_in() method of ColumnOperators
implement the NOT IN operator.
This is equivalent to using negation with ColumnOperators.in_(), i.e. ~x.in_(y).
In the case that other is an empty sequence, the compiler produces an “empty not in” expression. This defaults to the expression “1 = 1” to produce true in all cases. The create_engine.empty_in_strategy may be used to alter this behavior.
Changed in version 1.4: The not_in() operator is renamed from notin_() in previous releases. The previous name remains available for backwards compatibility.
Changed in version 1.2: The ColumnOperators.in_() and ColumnOperators.not_in() operators now produce a “static” expression for an empty IN sequence by default.
See also
ColumnOperators.in_()
method sqlalchemy.schema.Column.not_like(other: Any, escape: str | None = None) → ColumnOperators
inherited from the ColumnOperators.not_like() method of ColumnOperators
implement the NOT LIKE operator.
This is equivalent to using negation with ColumnOperators.like(), i.e. ~x.like(y).
Changed in version 1.4: The not_like() operator is renamed from notlike() in previous releases. The previous name remains available for backwards compatibility.
See also
ColumnOperators.like()
method sqlalchemy.schema.Column.notilike(other: Any, escape: str | None = None) → ColumnOperators
inherited from the ColumnOperators.notilike() method of ColumnOperators
implement the NOT ILIKE operator.
This is equivalent to using negation with ColumnOperators.ilike(), i.e. ~x.ilike(y).
Changed in version 1.4: The not_ilike() operator is renamed from notilike() in previous releases. The previous name remains available for backwards compatibility.
See also
ColumnOperators.ilike()
method sqlalchemy.schema.Column.notin_(other: Any) → ColumnOperators
inherited from the ColumnOperators.notin_() method of ColumnOperators
implement the NOT IN operator.
This is equivalent to using negation with ColumnOperators.in_(), i.e. ~x.in_(y).
In the case that other is an empty sequence, the compiler produces an “empty not in” expression. This defaults to the expression “1 = 1” to produce true in all cases. The create_engine.empty_in_strategy may be used to alter this behavior.
Changed in version 1.4: The not_in() operator is renamed from notin_() in previous releases. The previous name remains available for backwards compatibility.
Changed in version 1.2: The ColumnOperators.in_() and ColumnOperators.not_in() operators now produce a “static” expression for an empty IN sequence by default.
See also
ColumnOperators.in_()
method sqlalchemy.schema.Column.notlike(other: Any, escape: str | None = None) → ColumnOperators
inherited from the ColumnOperators.notlike() method of ColumnOperators
implement the NOT LIKE operator.
This is equivalent to using negation with ColumnOperators.like(), i.e. ~x.like(y).
Changed in version 1.4: The not_like() operator is renamed from notlike() in previous releases. The previous name remains available for backwards compatibility.
See also
ColumnOperators.like()
method sqlalchemy.schema.Column.nulls_first() → ColumnOperators
inherited from the ColumnOperators.nulls_first() method of ColumnOperators
Produce a nulls_first() clause against the parent object.
Changed in version 1.4: The nulls_first() operator is renamed from nullsfirst() in previous releases. The previous name remains available for backwards compatibility.
method sqlalchemy.schema.Column.nulls_last() → ColumnOperators
inherited from the ColumnOperators.nulls_last() method of ColumnOperators
Produce a nulls_last() clause against the parent object.
Changed in version 1.4: The nulls_last() operator is renamed from nullslast() in previous releases. The previous name remains available for backwards compatibility.
method sqlalchemy.schema.Column.nullsfirst() → ColumnOperators
inherited from the ColumnOperators.nullsfirst() method of ColumnOperators
Produce a nulls_first() clause against the parent object.
Changed in version 1.4: The nulls_first() operator is renamed from nullsfirst() in previous releases. The previous name remains available for backwards compatibility.
method sqlalchemy.schema.Column.nullslast() → ColumnOperators
inherited from the ColumnOperators.nullslast() method of ColumnOperators
Produce a nulls_last() clause against the parent object.
Changed in version 1.4: The nulls_last() operator is renamed from nullslast() in previous releases. The previous name remains available for backwards compatibility.
method sqlalchemy.schema.Column.op(opstring: str, precedence: int = 0, is_comparison: bool = False, return_type: Type[TypeEngine[Any]] | TypeEngine[Any] | None = None, python_impl: Callable[..., Any] | None = None) → Callable[[Any], Operators]
inherited from the Operators.op() method of Operators
Produce a generic operator function.
e.g.:
somecolumn.op("*")(5)
produces:
somecolumn * 5
This function can also be used to make bitwise operators explicit. For example:
somecolumn.op("&")(0xFF)
is a bitwise AND of the value in somecolumn.
Parameters:
• opstring – a string which will be output as the infix operator between this element and the expression passed to the generated function.
• precedence – 
precedence which the database is expected to apply to the operator in SQL expressions. This integer value acts as a hint for the SQL compiler to know when explicit parenthesis should be rendered around a particular operation. A lower number will cause the expression to be parenthesized when applied against another operator with higher precedence. The default value of 0 is lower than all operators except for the comma (,) and AS operators. A value of 100 will be higher or equal to all operators, and -100 will be lower than or equal to all operators.
See also
I’m using op() to generate a custom operator and my parenthesis are not coming out correctly - detailed description of how the SQLAlchemy SQL compiler renders parenthesis
• is_comparison – 
legacy; if True, the operator will be considered as a “comparison” operator, that is which evaluates to a boolean true/false value, like ==, >, etc. This flag is provided so that ORM relationships can establish that the operator is a comparison operator when used in a custom join condition.
Using the is_comparison parameter is superseded by using the Operators.bool_op() method instead; this more succinct operator sets this parameter automatically, but also provides correct PEP 484 typing support as the returned object will express a “boolean” datatype, i.e. BinaryExpression[bool].
• return_type – a TypeEngine class or object that will force the return type of an expression produced by this operator to be of that type. By default, operators that specify Operators.op.is_comparison will resolve to Boolean, and those that do not will be of the same type as the left-hand operand.
• python_impl – 
an optional Python function that can evaluate two Python values in the same way as this operator works when run on the database server. Useful for in-Python SQL expression evaluation functions, such as for ORM hybrid attributes, and the ORM “evaluator” used to match objects in a session after a multi-row update or delete.
e.g.:
>>> expr = column("x").op("+", python_impl=lambda a, b: a + b)("y")
The operator for the above expression will also work for non-SQL left and right objects:
>>> expr.operator(5, 10)
15
• Added in version 2.0.
See also
Operators.bool_op()
Redefining and Creating New Operators
Using custom operators in join conditions
method sqlalchemy.schema.Column.operate(op: OperatorType, *other: Any, **kwargs: Any) → ColumnElement[Any]
inherited from the ColumnElement.operate() method of ColumnElement
Operate on an argument.
This is the lowest level of operation, raises NotImplementedError by default.
Overriding this on a subclass can allow common behavior to be applied to all operations. For example, overriding ColumnOperators to apply func.lower() to the left and right side:
class MyComparator(ColumnOperators):
    def operate(self, op, other, **kwargs):
        return op(func.lower(self), func.lower(other), **kwargs)
Parameters:
• op – Operator callable.
• *other – the ‘other’ side of the operation. Will be a single scalar for most operations.
• **kwargs – modifiers. These may be passed by special operators such as ColumnOperators.contains().
method sqlalchemy.schema.Column.params(*optionaldict, **kwargs)
inherited from the Immutable.params() method of Immutable
Return a copy with bindparam() elements replaced.
Returns a copy of this ClauseElement with bindparam() elements replaced with values taken from the given dictionary:
>>> clause = column("x") + bindparam("foo")
>>> print(clause.compile().params)
{'foo':None}
>>> print(clause.params({"foo": 7}).compile().params)
{'foo':7}
attribute sqlalchemy.schema.Column.proxy_set: util.generic_fn_descriptor[FrozenSet[Any]]
inherited from the ColumnElement.proxy_set attribute of ColumnElement
set of all columns we are proxying
as of 2.0 this is explicitly deannotated columns. previously it was effectively deannotated columns but wasn’t enforced. annotated columns should basically not go into sets if at all possible because their hashing behavior is very non-performant.
method sqlalchemy.schema.Column.references(column: Column[Any]) → bool
Return True if this Column references the given column via foreign key.
method sqlalchemy.schema.Column.regexp_match(pattern: Any, flags: str | None = None) → ColumnOperators
inherited from the ColumnOperators.regexp_match() method of ColumnOperators
Implements a database-specific ‘regexp match’ operator.
E.g.:
stmt = select(table.c.some_column).where(
    table.c.some_column.regexp_match("^(b|c)")
)
ColumnOperators.regexp_match() attempts to resolve to a REGEXP-like function or operator provided by the backend, however the specific regular expression syntax and flags available are not backend agnostic.
Examples include:
• PostgreSQL - renders x ~ y or x !~ y when negated.
• Oracle Database - renders REGEXP_LIKE(x, y)
• SQLite - uses SQLite’s REGEXP placeholder operator and calls into the Python re.match() builtin.
• other backends may provide special implementations.
• Backends without any special implementation will emit the operator as “REGEXP” or “NOT REGEXP”. This is compatible with SQLite and MySQL, for example.
Regular expression support is currently implemented for Oracle Database, PostgreSQL, MySQL and MariaDB. Partial support is available for SQLite. Support among third-party dialects may vary.
Parameters:
• pattern – The regular expression pattern string or column clause.
• flags – Any regular expression string flags to apply, passed as plain Python string only. These flags are backend specific. Some backends, like PostgreSQL and MariaDB, may alternatively specify the flags as part of the pattern. When using the ignore case flag ‘i’ in PostgreSQL, the ignore case regexp match operator ~* or !~* will be used.
Added in version 1.4.
Changed in version 1.4.48,: 2.0.18 Note that due to an implementation error, the “flags” parameter previously accepted SQL expression objects such as column expressions in addition to plain Python strings. This implementation did not work correctly with caching and was removed; strings only should be passed for the “flags” parameter, as these flags are rendered as literal inline values within SQL expressions.
See also
ColumnOperators.regexp_replace()
method sqlalchemy.schema.Column.regexp_replace(pattern: Any, replacement: Any, flags: str | None = None) → ColumnOperators
inherited from the ColumnOperators.regexp_replace() method of ColumnOperators
Implements a database-specific ‘regexp replace’ operator.
E.g.:
stmt = select(
    table.c.some_column.regexp_replace("b(..)", "XY", flags="g")
)
ColumnOperators.regexp_replace() attempts to resolve to a REGEXP_REPLACE-like function provided by the backend, that usually emit the function REGEXP_REPLACE(). However, the specific regular expression syntax and flags available are not backend agnostic.
Regular expression replacement support is currently implemented for Oracle Database, PostgreSQL, MySQL 8 or greater and MariaDB. Support among third-party dialects may vary.
Parameters:
• pattern – The regular expression pattern string or column clause.
• pattern – The replacement string or column clause.
• flags – Any regular expression string flags to apply, passed as plain Python string only. These flags are backend specific. Some backends, like PostgreSQL and MariaDB, may alternatively specify the flags as part of the pattern.
Added in version 1.4.
Changed in version 1.4.48,: 2.0.18 Note that due to an implementation error, the “flags” parameter previously accepted SQL expression objects such as column expressions in addition to plain Python strings. This implementation did not work correctly with caching and was removed; strings only should be passed for the “flags” parameter, as these flags are rendered as literal inline values within SQL expressions.
See also
ColumnOperators.regexp_match()
method sqlalchemy.schema.Column.reverse_operate(op: OperatorType, other: Any, **kwargs: Any) → ColumnElement[Any]
inherited from the ColumnElement.reverse_operate() method of ColumnElement
Reverse operate on an argument.
Usage is the same as operate().
method sqlalchemy.schema.Column.self_group(against: OperatorType | None = None) → ColumnElement[Any]
inherited from the ColumnElement.self_group() method of ColumnElement
Apply a ‘grouping’ to this ClauseElement.
This method is overridden by subclasses to return a “grouping” construct, i.e. parenthesis. In particular it’s used by “binary” expressions to provide a grouping around themselves when placed into a larger expression, as well as by select() constructs when placed into the FROM clause of another select(). (Note that subqueries should be normally created using the Select.alias() method, as many platforms require nested SELECT statements to be named).
As expressions are composed together, the application of self_group() is automatic - end-user code should never need to use this method directly. Note that SQLAlchemy’s clause constructs take operator precedence into account - so parenthesis might not be needed, for example, in an expression like x OR (y AND z) - AND takes precedence over OR.
The base self_group() method of ClauseElement just returns self.
method sqlalchemy.schema.Column.shares_lineage(othercolumn: ColumnElement[Any]) → bool
inherited from the ColumnElement.shares_lineage() method of ColumnElement
Return True if the given ColumnElement has a common ancestor to this ColumnElement.
method sqlalchemy.schema.Column.startswith(other: Any, escape: str | None = None, autoescape: bool = False) → ColumnOperators
inherited from the ColumnOperators.startswith() method of ColumnOperators
Implement the startswith operator.
Produces a LIKE expression that tests against a match for the start of a string value:
column LIKE <other> || '%'
E.g.:
stmt = select(sometable).where(sometable.c.column.startswith("foobar"))
Since the operator uses LIKE, wildcard characters "%" and "_" that are present inside the <other> expression will behave like wildcards as well. For literal string values, the ColumnOperators.startswith.autoescape flag may be set to True to apply escaping to occurrences of these characters within the string value so that they match as themselves and not as wildcard characters. Alternatively, the ColumnOperators.startswith.escape parameter will establish a given character as an escape character which can be of use when the target expression is not a literal string.
Parameters:
• other – expression to be compared. This is usually a plain string value, but can also be an arbitrary SQL expression. LIKE wildcard characters % and _ are not escaped by default unless the ColumnOperators.startswith.autoescape flag is set to True.
• autoescape – 
boolean; when True, establishes an escape character within the LIKE expression, then applies it to all occurrences of "%", "_" and the escape character itself within the comparison value, which is assumed to be a literal string and not a SQL expression.
An expression such as:
somecolumn.startswith("foo%bar", autoescape=True)
Will render as:
somecolumn LIKE :param || '%' ESCAPE '/'
•  With the value of :param as "foo/%bar".
•  escape – 
a character which when given will render with the ESCAPE keyword to establish that character as the escape character. This character can then be placed preceding occurrences of % and _ to allow them to act as themselves and not wildcard characters.
An expression such as:
somecolumn.startswith("foo/%bar", escape="^")
Will render as:
somecolumn LIKE :param || '%' ESCAPE '^'
The parameter may also be combined with ColumnOperators.startswith.autoescape:
somecolumn.startswith("foo%bar^bat", escape="^", autoescape=True)
• Where above, the given literal parameter will be converted to "foo^%bar^^bat" before being passed to the database.
See also
ColumnOperators.endswith()
ColumnOperators.contains()
ColumnOperators.like()
attribute sqlalchemy.schema.Column.timetuple: Literal[None] = None
inherited from the ColumnOperators.timetuple attribute of ColumnOperators
Hack, allows datetime objects to be compared on the LHS.
attribute sqlalchemy.schema.Column.unique: bool | None
The value of the Column.unique parameter.
Does not indicate if this Column is actually subject to a unique constraint or not; use Table.indexes and Table.constraints.
See also
Table.indexes
Table.constraints.
method sqlalchemy.schema.Column.unique_params(*optionaldict, **kwargs)
inherited from the Immutable.unique_params() method of Immutable
Return a copy with bindparam() elements replaced.
Same functionality as ClauseElement.params(), except adds unique=True to affected bind parameters so that multiple statements can be used.
class sqlalchemy.schema.MetaData
A collection of Table objects and their associated schema constructs.
Holds a collection of Table objects as well as an optional binding to an Engine or Connection. If bound, the Table objects in the collection and their columns may participate in implicit SQL execution.
The Table objects themselves are stored in the MetaData.tables dictionary.
MetaData is a thread-safe object for read operations. Construction of new tables within a single MetaData object, either explicitly or via reflection, may not be completely thread-safe.
See also
Describing Databases with MetaData - Introduction to database metadata
Members
__init__(), clear(), create_all(), drop_all(), reflect(), remove(), sorted_tables, tables
Class signature
class sqlalchemy.schema.MetaData (sqlalchemy.schema.HasSchemaAttr)
method sqlalchemy.schema.MetaData.__init__(schema: str | None = None, quote_schema: bool | None = None, naming_convention: _NamingSchemaParameter | None = None, info: _InfoType | None = None) → None
Create a new MetaData object.
Parameters:
• schema – 
The default schema to use for the Table, Sequence, and potentially other objects associated with this MetaData. Defaults to None.
See also
Specifying a Default Schema Name with MetaData - details on how the MetaData.schema parameter is used.
Table.schema
Sequence.schema
• quote_schema – Sets the quote_schema flag for those Table, Sequence, and other objects which make usage of the local schema name.
• info – Optional data dictionary which will be populated into the SchemaItem.info attribute of this object.
• naming_convention – 
a dictionary referring to values which will establish default naming conventions for Constraint and Index objects, for those objects which are not given a name explicitly.
The keys of this dictionary may be:
o a constraint or Index class, e.g. the UniqueConstraint, ForeignKeyConstraint class, the Index class
o a string mnemonic for one of the known constraint classes; "fk", "pk", "ix", "ck", "uq" for foreign key, primary key, index, check, and unique constraint, respectively.
o the string name of a user-defined “token” that can be used to define new naming tokens.
The values associated with each “constraint class” or “constraint mnemonic” key are string naming templates, such as "uq_%(table_name)s_%(column_0_name)s", which describe how the name should be composed. The values associated with user-defined “token” keys should be callables of the form fn(constraint, table), which accepts the constraint/index object and Table as arguments, returning a string result.
The built-in names are as follows, some of which may only be available for certain types of constraint:
o %(table_name)s - the name of the Table object associated with the constraint.
o %(referred_table_name)s - the name of the Table object associated with the referencing target of a ForeignKeyConstraint.
o %(column_0_name)s - the name of the Column at index position “0” within the constraint.
o %(column_0N_name)s - the name of all Column objects in order within the constraint, joined without a separator.
o %(column_0_N_name)s - the name of all Column objects in order within the constraint, joined with an underscore as a separator.
o %(column_0_label)s, %(column_0N_label)s, %(column_0_N_label)s - the label of either the zeroth Column or all Columns, separated with or without an underscore
o %(column_0_key)s, %(column_0N_key)s, %(column_0_N_key)s - the key of either the zeroth Column or all Columns, separated with or without an underscore
o %(referred_column_0_name)s, %(referred_column_0N_name)s %(referred_column_0_N_name)s, %(referred_column_0_key)s, %(referred_column_0N_key)s, … column tokens which render the names/keys/labels of columns that are referenced by a ForeignKeyConstraint.
o %(constraint_name)s - a special key that refers to the existing name given to the constraint. When this key is present, the Constraint object’s existing name will be replaced with one that is composed from template string that uses this token. When this token is present, it is required that the Constraint is given an explicit name ahead of time.
o user-defined: any additional token may be implemented by passing it along with a fn(constraint, table) callable to the naming_convention dictionary.
Added in version 1.3.0: - added new %(column_0N_name)s, %(column_0_N_name)s, and related tokens that produce concatenations of names, keys, or labels for all columns referred to by a given constraint.
See also
Configuring Constraint Naming Conventions - for detailed usage examples.
method sqlalchemy.schema.MetaData.clear() → None
Clear all Table objects from this MetaData.
method sqlalchemy.schema.MetaData.create_all(bind: _CreateDropBind, tables: _typing_Sequence[Table] | None = None, checkfirst: bool = True) → None
Create all tables stored in this metadata.
Conditional by default, will not attempt to recreate tables already present in the target database.
Parameters:
• bind – A Connection or Engine used to access the database.
• tables – Optional list of Table objects, which is a subset of the total tables in the MetaData (others are ignored).
• checkfirst – Defaults to True, don’t issue CREATEs for tables already present in the target database.
method sqlalchemy.schema.MetaData.drop_all(bind: _CreateDropBind, tables: _typing_Sequence[Table] | None = None, checkfirst: bool = True) → None
Drop all tables stored in this metadata.
Conditional by default, will not attempt to drop tables not present in the target database.
Parameters:
• bind – A Connection or Engine used to access the database.
• tables – Optional list of Table objects, which is a subset of the total tables in the MetaData (others are ignored).
• checkfirst – Defaults to True, only issue DROPs for tables confirmed to be present in the target database.
method sqlalchemy.schema.MetaData.reflect(bind: Engine | Connection, schema: str | None = None, views: bool = False, only: _typing_Sequence[str] | Callable[[str, MetaData], bool] | None = None, extend_existing: bool = False, autoload_replace: bool = True, resolve_fks: bool = True, **dialect_kwargs: Any) → None
Load all available table definitions from the database.
Automatically creates Table entries in this MetaData for any table available in the database but not yet present in the MetaData. May be called multiple times to pick up tables recently added to the database, however no special action is taken if a table in this MetaData no longer exists in the database.
Parameters:
• bind – A Connection or Engine used to access the database.
• schema – Optional, query and reflect tables from an alternate schema. If None, the schema associated with this MetaData is used, if any.
• views – If True, also reflect views (materialized and plain).
• only – 
Optional. Load only a sub-set of available named tables. May be specified as a sequence of names or a callable.
If a sequence of names is provided, only those tables will be reflected. An error is raised if a table is requested but not available. Named tables already present in this MetaData are ignored.
If a callable is provided, it will be used as a boolean predicate to filter the list of potential table names. The callable is called with a table name and this MetaData instance as positional arguments and should return a true value for any table to reflect.
• extend_existing – Passed along to each Table as Table.extend_existing.
• autoload_replace – Passed along to each Table as Table.autoload_replace.
• resolve_fks – 
if True, reflect Table objects linked to ForeignKey objects located in each Table. For MetaData.reflect(), this has the effect of reflecting related tables that might otherwise not be in the list of tables being reflected, for example if the referenced table is in a different schema or is omitted via the MetaData.reflect.only parameter. When False, ForeignKey objects are not followed to the Table in which they link, however if the related table is also part of the list of tables that would be reflected in any case, the ForeignKey object will still resolve to its related Table after the MetaData.reflect() operation is complete. Defaults to True.
Added in version 1.3.0.
See also
Table.resolve_fks
• **dialect_kwargs – Additional keyword arguments not mentioned above are dialect specific, and passed in the form <dialectname>_<argname>. See the documentation regarding an individual dialect at Dialects for detail on documented arguments.
See also
Reflecting Database Objects
DDLEvents.column_reflect() - Event used to customize the reflected columns. Usually used to generalize the types using TypeEngine.as_generic()
Reflecting with Database-Agnostic Types - describes how to reflect tables using general types.
method sqlalchemy.schema.MetaData.remove(table: Table) → None
Remove the given Table object from this MetaData.
attribute sqlalchemy.schema.MetaData.sorted_tables
Returns a list of Table objects sorted in order of foreign key dependency.
The sorting will place Table objects that have dependencies first, before the dependencies themselves, representing the order in which they can be created. To get the order in which the tables would be dropped, use the reversed() Python built-in.
Warning
The MetaData.sorted_tables attribute cannot by itself accommodate automatic resolution of dependency cycles between tables, which are usually caused by mutually dependent foreign key constraints. When these cycles are detected, the foreign keys of these tables are omitted from consideration in the sort. A warning is emitted when this condition occurs, which will be an exception raise in a future release. Tables which are not part of the cycle will still be returned in dependency order.
To resolve these cycles, the ForeignKeyConstraint.use_alter parameter may be applied to those constraints which create a cycle. Alternatively, the sort_tables_and_constraints() function will automatically return foreign key constraints in a separate collection when cycles are detected so that they may be applied to a schema separately.
Changed in version 1.3.17: - a warning is emitted when MetaData.sorted_tables cannot perform a proper sort due to cyclical dependencies. This will be an exception in a future release. Additionally, the sort will continue to return other tables not involved in the cycle in dependency order which was not the case previously.
See also
sort_tables()
sort_tables_and_constraints()
MetaData.tables
Inspector.get_table_names()
Inspector.get_sorted_table_and_fkc_names()
attribute sqlalchemy.schema.MetaData.tables: util.FacadeDict[str, Table]
A dictionary of Table objects keyed to their name or “table key”.
The exact key is that determined by the Table.key attribute; for a table with no Table.schema attribute, this is the same as Table.name. For a table with a schema, it is typically of the form schemaname.tablename.
See also
MetaData.sorted_tables
class sqlalchemy.schema.SchemaConst
Members
BLANK_SCHEMA, NULL_UNSPECIFIED, RETAIN_SCHEMA
Class signature
class sqlalchemy.schema.SchemaConst (enum.Enum)
attribute sqlalchemy.schema.SchemaConst.BLANK_SCHEMA = 2
Symbol indicating that a Table or Sequence should have ‘None’ for its schema, even if the parent MetaData has specified a schema.
See also
MetaData.schema
Table.schema
Sequence.schema
attribute sqlalchemy.schema.SchemaConst.NULL_UNSPECIFIED = 3
Symbol indicating the “nullable” keyword was not passed to a Column.
This is used to distinguish between the use case of passing nullable=None to a Column, which has special meaning on some backends such as SQL Server.
attribute sqlalchemy.schema.SchemaConst.RETAIN_SCHEMA = 1
Symbol indicating that a Table, Sequence or in some cases a ForeignKey object, in situations where the object is being copied for a Table.to_metadata() operation, should retain the schema name that it already has.
class sqlalchemy.schema.SchemaItem
Base class for items that define a database schema.
Members
info
Class signature
class sqlalchemy.schema.SchemaItem (sqlalchemy.sql.expression.SchemaVisitable)
attribute sqlalchemy.schema.SchemaItem.info
Info dictionary associated with the object, allowing user-defined data to be associated with this SchemaItem.
The dictionary is automatically generated when first accessed. It can also be specified in the constructor of some objects, such as Table and Column.
function sqlalchemy.schema.insert_sentinel(name: str | None = None, type_: _TypeEngineArgument[_T] | None = None, *, default: Any | None = None, omit_from_statements: bool = True) → Column[Any]
Provides a surrogate Column that will act as a dedicated insert sentinel column, allowing efficient bulk inserts with deterministic RETURNING sorting for tables that don’t otherwise have qualifying primary key configurations.
Adding this column to a Table object requires that a corresponding database table actually has this column present, so if adding it to an existing model, existing database tables would need to be migrated (e.g. using ALTER TABLE or similar) to include this column.
For background on how this object is used, see the section Configuring Sentinel Columns as part of the section “Insert Many Values” Behavior for INSERT statements.
The Column returned will be a nullable integer column by default and make use of a sentinel-specific default generator used only in “insertmanyvalues” operations.
See also
orm_insert_sentinel()
Column.insert_sentinel
“Insert Many Values” Behavior for INSERT statements
Configuring Sentinel Columns
Added in version 2.0.10.
class sqlalchemy.schema.Table
Represent a table in a database.
e.g.:
mytable = Table(
    "mytable",
    metadata,
    Column("mytable_id", Integer, primary_key=True),
    Column("value", String(50)),
)
The Table object constructs a unique instance of itself based on its name and optional schema name within the given MetaData object. Calling the Table constructor with the same name and same MetaData argument a second time will return the same Table object - in this way the Table constructor acts as a registry function.
See also
Describing Databases with MetaData - Introduction to database metadata
Members
__init__(), add_is_dependent_on(), alias(), append_column(), append_constraint(), argument_for(), autoincrement_column, c, columns, compare(), compile(), constraints, corresponding_column(), create(), delete(), description, dialect_kwargs, dialect_options, drop(), entity_namespace, exported_columns, foreign_key_constraints, foreign_keys, get_children(), implicit_returning, indexes, info, inherit_cache, insert(), is_derived_from(), join(), key, kwargs, lateral(), outerjoin(), params(), primary_key, replace_selectable(), schema, select(), self_group(), table_valued(), tablesample(), to_metadata(), tometadata(), unique_params(), update()
Class signature
class sqlalchemy.schema.Table (sqlalchemy.sql.expression.DialectKWArgs, sqlalchemy.schema.HasSchemaAttr, sqlalchemy.sql.expression.TableClause, sqlalchemy.inspection.Inspectable)
method sqlalchemy.schema.Table.__init__(name: str, metadata: MetaData, *args: SchemaItem, schema: str | Literal[SchemaConst.BLANK_SCHEMA] | None = None, quote: bool | None = None, quote_schema: bool | None = None, autoload_with: Engine | Connection | None = None, autoload_replace: bool = True, keep_existing: bool = False, extend_existing: bool = False, resolve_fks: bool = True, include_columns: Collection[str] | None = None, implicit_returning: bool = True, comment: str | None = None, info: Dict[Any, Any] | None = None, listeners: _typing_Sequence[Tuple[str, Callable[..., Any]]] | None = None, prefixes: _typing_Sequence[str] | None = None, _extend_on: Set[Table] | None = None, _no_init: bool = True, **kw: Any) → None
Constructor for Table.
Parameters:
• name – 
The name of this table as represented in the database.
The table name, along with the value of the schema parameter, forms a key which uniquely identifies this Table within the owning MetaData collection. Additional calls to Table with the same name, metadata, and schema name will return the same Table object.
Names which contain no upper case characters will be treated as case insensitive names, and will not be quoted unless they are a reserved word or contain special characters. A name with any number of upper case characters is considered to be case sensitive, and will be sent as quoted.
To enable unconditional quoting for the table name, specify the flag quote=True to the constructor, or use the quoted_name construct to specify the name.
• metadata – a MetaData object which will contain this table. The metadata is used as a point of association of this table with other tables which are referenced via foreign key. It also may be used to associate this table with a particular Connection or Engine.
• *args – Additional positional arguments are used primarily to add the list of Column objects contained within this table. Similar to the style of a CREATE TABLE statement, other SchemaItem constructs may be added here, including PrimaryKeyConstraint, and ForeignKeyConstraint.
• autoload_replace – 
Defaults to True; when using Table.autoload_with in conjunction with Table.extend_existing, indicates that Column objects present in the already-existing Table object should be replaced with columns of the same name retrieved from the autoload process. When False, columns already present under existing names will be omitted from the reflection process.
Note that this setting does not impact Column objects specified programmatically within the call to Table that also is autoloading; those Column objects will always replace existing columns of the same name when Table.extend_existing is True.
See also
Table.autoload_with
Table.extend_existing
• autoload_with – 
An Engine or Connection object, or a Inspector object as returned by inspect() against one, with which this Table object will be reflected. When set to a non-None value, the autoload process will take place for this table against the given engine or connection.
See also
Reflecting Database Objects
DDLEvents.column_reflect()
Reflecting with Database-Agnostic Types
• extend_existing – 
When True, indicates that if this Table is already present in the given MetaData, apply further arguments within the constructor to the existing Table.
If Table.extend_existing or Table.keep_existing are not set, and the given name of the new Table refers to a Table that is already present in the target MetaData collection, and this Table specifies additional columns or other constructs or flags that modify the table’s state, an error is raised. The purpose of these two mutually-exclusive flags is to specify what action should be taken when a Table is specified that matches an existing Table, yet specifies additional constructs.
Table.extend_existing will also work in conjunction with Table.autoload_with to run a new reflection operation against the database, even if a Table of the same name is already present in the target MetaData; newly reflected Column objects and other options will be added into the state of the Table, potentially overwriting existing columns and options of the same name.
As is always the case with Table.autoload_with, Column objects can be specified in the same Table constructor, which will take precedence. Below, the existing table mytable will be augmented with Column objects both reflected from the database, as well as the given Column named “y”:
Table(
    "mytable",
    metadata,
    Column("y", Integer),
    extend_existing=True,
    autoload_with=engine,
)
•  See also
Table.autoload_with
Table.autoload_replace
Table.keep_existing
•  implicit_returning – 
True by default - indicates that RETURNING can be used, typically by the ORM, in order to fetch server-generated values such as primary key values and server side defaults, on those backends which support RETURNING.
In modern SQLAlchemy there is generally no reason to alter this setting, except for some backend specific cases (see Triggers in the SQL Server dialect documentation for one such example).
•  include_columns – A list of strings indicating a subset of columns to be loaded via the autoload operation; table columns who aren’t present in this list will not be represented on the resulting Table object. Defaults to None which indicates all columns should be reflected.
•  resolve_fks – 
Whether or not to reflect Table objects related to this one via ForeignKey objects, when Table.autoload_with is specified. Defaults to True. Set to False to disable reflection of related tables as ForeignKey objects are encountered; may be used either to save on SQL calls or to avoid issues with related tables that can’t be accessed. Note that if a related table is already present in the MetaData collection, or becomes present later, a ForeignKey object associated with this Table will resolve to that table normally.
Added in version 1.3.
See also
MetaData.reflect.resolve_fks
•  info – Optional data dictionary which will be populated into the SchemaItem.info attribute of this object.
•  keep_existing – 
When True, indicates that if this Table is already present in the given MetaData, ignore further arguments within the constructor to the existing Table, and return the Table object as originally created. This is to allow a function that wishes to define a new Table on first call, but on subsequent calls will return the same Table, without any of the declarations (particularly constraints) being applied a second time.
If Table.extend_existing or Table.keep_existing are not set, and the given name of the new Table refers to a Table that is already present in the target MetaData collection, and this Table specifies additional columns or other constructs or flags that modify the table’s state, an error is raised. The purpose of these two mutually-exclusive flags is to specify what action should be taken when a Table is specified that matches an existing Table, yet specifies additional constructs.
See also
Table.extend_existing
•  listeners – 
A list of tuples of the form (<eventname>, <fn>) which will be passed to listen() upon construction. This alternate hook to listen() allows the establishment of a listener function specific to this Table before the “autoload” process begins. Historically this has been intended for use with the DDLEvents.column_reflect() event, however note that this event hook may now be associated with the MetaData object directly:
def listen_for_reflect(table, column_info):
    "handle the column reflection event"
    # ...


t = Table(
    "sometable",
    autoload_with=engine,
    listeners=[("column_reflect", listen_for_reflect)],
)
• See also
DDLEvents.column_reflect()
• must_exist – When True, indicates that this Table must already be present in the given MetaData collection, else an exception is raised.
• prefixes – A list of strings to insert after CREATE in the CREATE TABLE statement. They will be separated by spaces.
• quote – 
Force quoting of this table’s name on or off, corresponding to True or False. When left at its default of None, the column identifier will be quoted according to whether the name is case sensitive (identifiers with at least one upper case character are treated as case sensitive), or if it’s a reserved word. This flag is only needed to force quoting of a reserved word which is not known by the SQLAlchemy dialect.
Note
setting this flag to False will not provide case-insensitive behavior for table reflection; table reflection will always search for a mixed-case name in a case sensitive fashion. Case insensitive names are specified in SQLAlchemy only by stating the name with all lower case characters.
• quote_schema – same as ‘quote’ but applies to the schema identifier.
• schema – 
The schema name for this table, which is required if the table resides in a schema other than the default selected schema for the engine’s database connection. Defaults to None.
If the owning MetaData of this Table specifies its own MetaData.schema parameter, then that schema name will be applied to this Table if the schema parameter here is set to None. To set a blank schema name on a Table that would otherwise use the schema set on the owning MetaData, specify the special symbol BLANK_SCHEMA.
The quoting rules for the schema name are the same as those for the name parameter, in that quoting is applied for reserved words or case-sensitive names; to enable unconditional quoting for the schema name, specify the flag quote_schema=True to the constructor, or use the quoted_name construct to specify the name.
• comment – 
Optional string that will render an SQL comment on table creation.
Added in version 1.2: Added the Table.comment parameter to Table.
• **kw – Additional keyword arguments not mentioned above are dialect specific, and passed in the form <dialectname>_<argname>. See the documentation regarding an individual dialect at Dialects for detail on documented arguments.
method sqlalchemy.schema.Table.add_is_dependent_on(table: Table) → None
Add a ‘dependency’ for this Table.
This is another Table object which must be created first before this one can, or dropped after this one.
Usually, dependencies between tables are determined via ForeignKey objects. However, for other situations that create dependencies outside of foreign keys (rules, inheriting), this method can manually establish such a link.
method sqlalchemy.schema.Table.alias(name: str | None = None, flat: bool = False) → NamedFromClause
inherited from the FromClause.alias() method of FromClause
Return an alias of this FromClause.
E.g.:
a2 = some_table.alias("a2")
The above code creates an Alias object which can be used as a FROM clause in any SELECT statement.
See also
Using Aliases
alias()
method sqlalchemy.schema.Table.append_column(column: ColumnClause[Any], replace_existing: bool = False) → None
Append a Column to this Table.
The “key” of the newly added Column, i.e. the value of its .key attribute, will then be available in the .c collection of this Table, and the column definition will be included in any CREATE TABLE, SELECT, UPDATE, etc. statements generated from this Table construct.
Note that this does not change the definition of the table as it exists within any underlying database, assuming that table has already been created in the database. Relational databases support the addition of columns to existing tables using the SQL ALTER command, which would need to be emitted for an already-existing table that doesn’t contain the newly added column.
Parameters:
replace_existing – 
When True, allows replacing existing columns. When False, the default, an warning will be raised if a column with the same .key already exists. A future version of sqlalchemy will instead rise a warning.
Added in version 1.4.0.
method sqlalchemy.schema.Table.append_constraint(constraint: Index | Constraint) → None
Append a Constraint to this Table.
This has the effect of the constraint being included in any future CREATE TABLE statement, assuming specific DDL creation events have not been associated with the given Constraint object.
Note that this does not produce the constraint within the relational database automatically, for a table that already exists in the database. To add a constraint to an existing relational database table, the SQL ALTER command must be used. SQLAlchemy also provides the AddConstraint construct which can produce this SQL when invoked as an executable clause.
classmethod sqlalchemy.schema.Table.argument_for(dialect_name, argument_name, default)
inherited from the DialectKWArgs.argument_for() method of DialectKWArgs
Add a new kind of dialect-specific keyword argument for this class.
E.g.:
Index.argument_for("mydialect", "length", None)

some_index = Index("a", "b", mydialect_length=5)
The DialectKWArgs.argument_for() method is a per-argument way adding extra arguments to the DefaultDialect.construct_arguments dictionary. This dictionary provides a list of argument names accepted by various schema-level constructs on behalf of a dialect.
New dialects should typically specify this dictionary all at once as a data member of the dialect class. The use case for ad-hoc addition of argument names is typically for end-user code that is also using a custom compilation scheme which consumes the additional arguments.
Parameters:
• dialect_name – name of a dialect. The dialect must be locatable, else a NoSuchModuleError is raised. The dialect must also include an existing DefaultDialect.construct_arguments collection, indicating that it participates in the keyword-argument validation and default system, else ArgumentError is raised. If the dialect does not include this collection, then any keyword argument can be specified on behalf of this dialect already. All dialects packaged within SQLAlchemy include this collection, however for third party dialects, support may vary.
• argument_name – name of the parameter.
• default – default value of the parameter.
attribute sqlalchemy.schema.Table.autoincrement_column
Returns the Column object which currently represents the “auto increment” column, if any, else returns None.
This is based on the rules for Column as defined by the Column.autoincrement parameter, which generally means the column within a single integer column primary key constraint that is not constrained by a foreign key. If the table does not have such a primary key constraint, then there’s no “autoincrement” column. A Table may have only one column defined as the “autoincrement” column.
Added in version 2.0.4.
See also
Column.autoincrement
attribute sqlalchemy.schema.Table.c
inherited from the FromClause.c attribute of FromClause
A synonym for FromClause.columns
Returns:
a ColumnCollection
attribute sqlalchemy.schema.Table.columns
inherited from the FromClause.columns attribute of FromClause
A named-based collection of ColumnElement objects maintained by this FromClause.
The columns, or c collection, is the gateway to the construction of SQL expressions using table-bound or other selectable-bound columns:
select(mytable).where(mytable.c.somecolumn == 5)
Returns:
a ColumnCollection object.
method sqlalchemy.schema.Table.compare(other: ClauseElement, **kw: Any) → bool
inherited from the ClauseElement.compare() method of ClauseElement
Compare this ClauseElement to the given ClauseElement.
Subclasses should override the default behavior, which is a straight identity comparison.
**kw are arguments consumed by subclass compare() methods and may be used to modify the criteria for comparison (see ColumnElement).
method sqlalchemy.schema.Table.compile(bind: _HasDialect | None = None, dialect: Dialect | None = None, **kw: Any) → Compiled
inherited from the CompilerElement.compile() method of CompilerElement
Compile this SQL expression.
The return value is a Compiled object. Calling str() or unicode() on the returned value will yield a string representation of the result. The Compiled object also can return a dictionary of bind parameter names and values using the params accessor.
Parameters:
• bind – An Connection or Engine which can provide a Dialect in order to generate a Compiled object. If the bind and dialect parameters are both omitted, a default SQL compiler is used.
• column_keys – Used for INSERT and UPDATE statements, a list of column names which should be present in the VALUES clause of the compiled statement. If None, all columns from the target table object are rendered.
• dialect – A Dialect instance which can generate a Compiled object. This argument takes precedence over the bind argument.
• compile_kwargs – 
optional dictionary of additional parameters that will be passed through to the compiler within all “visit” methods. This allows any custom flag to be passed through to a custom compilation construct, for example. It is also used for the case of passing the literal_binds flag through:
from sqlalchemy.sql import table, column, select

t = table("t", column("x"))

s = select(t).where(t.c.x == 5)

print(s.compile(compile_kwargs={"literal_binds": True}))
• 
See also
How do I render SQL expressions as strings, possibly with bound parameters inlined?
attribute sqlalchemy.schema.Table.constraints: Set[Constraint]
A collection of all Constraint objects associated with this Table.
Includes PrimaryKeyConstraint, ForeignKeyConstraint, UniqueConstraint, CheckConstraint. A separate collection Table.foreign_key_constraints refers to the collection of all ForeignKeyConstraint objects, and the Table.primary_key attribute refers to the single PrimaryKeyConstraint associated with the Table.
See also
Table.constraints
Table.primary_key
Table.foreign_key_constraints
Table.indexes
Inspector
method sqlalchemy.schema.Table.corresponding_column(column: KeyedColumnElement[Any], require_embedded: bool = False) → KeyedColumnElement[Any] | None
inherited from the Selectable.corresponding_column() method of Selectable
Given a ColumnElement, return the exported ColumnElement object from the Selectable.exported_columns collection of this Selectable which corresponds to that original ColumnElement via a common ancestor column.
Parameters:
• column – the target ColumnElement to be matched.
• require_embedded – only return corresponding columns for the given ColumnElement, if the given ColumnElement is actually present within a sub-element of this Selectable. Normally the column will match if it merely shares a common ancestor with one of the exported columns of this Selectable.
See also
Selectable.exported_columns - the ColumnCollection that is used for the operation.
ColumnCollection.corresponding_column() - implementation method.
method sqlalchemy.schema.Table.create(bind: _CreateDropBind, checkfirst: bool = False) → None
Issue a CREATE statement for this Table, using the given Connection or Engine for connectivity.
See also
MetaData.create_all().
method sqlalchemy.schema.Table.delete() → Delete
inherited from the TableClause.delete() method of TableClause
Generate a delete() construct against this TableClause.
E.g.:
table.delete().where(table.c.id == 7)
See delete() for argument and usage information.
attribute sqlalchemy.schema.Table.description
inherited from the TableClause.description attribute of TableClause
attribute sqlalchemy.schema.Table.dialect_kwargs
inherited from the DialectKWArgs.dialect_kwargs attribute of DialectKWArgs
A collection of keyword arguments specified as dialect-specific options to this construct.
The arguments are present here in their original <dialect>_<kwarg> format. Only arguments that were actually passed are included; unlike the DialectKWArgs.dialect_options collection, which contains all options known by this dialect including defaults.
The collection is also writable; keys are accepted of the form <dialect>_<kwarg> where the value will be assembled into the list of options.
See also
DialectKWArgs.dialect_options - nested dictionary form
attribute sqlalchemy.schema.Table.dialect_options
inherited from the DialectKWArgs.dialect_options attribute of DialectKWArgs
A collection of keyword arguments specified as dialect-specific options to this construct.
This is a two-level nested registry, keyed to <dialect_name> and <argument_name>. For example, the postgresql_where argument would be locatable as:
arg = my_object.dialect_options["postgresql"]["where"]
Added in version 0.9.2.
See also
DialectKWArgs.dialect_kwargs - flat dictionary form
method sqlalchemy.schema.Table.drop(bind: _CreateDropBind, checkfirst: bool = False) → None
Issue a DROP statement for this Table, using the given Connection or Engine for connectivity.
See also
MetaData.drop_all().
attribute sqlalchemy.schema.Table.entity_namespace
inherited from the FromClause.entity_namespace attribute of FromClause
Return a namespace used for name-based access in SQL expressions.
This is the namespace that is used to resolve “filter_by()” type expressions, such as:
stmt.filter_by(address="some address")
It defaults to the .c collection, however internally it can be overridden using the “entity_namespace” annotation to deliver alternative results.
attribute sqlalchemy.schema.Table.exported_columns
inherited from the FromClause.exported_columns attribute of FromClause
A ColumnCollection that represents the “exported” columns of this Selectable.
The “exported” columns for a FromClause object are synonymous with the FromClause.columns collection.
Added in version 1.4.
See also
Selectable.exported_columns
SelectBase.exported_columns
attribute sqlalchemy.schema.Table.foreign_key_constraints
ForeignKeyConstraint objects referred to by this Table.
This list is produced from the collection of ForeignKey objects currently associated.
See also
Table.constraints
Table.foreign_keys
Table.indexes
attribute sqlalchemy.schema.Table.foreign_keys
inherited from the FromClause.foreign_keys attribute of FromClause
Return the collection of ForeignKey marker objects which this FromClause references.
Each ForeignKey is a member of a Table-wide ForeignKeyConstraint.
See also
Table.foreign_key_constraints
method sqlalchemy.schema.Table.get_children(*, omit_attrs: Tuple[str, ...] = (), **kw: Any) → Iterable[HasTraverseInternals]
inherited from the HasTraverseInternals.get_children() method of HasTraverseInternals
Return immediate child HasTraverseInternals elements of this HasTraverseInternals.
This is used for visit traversal.
**kw may contain flags that change the collection that is returned, for example to return a subset of items in order to cut down on larger traversals, or to return child items from a different context (such as schema-level collections instead of clause-level).
attribute sqlalchemy.schema.Table.implicit_returning = False
inherited from the TableClause.implicit_returning attribute of TableClause
TableClause doesn’t support having a primary key or column -level defaults, so implicit returning doesn’t apply.
attribute sqlalchemy.schema.Table.indexes: Set[Index]
A collection of all Index objects associated with this Table.
See also
Inspector.get_indexes()
attribute sqlalchemy.schema.Table.info
inherited from the SchemaItem.info attribute of SchemaItem
Info dictionary associated with the object, allowing user-defined data to be associated with this SchemaItem.
The dictionary is automatically generated when first accessed. It can also be specified in the constructor of some objects, such as Table and Column.
attribute sqlalchemy.schema.Table.inherit_cache: bool | None = None
inherited from the HasCacheKey.inherit_cache attribute of HasCacheKey
Indicate if this HasCacheKey instance should make use of the cache key generation scheme used by its immediate superclass.
The attribute defaults to None, which indicates that a construct has not yet taken into account whether or not its appropriate for it to participate in caching; this is functionally equivalent to setting the value to False, except that a warning is also emitted.
This flag can be set to True on a particular class, if the SQL that corresponds to the object does not change based on attributes which are local to this class, and not its superclass.
See also
Enabling Caching Support for Custom Constructs - General guideslines for setting the HasCacheKey.inherit_cache attribute for third-party or user defined SQL constructs.
method sqlalchemy.schema.Table.insert() → Insert
inherited from the TableClause.insert() method of TableClause
Generate an Insert construct against this TableClause.
E.g.:
table.insert().values(name="foo")
See insert() for argument and usage information.
method sqlalchemy.schema.Table.is_derived_from(fromclause: FromClause | None) → bool
inherited from the FromClause.is_derived_from() method of FromClause
Return True if this FromClause is ‘derived’ from the given FromClause.
An example would be an Alias of a Table is derived from that Table.
method sqlalchemy.schema.Table.join(right: _FromClauseArgument, onclause: _ColumnExpressionArgument[bool] | None = None, isouter: bool = False, full: bool = False) → Join
inherited from the FromClause.join() method of FromClause
Return a Join from this FromClause to another FromClause.
E.g.:
from sqlalchemy import join

j = user_table.join(
    address_table, user_table.c.id == address_table.c.user_id
)
stmt = select(user_table).select_from(j)
would emit SQL along the lines of:
SELECT user.id, user.name FROM user
JOIN address ON user.id = address.user_id
Parameters:
• right – the right side of the join; this is any FromClause object such as a Table object, and may also be a selectable-compatible object such as an ORM-mapped class.
• onclause – a SQL expression representing the ON clause of the join. If left at None, FromClause.join() will attempt to join the two tables based on a foreign key relationship.
• isouter – if True, render a LEFT OUTER JOIN, instead of JOIN.
• full – if True, render a FULL OUTER JOIN, instead of LEFT OUTER JOIN. Implies FromClause.join.isouter.
See also
join() - standalone function
Join - the type of object produced
attribute sqlalchemy.schema.Table.key
Return the ‘key’ for this Table.
This value is used as the dictionary key within the MetaData.tables collection. It is typically the same as that of Table.name for a table with no Table.schema set; otherwise it is typically of the form schemaname.tablename.
attribute sqlalchemy.schema.Table.kwargs
inherited from the DialectKWArgs.kwargs attribute of DialectKWArgs
A synonym for DialectKWArgs.dialect_kwargs.
method sqlalchemy.schema.Table.lateral(name: str | None = None) → LateralFromClause
inherited from the Selectable.lateral() method of Selectable
Return a LATERAL alias of this Selectable.
The return value is the Lateral construct also provided by the top-level lateral() function.
See also
LATERAL correlation - overview of usage.
method sqlalchemy.schema.Table.outerjoin(right: _FromClauseArgument, onclause: _ColumnExpressionArgument[bool] | None = None, full: bool = False) → Join
inherited from the FromClause.outerjoin() method of FromClause
Return a Join from this FromClause to another FromClause, with the “isouter” flag set to True.
E.g.:
from sqlalchemy import outerjoin

j = user_table.outerjoin(
    address_table, user_table.c.id == address_table.c.user_id
)
The above is equivalent to:
j = user_table.join(
    address_table, user_table.c.id == address_table.c.user_id, isouter=True
)
Parameters:
• right – the right side of the join; this is any FromClause object such as a Table object, and may also be a selectable-compatible object such as an ORM-mapped class.
• onclause – a SQL expression representing the ON clause of the join. If left at None, FromClause.join() will attempt to join the two tables based on a foreign key relationship.
• full – if True, render a FULL OUTER JOIN, instead of LEFT OUTER JOIN.
See also
FromClause.join()
Join
method sqlalchemy.schema.Table.params(*optionaldict, **kwargs)
inherited from the Immutable.params() method of Immutable
Return a copy with bindparam() elements replaced.
Returns a copy of this ClauseElement with bindparam() elements replaced with values taken from the given dictionary:
>>> clause = column("x") + bindparam("foo")
>>> print(clause.compile().params)
{'foo':None}
>>> print(clause.params({"foo": 7}).compile().params)
{'foo':7}
attribute sqlalchemy.schema.Table.primary_key
inherited from the FromClause.primary_key attribute of FromClause
Return the iterable collection of Column objects which comprise the primary key of this _selectable.FromClause.
For a Table object, this collection is represented by the PrimaryKeyConstraint which itself is an iterable collection of Column objects.
method sqlalchemy.schema.Table.replace_selectable(old: FromClause, alias: Alias) → Self
inherited from the Selectable.replace_selectable() method of Selectable
Replace all occurrences of FromClause ‘old’ with the given Alias object, returning a copy of this FromClause.
Deprecated since version 1.4: The Selectable.replace_selectable() method is deprecated, and will be removed in a future release. Similar functionality is available via the sqlalchemy.sql.visitors module.
attribute sqlalchemy.schema.Table.schema: str | None = None
inherited from the FromClause.schema attribute of FromClause
Define the ‘schema’ attribute for this FromClause.
This is typically None for most objects except that of Table, where it is taken as the value of the Table.schema argument.
method sqlalchemy.schema.Table.select() → Select
inherited from the FromClause.select() method of FromClause
Return a SELECT of this FromClause.
e.g.:
stmt = some_table.select().where(some_table.c.id == 5)
See also
select() - general purpose method which allows for arbitrary column lists.
method sqlalchemy.schema.Table.self_group(against: OperatorType | None = None) → ClauseElement
inherited from the ClauseElement.self_group() method of ClauseElement
Apply a ‘grouping’ to this ClauseElement.
This method is overridden by subclasses to return a “grouping” construct, i.e. parenthesis. In particular it’s used by “binary” expressions to provide a grouping around themselves when placed into a larger expression, as well as by select() constructs when placed into the FROM clause of another select(). (Note that subqueries should be normally created using the Select.alias() method, as many platforms require nested SELECT statements to be named).
As expressions are composed together, the application of self_group() is automatic - end-user code should never need to use this method directly. Note that SQLAlchemy’s clause constructs take operator precedence into account - so parenthesis might not be needed, for example, in an expression like x OR (y AND z) - AND takes precedence over OR.
The base self_group() method of ClauseElement just returns self.
method sqlalchemy.schema.Table.table_valued() → TableValuedColumn[Any]
inherited from the NamedFromClause.table_valued() method of NamedFromClause
Return a TableValuedColumn object for this FromClause.
A TableValuedColumn is a ColumnElement that represents a complete row in a table. Support for this construct is backend dependent, and is supported in various forms by backends such as PostgreSQL, Oracle Database and SQL Server.
E.g.:
>>> from sqlalchemy import select, column, func, table
>>> a = table("a", column("id"), column("x"), column("y"))
>>> stmt = select(func.row_to_json(a.table_valued()))
>>> print(stmt)
SELECT row_to_json(a) AS row_to_json_1
FROM a
Added in version 1.4.0b2.
See also
Working with SQL Functions - in the SQLAlchemy Unified Tutorial
method sqlalchemy.schema.Table.tablesample(sampling: float | Function[Any], name: str | None = None, seed: roles.ExpressionElementRole[Any] | None = None) → TableSample
inherited from the FromClause.tablesample() method of FromClause
Return a TABLESAMPLE alias of this FromClause.
The return value is the TableSample construct also provided by the top-level tablesample() function.
See also
tablesample() - usage guidelines and parameters
method sqlalchemy.schema.Table.to_metadata(metadata: MetaData, schema: str | Literal[SchemaConst.RETAIN_SCHEMA] = SchemaConst.RETAIN_SCHEMA, referred_schema_fn: Callable[[Table, str | None, ForeignKeyConstraint, str | None], str | None] | None = None, name: str | None = None) → Table
Return a copy of this Table associated with a different MetaData.
E.g.:
m1 = MetaData()

user = Table("user", m1, Column("id", Integer, primary_key=True))

m2 = MetaData()
user_copy = user.to_metadata(m2)
Changed in version 1.4: The Table.to_metadata() function was renamed from Table.tometadata().
Parameters:
• metadata – Target MetaData object, into which the new Table object will be created.
• schema – 
optional string name indicating the target schema. Defaults to the special symbol RETAIN_SCHEMA which indicates that no change to the schema name should be made in the new Table. If set to a string name, the new Table will have this new name as the .schema. If set to None, the schema will be set to that of the schema set on the target MetaData, which is typically None as well, unless set explicitly:
m2 = MetaData(schema="newschema")

# user_copy_one will have "newschema" as the schema name
user_copy_one = user.to_metadata(m2, schema=None)

m3 = MetaData()  # schema defaults to None

# user_copy_two will have None as the schema name
user_copy_two = user.to_metadata(m3, schema=None)
•  •  referred_schema_fn – 
optional callable which can be supplied in order to provide for the schema name that should be assigned to the referenced table of a ForeignKeyConstraint. The callable accepts this parent Table, the target schema that we are changing to, the ForeignKeyConstraint object, and the existing “target schema” of that constraint. The function should return the string schema name that should be applied. To reset the schema to “none”, return the symbol BLANK_SCHEMA. To effect no change, return None or RETAIN_SCHEMA.
Changed in version 1.4.33: The referred_schema_fn function may return the BLANK_SCHEMA or RETAIN_SCHEMA symbols.
E.g.:
def referred_schema_fn(table, to_schema, constraint, referred_schema):
    if referred_schema == "base_tables":
        return referred_schema
    else:
        return to_schema


new_table = table.to_metadata(
    m2, schema="alt_schema", referred_schema_fn=referred_schema_fn
)
• 
• name – optional string name indicating the target table name. If not specified or None, the table name is retained. This allows a Table to be copied to the same MetaData target with a new name.
method sqlalchemy.schema.Table.tometadata(metadata: MetaData, schema: str | Literal[SchemaConst.RETAIN_SCHEMA] = SchemaConst.RETAIN_SCHEMA, referred_schema_fn: Callable[[Table, str | None, ForeignKeyConstraint, str | None], str | None] | None = None, name: str | None = None) → Table
Return a copy of this Table associated with a different MetaData.
Deprecated since version 1.4: Table.tometadata() is renamed to Table.to_metadata()
See Table.to_metadata() for a full description.
method sqlalchemy.schema.Table.unique_params(*optionaldict, **kwargs)
inherited from the Immutable.unique_params() method of Immutable
Return a copy with bindparam() elements replaced.
Same functionality as ClauseElement.params(), except adds unique=True to affected bind parameters so that multiple statements can be used.
method sqlalchemy.schema.Table.update() → Update
inherited from the TableClause.update() method of TableClause
Generate an update() construct against this TableClause.
E.g.:
table.update().where(table.c.id == 7).values(name="foo")
See update() for argument and usage information.


Reflecting Database Objects
A Table object can be instructed to load information about itself from the corresponding database schema object already existing within the database. This process is called reflection. In the most simple case you need only specify the table name, a MetaData object, and the autoload_with argument:
>>> messages = Table("messages", metadata_obj, autoload_with=engine)
>>> [c.name for c in messages.columns]
['message_id', 'message_name', 'date']
The above operation will use the given engine to query the database for information about the messages table, and will then generate Column, ForeignKey, and other objects corresponding to this information as though the Table object were hand-constructed in Python.
When tables are reflected, if a given table references another one via foreign key, a second Table object is created within the MetaData object representing the connection. Below, assume the table shopping_cart_items references a table named shopping_carts. Reflecting the shopping_cart_items table has the effect such that the shopping_carts table will also be loaded:
>>> shopping_cart_items = Table("shopping_cart_items", metadata_obj, autoload_with=engine)
>>> "shopping_carts" in metadata_obj.tables
True
The MetaData has an interesting “singleton-like” behavior such that if you requested both tables individually, MetaData will ensure that exactly one Table object is created for each distinct table name. The Table constructor actually returns to you the already-existing Table object if one already exists with the given name. Such as below, we can access the already generated shopping_carts table just by naming it:
shopping_carts = Table("shopping_carts", metadata_obj)
Of course, it’s a good idea to use autoload_with=engine with the above table regardless. This is so that the table’s attributes will be loaded if they have not been already. The autoload operation only occurs for the table if it hasn’t already been loaded; once loaded, new calls to Table with the same name will not re-issue any reflection queries.
Overriding Reflected Columns
Individual columns can be overridden with explicit values when reflecting tables; this is handy for specifying custom datatypes, constraints such as primary keys that may not be configured within the database, etc.:
>>> mytable = Table(
...     "mytable",
...     metadata_obj,
...     Column(
...         "id", Integer, primary_key=True
...     ),  # override reflected 'id' to have primary key
...     Column("mydata", Unicode(50)),  # override reflected 'mydata' to be Unicode
...     # additional Column objects which require no change are reflected normally
...     autoload_with=some_engine,
... )
See also
Working with Custom Types and Reflection - illustrates how the above column override technique applies to the use of custom datatypes with table reflection.
Reflecting Views
The reflection system can also reflect views. Basic usage is the same as that of a table:
my_view = Table("some_view", metadata, autoload_with=engine)
Above, my_view is a Table object with Column objects representing the names and types of each column within the view “some_view”.
Usually, it’s desired to have at least a primary key constraint when reflecting a view, if not foreign keys as well. View reflection doesn’t extrapolate these constraints.
Use the “override” technique for this, specifying explicitly those columns which are part of the primary key or have foreign key constraints:
my_view = Table(
    "some_view",
    metadata,
    Column("view_id", Integer, primary_key=True),
    Column("related_thing", Integer, ForeignKey("othertable.thing_id")),
    autoload_with=engine,
)
Reflecting All Tables at Once
The MetaData object can also get a listing of tables and reflect the full set. This is achieved by using the reflect() method. After calling it, all located tables are present within the MetaData object’s dictionary of tables:
metadata_obj = MetaData()
metadata_obj.reflect(bind=someengine)
users_table = metadata_obj.tables["users"]
addresses_table = metadata_obj.tables["addresses"]
metadata.reflect() also provides a handy way to clear or delete all the rows in a database:
metadata_obj = MetaData()
metadata_obj.reflect(bind=someengine)
with someengine.begin() as conn:
    for table in reversed(metadata_obj.sorted_tables):
        conn.execute(table.delete())
Reflecting Tables from Other Schemas
The section Specifying the Schema Name introduces the concept of table schemas, which are namespaces within a database that contain tables and other objects, and which can be specified explicitly. The “schema” for a Table object, as well as for other objects like views, indexes and sequences, can be set up using the Table.schema parameter, and also as the default schema for a MetaData object using the MetaData.schema parameter.
The use of this schema parameter directly affects where the table reflection feature will look when it is asked to reflect objects. For example, given a MetaData object configured with a default schema name “project” via its MetaData.schema parameter:
>>> metadata_obj = MetaData(schema="project")
The MetaData.reflect() will then utilize that configured .schema for reflection:
>>> # uses `schema` configured in metadata_obj
>>> metadata_obj.reflect(someengine)
The end result is that Table objects from the “project” schema will be reflected, and they will be populated as schema-qualified with that name:
>>> metadata_obj.tables["project.messages"]
Table('messages', MetaData(), Column('message_id', INTEGER(), table=<messages>), schema='project')
Similarly, an individual Table object that includes the Table.schema parameter will also be reflected from that database schema, overriding any default schema that may have been configured on the owning MetaData collection:
>>> messages = Table("messages", metadata_obj, schema="project", autoload_with=someengine)
>>> messages
Table('messages', MetaData(), Column('message_id', INTEGER(), table=<messages>), schema='project')
Finally, the MetaData.reflect() method itself also allows a MetaData.reflect.schema parameter to be passed, so we could also load tables from the “project” schema for a default configured MetaData object:
>>> metadata_obj = MetaData()
>>> metadata_obj.reflect(someengine, schema="project")
We can call MetaData.reflect() any number of times with different MetaData.schema arguments (or none at all) to continue populating the MetaData object with more objects:
>>> # add tables from the "customer" schema
>>> metadata_obj.reflect(someengine, schema="customer")
>>> # add tables from the default schema
>>> metadata_obj.reflect(someengine)
Interaction of Schema-qualified Reflection with the Default Schema
Section Best Practices Summarized
In this section, we discuss SQLAlchemy’s reflection behavior regarding tables that are visible in the “default schema” of a database session, and how these interact with SQLAlchemy directives that include the schema explicitly. As a best practice, ensure the “default” schema for a database is just a single name, and not a list of names; for tables that are part of this “default” schema and can be named without schema qualification in DDL and SQL, leave corresponding Table.schema and similar schema parameters set to their default of None.
As described at Specifying a Default Schema Name with MetaData, databases that have the concept of schemas usually also include the concept of a “default” schema. The reason for this is naturally that when one refers to table objects without a schema as is common, a schema-capable database will still consider that table to be in a “schema” somewhere. Some databases such as PostgreSQL take this concept further into the notion of a schema search path where multiple schema names can be considered in a particular database session to be “implicit”; referring to a table name that it’s any of those schemas will not require that the schema name be present (while at the same time it’s also perfectly fine if the schema name is present).
Since most relational databases therefore have the concept of a particular table object which can be referenced both in a schema-qualified way, as well as an “implicit” way where no schema is present, this presents a complexity for SQLAlchemy’s reflection feature. Reflecting a table in a schema-qualified manner will always populate its Table.schema attribute and additionally affect how this Table is organized into the MetaData.tables collection, that is, in a schema qualified manner. Conversely, reflecting the same table in a non-schema qualified manner will organize it into the MetaData.tables collection without being schema qualified. The end result is that there would be two separate Table objects in the single MetaData collection representing the same table in the actual database.
To illustrate the ramifications of this issue, consider tables from the “project” schema in the previous example, and suppose also that the “project” schema is the default schema of our database connection, or if using a database such as PostgreSQL suppose the “project” schema is set up in the PostgreSQL search_path. This would mean that the database accepts the following two SQL statements as equivalent:
-- schema qualified
SELECT message_id FROM project.messages

-- non-schema qualified
SELECT message_id FROM messages
This is not a problem as the table can be found in both ways. However in SQLAlchemy, it’s the identity of the Table object that determines its semantic role within a SQL statement. Based on the current decisions within SQLAlchemy, this means that if we reflect the same “messages” table in both a schema-qualified as well as a non-schema qualified manner, we get two Table objects that will not be treated as semantically equivalent:
>>> # reflect in non-schema qualified fashion
>>> messages_table_1 = Table("messages", metadata_obj, autoload_with=someengine)
>>> # reflect in schema qualified fashion
>>> messages_table_2 = Table(
...     "messages", metadata_obj, schema="project", autoload_with=someengine
... )
>>> # two different objects
>>> messages_table_1 is messages_table_2
False
>>> # stored in two different ways
>>> metadata.tables["messages"] is messages_table_1
True
>>> metadata.tables["project.messages"] is messages_table_2
True
The above issue becomes more complicated when the tables being reflected contain foreign key references to other tables. Suppose “messages” has a “project_id” column which refers to rows in another schema-local table “projects”, meaning there is a ForeignKeyConstraint object that is part of the definition of the “messages” table.
We can find ourselves in a situation where one MetaData collection may contain as many as four Table objects representing these two database tables, where one or two of the additional tables were generated by the reflection process; this is because when the reflection process encounters a foreign key constraint on a table being reflected, it branches out to reflect that referenced table as well. The decision making it uses to assign the schema to this referenced table is that SQLAlchemy will omit a default schema from the reflected ForeignKeyConstraint object if the owning Table also omits its schema name and also that these two objects are in the same schema, but will include it if it were not omitted.
The common scenario is when the reflection of a table in a schema qualified fashion then loads a related table that will also be performed in a schema qualified fashion:
>>> # reflect "messages" in a schema qualified fashion
>>> messages_table_1 = Table(
...     "messages", metadata_obj, schema="project", autoload_with=someengine
... )
The above messages_table_1 will refer to projects also in a schema qualified fashion. This “projects” table will be reflected automatically by the fact that “messages” refers to it:
>>> messages_table_1.c.project_id
Column('project_id', INTEGER(), ForeignKey('project.projects.project_id'), table=<messages>)
if some other part of the code reflects “projects” in a non-schema qualified fashion, there are now two projects tables that are not the same:
>>> # reflect "projects" in a non-schema qualified fashion
>>> projects_table_1 = Table("projects", metadata_obj, autoload_with=someengine)
>>> # messages does not refer to projects_table_1 above
>>> messages_table_1.c.project_id.references(projects_table_1.c.project_id)
False
>>> # it refers to this one
>>> projects_table_2 = metadata_obj.tables["project.projects"]
>>> messages_table_1.c.project_id.references(projects_table_2.c.project_id)
True
>>> # they're different, as one non-schema qualified and the other one is
>>> projects_table_1 is projects_table_2
False
The above confusion can cause problems within applications that use table reflection to load up application-level Table objects, as well as within migration scenarios, in particular such as when using Alembic Migrations to detect new tables and foreign key constraints.
The above behavior can be remedied by sticking to one simple practice:
• Don’t include the Table.schema parameter for any Table that expects to be located in the default schema of the database.
For PostgreSQL and other databases that support a “search” path for schemas, add the following additional practice:
• Keep the “search path” narrowed down to one schema only, which is the default schema.
See also
Remote-Schema Table Introspection and PostgreSQL search_path - additional details of this behavior as regards the PostgreSQL database.
Fine Grained Reflection with Inspector
A low level interface which provides a backend-agnostic system of loading lists of schema, table, column, and constraint descriptions from a given database is also available. This is known as the “Inspector”:
from sqlalchemy import create_engine
from sqlalchemy import inspect

engine = create_engine("...")
insp = inspect(engine)
print(insp.get_table_names())
Object NameDescriptionInspectorPerforms database schema inspection.ReflectedCheckConstraintDictionary representing the reflected elements corresponding to CheckConstraint.ReflectedColumnDictionary representing the reflected elements corresponding to a Column object.ReflectedComputedRepresent the reflected elements of a computed column, corresponding to the Computed construct.ReflectedForeignKeyConstraintDictionary representing the reflected elements corresponding to ForeignKeyConstraint.ReflectedIdentityrepresent the reflected IDENTITY structure of a column, corresponding to the Identity construct.ReflectedIndexDictionary representing the reflected elements corresponding to Index.ReflectedPrimaryKeyConstraintDictionary representing the reflected elements corresponding to PrimaryKeyConstraint.ReflectedTableCommentDictionary representing the reflected comment corresponding to the Table.comment attribute.ReflectedUniqueConstraintDictionary representing the reflected elements corresponding to UniqueConstraint.class sqlalchemy.engine.reflection.Inspector
Performs database schema inspection.
The Inspector acts as a proxy to the reflection methods of the Dialect, providing a consistent interface as well as caching support for previously fetched metadata.
A Inspector object is usually created via the inspect() function, which may be passed an Engine or a Connection:
from sqlalchemy import inspect, create_engine

engine = create_engine("...")
insp = inspect(engine)
Where above, the Dialect associated with the engine may opt to return an Inspector subclass that provides additional methods specific to the dialect’s target database.
Members
__init__(), bind, clear_cache(), default_schema_name, dialect, engine, from_engine(), get_check_constraints(), get_columns(), get_foreign_keys(), get_indexes(), get_materialized_view_names(), get_multi_check_constraints(), get_multi_columns(), get_multi_foreign_keys(), get_multi_indexes(), get_multi_pk_constraint(), get_multi_table_comment(), get_multi_table_options(), get_multi_unique_constraints(), get_pk_constraint(), get_schema_names(), get_sequence_names(), get_sorted_table_and_fkc_names(), get_table_comment(), get_table_names(), get_table_options(), get_temp_table_names(), get_temp_view_names(), get_unique_constraints(), get_view_definition(), get_view_names(), has_index(), has_schema(), has_sequence(), has_table(), info_cache, reflect_table(), sort_tables_on_foreign_key_dependency()
Class signature
class sqlalchemy.engine.reflection.Inspector (sqlalchemy.inspection.Inspectable)
method sqlalchemy.engine.reflection.Inspector.__init__(bind: Engine | Connection)
Initialize a new Inspector.
Deprecated since version 1.4: The __init__() method on Inspector is deprecated and will be removed in a future release. Please use the inspect() function on an Engine or Connection in order to acquire an Inspector.
Parameters:
bind – a Connection, which is typically an instance of Engine or Connection.
For a dialect-specific instance of Inspector, see Inspector.from_engine()
attribute sqlalchemy.engine.reflection.Inspector.bind: Engine | Connection
method sqlalchemy.engine.reflection.Inspector.clear_cache() → None
reset the cache for this Inspector.
Inspection methods that have data cached will emit SQL queries when next called to get new data.
Added in version 2.0.
attribute sqlalchemy.engine.reflection.Inspector.default_schema_name
Return the default schema name presented by the dialect for the current engine’s database user.
E.g. this is typically public for PostgreSQL and dbo for SQL Server.
attribute sqlalchemy.engine.reflection.Inspector.dialect: Dialect
attribute sqlalchemy.engine.reflection.Inspector.engine: Engine
classmethod sqlalchemy.engine.reflection.Inspector.from_engine(bind: Engine) → Inspector
Construct a new dialect-specific Inspector object from the given engine or connection.
Deprecated since version 1.4: The from_engine() method on Inspector is deprecated and will be removed in a future release. Please use the inspect() function on an Engine or Connection in order to acquire an Inspector.
Parameters:
bind – a Connection or Engine.
This method differs from direct a direct constructor call of Inspector in that the Dialect is given a chance to provide a dialect-specific Inspector instance, which may provide additional methods.
See the example at Inspector.
method sqlalchemy.engine.reflection.Inspector.get_check_constraints(table_name: str, schema: str | None = None, **kw: Any) → List[ReflectedCheckConstraint]
Return information about check constraints in table_name.
Given a string table_name and an optional string schema, return check constraint information as a list of ReflectedCheckConstraint.
Parameters:
• table_name – string name of the table. For special quoting, use quoted_name.
• schema – string schema name; if omitted, uses the default schema of the database connection. For special quoting, use quoted_name.
• **kw – Additional keyword argument to pass to the dialect specific implementation. See the documentation of the dialect in use for more information.
Returns:
a list of dictionaries, each representing the definition of a check constraints.
See also
Inspector.get_multi_check_constraints()
method sqlalchemy.engine.reflection.Inspector.get_columns(table_name: str, schema: str | None = None, **kw: Any) → List[ReflectedColumn]
Return information about columns in table_name.
Given a string table_name and an optional string schema, return column information as a list of ReflectedColumn.
Parameters:
• table_name – string name of the table. For special quoting, use quoted_name.
• schema – string schema name; if omitted, uses the default schema of the database connection. For special quoting, use quoted_name.
• **kw – Additional keyword argument to pass to the dialect specific implementation. See the documentation of the dialect in use for more information.
Returns:
list of dictionaries, each representing the definition of a database column.
See also
Inspector.get_multi_columns().
method sqlalchemy.engine.reflection.Inspector.get_foreign_keys(table_name: str, schema: str | None = None, **kw: Any) → List[ReflectedForeignKeyConstraint]
Return information about foreign_keys in table_name.
Given a string table_name, and an optional string schema, return foreign key information as a list of ReflectedForeignKeyConstraint.
Parameters:
• table_name – string name of the table. For special quoting, use quoted_name.
• schema – string schema name; if omitted, uses the default schema of the database connection. For special quoting, use quoted_name.
• **kw – Additional keyword argument to pass to the dialect specific implementation. See the documentation of the dialect in use for more information.
Returns:
a list of dictionaries, each representing the a foreign key definition.
See also
Inspector.get_multi_foreign_keys()
method sqlalchemy.engine.reflection.Inspector.get_indexes(table_name: str, schema: str | None = None, **kw: Any) → List[ReflectedIndex]
Return information about indexes in table_name.
Given a string table_name and an optional string schema, return index information as a list of ReflectedIndex.
Parameters:
• table_name – string name of the table. For special quoting, use quoted_name.
• schema – string schema name; if omitted, uses the default schema of the database connection. For special quoting, use quoted_name.
• **kw – Additional keyword argument to pass to the dialect specific implementation. See the documentation of the dialect in use for more information.
Returns:
a list of dictionaries, each representing the definition of an index.
See also
Inspector.get_multi_indexes()
method sqlalchemy.engine.reflection.Inspector.get_materialized_view_names(schema: str | None = None, **kw: Any) → List[str]
Return all materialized view names in schema.
Parameters:
• schema – Optional, retrieve names from a non-default schema. For special quoting, use quoted_name.
• **kw – Additional keyword argument to pass to the dialect specific implementation. See the documentation of the dialect in use for more information.
Added in version 2.0.
See also
Inspector.get_view_names()
method sqlalchemy.engine.reflection.Inspector.get_multi_check_constraints(schema: Optional[str] = None, filter_names: Optional[Sequence[str]] = None, kind: ObjectKind = <ObjectKind.TABLE: 1>, scope: ObjectScope = <ObjectScope.DEFAULT: 1>, **kw: Any) → Dict[TableKey, List[ReflectedCheckConstraint]]
Return information about check constraints in all tables in the given schema.
The tables can be filtered by passing the names to use to filter_names.
For each table the value is a list of ReflectedCheckConstraint.
Parameters:
• schema – string schema name; if omitted, uses the default schema of the database connection. For special quoting, use quoted_name.
• filter_names – optionally return information only for the objects listed here.
• kind – a ObjectKind that specifies the type of objects to reflect. Defaults to ObjectKind.TABLE.
• scope – a ObjectScope that specifies if constraints of default, temporary or any tables should be reflected. Defaults to ObjectScope.DEFAULT.
• **kw – Additional keyword argument to pass to the dialect specific implementation. See the documentation of the dialect in use for more information.
Returns:
a dictionary where the keys are two-tuple schema,table-name and the values are list of dictionaries, each representing the definition of a check constraints. The schema is None if no schema is provided.
Added in version 2.0.
See also
Inspector.get_check_constraints()
method sqlalchemy.engine.reflection.Inspector.get_multi_columns(schema: Optional[str] = None, filter_names: Optional[Sequence[str]] = None, kind: ObjectKind = <ObjectKind.TABLE: 1>, scope: ObjectScope = <ObjectScope.DEFAULT: 1>, **kw: Any) → Dict[TableKey, List[ReflectedColumn]]
Return information about columns in all objects in the given schema.
The objects can be filtered by passing the names to use to filter_names.
For each table the value is a list of ReflectedColumn.
Parameters:
• schema – string schema name; if omitted, uses the default schema of the database connection. For special quoting, use quoted_name.
• filter_names – optionally return information only for the objects listed here.
• kind – a ObjectKind that specifies the type of objects to reflect. Defaults to ObjectKind.TABLE.
• scope – a ObjectScope that specifies if columns of default, temporary or any tables should be reflected. Defaults to ObjectScope.DEFAULT.
• **kw – Additional keyword argument to pass to the dialect specific implementation. See the documentation of the dialect in use for more information.
Returns:
a dictionary where the keys are two-tuple schema,table-name and the values are list of dictionaries, each representing the definition of a database column. The schema is None if no schema is provided.
Added in version 2.0.
See also
Inspector.get_columns()
method sqlalchemy.engine.reflection.Inspector.get_multi_foreign_keys(schema: Optional[str] = None, filter_names: Optional[Sequence[str]] = None, kind: ObjectKind = <ObjectKind.TABLE: 1>, scope: ObjectScope = <ObjectScope.DEFAULT: 1>, **kw: Any) → Dict[TableKey, List[ReflectedForeignKeyConstraint]]
Return information about foreign_keys in all tables in the given schema.
The tables can be filtered by passing the names to use to filter_names.
For each table the value is a list of ReflectedForeignKeyConstraint.
Parameters:
• schema – string schema name; if omitted, uses the default schema of the database connection. For special quoting, use quoted_name.
• filter_names – optionally return information only for the objects listed here.
• kind – a ObjectKind that specifies the type of objects to reflect. Defaults to ObjectKind.TABLE.
• scope – a ObjectScope that specifies if foreign keys of default, temporary or any tables should be reflected. Defaults to ObjectScope.DEFAULT.
• **kw – Additional keyword argument to pass to the dialect specific implementation. See the documentation of the dialect in use for more information.
Returns:
a dictionary where the keys are two-tuple schema,table-name and the values are list of dictionaries, each representing a foreign key definition. The schema is None if no schema is provided.
Added in version 2.0.
See also
Inspector.get_foreign_keys()
method sqlalchemy.engine.reflection.Inspector.get_multi_indexes(schema: Optional[str] = None, filter_names: Optional[Sequence[str]] = None, kind: ObjectKind = <ObjectKind.TABLE: 1>, scope: ObjectScope = <ObjectScope.DEFAULT: 1>, **kw: Any) → Dict[TableKey, List[ReflectedIndex]]
Return information about indexes in in all objects in the given schema.
The objects can be filtered by passing the names to use to filter_names.
For each table the value is a list of ReflectedIndex.
Parameters:
• schema – string schema name; if omitted, uses the default schema of the database connection. For special quoting, use quoted_name.
• filter_names – optionally return information only for the objects listed here.
• kind – a ObjectKind that specifies the type of objects to reflect. Defaults to ObjectKind.TABLE.
• scope – a ObjectScope that specifies if indexes of default, temporary or any tables should be reflected. Defaults to ObjectScope.DEFAULT.
• **kw – Additional keyword argument to pass to the dialect specific implementation. See the documentation of the dialect in use for more information.
Returns:
a dictionary where the keys are two-tuple schema,table-name and the values are list of dictionaries, each representing the definition of an index. The schema is None if no schema is provided.
Added in version 2.0.
See also
Inspector.get_indexes()
method sqlalchemy.engine.reflection.Inspector.get_multi_pk_constraint(schema: Optional[str] = None, filter_names: Optional[Sequence[str]] = None, kind: ObjectKind = <ObjectKind.TABLE: 1>, scope: ObjectScope = <ObjectScope.DEFAULT: 1>, **kw: Any) → Dict[TableKey, ReflectedPrimaryKeyConstraint]
Return information about primary key constraints in all tables in the given schema.
The tables can be filtered by passing the names to use to filter_names.
For each table the value is a ReflectedPrimaryKeyConstraint.
Parameters:
• schema – string schema name; if omitted, uses the default schema of the database connection. For special quoting, use quoted_name.
• filter_names – optionally return information only for the objects listed here.
• kind – a ObjectKind that specifies the type of objects to reflect. Defaults to ObjectKind.TABLE.
• scope – a ObjectScope that specifies if primary keys of default, temporary or any tables should be reflected. Defaults to ObjectScope.DEFAULT.
• **kw – Additional keyword argument to pass to the dialect specific implementation. See the documentation of the dialect in use for more information.
Returns:
a dictionary where the keys are two-tuple schema,table-name and the values are dictionaries, each representing the definition of a primary key constraint. The schema is None if no schema is provided.
Added in version 2.0.
See also
Inspector.get_pk_constraint()
method sqlalchemy.engine.reflection.Inspector.get_multi_table_comment(schema: Optional[str] = None, filter_names: Optional[Sequence[str]] = None, kind: ObjectKind = <ObjectKind.TABLE: 1>, scope: ObjectScope = <ObjectScope.DEFAULT: 1>, **kw: Any) → Dict[TableKey, ReflectedTableComment]
Return information about the table comment in all objects in the given schema.
The objects can be filtered by passing the names to use to filter_names.
For each table the value is a ReflectedTableComment.
Raises NotImplementedError for a dialect that does not support comments.
Parameters:
• schema – string schema name; if omitted, uses the default schema of the database connection. For special quoting, use quoted_name.
• filter_names – optionally return information only for the objects listed here.
• kind – a ObjectKind that specifies the type of objects to reflect. Defaults to ObjectKind.TABLE.
• scope – a ObjectScope that specifies if comments of default, temporary or any tables should be reflected. Defaults to ObjectScope.DEFAULT.
• **kw – Additional keyword argument to pass to the dialect specific implementation. See the documentation of the dialect in use for more information.
Returns:
a dictionary where the keys are two-tuple schema,table-name and the values are dictionaries, representing the table comments. The schema is None if no schema is provided.
Added in version 2.0.
See also
Inspector.get_table_comment()
method sqlalchemy.engine.reflection.Inspector.get_multi_table_options(schema: Optional[str] = None, filter_names: Optional[Sequence[str]] = None, kind: ObjectKind = <ObjectKind.TABLE: 1>, scope: ObjectScope = <ObjectScope.DEFAULT: 1>, **kw: Any) → Dict[TableKey, Dict[str, Any]]
Return a dictionary of options specified when the tables in the given schema were created.
The tables can be filtered by passing the names to use to filter_names.
This currently includes some options that apply to MySQL and Oracle tables.
Parameters:
• schema – string schema name; if omitted, uses the default schema of the database connection. For special quoting, use quoted_name.
• filter_names – optionally return information only for the objects listed here.
• kind – a ObjectKind that specifies the type of objects to reflect. Defaults to ObjectKind.TABLE.
• scope – a ObjectScope that specifies if options of default, temporary or any tables should be reflected. Defaults to ObjectScope.DEFAULT.
• **kw – Additional keyword argument to pass to the dialect specific implementation. See the documentation of the dialect in use for more information.
Returns:
a dictionary where the keys are two-tuple schema,table-name and the values are dictionaries with the table options. The returned keys in each dict depend on the dialect in use. Each one is prefixed with the dialect name. The schema is None if no schema is provided.
Added in version 2.0.
See also
Inspector.get_table_options()
method sqlalchemy.engine.reflection.Inspector.get_multi_unique_constraints(schema: Optional[str] = None, filter_names: Optional[Sequence[str]] = None, kind: ObjectKind = <ObjectKind.TABLE: 1>, scope: ObjectScope = <ObjectScope.DEFAULT: 1>, **kw: Any) → Dict[TableKey, List[ReflectedUniqueConstraint]]
Return information about unique constraints in all tables in the given schema.
The tables can be filtered by passing the names to use to filter_names.
For each table the value is a list of ReflectedUniqueConstraint.
Parameters:
• schema – string schema name; if omitted, uses the default schema of the database connection. For special quoting, use quoted_name.
• filter_names – optionally return information only for the objects listed here.
• kind – a ObjectKind that specifies the type of objects to reflect. Defaults to ObjectKind.TABLE.
• scope – a ObjectScope that specifies if constraints of default, temporary or any tables should be reflected. Defaults to ObjectScope.DEFAULT.
• **kw – Additional keyword argument to pass to the dialect specific implementation. See the documentation of the dialect in use for more information.
Returns:
a dictionary where the keys are two-tuple schema,table-name and the values are list of dictionaries, each representing the definition of an unique constraint. The schema is None if no schema is provided.
Added in version 2.0.
See also
Inspector.get_unique_constraints()
method sqlalchemy.engine.reflection.Inspector.get_pk_constraint(table_name: str, schema: str | None = None, **kw: Any) → ReflectedPrimaryKeyConstraint
Return information about primary key constraint in table_name.
Given a string table_name, and an optional string schema, return primary key information as a ReflectedPrimaryKeyConstraint.
Parameters:
• table_name – string name of the table. For special quoting, use quoted_name.
• schema – string schema name; if omitted, uses the default schema of the database connection. For special quoting, use quoted_name.
• **kw – Additional keyword argument to pass to the dialect specific implementation. See the documentation of the dialect in use for more information.
Returns:
a dictionary representing the definition of a primary key constraint.
See also
Inspector.get_multi_pk_constraint()
method sqlalchemy.engine.reflection.Inspector.get_schema_names(**kw: Any) → List[str]
Return all schema names.
Parameters:
**kw – Additional keyword argument to pass to the dialect specific implementation. See the documentation of the dialect in use for more information.
method sqlalchemy.engine.reflection.Inspector.get_sequence_names(schema: str | None = None, **kw: Any) → List[str]
Return all sequence names in schema.
Parameters:
• schema – Optional, retrieve names from a non-default schema. For special quoting, use quoted_name.
• **kw – Additional keyword argument to pass to the dialect specific implementation. See the documentation of the dialect in use for more information.
method sqlalchemy.engine.reflection.Inspector.get_sorted_table_and_fkc_names(schema: str | None = None, **kw: Any) → List[Tuple[str | None, List[Tuple[str, str | None]]]]
Return dependency-sorted table and foreign key constraint names in referred to within a particular schema.
This will yield 2-tuples of (tablename, [(tname, fkname), (tname, fkname), ...]) consisting of table names in CREATE order grouped with the foreign key constraint names that are not detected as belonging to a cycle. The final element will be (None, [(tname, fkname), (tname, fkname), ..]) which will consist of remaining foreign key constraint names that would require a separate CREATE step after-the-fact, based on dependencies between tables.
Parameters:
• schema – schema name to query, if not the default schema.
• **kw – Additional keyword argument to pass to the dialect specific implementation. See the documentation of the dialect in use for more information.
See also
Inspector.get_table_names()
sort_tables_and_constraints() - similar method which works with an already-given MetaData.
method sqlalchemy.engine.reflection.Inspector.get_table_comment(table_name: str, schema: str | None = None, **kw: Any) → ReflectedTableComment
Return information about the table comment for table_name.
Given a string table_name and an optional string schema, return table comment information as a ReflectedTableComment.
Raises NotImplementedError for a dialect that does not support comments.
Parameters:
• table_name – string name of the table. For special quoting, use quoted_name.
• schema – string schema name; if omitted, uses the default schema of the database connection. For special quoting, use quoted_name.
• **kw – Additional keyword argument to pass to the dialect specific implementation. See the documentation of the dialect in use for more information.
Returns:
a dictionary, with the table comment.
Added in version 1.2.
See also
Inspector.get_multi_table_comment()
method sqlalchemy.engine.reflection.Inspector.get_table_names(schema: str | None = None, **kw: Any) → List[str]
Return all table names within a particular schema.
The names are expected to be real tables only, not views. Views are instead returned using the Inspector.get_view_names() and/or Inspector.get_materialized_view_names() methods.
Parameters:
• schema – Schema name. If schema is left at None, the database’s default schema is used, else the named schema is searched. If the database does not support named schemas, behavior is undefined if schema is not passed as None. For special quoting, use quoted_name.
• **kw – Additional keyword argument to pass to the dialect specific implementation. See the documentation of the dialect in use for more information.
See also
Inspector.get_sorted_table_and_fkc_names()
MetaData.sorted_tables
method sqlalchemy.engine.reflection.Inspector.get_table_options(table_name: str, schema: str | None = None, **kw: Any) → Dict[str, Any]
Return a dictionary of options specified when the table of the given name was created.
This currently includes some options that apply to MySQL and Oracle Database tables.
Parameters:
• table_name – string name of the table. For special quoting, use quoted_name.
• schema – string schema name; if omitted, uses the default schema of the database connection. For special quoting, use quoted_name.
• **kw – Additional keyword argument to pass to the dialect specific implementation. See the documentation of the dialect in use for more information.
Returns:
a dict with the table options. The returned keys depend on the dialect in use. Each one is prefixed with the dialect name.
See also
Inspector.get_multi_table_options()
method sqlalchemy.engine.reflection.Inspector.get_temp_table_names(**kw: Any) → List[str]
Return a list of temporary table names for the current bind.
This method is unsupported by most dialects; currently only Oracle Database, PostgreSQL and SQLite implements it.
Parameters:
**kw – Additional keyword argument to pass to the dialect specific implementation. See the documentation of the dialect in use for more information.
method sqlalchemy.engine.reflection.Inspector.get_temp_view_names(**kw: Any) → List[str]
Return a list of temporary view names for the current bind.
This method is unsupported by most dialects; currently only PostgreSQL and SQLite implements it.
Parameters:
**kw – Additional keyword argument to pass to the dialect specific implementation. See the documentation of the dialect in use for more information.
method sqlalchemy.engine.reflection.Inspector.get_unique_constraints(table_name: str, schema: str | None = None, **kw: Any) → List[ReflectedUniqueConstraint]
Return information about unique constraints in table_name.
Given a string table_name and an optional string schema, return unique constraint information as a list of ReflectedUniqueConstraint.
Parameters:
• table_name – string name of the table. For special quoting, use quoted_name.
• schema – string schema name; if omitted, uses the default schema of the database connection. For special quoting, use quoted_name.
• **kw – Additional keyword argument to pass to the dialect specific implementation. See the documentation of the dialect in use for more information.
Returns:
a list of dictionaries, each representing the definition of an unique constraint.
See also
Inspector.get_multi_unique_constraints()
method sqlalchemy.engine.reflection.Inspector.get_view_definition(view_name: str, schema: str | None = None, **kw: Any) → str
Return definition for the plain or materialized view called view_name.
Parameters:
• view_name – Name of the view.
• schema – Optional, retrieve names from a non-default schema. For special quoting, use quoted_name.
• **kw – Additional keyword argument to pass to the dialect specific implementation. See the documentation of the dialect in use for more information.
method sqlalchemy.engine.reflection.Inspector.get_view_names(schema: str | None = None, **kw: Any) → List[str]
Return all non-materialized view names in schema.
Parameters:
• schema – Optional, retrieve names from a non-default schema. For special quoting, use quoted_name.
• **kw – Additional keyword argument to pass to the dialect specific implementation. See the documentation of the dialect in use for more information.
Changed in version 2.0: For those dialects that previously included the names of materialized views in this list (currently PostgreSQL), this method no longer returns the names of materialized views. the Inspector.get_materialized_view_names() method should be used instead.
See also
Inspector.get_materialized_view_names()
method sqlalchemy.engine.reflection.Inspector.has_index(table_name: str, index_name: str, schema: str | None = None, **kw: Any) → bool
Check the existence of a particular index name in the database.
Parameters:
• table_name – the name of the table the index belongs to
• index_name – the name of the index to check
• schema – schema name to query, if not the default schema.
• **kw – Additional keyword argument to pass to the dialect specific implementation. See the documentation of the dialect in use for more information.
Added in version 2.0.
method sqlalchemy.engine.reflection.Inspector.has_schema(schema_name: str, **kw: Any) → bool
Return True if the backend has a schema with the given name.
Parameters:
• schema_name – name of the schema to check
• **kw – Additional keyword argument to pass to the dialect specific implementation. See the documentation of the dialect in use for more information.
Added in version 2.0.
method sqlalchemy.engine.reflection.Inspector.has_sequence(sequence_name: str, schema: str | None = None, **kw: Any) → bool
Return True if the backend has a sequence with the given name.
Parameters:
• sequence_name – name of the sequence to check
• schema – schema name to query, if not the default schema.
• **kw – Additional keyword argument to pass to the dialect specific implementation. See the documentation of the dialect in use for more information.
Added in version 1.4.
method sqlalchemy.engine.reflection.Inspector.has_table(table_name: str, schema: str | None = None, **kw: Any) → bool
Return True if the backend has a table, view, or temporary table of the given name.
Parameters:
• table_name – name of the table to check
• schema – schema name to query, if not the default schema.
• **kw – Additional keyword argument to pass to the dialect specific implementation. See the documentation of the dialect in use for more information.
Added in version 1.4: - the Inspector.has_table() method replaces the Engine.has_table() method.
Changed in version 2.0::: Inspector.has_table() now formally supports checking for additional table-like objects:
• any type of views (plain or materialized)
• temporary tables of any kind
Previously, these two checks were not formally specified and different dialects would vary in their behavior. The dialect testing suite now includes tests for all of these object types and should be supported by all SQLAlchemy-included dialects. Support among third party dialects may be lagging, however.
attribute sqlalchemy.engine.reflection.Inspector.info_cache: Dict[Any, Any]
method sqlalchemy.engine.reflection.Inspector.reflect_table(table: Table, include_columns: Collection[str] | None, exclude_columns: Collection[str] = (), resolve_fks: bool = True, _extend_on: Set[Table] | None = None, _reflect_info: _ReflectionInfo | None = None) → None
Given a Table object, load its internal constructs based on introspection.
This is the underlying method used by most dialects to produce table reflection. Direct usage is like:
from sqlalchemy import create_engine, MetaData, Table
from sqlalchemy import inspect

engine = create_engine("...")
meta = MetaData()
user_table = Table("user", meta)
insp = inspect(engine)
insp.reflect_table(user_table, None)
Changed in version 1.4: Renamed from reflecttable to reflect_table
Parameters:
• table – a Table instance.
• include_columns – a list of string column names to include in the reflection process. If None, all columns are reflected.
method sqlalchemy.engine.reflection.Inspector.sort_tables_on_foreign_key_dependency(consider_schemas: Collection[str | None] = (None,), **kw: Any) → List[Tuple[Tuple[str | None, str] | None, List[Tuple[Tuple[str | None, str], str | None]]]]
Return dependency-sorted table and foreign key constraint names referred to within multiple schemas.
This method may be compared to Inspector.get_sorted_table_and_fkc_names(), which works on one schema at a time; here, the method is a generalization that will consider multiple schemas at once including that it will resolve for cross-schema foreign keys.
Added in version 2.0.
class sqlalchemy.engine.interfaces.ReflectedColumn
Dictionary representing the reflected elements corresponding to a Column object.
The ReflectedColumn structure is returned by the get_columns method.
Members
autoincrement, comment, computed, default, dialect_options, identity, name, nullable, type
Class signature
class sqlalchemy.engine.interfaces.ReflectedColumn (builtins.dict)
attribute sqlalchemy.engine.interfaces.ReflectedColumn.autoincrement: NotRequired[bool]
database-dependent autoincrement flag.
This flag indicates if the column has a database-side “autoincrement” flag of some kind. Within SQLAlchemy, other kinds of columns may also act as an “autoincrement” column without necessarily having such a flag on them.
See Column.autoincrement for more background on “autoincrement”.
attribute sqlalchemy.engine.interfaces.ReflectedColumn.comment: NotRequired[str | None]
comment for the column, if present. Only some dialects return this key
attribute sqlalchemy.engine.interfaces.ReflectedColumn.computed: NotRequired[ReflectedComputed]
indicates that this column is computed by the database. Only some dialects return this key.
Added in version 1.3.16: - added support for computed reflection.
attribute sqlalchemy.engine.interfaces.ReflectedColumn.default: str | None
column default expression as a SQL string
attribute sqlalchemy.engine.interfaces.ReflectedColumn.dialect_options: NotRequired[Dict[str, Any]]
Additional dialect-specific options detected for this reflected object
attribute sqlalchemy.engine.interfaces.ReflectedColumn.identity: NotRequired[ReflectedIdentity]
indicates this column is an IDENTITY column. Only some dialects return this key.
Added in version 1.4: - added support for identity column reflection.
attribute sqlalchemy.engine.interfaces.ReflectedColumn.name: str
column name
attribute sqlalchemy.engine.interfaces.ReflectedColumn.nullable: bool
boolean flag if the column is NULL or NOT NULL
attribute sqlalchemy.engine.interfaces.ReflectedColumn.type: TypeEngine[Any]
column type represented as a TypeEngine instance.
class sqlalchemy.engine.interfaces.ReflectedComputed
Represent the reflected elements of a computed column, corresponding to the Computed construct.
The ReflectedComputed structure is part of the ReflectedColumn structure, which is returned by the Inspector.get_columns() method.
Members
persisted, sqltext
Class signature
class sqlalchemy.engine.interfaces.ReflectedComputed (builtins.dict)
attribute sqlalchemy.engine.interfaces.ReflectedComputed.persisted: NotRequired[bool]
indicates if the value is stored in the table or computed on demand
attribute sqlalchemy.engine.interfaces.ReflectedComputed.sqltext: str
the expression used to generate this column returned as a string SQL expression
class sqlalchemy.engine.interfaces.ReflectedCheckConstraint
Dictionary representing the reflected elements corresponding to CheckConstraint.
The ReflectedCheckConstraint structure is returned by the Inspector.get_check_constraints() method.
Members
dialect_options, sqltext
Class signature
class sqlalchemy.engine.interfaces.ReflectedCheckConstraint (builtins.dict)
attribute sqlalchemy.engine.interfaces.ReflectedCheckConstraint.dialect_options: NotRequired[Dict[str, Any]]
Additional dialect-specific options detected for this check constraint
Added in version 1.3.8.
attribute sqlalchemy.engine.interfaces.ReflectedCheckConstraint.sqltext: str
the check constraint’s SQL expression
class sqlalchemy.engine.interfaces.ReflectedForeignKeyConstraint
Dictionary representing the reflected elements corresponding to ForeignKeyConstraint.
The ReflectedForeignKeyConstraint structure is returned by the Inspector.get_foreign_keys() method.
Members
constrained_columns, options, referred_columns, referred_schema, referred_table
Class signature
class sqlalchemy.engine.interfaces.ReflectedForeignKeyConstraint (builtins.dict)
attribute sqlalchemy.engine.interfaces.ReflectedForeignKeyConstraint.constrained_columns: List[str]
local column names which comprise the foreign key
attribute sqlalchemy.engine.interfaces.ReflectedForeignKeyConstraint.options: NotRequired[Dict[str, Any]]
Additional options detected for this foreign key constraint
attribute sqlalchemy.engine.interfaces.ReflectedForeignKeyConstraint.referred_columns: List[str]
referred column names that correspond to constrained_columns
attribute sqlalchemy.engine.interfaces.ReflectedForeignKeyConstraint.referred_schema: str | None
schema name of the table being referred
attribute sqlalchemy.engine.interfaces.ReflectedForeignKeyConstraint.referred_table: str
name of the table being referred
class sqlalchemy.engine.interfaces.ReflectedIdentity
represent the reflected IDENTITY structure of a column, corresponding to the Identity construct.
The ReflectedIdentity structure is part of the ReflectedColumn structure, which is returned by the Inspector.get_columns() method.
Members
always, cache, cycle, increment, maxvalue, minvalue, nomaxvalue, nominvalue, on_null, order, start
Class signature
class sqlalchemy.engine.interfaces.ReflectedIdentity (builtins.dict)
attribute sqlalchemy.engine.interfaces.ReflectedIdentity.always: bool
type of identity column
attribute sqlalchemy.engine.interfaces.ReflectedIdentity.cache: int | None
number of future values in the sequence which are calculated in advance.
attribute sqlalchemy.engine.interfaces.ReflectedIdentity.cycle: bool
allows the sequence to wrap around when the maxvalue or minvalue has been reached.
attribute sqlalchemy.engine.interfaces.ReflectedIdentity.increment: int
increment value of the sequence
attribute sqlalchemy.engine.interfaces.ReflectedIdentity.maxvalue: int
the maximum value of the sequence.
attribute sqlalchemy.engine.interfaces.ReflectedIdentity.minvalue: int
the minimum value of the sequence.
attribute sqlalchemy.engine.interfaces.ReflectedIdentity.nomaxvalue: bool
no maximum value of the sequence.
attribute sqlalchemy.engine.interfaces.ReflectedIdentity.nominvalue: bool
no minimum value of the sequence.
attribute sqlalchemy.engine.interfaces.ReflectedIdentity.on_null: bool
indicates ON NULL
attribute sqlalchemy.engine.interfaces.ReflectedIdentity.order: bool
if true, renders the ORDER keyword.
attribute sqlalchemy.engine.interfaces.ReflectedIdentity.start: int
starting index of the sequence
class sqlalchemy.engine.interfaces.ReflectedIndex
Dictionary representing the reflected elements corresponding to Index.
The ReflectedIndex structure is returned by the Inspector.get_indexes() method.
Members
column_names, column_sorting, dialect_options, duplicates_constraint, expressions, include_columns, name, unique
Class signature
class sqlalchemy.engine.interfaces.ReflectedIndex (builtins.dict)
attribute sqlalchemy.engine.interfaces.ReflectedIndex.column_names: List[str | None]
column names which the index references. An element of this list is None if it’s an expression and is returned in the expressions list.
attribute sqlalchemy.engine.interfaces.ReflectedIndex.column_sorting: NotRequired[Dict[str, Tuple[str]]]
optional dict mapping column names or expressions to tuple of sort keywords, which may include asc, desc, nulls_first, nulls_last.
Added in version 1.3.5.
attribute sqlalchemy.engine.interfaces.ReflectedIndex.dialect_options: NotRequired[Dict[str, Any]]
Additional dialect-specific options detected for this index
attribute sqlalchemy.engine.interfaces.ReflectedIndex.duplicates_constraint: NotRequired[str | None]
Indicates if this index mirrors a constraint with this name
attribute sqlalchemy.engine.interfaces.ReflectedIndex.expressions: NotRequired[List[str]]
Expressions that compose the index. This list, when present, contains both plain column names (that are also in column_names) and expressions (that are None in column_names).
attribute sqlalchemy.engine.interfaces.ReflectedIndex.include_columns: NotRequired[List[str]]
columns to include in the INCLUDE clause for supporting databases.
Deprecated since version 2.0: Legacy value, will be replaced with index_dict["dialect_options"]["<dialect name>_include"]
attribute sqlalchemy.engine.interfaces.ReflectedIndex.name: str | None
index name
attribute sqlalchemy.engine.interfaces.ReflectedIndex.unique: bool
whether or not the index has a unique flag
class sqlalchemy.engine.interfaces.ReflectedPrimaryKeyConstraint
Dictionary representing the reflected elements corresponding to PrimaryKeyConstraint.
The ReflectedPrimaryKeyConstraint structure is returned by the Inspector.get_pk_constraint() method.
Members
constrained_columns, dialect_options
Class signature
class sqlalchemy.engine.interfaces.ReflectedPrimaryKeyConstraint (builtins.dict)
attribute sqlalchemy.engine.interfaces.ReflectedPrimaryKeyConstraint.constrained_columns: List[str]
column names which comprise the primary key
attribute sqlalchemy.engine.interfaces.ReflectedPrimaryKeyConstraint.dialect_options: NotRequired[Dict[str, Any]]
Additional dialect-specific options detected for this primary key
class sqlalchemy.engine.interfaces.ReflectedUniqueConstraint
Dictionary representing the reflected elements corresponding to UniqueConstraint.
The ReflectedUniqueConstraint structure is returned by the Inspector.get_unique_constraints() method.
Members
column_names, dialect_options, duplicates_index
Class signature
class sqlalchemy.engine.interfaces.ReflectedUniqueConstraint (builtins.dict)
attribute sqlalchemy.engine.interfaces.ReflectedUniqueConstraint.column_names: List[str]
column names which comprise the unique constraint
attribute sqlalchemy.engine.interfaces.ReflectedUniqueConstraint.dialect_options: NotRequired[Dict[str, Any]]
Additional dialect-specific options detected for this unique constraint
attribute sqlalchemy.engine.interfaces.ReflectedUniqueConstraint.duplicates_index: NotRequired[str | None]
Indicates if this unique constraint duplicates an index with this name
class sqlalchemy.engine.interfaces.ReflectedTableComment
Dictionary representing the reflected comment corresponding to the Table.comment attribute.
The ReflectedTableComment structure is returned by the Inspector.get_table_comment() method.
Members
text
Class signature
class sqlalchemy.engine.interfaces.ReflectedTableComment (builtins.dict)
attribute sqlalchemy.engine.interfaces.ReflectedTableComment.text: str | None
text of the comment
Reflecting with Database-Agnostic Types
When the columns of a table are reflected, using either the Table.autoload_with parameter of Table or the Inspector.get_columns() method of Inspector, the datatypes will be as specific as possible to the target database. This means that if an “integer” datatype is reflected from a MySQL database, the type will be represented by the sqlalchemy.dialects.mysql.INTEGER class, which includes MySQL-specific attributes such as “display_width”. Or on PostgreSQL, a PostgreSQL-specific datatype such as sqlalchemy.dialects.postgresql.INTERVAL or sqlalchemy.dialects.postgresql.ENUM may be returned.
There is a use case for reflection which is that a given Table is to be transferred to a different vendor database. To suit this use case, there is a technique by which these vendor-specific datatypes can be converted on the fly to be instance of SQLAlchemy backend-agnostic datatypes, for the examples above types such as Integer, Interval and Enum. This may be achieved by intercepting the column reflection using the DDLEvents.column_reflect() event in conjunction with the TypeEngine.as_generic() method.
Given a table in MySQL (chosen because MySQL has a lot of vendor-specific datatypes and options):
CREATE TABLE IF NOT EXISTS my_table (
    id INTEGER PRIMARY KEY AUTO_INCREMENT,
    data1 VARCHAR(50) CHARACTER SET latin1,
    data2 MEDIUMINT(4),
    data3 TINYINT(2)
)
The above table includes MySQL-only integer types MEDIUMINT and TINYINT as well as a VARCHAR that includes the MySQL-only CHARACTER SET option. If we reflect this table normally, it produces a Table object that will contain those MySQL-specific datatypes and options:
>>> from sqlalchemy import MetaData, Table, create_engine
>>> mysql_engine = create_engine("mysql+mysqldb://scott:tiger@localhost/test")
>>> metadata_obj = MetaData()
>>> my_mysql_table = Table("my_table", metadata_obj, autoload_with=mysql_engine)
The above example reflects the above table schema into a new Table object. We can then, for demonstration purposes, print out the MySQL-specific “CREATE TABLE” statement using the CreateTable construct:
>>> from sqlalchemy.schema import CreateTable
>>> print(CreateTable(my_mysql_table).compile(mysql_engine))
CREATE TABLE my_table (
id INTEGER(11) NOT NULL AUTO_INCREMENT,
data1 VARCHAR(50) CHARACTER SET latin1,
data2 MEDIUMINT(4),
data3 TINYINT(2),
PRIMARY KEY (id)
)ENGINE=InnoDB DEFAULT CHARSET=utf8mb4
Above, the MySQL-specific datatypes and options were maintained. If we wanted a Table that we could instead transfer cleanly to another database vendor, replacing the special datatypes sqlalchemy.dialects.mysql.MEDIUMINT and sqlalchemy.dialects.mysql.TINYINT with Integer, we can choose instead to “genericize” the datatypes on this table, or otherwise change them in any way we’d like, by establishing a handler using the DDLEvents.column_reflect() event. The custom handler will make use of the TypeEngine.as_generic() method to convert the above MySQL-specific type objects into generic ones, by replacing the "type" entry within the column dictionary entry that is passed to the event handler. The format of this dictionary is described at Inspector.get_columns():
>>> from sqlalchemy import event
>>> metadata_obj = MetaData()

>>> @event.listens_for(metadata_obj, "column_reflect")
... def genericize_datatypes(inspector, tablename, column_dict):
...     column_dict["type"] = column_dict["type"].as_generic()

>>> my_generic_table = Table("my_table", metadata_obj, autoload_with=mysql_engine)
We now get a new Table that is generic and uses Integer for those datatypes. We can now emit a “CREATE TABLE” statement for example on a PostgreSQL database:
>>> pg_engine = create_engine("postgresql+psycopg2://scott:tiger@localhost/test", echo=True)
>>> my_generic_table.create(pg_engine)
CREATE TABLE my_table (
    id SERIAL NOT NULL,
    data1 VARCHAR(50),
    data2 INTEGER,
    data3 INTEGER,
    PRIMARY KEY (id)
)
Noting above also that SQLAlchemy will usually make a decent guess for other behaviors, such as that the MySQL AUTO_INCREMENT directive is represented in PostgreSQL most closely using the SERIAL auto-incrementing datatype.
Added in version 1.4: Added the TypeEngine.as_generic() method and additionally improved the use of the DDLEvents.column_reflect() event such that it may be applied to a MetaData object for convenience.
Limitations of Reflection
It’s important to note that the reflection process recreates Table metadata using only information which is represented in the relational database. This process by definition cannot restore aspects of a schema that aren’t actually stored in the database. State which is not available from reflection includes but is not limited to:
• Client side defaults, either Python functions or SQL expressions defined using the default keyword of Column (note this is separate from server_default, which specifically is what’s available via reflection).
• Column information, e.g. data that might have been placed into the Column.info dictionary
• The value of the .quote setting for Column or Table
• The association of a particular Sequence with a given Column
The relational database also in many cases reports on table metadata in a different format than what was specified in SQLAlchemy. The Table objects returned from reflection cannot be always relied upon to produce the identical DDL as the original Python-defined Table objects. Areas where this occurs includes server defaults, column-associated sequences and various idiosyncrasies regarding constraints and datatypes. Server side defaults may be returned with cast directives (typically PostgreSQL will include a ::<type> cast) or different quoting patterns than originally specified.
Another category of limitation includes schema structures for which reflection is only partially or not yet defined. Recent improvements to reflection allow things like views, indexes and foreign key options to be reflected. As of this writing, structures like CHECK constraints, table comments, and triggers are not reflected.


Column INSERT/UPDATE Defaults
Column INSERT and UPDATE defaults refer to functions that create a default value for a particular column in a row as an INSERT or UPDATE statement is proceeding against that row, in the case where no value was provided to the INSERT or UPDATE statement for that column. That is, if a table has a column called “timestamp”, and an INSERT statement proceeds which does not include a value for this column, an INSERT default would create a new value, such as the current time, that is used as the value to be INSERTed into the “timestamp” column. If the statement does include a value for this column, then the default does not take place.
Column defaults can be server-side functions or constant values which are defined in the database along with the schema in DDL, or as SQL expressions which are rendered directly within an INSERT or UPDATE statement emitted by SQLAlchemy; they may also be client-side Python functions or constant values which are invoked by SQLAlchemy before data is passed to the database.
Note
A column default handler should not be confused with a construct that intercepts and modifies incoming values for INSERT and UPDATE statements which are provided to the statement as it is invoked. This is known as data marshalling, where a column value is modified in some way by the application before being sent to the database. SQLAlchemy provides a few means of achieving this which include using custom datatypes, SQL execution events and in the ORM custom validators as well as attribute events. Column defaults are only invoked when there is no value present for a column in a SQL DML statement.
SQLAlchemy provides an array of features regarding default generation functions which take place for non-present values during INSERT and UPDATE statements. Options include:
• Scalar values used as defaults during INSERT and UPDATE operations
• Python functions which execute upon INSERT and UPDATE operations
• SQL expressions which are embedded in INSERT statements (or in some cases execute beforehand)
• SQL expressions which are embedded in UPDATE statements
• Server side default values used during INSERT
• Markers for server-side triggers used during UPDATE
The general rule for all insert/update defaults is that they only take effect if no value for a particular column is passed as an execute() parameter; otherwise, the given value is used.
Scalar Defaults
The simplest kind of default is a scalar value used as the default value of a column:
Table("mytable", metadata_obj, Column("somecolumn", Integer, default=12))
Above, the value “12” will be bound as the column value during an INSERT if no other value is supplied.
A scalar value may also be associated with an UPDATE statement, though this is not very common (as UPDATE statements are usually looking for dynamic defaults):
Table("mytable", metadata_obj, Column("somecolumn", Integer, onupdate=25))
Python-Executed Functions
The Column.default and Column.onupdate keyword arguments also accept Python functions. These functions are invoked at the time of insert or update if no other value for that column is supplied, and the value returned is used for the column’s value. Below illustrates a crude “sequence” that assigns an incrementing counter to a primary key column:
# a function which counts upwards
i = 0


def mydefault():
    global i
    i += 1
    return i


t = Table(
    "mytable",
    metadata_obj,
    Column("id", Integer, primary_key=True, default=mydefault),
)
It should be noted that for real “incrementing sequence” behavior, the built-in capabilities of the database should normally be used, which may include sequence objects or other autoincrementing capabilities. For primary key columns, SQLAlchemy will in most cases use these capabilities automatically. See the API documentation for Column including the Column.autoincrement flag, as well as the section on Sequence later in this chapter for background on standard primary key generation techniques.
To illustrate onupdate, we assign the Python datetime function now to the Column.onupdate attribute:
import datetime

t = Table(
    "mytable",
    metadata_obj,
    Column("id", Integer, primary_key=True),
    # define 'last_updated' to be populated with datetime.now()
    Column("last_updated", DateTime, onupdate=datetime.datetime.now),
)
When an update statement executes and no value is passed for last_updated, the datetime.datetime.now() Python function is executed and its return value used as the value for last_updated. Notice that we provide now as the function itself without calling it (i.e. there are no parenthesis following) - SQLAlchemy will execute the function at the time the statement executes.
Context-Sensitive Default Functions
The Python functions used by Column.default and Column.onupdate may also make use of the current statement’s context in order to determine a value. The context of a statement is an internal SQLAlchemy object which contains all information about the statement being executed, including its source expression, the parameters associated with it and the cursor. The typical use case for this context with regards to default generation is to have access to the other values being inserted or updated on the row. To access the context, provide a function that accepts a single context argument:
def mydefault(context):
    return context.get_current_parameters()["counter"] + 12


t = Table(
    "mytable",
    metadata_obj,
    Column("counter", Integer),
    Column("counter_plus_twelve", Integer, default=mydefault, onupdate=mydefault),
)
The above default generation function is applied so that it will execute for all INSERT and UPDATE statements where a value for counter_plus_twelve was otherwise not provided, and the value will be that of whatever value is present in the execution for the counter column, plus the number 12.
For a single statement that is being executed using “executemany” style, e.g. with multiple parameter sets passed to Connection.execute(), the user-defined function is called once for each set of parameters. For the use case of a multi-valued Insert construct (e.g. with more than one VALUES clause set up via the Insert.values() method), the user-defined function is also called once for each set of parameters.
When the function is invoked, the special method DefaultExecutionContext.get_current_parameters() is available from the context object (an subclass of DefaultExecutionContext). This method returns a dictionary of column-key to values that represents the full set of values for the INSERT or UPDATE statement. In the case of a multi-valued INSERT construct, the subset of parameters that corresponds to the individual VALUES clause is isolated from the full parameter dictionary and returned alone.
Added in version 1.2: Added DefaultExecutionContext.get_current_parameters() method, which improves upon the still-present DefaultExecutionContext.current_parameters attribute by offering the service of organizing multiple VALUES clauses into individual parameter dictionaries.
Client-Invoked SQL Expressions
The Column.default and Column.onupdate keywords may also be passed SQL expressions, which are in most cases rendered inline within the INSERT or UPDATE statement:
t = Table(
    "mytable",
    metadata_obj,
    Column("id", Integer, primary_key=True),
    # define 'create_date' to default to now()
    Column("create_date", DateTime, default=func.now()),
    # define 'key' to pull its default from the 'keyvalues' table
    Column(
        "key",
        String(20),
        default=select(keyvalues.c.key).where(keyvalues.c.type="type1"),
    ),
    # define 'last_modified' to use the current_timestamp SQL function on update
    Column("last_modified", DateTime, onupdate=func.utc_timestamp()),
)
Above, the create_date column will be populated with the result of the now() SQL function (which, depending on backend, compiles into NOW() or CURRENT_TIMESTAMP in most cases) during an INSERT statement, and the key column with the result of a SELECT subquery from another table. The last_modified column will be populated with the value of the SQL UTC_TIMESTAMP() MySQL function when an UPDATE statement is emitted for this table.
Note
When using SQL functions with the func construct, we “call” the named function, e.g. with parenthesis as in func.now(). This differs from when we specify a Python callable as a default such as datetime.datetime, where we pass the function itself, but we don’t invoke it ourselves. In the case of a SQL function, invoking func.now() returns the SQL expression object that will render the “NOW” function into the SQL being emitted.
Default and update SQL expressions specified by Column.default and Column.onupdate are invoked explicitly by SQLAlchemy when an INSERT or UPDATE statement occurs, typically rendered inline within the DML statement except in certain cases listed below. This is different than a “server side” default, which is part of the table’s DDL definition, e.g. as part of the “CREATE TABLE” statement, which are likely more common. For server side defaults, see the next section Server-invoked DDL-Explicit Default Expressions.
When a SQL expression indicated by Column.default is used with primary key columns, there are some cases where SQLAlchemy must “pre-execute” the default generation SQL function, meaning it is invoked in a separate SELECT statement, and the resulting value is passed as a parameter to the INSERT. This only occurs for primary key columns for an INSERT statement that is being asked to return this primary key value, where RETURNING or cursor.lastrowid may not be used. An Insert construct that specifies the insert.inline flag will always render default expressions inline.
When the statement is executed with a single set of parameters (that is, it is not an “executemany” style execution), the returned CursorResult will contain a collection accessible via CursorResult.postfetch_cols() which contains a list of all Column objects which had an inline-executed default. Similarly, all parameters which were bound to the statement, including all Python and SQL expressions which were pre-executed, are present in the CursorResult.last_inserted_params() or CursorResult.last_updated_params() collections on CursorResult. The CursorResult.inserted_primary_key collection contains a list of primary key values for the row inserted (a list so that single-column and composite-column primary keys are represented in the same format).
Server-invoked DDL-Explicit Default Expressions
A variant on the SQL expression default is the Column.server_default, which gets placed in the CREATE TABLE statement during a Table.create() operation:
t = Table(
    "test",
    metadata_obj,
    Column("abc", String(20), server_default="abc"),
    Column("created_at", DateTime, server_default=func.sysdate()),
    Column("index_value", Integer, server_default=text("0")),
)
A create call for the above table will produce:
CREATE TABLE test (
    abc varchar(20) default 'abc',
    created_at datetime default sysdate,
    index_value integer default 0
)
The above example illustrates the two typical use cases for Column.server_default, that of the SQL function (SYSDATE in the above example) as well as a server-side constant value (the integer “0” in the above example). It is advisable to use the text() construct for any literal SQL values as opposed to passing the raw value, as SQLAlchemy does not typically perform any quoting or escaping on these values.
Like client-generated expressions, Column.server_default can accommodate SQL expressions in general, however it is expected that these will usually be simple functions and expressions, and not the more complex cases like an embedded SELECT.
Marking Implicitly Generated Values, timestamps, and Triggered Columns
Columns which generate a new value on INSERT or UPDATE based on other server-side database mechanisms, such as database-specific auto-generating behaviors such as seen with TIMESTAMP columns on some platforms, as well as custom triggers that invoke upon INSERT or UPDATE to generate a new value, may be called out using FetchedValue as a marker:
from sqlalchemy.schema import FetchedValue

t = Table(
    "test",
    metadata_obj,
    Column("id", Integer, primary_key=True),
    Column("abc", TIMESTAMP, server_default=FetchedValue()),
    Column("def", String(20), server_onupdate=FetchedValue()),
)
The FetchedValue indicator does not affect the rendered DDL for the CREATE TABLE. Instead, it marks the column as one that will have a new value populated by the database during the process of an INSERT or UPDATE statement, and for supporting databases may be used to indicate that the column should be part of a RETURNING or OUTPUT clause for the statement. Tools such as the SQLAlchemy ORM then make use of this marker in order to know how to get at the value of the column after such an operation. In particular, the ValuesBase.return_defaults() method can be used with an Insert or Update construct to indicate that these values should be returned.
For details on using FetchedValue with the ORM, see Fetching Server-Generated Defaults.
Warning
The Column.server_onupdate directive does not currently produce MySQL’s “ON UPDATE CURRENT_TIMESTAMP()” clause. See Rendering ON UPDATE CURRENT TIMESTAMP for MySQL / MariaDB’s explicit_defaults_for_timestamp for background on how to produce this clause.
See also
Fetching Server-Generated Defaults
Defining Sequences
SQLAlchemy represents database sequences using the Sequence object, which is considered to be a special case of “column default”. It only has an effect on databases which have explicit support for sequences, which among SQLAlchemy’s included dialects includes PostgreSQL, Oracle Database, MS SQL Server, and MariaDB. The Sequence object is otherwise ignored.
Tip
In newer database engines, the Identity construct should likely be preferred vs. Sequence for generation of integer primary key values. See the section Identity Columns (GENERATED { ALWAYS | BY DEFAULT } AS IDENTITY) for background on this construct.
The Sequence may be placed on any column as a “default” generator to be used during INSERT operations, and can also be configured to fire off during UPDATE operations if desired. It is most commonly used in conjunction with a single integer primary key column:
table = Table(
    "cartitems",
    metadata_obj,
    Column(
        "cart_id",
        Integer,
        Sequence("cart_id_seq", start=1),
        primary_key=True,
    ),
    Column("description", String(40)),
    Column("createdate", DateTime()),
)
Where above, the table cartitems is associated with a sequence named cart_id_seq. Emitting MetaData.create_all() for the above table will include:
CREATE SEQUENCE cart_id_seq START WITH 1

CREATE TABLE cartitems (
  cart_id INTEGER NOT NULL,
  description VARCHAR(40),
  createdate TIMESTAMP WITHOUT TIME ZONE,
  PRIMARY KEY (cart_id)
)
Tip
When using tables with explicit schema names (detailed at Specifying the Schema Name), the configured schema of the Table is not automatically shared by an embedded Sequence, instead, specify Sequence.schema:
Sequence("cart_id_seq", start=1, schema="some_schema")
The Sequence may also be made to automatically make use of the MetaData.schema setting on the MetaData in use; see Associating a Sequence with the MetaData for background.
When Insert DML constructs are invoked against the cartitems table, without an explicit value passed for the cart_id column, the cart_id_seq sequence will be used to generate a value on participating backends. Typically, the sequence function is embedded in the INSERT statement, which is combined with RETURNING so that the newly generated value can be returned to the Python process:
INSERT INTO cartitems (cart_id, description, createdate)
VALUES (next_val(cart_id_seq), 'some description', '2015-10-15 12:00:15')
RETURNING cart_id
When using Connection.execute() to invoke an Insert construct, newly generated primary key identifiers, including but not limited to those generated using Sequence, are available from the CursorResult construct using the CursorResult.inserted_primary_key attribute.
When the Sequence is associated with a Column as its Python-side default generator, the Sequence will also be subject to “CREATE SEQUENCE” and “DROP SEQUENCE” DDL when similar DDL is emitted for the owning Table, such as when using MetaData.create_all() to generate DDL for a series of tables.
The Sequence may also be associated with a MetaData construct directly. This allows the Sequence to be used in more than one Table at a time and also allows the MetaData.schema parameter to be inherited. See the section Associating a Sequence with the MetaData for background.
Associating a Sequence on a SERIAL column
PostgreSQL’s SERIAL datatype is an auto-incrementing type that implies the implicit creation of a PostgreSQL sequence when CREATE TABLE is emitted. The Sequence construct, when indicated for a Column, may indicate that it should not be used in this specific case by specifying a value of True for the Sequence.optional parameter. This allows the given Sequence to be used for backends that have no alternative primary key generation system but to ignore it for backends such as PostgreSQL which will automatically generate a sequence for a particular column:
table = Table(
    "cartitems",
    metadata_obj,
    Column(
        "cart_id",
        Integer,
        # use an explicit Sequence where available, but not on
        # PostgreSQL where SERIAL will be used
        Sequence("cart_id_seq", start=1, optional=True),
        primary_key=True,
    ),
    Column("description", String(40)),
    Column("createdate", DateTime()),
)
In the above example, CREATE TABLE for PostgreSQL will make use of the SERIAL datatype for the cart_id column, and the cart_id_seq sequence will be ignored. However on Oracle Database, the cart_id_seq sequence will be created explicitly.
Tip
This particular interaction of SERIAL and SEQUENCE is fairly legacy, and as in other cases, using Identity instead will simplify the operation to simply use IDENTITY on all supported backends.
Executing a Sequence Standalone
A SEQUENCE is a first class schema object in SQL and can be used to generate values independently in the database. If you have a Sequence object, it can be invoked with its “next value” instruction by passing it directly to a SQL execution method:
with my_engine.connect() as conn:
    seq = Sequence("some_sequence", start=1)
    nextid = conn.execute(seq)
In order to embed the “next value” function of a Sequence inside of a SQL statement like a SELECT or INSERT, use the Sequence.next_value() method, which will render at statement compilation time a SQL function that is appropriate for the target backend:
>>> my_seq = Sequence("some_sequence", start=1)
>>> stmt = select(my_seq.next_value())
>>> print(stmt.compile(dialect=postgresql.dialect()))
SELECT nextval('some_sequence') AS next_value_1
Associating a Sequence with the MetaData
For a Sequence that is to be associated with arbitrary Table objects, the Sequence may be associated with a particular MetaData, using the Sequence.metadata parameter:
seq = Sequence("my_general_seq", metadata=metadata_obj, start=1)
Such a sequence can then be associated with columns in the usual way:
table = Table(
    "cartitems",
    metadata_obj,
    seq,
    Column("description", String(40)),
    Column("createdate", DateTime()),
)
In the above example, the Sequence object is treated as an independent schema construct that can exist on its own or be shared among tables.
Explicitly associating the Sequence with MetaData allows for the following behaviors:
• The Sequence will inherit the MetaData.schema parameter specified to the target MetaData, which affects the production of CREATE / DROP DDL as well as how the Sequence.next_value() function is rendered in SQL statements.
• The MetaData.create_all() and MetaData.drop_all() methods will emit CREATE / DROP for this Sequence, even if the Sequence is not associated with any Table / Column that’s a member of this MetaData.
Associating a Sequence as the Server Side Default
Note
The following technique is known to work only with the PostgreSQL database. It does not work with Oracle Database.
The preceding sections illustrate how to associate a Sequence with a Column as the Python side default generator:
Column(
    "cart_id",
    Integer,
    Sequence("cart_id_seq", metadata=metadata_obj, start=1),
    primary_key=True,
)
In the above case, the Sequence will automatically be subject to CREATE SEQUENCE / DROP SEQUENCE DDL when the related Table is subject to CREATE / DROP. However, the sequence will not be present as the server-side default for the column when CREATE TABLE is emitted.
If we want the sequence to be used as a server-side default, meaning it takes place even if we emit INSERT commands to the table from the SQL command line, we can use the Column.server_default parameter in conjunction with the value-generation function of the sequence, available from the Sequence.next_value() method. Below we illustrate the same Sequence being associated with the Column both as the Python-side default generator as well as the server-side default generator:
cart_id_seq = Sequence("cart_id_seq", metadata=metadata_obj, start=1)
table = Table(
    "cartitems",
    metadata_obj,
    Column(
        "cart_id",
        Integer,
        cart_id_seq,
        server_default=cart_id_seq.next_value(),
        primary_key=True,
    ),
    Column("description", String(40)),
    Column("createdate", DateTime()),
)
or with the ORM:
class CartItem(Base):
    __tablename__ = "cartitems"

    cart_id_seq = Sequence("cart_id_seq", metadata=Base.metadata, start=1)
    cart_id = Column(
        Integer, cart_id_seq, server_default=cart_id_seq.next_value(), primary_key=True
    )
    description = Column(String(40))
    createdate = Column(DateTime)
When the “CREATE TABLE” statement is emitted, on PostgreSQL it would be emitted as:
CREATE TABLE cartitems (
    cart_id INTEGER DEFAULT nextval('cart_id_seq') NOT NULL,
    description VARCHAR(40),
    createdate TIMESTAMP WITHOUT TIME ZONE,
    PRIMARY KEY (cart_id)
)
Placement of the Sequence in both the Python-side and server-side default generation contexts ensures that the “primary key fetch” logic works in all cases. Typically, sequence-enabled databases also support RETURNING for INSERT statements, which is used automatically by SQLAlchemy when emitting this statement. However if RETURNING is not used for a particular insert, then SQLAlchemy would prefer to “pre-execute” the sequence outside of the INSERT statement itself, which only works if the sequence is included as the Python-side default generator function.
The example also associates the Sequence with the enclosing MetaData directly, which again ensures that the Sequence is fully associated with the parameters of the MetaData collection including the default schema, if any.
See also
Sequences/SERIAL/IDENTITY - in the PostgreSQL dialect documentation
RETURNING Support - in the Oracle Database dialect documentation
Computed Columns (GENERATED ALWAYS AS)
Added in version 1.3.11.
The Computed construct allows a Column to be declared in DDL as a “GENERATED ALWAYS AS” column, that is, one which has a value that is computed by the database server. The construct accepts a SQL expression typically declared textually using a string or the text() construct, in a similar manner as that of CheckConstraint. The SQL expression is then interpreted by the database server in order to determine the value for the column within a row.
Example:
from sqlalchemy import Table, Column, MetaData, Integer, Computed

metadata_obj = MetaData()

square = Table(
    "square",
    metadata_obj,
    Column("id", Integer, primary_key=True),
    Column("side", Integer),
    Column("area", Integer, Computed("side * side")),
    Column("perimeter", Integer, Computed("4 * side")),
)
The DDL for the square table when run on a PostgreSQL 12 backend will look like:
CREATE TABLE square (
    id SERIAL NOT NULL,
    side INTEGER,
    area INTEGER GENERATED ALWAYS AS (side * side) STORED,
    perimeter INTEGER GENERATED ALWAYS AS (4 * side) STORED,
    PRIMARY KEY (id)
)
Whether the value is persisted upon INSERT and UPDATE, or if it is calculated on fetch, is an implementation detail of the database; the former is known as “stored” and the latter is known as “virtual”. Some database implementations support both, but some only support one or the other. The optional Computed.persisted flag may be specified as True or False to indicate if the “STORED” or “VIRTUAL” keyword should be rendered in DDL, however this will raise an error if the keyword is not supported by the target backend; leaving it unset will use a working default for the target backend.
The Computed construct is a subclass of the FetchedValue object, and will set itself up as both the “server default” and “server onupdate” generator for the target Column, meaning it will be treated as a default generating column when INSERT and UPDATE statements are generated, as well as that it will be fetched as a generating column when using the ORM. This includes that it will be part of the RETURNING clause of the database for databases which support RETURNING and the generated values are to be eagerly fetched.
Note
A Column that is defined with the Computed construct may not store any value outside of that which the server applies to it; SQLAlchemy’s behavior when a value is passed for such a column to be written in INSERT or UPDATE is currently that the value will be ignored.
“GENERATED ALWAYS AS” is currently known to be supported by:
• MySQL version 5.7 and onwards
• MariaDB 10.x series and onwards
• PostgreSQL as of version 12
• Oracle Database - with the caveat that RETURNING does not work correctly with UPDATE (a warning will be emitted to this effect when the UPDATE..RETURNING that includes a computed column is rendered)
• Microsoft SQL Server
• SQLite as of version 3.31
When Computed is used with an unsupported backend, if the target dialect does not support it, a CompileError is raised when attempting to render the construct. Otherwise, if the dialect supports it but the particular database server version in use does not, then a subclass of DBAPIError, usually OperationalError, is raised when the DDL is emitted to the database.
See also
Computed
Identity Columns (GENERATED { ALWAYS | BY DEFAULT } AS IDENTITY)
Added in version 1.4.
The Identity construct allows a Column to be declared as an identity column and rendered in DDL as “GENERATED { ALWAYS | BY DEFAULT } AS IDENTITY”. An identity column has its value automatically generated by the database server using an incrementing (or decrementing) sequence. The construct shares most of its option to control the database behaviour with Sequence.
Example:
from sqlalchemy import Table, Column, MetaData, Integer, Identity, String

metadata_obj = MetaData()

data = Table(
    "data",
    metadata_obj,
    Column("id", Integer, Identity(start=42, cycle=True), primary_key=True),
    Column("data", String),
)
The DDL for the data table when run on a PostgreSQL 12 backend will look like:
CREATE TABLE data (
    id INTEGER GENERATED BY DEFAULT AS IDENTITY (START WITH 42 CYCLE) NOT NULL,
    data VARCHAR,
    PRIMARY KEY (id)
)
The database will generate a value for the id column upon insert, starting from 42, if the statement did not already contain a value for the id column. An identity column can also require that the database generates the value of the column, ignoring the value passed with the statement or raising an error, depending on the backend. To activate this mode, set the parameter Identity.always to True in the Identity construct. Updating the previous example to include this parameter will generate the following DDL:
CREATE TABLE data (
    id INTEGER GENERATED ALWAYS AS IDENTITY (START WITH 42 CYCLE) NOT NULL,
    data VARCHAR,
    PRIMARY KEY (id)
)
The Identity construct is a subclass of the FetchedValue object, and will set itself up as the “server default” generator for the target Column, meaning it will be treated as a default generating column when INSERT statements are generated, as well as that it will be fetched as a generating column when using the ORM. This includes that it will be part of the RETURNING clause of the database for databases which support RETURNING and the generated values are to be eagerly fetched.
The Identity construct is currently known to be supported by:
• PostgreSQL as of version 10.
• Oracle Database as of version 12. It also supports passing always=None to enable the default generated mode and the parameter on_null=True to specify “ON NULL” in conjunction with a “BY DEFAULT” identity column.
• Microsoft SQL Server. MSSQL uses a custom syntax that only supports the start and increment parameters, and ignores all other.
When Identity is used with an unsupported backend, it is ignored, and the default SQLAlchemy logic for autoincrementing columns is used.
An error is raised when a Column specifies both an Identity and also sets Column.autoincrement to False.
See also
Identity
Default Objects API
Object NameDescriptionColumnDefaultA plain default value on a column.ComputedDefines a generated column, i.e. “GENERATED ALWAYS AS” syntax.DefaultClauseA DDL-specified DEFAULT column value.DefaultGeneratorBase class for column default values.FetchedValueA marker for a transparent database-side default.IdentityDefines an identity column, i.e. “GENERATED { ALWAYS | BY DEFAULT } AS IDENTITY” syntax.SequenceRepresents a named database sequence.class sqlalchemy.schema.Computed
Defines a generated column, i.e. “GENERATED ALWAYS AS” syntax.
The Computed construct is an inline construct added to the argument list of a Column object:
from sqlalchemy import Computed

Table(
    "square",
    metadata_obj,
    Column("side", Float, nullable=False),
    Column("area", Float, Computed("side * side")),
)
See the linked documentation below for complete details.
Added in version 1.3.11.
See also
Computed Columns (GENERATED ALWAYS AS)
Members
__init__(), copy()
Class signature
class sqlalchemy.schema.Computed (sqlalchemy.schema.FetchedValue, sqlalchemy.schema.SchemaItem)
method sqlalchemy.schema.Computed.__init__(sqltext: _DDLColumnArgument, persisted: bool | None = None) → None
Construct a GENERATED ALWAYS AS DDL construct to accompany a Column.
Parameters:
• sqltext – A string containing the column generation expression, which will be used verbatim, or a SQL expression construct, such as a text() object. If given as a string, the object is converted to a text() object.
• persisted – 
Optional, controls how this column should be persisted by the database. Possible values are:
o None, the default, it will use the default persistence defined by the database.
o True, will render GENERATED ALWAYS AS ... STORED, or the equivalent for the target database if supported.
o False, will render GENERATED ALWAYS AS ... VIRTUAL, or the equivalent for the target database if supported.
Specifying True or False may raise an error when the DDL is emitted to the target database if the database does not support that persistence option. Leaving this parameter at its default of None is guaranteed to succeed for all databases that support GENERATED ALWAYS AS.
method sqlalchemy.schema.Computed.copy(*, target_table: Table | None = None, **kw: Any) → Computed
Deprecated since version 1.4: The Computed.copy() method is deprecated and will be removed in a future release.
class sqlalchemy.schema.ColumnDefault
A plain default value on a column.
This could correspond to a constant, a callable function, or a SQL clause.
ColumnDefault is generated automatically whenever the default, onupdate arguments of Column are used. A ColumnDefault can be passed positionally as well.
For example, the following:
Column("foo", Integer, default=50)
Is equivalent to:
Column("foo", Integer, ColumnDefault(50))
Class signature
class sqlalchemy.schema.ColumnDefault (sqlalchemy.schema.DefaultGenerator, abc.ABC)
class sqlalchemy.schema.DefaultClause
A DDL-specified DEFAULT column value.
DefaultClause is a FetchedValue that also generates a “DEFAULT” clause when “CREATE TABLE” is emitted.
DefaultClause is generated automatically whenever the server_default, server_onupdate arguments of Column are used. A DefaultClause can be passed positionally as well.
For example, the following:
Column("foo", Integer, server_default="50")
Is equivalent to:
Column("foo", Integer, DefaultClause("50"))
Class signature
class sqlalchemy.schema.DefaultClause (sqlalchemy.schema.FetchedValue)
class sqlalchemy.schema.DefaultGenerator
Base class for column default values.
This object is only present on column.default or column.onupdate. It’s not valid as a server default.
Class signature
class sqlalchemy.schema.DefaultGenerator (sqlalchemy.sql.expression.Executable, sqlalchemy.schema.SchemaItem)
class sqlalchemy.schema.FetchedValue
A marker for a transparent database-side default.
Use FetchedValue when the database is configured to provide some automatic default for a column.
E.g.:
Column("foo", Integer, FetchedValue())
Would indicate that some trigger or default generator will create a new value for the foo column during an INSERT.
See also
Marking Implicitly Generated Values, timestamps, and Triggered Columns
Class signature
class sqlalchemy.schema.FetchedValue (sqlalchemy.sql.expression.SchemaEventTarget)
class sqlalchemy.schema.Sequence
Represents a named database sequence.
The Sequence object represents the name and configurational parameters of a database sequence. It also represents a construct that can be “executed” by a SQLAlchemy Engine or Connection, rendering the appropriate “next value” function for the target database and returning a result.
The Sequence is typically associated with a primary key column:
some_table = Table(
    "some_table",
    metadata,
    Column(
        "id",
        Integer,
        Sequence("some_table_seq", start=1),
        primary_key=True,
    ),
)
When CREATE TABLE is emitted for the above Table, if the target platform supports sequences, a CREATE SEQUENCE statement will be emitted as well. For platforms that don’t support sequences, the Sequence construct is ignored.
See also
Defining Sequences
CreateSequence
DropSequence
Members
__init__(), create(), drop(), next_value()
Class signature
class sqlalchemy.schema.Sequence (sqlalchemy.schema.HasSchemaAttr, sqlalchemy.schema.IdentityOptions, sqlalchemy.schema.DefaultGenerator)
method sqlalchemy.schema.Sequence.__init__(name: str, start: int | None = None, increment: int | None = None, minvalue: int | None = None, maxvalue: int | None = None, nominvalue: bool | None = None, nomaxvalue: bool | None = None, cycle: bool | None = None, schema: str | Literal[SchemaConst.BLANK_SCHEMA] | None = None, cache: int | None = None, order: bool | None = None, data_type: _TypeEngineArgument[int] | None = None, optional: bool = False, quote: bool | None = None, metadata: MetaData | None = None, quote_schema: bool | None = None, for_update: bool = False) → None
Construct a Sequence object.
Parameters:
• name – the name of the sequence.
• start – 
the starting index of the sequence. This value is used when the CREATE SEQUENCE command is emitted to the database as the value of the “START WITH” clause. If None, the clause is omitted, which on most platforms indicates a starting value of 1.
Changed in version 2.0: The Sequence.start parameter is required in order to have DDL emit “START WITH”. This is a reversal of a change made in version 1.4 which would implicitly render “START WITH 1” if the Sequence.start were not included. See The Sequence construct reverts to not having any explicit default “start” value; impacts MS SQL Server for more detail.
• increment – the increment value of the sequence. This value is used when the CREATE SEQUENCE command is emitted to the database as the value of the “INCREMENT BY” clause. If None, the clause is omitted, which on most platforms indicates an increment of 1.
• minvalue – the minimum value of the sequence. This value is used when the CREATE SEQUENCE command is emitted to the database as the value of the “MINVALUE” clause. If None, the clause is omitted, which on most platforms indicates a minvalue of 1 and -2^63-1 for ascending and descending sequences, respectively.
• maxvalue – the maximum value of the sequence. This value is used when the CREATE SEQUENCE command is emitted to the database as the value of the “MAXVALUE” clause. If None, the clause is omitted, which on most platforms indicates a maxvalue of 2^63-1 and -1 for ascending and descending sequences, respectively.
• nominvalue – no minimum value of the sequence. This value is used when the CREATE SEQUENCE command is emitted to the database as the value of the “NO MINVALUE” clause. If None, the clause is omitted, which on most platforms indicates a minvalue of 1 and -2^63-1 for ascending and descending sequences, respectively.
• nomaxvalue – no maximum value of the sequence. This value is used when the CREATE SEQUENCE command is emitted to the database as the value of the “NO MAXVALUE” clause. If None, the clause is omitted, which on most platforms indicates a maxvalue of 2^63-1 and -1 for ascending and descending sequences, respectively.
• cycle – allows the sequence to wrap around when the maxvalue or minvalue has been reached by an ascending or descending sequence respectively. This value is used when the CREATE SEQUENCE command is emitted to the database as the “CYCLE” clause. If the limit is reached, the next number generated will be the minvalue or maxvalue, respectively. If cycle=False (the default) any calls to nextval after the sequence has reached its maximum value will return an error.
• schema – optional schema name for the sequence, if located in a schema other than the default. The rules for selecting the schema name when a MetaData is also present are the same as that of Table.schema.
• cache – optional integer value; number of future values in the sequence which are calculated in advance. Renders the CACHE keyword understood by Oracle Database and PostgreSQL.
• order – optional boolean value; if True, renders the ORDER keyword, understood by Oracle Database, indicating the sequence is definitively ordered. May be necessary to provide deterministic ordering using Oracle RAC.
• data_type – 
The type to be returned by the sequence, for dialects that allow us to choose between INTEGER, BIGINT, etc. (e.g., mssql).
Added in version 1.4.0.
• optional – boolean value, when True, indicates that this Sequence object only needs to be explicitly generated on backends that don’t provide another way to generate primary key identifiers. Currently, it essentially means, “don’t create this sequence on the PostgreSQL backend, where the SERIAL keyword creates a sequence for us automatically”.
• quote – boolean value, when True or False, explicitly forces quoting of the Sequence.name on or off. When left at its default of None, normal quoting rules based on casing and reserved words take place.
• quote_schema – Set the quoting preferences for the schema name.
• metadata – 
optional MetaData object which this Sequence will be associated with. A Sequence that is associated with a MetaData gains the following capabilities:
o The Sequence will inherit the MetaData.schema parameter specified to the target MetaData, which affects the production of CREATE / DROP DDL, if any.
o The Sequence.create() and Sequence.drop() methods automatically use the engine bound to the MetaData object, if any.
o The MetaData.create_all() and MetaData.drop_all() methods will emit CREATE / DROP for this Sequence, even if the Sequence is not associated with any Table / Column that’s a member of this MetaData.
The above behaviors can only occur if the Sequence is explicitly associated with the MetaData via this parameter.
See also
Associating a Sequence with the MetaData - full discussion of the Sequence.metadata parameter.
• for_update – Indicates this Sequence, when associated with a Column, should be invoked for UPDATE statements on that column’s table, rather than for INSERT statements, when no value is otherwise present for that column in the statement.
method sqlalchemy.schema.Sequence.create(bind: _CreateDropBind, checkfirst: bool = True) → None
Creates this sequence in the database.
method sqlalchemy.schema.Sequence.drop(bind: _CreateDropBind, checkfirst: bool = True) → None
Drops this sequence from the database.
method sqlalchemy.schema.Sequence.next_value() → Function[int]
Return a next_value function element which will render the appropriate increment function for this Sequence within any SQL expression.
class sqlalchemy.schema.Identity
Defines an identity column, i.e. “GENERATED { ALWAYS | BY DEFAULT } AS IDENTITY” syntax.
The Identity construct is an inline construct added to the argument list of a Column object:
from sqlalchemy import Identity

Table(
    "foo",
    metadata_obj,
    Column("id", Integer, Identity()),
    Column("description", Text),
)
See the linked documentation below for complete details.
Added in version 1.4.
See also
Identity Columns (GENERATED { ALWAYS | BY DEFAULT } AS IDENTITY)
Members
__init__(), copy()
Class signature
class sqlalchemy.schema.Identity (sqlalchemy.schema.IdentityOptions, sqlalchemy.schema.FetchedValue, sqlalchemy.schema.SchemaItem)
method sqlalchemy.schema.Identity.__init__(always: bool = False, on_null: bool | None = None, start: int | None = None, increment: int | None = None, minvalue: int | None = None, maxvalue: int | None = None, nominvalue: bool | None = None, nomaxvalue: bool | None = None, cycle: bool | None = None, cache: int | None = None, order: bool | None = None) → None
Construct a GENERATED { ALWAYS | BY DEFAULT } AS IDENTITY DDL construct to accompany a Column.
See the Sequence documentation for a complete description of most parameters.
Note
MSSQL supports this construct as the preferred alternative to generate an IDENTITY on a column, but it uses non standard syntax that only support Identity.start and Identity.increment. All other parameters are ignored.
Parameters:
• always – A boolean, that indicates the type of identity column. If False is specified, the default, then the user-specified value takes precedence. If True is specified, a user-specified value is not accepted ( on some backends, like PostgreSQL, OVERRIDING SYSTEM VALUE, or similar, may be specified in an INSERT to override the sequence value). Some backends also have a default value for this parameter, None can be used to omit rendering this part in the DDL. It will be treated as False if a backend does not have a default value.
• on_null – Set to True to specify ON NULL in conjunction with a always=False identity column. This option is only supported on some backends, like Oracle Database.
• start – the starting index of the sequence.
• increment – the increment value of the sequence.
• minvalue – the minimum value of the sequence.
• maxvalue – the maximum value of the sequence.
• nominvalue – no minimum value of the sequence.
• nomaxvalue – no maximum value of the sequence.
• cycle – allows the sequence to wrap around when the maxvalue or minvalue has been reached.
• cache – optional integer value; number of future values in the sequence which are calculated in advance.
• order – optional boolean value; if true, renders the ORDER keyword.
method sqlalchemy.schema.Identity.copy(**kw: Any) → Identity
Deprecated since version 1.4: The Identity.copy() method is deprecated and will be removed in a future release.
Defining Constraints and Indexes
This section will discuss SQL constraints and indexes. In SQLAlchemy the key classes include ForeignKeyConstraint and Index.
Defining Foreign Keys
A foreign key in SQL is a table-level construct that constrains one or more columns in that table to only allow values that are present in a different set of columns, typically but not always located on a different table. We call the columns which are constrained the foreign key columns and the columns which they are constrained towards the referenced columns. The referenced columns almost always define the primary key for their owning table, though there are exceptions to this. The foreign key is the “joint” that connects together pairs of rows which have a relationship with each other, and SQLAlchemy assigns very deep importance to this concept in virtually every area of its operation.
In SQLAlchemy as well as in DDL, foreign key constraints can be defined as additional attributes within the table clause, or for single-column foreign keys they may optionally be specified within the definition of a single column. The single column foreign key is more common, and at the column level is specified by constructing a ForeignKey object as an argument to a Column object:
user_preference = Table(
    "user_preference",
    metadata_obj,
    Column("pref_id", Integer, primary_key=True),
    Column("user_id", Integer, ForeignKey("user.user_id"), nullable=False),
    Column("pref_name", String(40), nullable=False),
    Column("pref_value", String(100)),
)
Above, we define a new table user_preference for which each row must contain a value in the user_id column that also exists in the user table’s user_id column.
The argument to ForeignKey is most commonly a string of the form <tablename>.<columnname>, or for a table in a remote schema or “owner” of the form <schemaname>.<tablename>.<columnname>. It may also be an actual Column object, which as we’ll see later is accessed from an existing Table object via its c collection:
ForeignKey(user.c.user_id)
The advantage to using a string is that the in-python linkage between user and user_preference is resolved only when first needed, so that table objects can be easily spread across multiple modules and defined in any order.
Foreign keys may also be defined at the table level, using the ForeignKeyConstraint object. This object can describe a single- or multi-column foreign key. A multi-column foreign key is known as a composite foreign key, and almost always references a table that has a composite primary key. Below we define a table invoice which has a composite primary key:
invoice = Table(
    "invoice",
    metadata_obj,
    Column("invoice_id", Integer, primary_key=True),
    Column("ref_num", Integer, primary_key=True),
    Column("description", String(60), nullable=False),
)
And then a table invoice_item with a composite foreign key referencing invoice:
invoice_item = Table(
    "invoice_item",
    metadata_obj,
    Column("item_id", Integer, primary_key=True),
    Column("item_name", String(60), nullable=False),
    Column("invoice_id", Integer, nullable=False),
    Column("ref_num", Integer, nullable=False),
    ForeignKeyConstraint(
        ["invoice_id", "ref_num"], ["invoice.invoice_id", "invoice.ref_num"]
    ),
)
It’s important to note that the ForeignKeyConstraint is the only way to define a composite foreign key. While we could also have placed individual ForeignKey objects on both the invoice_item.invoice_id and invoice_item.ref_num columns, SQLAlchemy would not be aware that these two values should be paired together - it would be two individual foreign key constraints instead of a single composite foreign key referencing two columns.
Creating/Dropping Foreign Key Constraints via ALTER
The behavior we’ve seen in tutorials and elsewhere involving foreign keys with DDL illustrates that the constraints are typically rendered “inline” within the CREATE TABLE statement, such as:
CREATE TABLE addresses (
    id INTEGER NOT NULL,
    user_id INTEGER,
    email_address VARCHAR NOT NULL,
    PRIMARY KEY (id),
    CONSTRAINT user_id_fk FOREIGN KEY(user_id) REFERENCES users (id)
)
The CONSTRAINT .. FOREIGN KEY directive is used to create the constraint in an “inline” fashion within the CREATE TABLE definition. The MetaData.create_all() and MetaData.drop_all() methods do this by default, using a topological sort of all the Table objects involved such that tables are created and dropped in order of their foreign key dependency (this sort is also available via the MetaData.sorted_tables accessor).
This approach can’t work when two or more foreign key constraints are involved in a “dependency cycle”, where a set of tables are mutually dependent on each other, assuming the backend enforces foreign keys (always the case except on SQLite, MySQL/MyISAM). The methods will therefore break out constraints in such a cycle into separate ALTER statements, on all backends other than SQLite which does not support most forms of ALTER. Given a schema like:
node = Table(
    "node",
    metadata_obj,
    Column("node_id", Integer, primary_key=True),
    Column("primary_element", Integer, ForeignKey("element.element_id")),
)

element = Table(
    "element",
    metadata_obj,
    Column("element_id", Integer, primary_key=True),
    Column("parent_node_id", Integer),
    ForeignKeyConstraint(
        ["parent_node_id"], ["node.node_id"], name="fk_element_parent_node_id"
    ),
)
When we call upon MetaData.create_all() on a backend such as the PostgreSQL backend, the cycle between these two tables is resolved and the constraints are created separately:
>>> with engine.connect() as conn:
...     metadata_obj.create_all(conn, checkfirst=False)
CREATE TABLE element (
    element_id SERIAL NOT NULL,
    parent_node_id INTEGER,
    PRIMARY KEY (element_id)
)

CREATE TABLE node (
    node_id SERIAL NOT NULL,
    primary_element INTEGER,
    PRIMARY KEY (node_id)
)

ALTER TABLE element ADD CONSTRAINT fk_element_parent_node_id
    FOREIGN KEY(parent_node_id) REFERENCES node (node_id)
ALTER TABLE node ADD FOREIGN KEY(primary_element)
    REFERENCES element (element_id)
In order to emit DROP for these tables, the same logic applies, however note here that in SQL, to emit DROP CONSTRAINT requires that the constraint has a name. In the case of the 'node' table above, we haven’t named this constraint; the system will therefore attempt to emit DROP for only those constraints that are named:
>>> with engine.connect() as conn:
...     metadata_obj.drop_all(conn, checkfirst=False)
ALTER TABLE element DROP CONSTRAINT fk_element_parent_node_id
DROP TABLE node
DROP TABLE element
In the case where the cycle cannot be resolved, such as if we hadn’t applied a name to either constraint here, we will receive the following error:
sqlalchemy.exc.CircularDependencyError: Can't sort tables for DROP;
an unresolvable foreign key dependency exists between tables:
element, node.  Please ensure that the ForeignKey and ForeignKeyConstraint
objects involved in the cycle have names so that they can be dropped
using DROP CONSTRAINT.
This error only applies to the DROP case as we can emit “ADD CONSTRAINT” in the CREATE case without a name; the database typically assigns one automatically.
The ForeignKeyConstraint.use_alter and ForeignKey.use_alter keyword arguments can be used to manually resolve dependency cycles. We can add this flag only to the 'element' table as follows:
element = Table(
    "element",
    metadata_obj,
    Column("element_id", Integer, primary_key=True),
    Column("parent_node_id", Integer),
    ForeignKeyConstraint(
        ["parent_node_id"],
        ["node.node_id"],
        use_alter=True,
        name="fk_element_parent_node_id",
    ),
)
in our CREATE DDL we will see the ALTER statement only for this constraint, and not the other one:
>>> with engine.connect() as conn:
...     metadata_obj.create_all(conn, checkfirst=False)
CREATE TABLE element (
    element_id SERIAL NOT NULL,
    parent_node_id INTEGER,
    PRIMARY KEY (element_id)
)

CREATE TABLE node (
    node_id SERIAL NOT NULL,
    primary_element INTEGER,
    PRIMARY KEY (node_id),
    FOREIGN KEY(primary_element) REFERENCES element (element_id)
)

ALTER TABLE element ADD CONSTRAINT fk_element_parent_node_id
FOREIGN KEY(parent_node_id) REFERENCES node (node_id)
ForeignKeyConstraint.use_alter and ForeignKey.use_alter, when used in conjunction with a drop operation, will require that the constraint is named, else an error like the following is generated:
sqlalchemy.exc.CompileError: Can't emit DROP CONSTRAINT for constraint
ForeignKeyConstraint(...); it has no name
See also
Configuring Constraint Naming Conventions
sort_tables_and_constraints()
ON UPDATE and ON DELETE
Most databases support cascading of foreign key values, that is the when a parent row is updated the new value is placed in child rows, or when the parent row is deleted all corresponding child rows are set to null or deleted. In data definition language these are specified using phrases like “ON UPDATE CASCADE”, “ON DELETE CASCADE”, and “ON DELETE SET NULL”, corresponding to foreign key constraints. The phrase after “ON UPDATE” or “ON DELETE” may also allow other phrases that are specific to the database in use. The ForeignKey and ForeignKeyConstraint objects support the generation of this clause via the onupdate and ondelete keyword arguments. The value is any string which will be output after the appropriate “ON UPDATE” or “ON DELETE” phrase:
child = Table(
    "child",
    metadata_obj,
    Column(
        "id",
        Integer,
        ForeignKey("parent.id", onupdate="CASCADE", ondelete="CASCADE"),
        primary_key=True,
    ),
)

composite = Table(
    "composite",
    metadata_obj,
    Column("id", Integer, primary_key=True),
    Column("rev_id", Integer),
    Column("note_id", Integer),
    ForeignKeyConstraint(
        ["rev_id", "note_id"],
        ["revisions.id", "revisions.note_id"],
        onupdate="CASCADE",
        ondelete="SET NULL",
    ),
)
Note that some backends have special requirements for cascades to function:
• MySQL / MariaDB - the InnoDB storage engine should be used (this is typically the default in modern databases)
• SQLite - constraints are not enabled by default. See Foreign Key Support
See also
For background on integration of ON DELETE CASCADE with ORM relationship() constructs, see the following sections:
Using foreign key ON DELETE cascade with ORM relationships
Using foreign key ON DELETE with many-to-many relationships
PostgreSQL Constraint Options - indicates additional options available for foreign key cascades such as column lists
Foreign Key Support - background on enabling foreign key support with SQLite
UNIQUE Constraint
Unique constraints can be created anonymously on a single column using the unique keyword on Column. Explicitly named unique constraints and/or those with multiple columns are created via the UniqueConstraint table-level construct.
from sqlalchemy import UniqueConstraint

metadata_obj = MetaData()
mytable = Table(
    "mytable",
    metadata_obj,
    # per-column anonymous unique constraint
    Column("col1", Integer, unique=True),
    Column("col2", Integer),
    Column("col3", Integer),
    # explicit/composite unique constraint.  'name' is optional.
    UniqueConstraint("col2", "col3", name="uix_1"),
)
CHECK Constraint
Check constraints can be named or unnamed and can be created at the Column or Table level, using the CheckConstraint construct. The text of the check constraint is passed directly through to the database, so there is limited “database independent” behavior. Column level check constraints generally should only refer to the column to which they are placed, while table level constraints can refer to any columns in the table.
Note that some databases do not actively support check constraints such as older versions of MySQL (prior to 8.0.16).
from sqlalchemy import CheckConstraint

metadata_obj = MetaData()
mytable = Table(
    "mytable",
    metadata_obj,
    # per-column CHECK constraint
    Column("col1", Integer, CheckConstraint("col1>5")),
    Column("col2", Integer),
    Column("col3", Integer),
    # table level CHECK constraint.  'name' is optional.
    CheckConstraint("col2 > col3 + 5", name="check1"),
)

mytable.create(engine)
CREATE TABLE mytable (
    col1 INTEGER  CHECK (col1>5),
    col2 INTEGER,
    col3 INTEGER,
    CONSTRAINT check1  CHECK (col2 > col3 + 5)
)
PRIMARY KEY Constraint
The primary key constraint of any Table object is implicitly present, based on the Column objects that are marked with the Column.primary_key flag. The PrimaryKeyConstraint object provides explicit access to this constraint, which includes the option of being configured directly:
from sqlalchemy import PrimaryKeyConstraint

my_table = Table(
    "mytable",
    metadata_obj,
    Column("id", Integer),
    Column("version_id", Integer),
    Column("data", String(50)),
    PrimaryKeyConstraint("id", "version_id", name="mytable_pk"),
)
See also
PrimaryKeyConstraint - detailed API documentation.
Setting up Constraints when using the Declarative ORM Extension
The Table is the SQLAlchemy Core construct that allows one to define table metadata, which among other things can be used by the SQLAlchemy ORM as a target to map a class. The Declarative extension allows the Table object to be created automatically, given the contents of the table primarily as a mapping of Column objects.
To apply table-level constraint objects such as ForeignKeyConstraint to a table defined using Declarative, use the __table_args__ attribute, described at Table Configuration.
Configuring Constraint Naming Conventions
Relational databases typically assign explicit names to all constraints and indexes. In the common case that a table is created using CREATE TABLE where constraints such as CHECK, UNIQUE, and PRIMARY KEY constraints are produced inline with the table definition, the database usually has a system in place in which names are automatically assigned to these constraints, if a name is not otherwise specified. When an existing database table is altered in a database using a command such as ALTER TABLE, this command typically needs to specify explicit names for new constraints as well as be able to specify the name of an existing constraint that is to be dropped or modified.
Constraints can be named explicitly using the Constraint.name parameter, and for indexes the Index.name parameter. However, in the case of constraints this parameter is optional. There are also the use cases of using the Column.unique and Column.index parameters which create UniqueConstraint and Index objects without an explicit name being specified.
The use case of alteration of existing tables and constraints can be handled by schema migration tools such as Alembic. However, neither Alembic nor SQLAlchemy currently create names for constraint objects where the name is otherwise unspecified, leading to the case where being able to alter existing constraints means that one must reverse-engineer the naming system used by the relational database to auto-assign names, or that care must be taken to ensure that all constraints are named.
In contrast to having to assign explicit names to all Constraint and Index objects, automated naming schemes can be constructed using events. This approach has the advantage that constraints will get a consistent naming scheme without the need for explicit name parameters throughout the code, and also that the convention takes place just as well for those constraints and indexes produced by the Column.unique and Column.index parameters. As of SQLAlchemy 0.9.2 this event-based approach is included, and can be configured using the argument MetaData.naming_convention.
Configuring a Naming Convention for a MetaData Collection
MetaData.naming_convention refers to a dictionary which accepts the Index class or individual Constraint classes as keys, and Python string templates as values. It also accepts a series of string-codes as alternative keys, "fk", "pk", "ix", "ck", "uq" for foreign key, primary key, index, check, and unique constraint, respectively. The string templates in this dictionary are used whenever a constraint or index is associated with this MetaData object that does not have an existing name given (including one exception case where an existing name can be further embellished).
An example naming convention that suits basic cases is as follows:
convention = {
    "ix": "ix_%(column_0_label)s",
    "uq": "uq_%(table_name)s_%(column_0_name)s",
    "ck": "ck_%(table_name)s_%(constraint_name)s",
    "fk": "fk_%(table_name)s_%(column_0_name)s_%(referred_table_name)s",
    "pk": "pk_%(table_name)s",
}

metadata_obj = MetaData(naming_convention=convention)
The above convention will establish names for all constraints within the target MetaData collection. For example, we can observe the name produced when we create an unnamed UniqueConstraint:
>>> user_table = Table(
...     "user",
...     metadata_obj,
...     Column("id", Integer, primary_key=True),
...     Column("name", String(30), nullable=False),
...     UniqueConstraint("name"),
... )
>>> list(user_table.constraints)[1].name
'uq_user_name'
This same feature takes effect even if we just use the Column.unique flag:
>>> user_table = Table(
...     "user",
...     metadata_obj,
...     Column("id", Integer, primary_key=True),
...     Column("name", String(30), nullable=False, unique=True),
... )
>>> list(user_table.constraints)[1].name
'uq_user_name'
A key advantage to the naming convention approach is that the names are established at Python construction time, rather than at DDL emit time. The effect this has when using Alembic’s --autogenerate feature is that the naming convention will be explicit when a new migration script is generated:
def upgrade():
    op.create_unique_constraint("uq_user_name", "user", ["name"])
The above "uq_user_name" string was copied from the UniqueConstraint object that --autogenerate located in our metadata.
The tokens available include %(table_name)s, %(referred_table_name)s, %(column_0_name)s, %(column_0_label)s, %(column_0_key)s, %(referred_column_0_name)s, and %(constraint_name)s, as well as multiple-column versions of each including %(column_0N_name)s, %(column_0_N_name)s, %(referred_column_0_N_name)s which render all column names separated with or without an underscore. The documentation for MetaData.naming_convention has further detail on each of these conventions.
The Default Naming Convention
The default value for MetaData.naming_convention handles the long-standing SQLAlchemy behavior of assigning a name to a Index object that is created using the Column.index parameter:
>>> from sqlalchemy.sql.schema import DEFAULT_NAMING_CONVENTION
>>> DEFAULT_NAMING_CONVENTION
immutabledict({'ix': 'ix_%(column_0_label)s'})
Truncation of Long Names
When a generated name, particularly those that use the multiple-column tokens, is too long for the identifier length limit of the target database (for example, PostgreSQL has a limit of 63 characters), the name will be deterministically truncated using a 4-character suffix based on the md5 hash of the long name. For example, the naming convention below will generate very long names given the column names in use:
metadata_obj = MetaData(
    naming_convention={"uq": "uq_%(table_name)s_%(column_0_N_name)s"}
)

long_names = Table(
    "long_names",
    metadata_obj,
    Column("information_channel_code", Integer, key="a"),
    Column("billing_convention_name", Integer, key="b"),
    Column("product_identifier", Integer, key="c"),
    UniqueConstraint("a", "b", "c"),
)
On the PostgreSQL dialect, names longer than 63 characters will be truncated as in the following example:
CREATE TABLE long_names (
    information_channel_code INTEGER,
    billing_convention_name INTEGER,
    product_identifier INTEGER,
    CONSTRAINT uq_long_names_information_channel_code_billing_conventi_a79e
    UNIQUE (information_channel_code, billing_convention_name, product_identifier)
)
The above suffix a79e is based on the md5 hash of the long name and will generate the same value every time to produce consistent names for a given schema.
Creating Custom Tokens for Naming Conventions
New tokens can also be added, by specifying an additional token and a callable within the naming_convention dictionary. For example, if we wanted to name our foreign key constraints using a GUID scheme, we could do that as follows:
import uuid


def fk_guid(constraint, table):
    str_tokens = (
        [
            table.name,
        ]
        + [element.parent.name for element in constraint.elements]
        + [element.target_fullname for element in constraint.elements]
    )
    guid = uuid.uuid5(uuid.NAMESPACE_OID, "_".join(str_tokens).encode("ascii"))
    return str(guid)


convention = {
    "fk_guid": fk_guid,
    "ix": "ix_%(column_0_label)s",
    "fk": "fk_%(fk_guid)s",
}
Above, when we create a new ForeignKeyConstraint, we will get a name as follows:
>>> metadata_obj = MetaData(naming_convention=convention)

>>> user_table = Table(
...     "user",
...     metadata_obj,
...     Column("id", Integer, primary_key=True),
...     Column("version", Integer, primary_key=True),
...     Column("data", String(30)),
... )
>>> address_table = Table(
...     "address",
...     metadata_obj,
...     Column("id", Integer, primary_key=True),
...     Column("user_id", Integer),
...     Column("user_version_id", Integer),
... )
>>> fk = ForeignKeyConstraint(["user_id", "user_version_id"], ["user.id", "user.version"])
>>> address_table.append_constraint(fk)
>>> fk.name
fk_0cd51ab5-8d70-56e8-a83c-86661737766d
See also
MetaData.naming_convention - for additional usage details as well as a listing of all available naming components.
The Importance of Naming Constraints - in the Alembic documentation.
Added in version 1.3.0: added multi-column naming tokens such as %(column_0_N_name)s. Generated names that go beyond the character limit for the target database will be deterministically truncated.
Naming CHECK Constraints
The CheckConstraint object is configured against an arbitrary SQL expression, which can have any number of columns present, and additionally is often configured using a raw SQL string. Therefore a common convention to use with CheckConstraint is one where we expect the object to have a name already, and we then enhance it with other convention elements. A typical convention is "ck_%(table_name)s_%(constraint_name)s":
metadata_obj = MetaData(
    naming_convention={"ck": "ck_%(table_name)s_%(constraint_name)s"}
)

Table(
    "foo",
    metadata_obj,
    Column("value", Integer),
    CheckConstraint("value > 5", name="value_gt_5"),
)
The above table will produce the name ck_foo_value_gt_5:
CREATE TABLE foo (
    value INTEGER,
    CONSTRAINT ck_foo_value_gt_5 CHECK (value > 5)
)
CheckConstraint also supports the %(columns_0_name)s token; we can make use of this by ensuring we use a Column or column() element within the constraint’s expression, either by declaring the constraint separate from the table:
metadata_obj = MetaData(naming_convention={"ck": "ck_%(table_name)s_%(column_0_name)s"})

foo = Table("foo", metadata_obj, Column("value", Integer))

CheckConstraint(foo.c.value > 5)
or by using a column() inline:
from sqlalchemy import column

metadata_obj = MetaData(naming_convention={"ck": "ck_%(table_name)s_%(column_0_name)s"})

foo = Table(
    "foo", metadata_obj, Column("value", Integer), CheckConstraint(column("value") > 5)
)
Both will produce the name ck_foo_value:
CREATE TABLE foo (
    value INTEGER,
    CONSTRAINT ck_foo_value CHECK (value > 5)
)
The determination of the name of “column zero” is performed by scanning the given expression for column objects. If the expression has more than one column present, the scan does use a deterministic search, however the structure of the expression will determine which column is noted as “column zero”.
Configuring Naming for Boolean, Enum, and other schema types
The SchemaType class refers to type objects such as Boolean and Enum which generate a CHECK constraint accompanying the type. The name for the constraint here is most directly set up by sending the “name” parameter, e.g. Boolean.name:
Table("foo", metadata_obj, Column("flag", Boolean(name="ck_foo_flag")))
The naming convention feature may be combined with these types as well, normally by using a convention which includes %(constraint_name)s and then applying a name to the type:
metadata_obj = MetaData(
    naming_convention={"ck": "ck_%(table_name)s_%(constraint_name)s"}
)

Table("foo", metadata_obj, Column("flag", Boolean(name="flag_bool")))
The above table will produce the constraint name ck_foo_flag_bool:
CREATE TABLE foo (
    flag BOOL,
    CONSTRAINT ck_foo_flag_bool CHECK (flag IN (0, 1))
)
The SchemaType classes use special internal symbols so that the naming convention is only determined at DDL compile time. On PostgreSQL, there’s a native BOOLEAN type, so the CHECK constraint of Boolean is not needed; we are safe to set up a Boolean type without a name, even though a naming convention is in place for check constraints. This convention will only be consulted for the CHECK constraint if we run against a database without a native BOOLEAN type like SQLite or MySQL.
The CHECK constraint may also make use of the column_0_name token, which works nicely with SchemaType since these constraints have only one column:
metadata_obj = MetaData(naming_convention={"ck": "ck_%(table_name)s_%(column_0_name)s"})

Table("foo", metadata_obj, Column("flag", Boolean()))
The above schema will produce:
CREATE TABLE foo (
    flag BOOL,
    CONSTRAINT ck_foo_flag CHECK (flag IN (0, 1))
)
Using Naming Conventions with ORM Declarative Mixins
When using the naming convention feature with ORM Declarative Mixins, individual constraint objects must exist for each actual table-mapped subclass. See the section Creating Indexes and Constraints with Naming Conventions on Mixins for background and examples.
Constraints API
Object NameDescriptionCheckConstraintA table- or column-level CHECK constraint.ColumnCollectionConstraintA constraint that proxies a ColumnCollection.ColumnCollectionMixinA ColumnCollection of Column objects.ConstraintA table-level SQL constraint.convMark a string indicating that a name has already been converted by a naming convention.ForeignKeyDefines a dependency between two columns.ForeignKeyConstraintA table-level FOREIGN KEY constraint.HasConditionalDDLdefine a class that includes the HasConditionalDDL.ddl_if() method, allowing for conditional rendering of DDL.PrimaryKeyConstraintA table-level PRIMARY KEY constraint.UniqueConstraintA table-level UNIQUE constraint.class sqlalchemy.schema.Constraint
A table-level SQL constraint.
Constraint serves as the base class for the series of constraint objects that can be associated with Table objects, including PrimaryKeyConstraint, ForeignKeyConstraint UniqueConstraint, and CheckConstraint.
Members
__init__(), argument_for(), copy(), ddl_if(), dialect_kwargs, dialect_options, info, kwargs
Class signature
class sqlalchemy.schema.Constraint (sqlalchemy.sql.expression.DialectKWArgs, sqlalchemy.schema.HasConditionalDDL, sqlalchemy.schema.SchemaItem)
method sqlalchemy.schema.Constraint.__init__(name: _ConstraintNameArgument = None, deferrable: bool | None = None, initially: str | None = None, info: _InfoType | None = None, comment: str | None = None, _create_rule: Any | None = None, _type_bound: bool = False, **dialect_kw: Any) → None
Create a SQL constraint.
Parameters:
• name – Optional, the in-database name of this Constraint.
• deferrable – Optional bool. If set, emit DEFERRABLE or NOT DEFERRABLE when issuing DDL for this constraint.
• initially – Optional string. If set, emit INITIALLY <value> when issuing DDL for this constraint.
• info – Optional data dictionary which will be populated into the SchemaItem.info attribute of this object.
• comment – 
Optional string that will render an SQL comment on foreign key constraint creation.
Added in version 2.0.
• **dialect_kw – Additional keyword arguments are dialect specific, and passed in the form <dialectname>_<argname>. See the documentation regarding an individual dialect at Dialects for detail on documented arguments.
• _create_rule – used internally by some datatypes that also create constraints.
• _type_bound – used internally to indicate that this constraint is associated with a specific datatype.
classmethod sqlalchemy.schema.Constraint.argument_for(dialect_name, argument_name, default)
inherited from the DialectKWArgs.argument_for() method of DialectKWArgs
Add a new kind of dialect-specific keyword argument for this class.
E.g.:
Index.argument_for("mydialect", "length", None)

some_index = Index("a", "b", mydialect_length=5)
The DialectKWArgs.argument_for() method is a per-argument way adding extra arguments to the DefaultDialect.construct_arguments dictionary. This dictionary provides a list of argument names accepted by various schema-level constructs on behalf of a dialect.
New dialects should typically specify this dictionary all at once as a data member of the dialect class. The use case for ad-hoc addition of argument names is typically for end-user code that is also using a custom compilation scheme which consumes the additional arguments.
Parameters:
• dialect_name – name of a dialect. The dialect must be locatable, else a NoSuchModuleError is raised. The dialect must also include an existing DefaultDialect.construct_arguments collection, indicating that it participates in the keyword-argument validation and default system, else ArgumentError is raised. If the dialect does not include this collection, then any keyword argument can be specified on behalf of this dialect already. All dialects packaged within SQLAlchemy include this collection, however for third party dialects, support may vary.
• argument_name – name of the parameter.
• default – default value of the parameter.
method sqlalchemy.schema.Constraint.copy(**kw: Any) → Self
Deprecated since version 1.4: The Constraint.copy() method is deprecated and will be removed in a future release.
method sqlalchemy.schema.Constraint.ddl_if(dialect: str | None = None, callable_: DDLIfCallable | None = None, state: Any | None = None) → Self
inherited from the HasConditionalDDL.ddl_if() method of HasConditionalDDL
apply a conditional DDL rule to this schema item.
These rules work in a similar manner to the ExecutableDDLElement.execute_if() callable, with the added feature that the criteria may be checked within the DDL compilation phase for a construct such as CreateTable. HasConditionalDDL.ddl_if() currently applies towards the Index construct as well as all Constraint constructs.
Parameters:
• dialect – string name of a dialect, or a tuple of string names to indicate multiple dialect types.
• callable_ – a callable that is constructed using the same form as that described in ExecutableDDLElement.execute_if.callable_.
• state – any arbitrary object that will be passed to the callable, if present.
Added in version 2.0.
See also
Controlling DDL Generation of Constraints and Indexes - background and usage examples
attribute sqlalchemy.schema.Constraint.dialect_kwargs
inherited from the DialectKWArgs.dialect_kwargs attribute of DialectKWArgs
A collection of keyword arguments specified as dialect-specific options to this construct.
The arguments are present here in their original <dialect>_<kwarg> format. Only arguments that were actually passed are included; unlike the DialectKWArgs.dialect_options collection, which contains all options known by this dialect including defaults.
The collection is also writable; keys are accepted of the form <dialect>_<kwarg> where the value will be assembled into the list of options.
See also
DialectKWArgs.dialect_options - nested dictionary form
attribute sqlalchemy.schema.Constraint.dialect_options
inherited from the DialectKWArgs.dialect_options attribute of DialectKWArgs
A collection of keyword arguments specified as dialect-specific options to this construct.
This is a two-level nested registry, keyed to <dialect_name> and <argument_name>. For example, the postgresql_where argument would be locatable as:
arg = my_object.dialect_options["postgresql"]["where"]
Added in version 0.9.2.
See also
DialectKWArgs.dialect_kwargs - flat dictionary form
attribute sqlalchemy.schema.Constraint.info
inherited from the SchemaItem.info attribute of SchemaItem
Info dictionary associated with the object, allowing user-defined data to be associated with this SchemaItem.
The dictionary is automatically generated when first accessed. It can also be specified in the constructor of some objects, such as Table and Column.
attribute sqlalchemy.schema.Constraint.kwargs
inherited from the DialectKWArgs.kwargs attribute of DialectKWArgs
A synonym for DialectKWArgs.dialect_kwargs.
class sqlalchemy.schema.ColumnCollectionMixin
A ColumnCollection of Column objects.
This collection represents the columns which are referred to by this object.
class sqlalchemy.schema.ColumnCollectionConstraint
A constraint that proxies a ColumnCollection.
Members
__init__(), argument_for(), columns, contains_column(), copy(), ddl_if(), dialect_kwargs, dialect_options, info, kwargs
Class signature
class sqlalchemy.schema.ColumnCollectionConstraint (sqlalchemy.schema.ColumnCollectionMixin, sqlalchemy.schema.Constraint)
method sqlalchemy.schema.ColumnCollectionConstraint.__init__(*columns: _DDLColumnArgument, name: _ConstraintNameArgument = None, deferrable: bool | None = None, initially: str | None = None, info: _InfoType | None = None, _autoattach: bool = True, _column_flag: bool = False, _gather_expressions: List[_DDLColumnArgument] | None = None, **dialect_kw: Any) → None
Parameters:
• *columns – A sequence of column names or Column objects.
• name – Optional, the in-database name of this constraint.
• deferrable – Optional bool. If set, emit DEFERRABLE or NOT DEFERRABLE when issuing DDL for this constraint.
• initially – Optional string. If set, emit INITIALLY <value> when issuing DDL for this constraint.
• **dialect_kw – other keyword arguments including dialect-specific arguments are propagated to the Constraint superclass.
classmethod sqlalchemy.schema.ColumnCollectionConstraint.argument_for(dialect_name, argument_name, default)
inherited from the DialectKWArgs.argument_for() method of DialectKWArgs
Add a new kind of dialect-specific keyword argument for this class.
E.g.:
Index.argument_for("mydialect", "length", None)

some_index = Index("a", "b", mydialect_length=5)
The DialectKWArgs.argument_for() method is a per-argument way adding extra arguments to the DefaultDialect.construct_arguments dictionary. This dictionary provides a list of argument names accepted by various schema-level constructs on behalf of a dialect.
New dialects should typically specify this dictionary all at once as a data member of the dialect class. The use case for ad-hoc addition of argument names is typically for end-user code that is also using a custom compilation scheme which consumes the additional arguments.
Parameters:
• dialect_name – name of a dialect. The dialect must be locatable, else a NoSuchModuleError is raised. The dialect must also include an existing DefaultDialect.construct_arguments collection, indicating that it participates in the keyword-argument validation and default system, else ArgumentError is raised. If the dialect does not include this collection, then any keyword argument can be specified on behalf of this dialect already. All dialects packaged within SQLAlchemy include this collection, however for third party dialects, support may vary.
• argument_name – name of the parameter.
• default – default value of the parameter.
attribute sqlalchemy.schema.ColumnCollectionConstraint.columns: ReadOnlyColumnCollection[str, Column[Any]]
inherited from the ColumnCollectionMixin.columns attribute of ColumnCollectionMixin
A ColumnCollection representing the set of columns for this constraint.
method sqlalchemy.schema.ColumnCollectionConstraint.contains_column(col: Column[Any]) → bool
Return True if this constraint contains the given column.
Note that this object also contains an attribute .columns which is a ColumnCollection of Column objects.
method sqlalchemy.schema.ColumnCollectionConstraint.copy(*, target_table: Table | None = None, **kw: Any) → ColumnCollectionConstraint
Deprecated since version 1.4: The ColumnCollectionConstraint.copy() method is deprecated and will be removed in a future release.
method sqlalchemy.schema.ColumnCollectionConstraint.ddl_if(dialect: str | None = None, callable_: DDLIfCallable | None = None, state: Any | None = None) → Self
inherited from the HasConditionalDDL.ddl_if() method of HasConditionalDDL
apply a conditional DDL rule to this schema item.
These rules work in a similar manner to the ExecutableDDLElement.execute_if() callable, with the added feature that the criteria may be checked within the DDL compilation phase for a construct such as CreateTable. HasConditionalDDL.ddl_if() currently applies towards the Index construct as well as all Constraint constructs.
Parameters:
• dialect – string name of a dialect, or a tuple of string names to indicate multiple dialect types.
• callable_ – a callable that is constructed using the same form as that described in ExecutableDDLElement.execute_if.callable_.
• state – any arbitrary object that will be passed to the callable, if present.
Added in version 2.0.
See also
Controlling DDL Generation of Constraints and Indexes - background and usage examples
attribute sqlalchemy.schema.ColumnCollectionConstraint.dialect_kwargs
inherited from the DialectKWArgs.dialect_kwargs attribute of DialectKWArgs
A collection of keyword arguments specified as dialect-specific options to this construct.
The arguments are present here in their original <dialect>_<kwarg> format. Only arguments that were actually passed are included; unlike the DialectKWArgs.dialect_options collection, which contains all options known by this dialect including defaults.
The collection is also writable; keys are accepted of the form <dialect>_<kwarg> where the value will be assembled into the list of options.
See also
DialectKWArgs.dialect_options - nested dictionary form
attribute sqlalchemy.schema.ColumnCollectionConstraint.dialect_options
inherited from the DialectKWArgs.dialect_options attribute of DialectKWArgs
A collection of keyword arguments specified as dialect-specific options to this construct.
This is a two-level nested registry, keyed to <dialect_name> and <argument_name>. For example, the postgresql_where argument would be locatable as:
arg = my_object.dialect_options["postgresql"]["where"]
Added in version 0.9.2.
See also
DialectKWArgs.dialect_kwargs - flat dictionary form
attribute sqlalchemy.schema.ColumnCollectionConstraint.info
inherited from the SchemaItem.info attribute of SchemaItem
Info dictionary associated with the object, allowing user-defined data to be associated with this SchemaItem.
The dictionary is automatically generated when first accessed. It can also be specified in the constructor of some objects, such as Table and Column.
attribute sqlalchemy.schema.ColumnCollectionConstraint.kwargs
inherited from the DialectKWArgs.kwargs attribute of DialectKWArgs
A synonym for DialectKWArgs.dialect_kwargs.
class sqlalchemy.schema.CheckConstraint
A table- or column-level CHECK constraint.
Can be included in the definition of a Table or Column.
Members
__init__(), argument_for(), columns, contains_column(), copy(), ddl_if(), dialect_kwargs, dialect_options, info, kwargs
Class signature
class sqlalchemy.schema.CheckConstraint (sqlalchemy.schema.ColumnCollectionConstraint)
method sqlalchemy.schema.CheckConstraint.__init__(sqltext: _TextCoercedExpressionArgument[Any], name: _ConstraintNameArgument = None, deferrable: bool | None = None, initially: str | None = None, table: Table | None = None, info: _InfoType | None = None, _create_rule: Any | None = None, _autoattach: bool = True, _type_bound: bool = False, **dialect_kw: Any) → None
Construct a CHECK constraint.
Parameters:
• sqltext – 
A string containing the constraint definition, which will be used verbatim, or a SQL expression construct. If given as a string, the object is converted to a text() object. If the textual string includes a colon character, escape this using a backslash:
CheckConstraint(r"foo ~ E'a(?\:b|c)d")
• 
• name – Optional, the in-database name of the constraint.
• deferrable – Optional bool. If set, emit DEFERRABLE or NOT DEFERRABLE when issuing DDL for this constraint.
• initially – Optional string. If set, emit INITIALLY <value> when issuing DDL for this constraint.
• info – Optional data dictionary which will be populated into the SchemaItem.info attribute of this object.
classmethod sqlalchemy.schema.CheckConstraint.argument_for(dialect_name, argument_name, default)
inherited from the DialectKWArgs.argument_for() method of DialectKWArgs
Add a new kind of dialect-specific keyword argument for this class.
E.g.:
Index.argument_for("mydialect", "length", None)

some_index = Index("a", "b", mydialect_length=5)
The DialectKWArgs.argument_for() method is a per-argument way adding extra arguments to the DefaultDialect.construct_arguments dictionary. This dictionary provides a list of argument names accepted by various schema-level constructs on behalf of a dialect.
New dialects should typically specify this dictionary all at once as a data member of the dialect class. The use case for ad-hoc addition of argument names is typically for end-user code that is also using a custom compilation scheme which consumes the additional arguments.
Parameters:
• dialect_name – name of a dialect. The dialect must be locatable, else a NoSuchModuleError is raised. The dialect must also include an existing DefaultDialect.construct_arguments collection, indicating that it participates in the keyword-argument validation and default system, else ArgumentError is raised. If the dialect does not include this collection, then any keyword argument can be specified on behalf of this dialect already. All dialects packaged within SQLAlchemy include this collection, however for third party dialects, support may vary.
• argument_name – name of the parameter.
• default – default value of the parameter.
attribute sqlalchemy.schema.CheckConstraint.columns: ReadOnlyColumnCollection[str, Column[Any]]
inherited from the ColumnCollectionMixin.columns attribute of ColumnCollectionMixin
A ColumnCollection representing the set of columns for this constraint.
method sqlalchemy.schema.CheckConstraint.contains_column(col: Column[Any]) → bool
inherited from the ColumnCollectionConstraint.contains_column() method of ColumnCollectionConstraint
Return True if this constraint contains the given column.
Note that this object also contains an attribute .columns which is a ColumnCollection of Column objects.
method sqlalchemy.schema.CheckConstraint.copy(*, target_table: Table | None = None, **kw: Any) → CheckConstraint
Deprecated since version 1.4: The CheckConstraint.copy() method is deprecated and will be removed in a future release.
method sqlalchemy.schema.CheckConstraint.ddl_if(dialect: str | None = None, callable_: DDLIfCallable | None = None, state: Any | None = None) → Self
inherited from the HasConditionalDDL.ddl_if() method of HasConditionalDDL
apply a conditional DDL rule to this schema item.
These rules work in a similar manner to the ExecutableDDLElement.execute_if() callable, with the added feature that the criteria may be checked within the DDL compilation phase for a construct such as CreateTable. HasConditionalDDL.ddl_if() currently applies towards the Index construct as well as all Constraint constructs.
Parameters:
• dialect – string name of a dialect, or a tuple of string names to indicate multiple dialect types.
• callable_ – a callable that is constructed using the same form as that described in ExecutableDDLElement.execute_if.callable_.
• state – any arbitrary object that will be passed to the callable, if present.
Added in version 2.0.
See also
Controlling DDL Generation of Constraints and Indexes - background and usage examples
attribute sqlalchemy.schema.CheckConstraint.dialect_kwargs
inherited from the DialectKWArgs.dialect_kwargs attribute of DialectKWArgs
A collection of keyword arguments specified as dialect-specific options to this construct.
The arguments are present here in their original <dialect>_<kwarg> format. Only arguments that were actually passed are included; unlike the DialectKWArgs.dialect_options collection, which contains all options known by this dialect including defaults.
The collection is also writable; keys are accepted of the form <dialect>_<kwarg> where the value will be assembled into the list of options.
See also
DialectKWArgs.dialect_options - nested dictionary form
attribute sqlalchemy.schema.CheckConstraint.dialect_options
inherited from the DialectKWArgs.dialect_options attribute of DialectKWArgs
A collection of keyword arguments specified as dialect-specific options to this construct.
This is a two-level nested registry, keyed to <dialect_name> and <argument_name>. For example, the postgresql_where argument would be locatable as:
arg = my_object.dialect_options["postgresql"]["where"]
Added in version 0.9.2.
See also
DialectKWArgs.dialect_kwargs - flat dictionary form
attribute sqlalchemy.schema.CheckConstraint.info
inherited from the SchemaItem.info attribute of SchemaItem
Info dictionary associated with the object, allowing user-defined data to be associated with this SchemaItem.
The dictionary is automatically generated when first accessed. It can also be specified in the constructor of some objects, such as Table and Column.
attribute sqlalchemy.schema.CheckConstraint.kwargs
inherited from the DialectKWArgs.kwargs attribute of DialectKWArgs
A synonym for DialectKWArgs.dialect_kwargs.
class sqlalchemy.schema.ForeignKey
Defines a dependency between two columns.
ForeignKey is specified as an argument to a Column object, e.g.:
t = Table(
    "remote_table",
    metadata,
    Column("remote_id", ForeignKey("main_table.id")),
)
Note that ForeignKey is only a marker object that defines a dependency between two columns. The actual constraint is in all cases represented by the ForeignKeyConstraint object. This object will be generated automatically when a ForeignKey is associated with a Column which in turn is associated with a Table. Conversely, when ForeignKeyConstraint is applied to a Table, ForeignKey markers are automatically generated to be present on each associated Column, which are also associated with the constraint object.
Note that you cannot define a “composite” foreign key constraint, that is a constraint between a grouping of multiple parent/child columns, using ForeignKey objects. To define this grouping, the ForeignKeyConstraint object must be used, and applied to the Table. The associated ForeignKey objects are created automatically.
The ForeignKey objects associated with an individual Column object are available in the foreign_keys collection of that column.
Further examples of foreign key configuration are in Defining Foreign Keys.
Members
__init__(), argument_for(), column, copy(), dialect_kwargs, dialect_options, get_referent(), info, kwargs, references(), target_fullname
Class signature
class sqlalchemy.schema.ForeignKey (sqlalchemy.sql.expression.DialectKWArgs, sqlalchemy.schema.SchemaItem)
method sqlalchemy.schema.ForeignKey.__init__(column: _DDLColumnArgument, _constraint: ForeignKeyConstraint | None = None, use_alter: bool = False, name: _ConstraintNameArgument = None, onupdate: str | None = None, ondelete: str | None = None, deferrable: bool | None = None, initially: str | None = None, link_to_name: bool = False, match: str | None = None, info: _InfoType | None = None, comment: str | None = None, _unresolvable: bool = False, **dialect_kw: Any)
Construct a column-level FOREIGN KEY.
The ForeignKey object when constructed generates a ForeignKeyConstraint which is associated with the parent Table object’s collection of constraints.
Parameters:
• column – A single target column for the key relationship. A Column object or a column name as a string: tablename.columnkey or schema.tablename.columnkey. columnkey is the key which has been assigned to the column (defaults to the column name itself), unless link_to_name is True in which case the rendered name of the column is used.
• name – Optional string. An in-database name for the key if constraint is not provided.
• onupdate – 
Optional string. If set, emit ON UPDATE <value> when issuing DDL for this constraint. Typical values include CASCADE, DELETE and RESTRICT.
See also
ON UPDATE and ON DELETE
• ondelete – 
Optional string. If set, emit ON DELETE <value> when issuing DDL for this constraint. Typical values include CASCADE, SET NULL and RESTRICT. Some dialects may allow for additional syntaxes.
See also
ON UPDATE and ON DELETE
• deferrable – Optional bool. If set, emit DEFERRABLE or NOT DEFERRABLE when issuing DDL for this constraint.
• initially – Optional string. If set, emit INITIALLY <value> when issuing DDL for this constraint.
• link_to_name – if True, the string name given in column is the rendered name of the referenced column, not its locally assigned key.
• use_alter – 
passed to the underlying ForeignKeyConstraint to indicate the constraint should be generated/dropped externally from the CREATE TABLE/ DROP TABLE statement. See ForeignKeyConstraint.use_alter for further description.
See also
ForeignKeyConstraint.use_alter
Creating/Dropping Foreign Key Constraints via ALTER
• match – Optional string. If set, emit MATCH <value> when issuing DDL for this constraint. Typical values include SIMPLE, PARTIAL and FULL.
• info – Optional data dictionary which will be populated into the SchemaItem.info attribute of this object.
• comment – 
Optional string that will render an SQL comment on foreign key constraint creation.
Added in version 2.0.
• **dialect_kw – Additional keyword arguments are dialect specific, and passed in the form <dialectname>_<argname>. The arguments are ultimately handled by a corresponding ForeignKeyConstraint. See the documentation regarding an individual dialect at Dialects for detail on documented arguments.
classmethod sqlalchemy.schema.ForeignKey.argument_for(dialect_name, argument_name, default)
inherited from the DialectKWArgs.argument_for() method of DialectKWArgs
Add a new kind of dialect-specific keyword argument for this class.
E.g.:
Index.argument_for("mydialect", "length", None)

some_index = Index("a", "b", mydialect_length=5)
The DialectKWArgs.argument_for() method is a per-argument way adding extra arguments to the DefaultDialect.construct_arguments dictionary. This dictionary provides a list of argument names accepted by various schema-level constructs on behalf of a dialect.
New dialects should typically specify this dictionary all at once as a data member of the dialect class. The use case for ad-hoc addition of argument names is typically for end-user code that is also using a custom compilation scheme which consumes the additional arguments.
Parameters:
• dialect_name – name of a dialect. The dialect must be locatable, else a NoSuchModuleError is raised. The dialect must also include an existing DefaultDialect.construct_arguments collection, indicating that it participates in the keyword-argument validation and default system, else ArgumentError is raised. If the dialect does not include this collection, then any keyword argument can be specified on behalf of this dialect already. All dialects packaged within SQLAlchemy include this collection, however for third party dialects, support may vary.
• argument_name – name of the parameter.
• default – default value of the parameter.
attribute sqlalchemy.schema.ForeignKey.column
Return the target Column referenced by this ForeignKey.
If no target column has been established, an exception is raised.
method sqlalchemy.schema.ForeignKey.copy(*, schema: str | None = None, **kw: Any) → ForeignKey
Deprecated since version 1.4: The ForeignKey.copy() method is deprecated and will be removed in a future release.
attribute sqlalchemy.schema.ForeignKey.dialect_kwargs
inherited from the DialectKWArgs.dialect_kwargs attribute of DialectKWArgs
A collection of keyword arguments specified as dialect-specific options to this construct.
The arguments are present here in their original <dialect>_<kwarg> format. Only arguments that were actually passed are included; unlike the DialectKWArgs.dialect_options collection, which contains all options known by this dialect including defaults.
The collection is also writable; keys are accepted of the form <dialect>_<kwarg> where the value will be assembled into the list of options.
See also
DialectKWArgs.dialect_options - nested dictionary form
attribute sqlalchemy.schema.ForeignKey.dialect_options
inherited from the DialectKWArgs.dialect_options attribute of DialectKWArgs
A collection of keyword arguments specified as dialect-specific options to this construct.
This is a two-level nested registry, keyed to <dialect_name> and <argument_name>. For example, the postgresql_where argument would be locatable as:
arg = my_object.dialect_options["postgresql"]["where"]
Added in version 0.9.2.
See also
DialectKWArgs.dialect_kwargs - flat dictionary form
method sqlalchemy.schema.ForeignKey.get_referent(table: FromClause) → Column[Any] | None
Return the Column in the given Table (or any FromClause) referenced by this ForeignKey.
Returns None if this ForeignKey does not reference the given Table.
attribute sqlalchemy.schema.ForeignKey.info
inherited from the SchemaItem.info attribute of SchemaItem
Info dictionary associated with the object, allowing user-defined data to be associated with this SchemaItem.
The dictionary is automatically generated when first accessed. It can also be specified in the constructor of some objects, such as Table and Column.
attribute sqlalchemy.schema.ForeignKey.kwargs
inherited from the DialectKWArgs.kwargs attribute of DialectKWArgs
A synonym for DialectKWArgs.dialect_kwargs.
method sqlalchemy.schema.ForeignKey.references(table: Table) → bool
Return True if the given Table is referenced by this ForeignKey.
attribute sqlalchemy.schema.ForeignKey.target_fullname
Return a string based ‘column specification’ for this ForeignKey.
This is usually the equivalent of the string-based “tablename.colname” argument first passed to the object’s constructor.
class sqlalchemy.schema.ForeignKeyConstraint
A table-level FOREIGN KEY constraint.
Defines a single column or composite FOREIGN KEY … REFERENCES constraint. For a no-frills, single column foreign key, adding a ForeignKey to the definition of a Column is a shorthand equivalent for an unnamed, single column ForeignKeyConstraint.
Examples of foreign key configuration are in Defining Foreign Keys.
Members
__init__(), argument_for(), column_keys, columns, contains_column(), copy(), ddl_if(), dialect_kwargs, dialect_options, elements, info, kwargs, referred_table
Class signature
class sqlalchemy.schema.ForeignKeyConstraint (sqlalchemy.schema.ColumnCollectionConstraint)
method sqlalchemy.schema.ForeignKeyConstraint.__init__(columns: _typing_Sequence[_DDLColumnArgument], refcolumns: _typing_Sequence[_DDLColumnArgument], name: _ConstraintNameArgument = None, onupdate: str | None = None, ondelete: str | None = None, deferrable: bool | None = None, initially: str | None = None, use_alter: bool = False, link_to_name: bool = False, match: str | None = None, table: Table | None = None, info: _InfoType | None = None, comment: str | None = None, **dialect_kw: Any) → None
Construct a composite-capable FOREIGN KEY.
Parameters:
• columns – A sequence of local column names. The named columns must be defined and present in the parent Table. The names should match the key given to each column (defaults to the name) unless link_to_name is True.
• refcolumns – A sequence of foreign column names or Column objects. The columns must all be located within the same Table.
• name – Optional, the in-database name of the key.
• onupdate – 
Optional string. If set, emit ON UPDATE <value> when issuing DDL for this constraint. Typical values include CASCADE, DELETE and RESTRICT.
See also
ON UPDATE and ON DELETE
• ondelete – 
Optional string. If set, emit ON DELETE <value> when issuing DDL for this constraint. Typical values include CASCADE, SET NULL and RESTRICT. Some dialects may allow for additional syntaxes.
See also
ON UPDATE and ON DELETE
• deferrable – Optional bool. If set, emit DEFERRABLE or NOT DEFERRABLE when issuing DDL for this constraint.
• initially – Optional string. If set, emit INITIALLY <value> when issuing DDL for this constraint.
• link_to_name – if True, the string name given in column is the rendered name of the referenced column, not its locally assigned key.
• use_alter – 
If True, do not emit the DDL for this constraint as part of the CREATE TABLE definition. Instead, generate it via an ALTER TABLE statement issued after the full collection of tables have been created, and drop it via an ALTER TABLE statement before the full collection of tables are dropped.
The use of ForeignKeyConstraint.use_alter is particularly geared towards the case where two or more tables are established within a mutually-dependent foreign key constraint relationship; however, the MetaData.create_all() and MetaData.drop_all() methods will perform this resolution automatically, so the flag is normally not needed.
See also
Creating/Dropping Foreign Key Constraints via ALTER
• match – Optional string. If set, emit MATCH <value> when issuing DDL for this constraint. Typical values include SIMPLE, PARTIAL and FULL.
• info – Optional data dictionary which will be populated into the SchemaItem.info attribute of this object.
• comment – 
Optional string that will render an SQL comment on foreign key constraint creation.
Added in version 2.0.
• **dialect_kw – Additional keyword arguments are dialect specific, and passed in the form <dialectname>_<argname>. See the documentation regarding an individual dialect at Dialects for detail on documented arguments.
classmethod sqlalchemy.schema.ForeignKeyConstraint.argument_for(dialect_name, argument_name, default)
inherited from the DialectKWArgs.argument_for() method of DialectKWArgs
Add a new kind of dialect-specific keyword argument for this class.
E.g.:
Index.argument_for("mydialect", "length", None)

some_index = Index("a", "b", mydialect_length=5)
The DialectKWArgs.argument_for() method is a per-argument way adding extra arguments to the DefaultDialect.construct_arguments dictionary. This dictionary provides a list of argument names accepted by various schema-level constructs on behalf of a dialect.
New dialects should typically specify this dictionary all at once as a data member of the dialect class. The use case for ad-hoc addition of argument names is typically for end-user code that is also using a custom compilation scheme which consumes the additional arguments.
Parameters:
• dialect_name – name of a dialect. The dialect must be locatable, else a NoSuchModuleError is raised. The dialect must also include an existing DefaultDialect.construct_arguments collection, indicating that it participates in the keyword-argument validation and default system, else ArgumentError is raised. If the dialect does not include this collection, then any keyword argument can be specified on behalf of this dialect already. All dialects packaged within SQLAlchemy include this collection, however for third party dialects, support may vary.
• argument_name – name of the parameter.
• default – default value of the parameter.
attribute sqlalchemy.schema.ForeignKeyConstraint.column_keys
Return a list of string keys representing the local columns in this ForeignKeyConstraint.
This list is either the original string arguments sent to the constructor of the ForeignKeyConstraint, or if the constraint has been initialized with Column objects, is the string .key of each element.
attribute sqlalchemy.schema.ForeignKeyConstraint.columns: ReadOnlyColumnCollection[str, Column[Any]]
inherited from the ColumnCollectionMixin.columns attribute of ColumnCollectionMixin
A ColumnCollection representing the set of columns for this constraint.
method sqlalchemy.schema.ForeignKeyConstraint.contains_column(col: Column[Any]) → bool
inherited from the ColumnCollectionConstraint.contains_column() method of ColumnCollectionConstraint
Return True if this constraint contains the given column.
Note that this object also contains an attribute .columns which is a ColumnCollection of Column objects.
method sqlalchemy.schema.ForeignKeyConstraint.copy(*, schema: str | None = None, target_table: Table | None = None, **kw: Any) → ForeignKeyConstraint
Deprecated since version 1.4: The ForeignKeyConstraint.copy() method is deprecated and will be removed in a future release.
method sqlalchemy.schema.ForeignKeyConstraint.ddl_if(dialect: str | None = None, callable_: DDLIfCallable | None = None, state: Any | None = None) → Self
inherited from the HasConditionalDDL.ddl_if() method of HasConditionalDDL
apply a conditional DDL rule to this schema item.
These rules work in a similar manner to the ExecutableDDLElement.execute_if() callable, with the added feature that the criteria may be checked within the DDL compilation phase for a construct such as CreateTable. HasConditionalDDL.ddl_if() currently applies towards the Index construct as well as all Constraint constructs.
Parameters:
• dialect – string name of a dialect, or a tuple of string names to indicate multiple dialect types.
• callable_ – a callable that is constructed using the same form as that described in ExecutableDDLElement.execute_if.callable_.
• state – any arbitrary object that will be passed to the callable, if present.
Added in version 2.0.
See also
Controlling DDL Generation of Constraints and Indexes - background and usage examples
attribute sqlalchemy.schema.ForeignKeyConstraint.dialect_kwargs
inherited from the DialectKWArgs.dialect_kwargs attribute of DialectKWArgs
A collection of keyword arguments specified as dialect-specific options to this construct.
The arguments are present here in their original <dialect>_<kwarg> format. Only arguments that were actually passed are included; unlike the DialectKWArgs.dialect_options collection, which contains all options known by this dialect including defaults.
The collection is also writable; keys are accepted of the form <dialect>_<kwarg> where the value will be assembled into the list of options.
See also
DialectKWArgs.dialect_options - nested dictionary form
attribute sqlalchemy.schema.ForeignKeyConstraint.dialect_options
inherited from the DialectKWArgs.dialect_options attribute of DialectKWArgs
A collection of keyword arguments specified as dialect-specific options to this construct.
This is a two-level nested registry, keyed to <dialect_name> and <argument_name>. For example, the postgresql_where argument would be locatable as:
arg = my_object.dialect_options["postgresql"]["where"]
Added in version 0.9.2.
See also
DialectKWArgs.dialect_kwargs - flat dictionary form
attribute sqlalchemy.schema.ForeignKeyConstraint.elements: List[ForeignKey]
A sequence of ForeignKey objects.
Each ForeignKey represents a single referring column/referred column pair.
This collection is intended to be read-only.
attribute sqlalchemy.schema.ForeignKeyConstraint.info
inherited from the SchemaItem.info attribute of SchemaItem
Info dictionary associated with the object, allowing user-defined data to be associated with this SchemaItem.
The dictionary is automatically generated when first accessed. It can also be specified in the constructor of some objects, such as Table and Column.
attribute sqlalchemy.schema.ForeignKeyConstraint.kwargs
inherited from the DialectKWArgs.kwargs attribute of DialectKWArgs
A synonym for DialectKWArgs.dialect_kwargs.
attribute sqlalchemy.schema.ForeignKeyConstraint.referred_table
The Table object to which this ForeignKeyConstraint references.
This is a dynamically calculated attribute which may not be available if the constraint and/or parent table is not yet associated with a metadata collection that contains the referred table.
class sqlalchemy.schema.HasConditionalDDL
define a class that includes the HasConditionalDDL.ddl_if() method, allowing for conditional rendering of DDL.
Currently applies to constraints and indexes.
Members
ddl_if()
Added in version 2.0.
method sqlalchemy.schema.HasConditionalDDL.ddl_if(dialect: str | None = None, callable_: DDLIfCallable | None = None, state: Any | None = None) → Self
apply a conditional DDL rule to this schema item.
These rules work in a similar manner to the ExecutableDDLElement.execute_if() callable, with the added feature that the criteria may be checked within the DDL compilation phase for a construct such as CreateTable. HasConditionalDDL.ddl_if() currently applies towards the Index construct as well as all Constraint constructs.
Parameters:
• dialect – string name of a dialect, or a tuple of string names to indicate multiple dialect types.
• callable_ – a callable that is constructed using the same form as that described in ExecutableDDLElement.execute_if.callable_.
• state – any arbitrary object that will be passed to the callable, if present.
Added in version 2.0.
See also
Controlling DDL Generation of Constraints and Indexes - background and usage examples
class sqlalchemy.schema.PrimaryKeyConstraint
A table-level PRIMARY KEY constraint.
The PrimaryKeyConstraint object is present automatically on any Table object; it is assigned a set of Column objects corresponding to those marked with the Column.primary_key flag:
>>> my_table = Table(
...     "mytable",
...     metadata,
...     Column("id", Integer, primary_key=True),
...     Column("version_id", Integer, primary_key=True),
...     Column("data", String(50)),
... )
>>> my_table.primary_key
PrimaryKeyConstraint(
    Column('id', Integer(), table=<mytable>,
           primary_key=True, nullable=False),
    Column('version_id', Integer(), table=<mytable>,
           primary_key=True, nullable=False)
)
The primary key of a Table can also be specified by using a PrimaryKeyConstraint object explicitly; in this mode of usage, the “name” of the constraint can also be specified, as well as other options which may be recognized by dialects:
my_table = Table(
    "mytable",
    metadata,
    Column("id", Integer),
    Column("version_id", Integer),
    Column("data", String(50)),
    PrimaryKeyConstraint("id", "version_id", name="mytable_pk"),
)
The two styles of column-specification should generally not be mixed. An warning is emitted if the columns present in the PrimaryKeyConstraint don’t match the columns that were marked as primary_key=True, if both are present; in this case, the columns are taken strictly from the PrimaryKeyConstraint declaration, and those columns otherwise marked as primary_key=True are ignored. This behavior is intended to be backwards compatible with previous behavior.
For the use case where specific options are to be specified on the PrimaryKeyConstraint, but the usual style of using primary_key=True flags is still desirable, an empty PrimaryKeyConstraint may be specified, which will take on the primary key column collection from the Table based on the flags:
my_table = Table(
    "mytable",
    metadata,
    Column("id", Integer, primary_key=True),
    Column("version_id", Integer, primary_key=True),
    Column("data", String(50)),
    PrimaryKeyConstraint(name="mytable_pk", mssql_clustered=True),
)
Members
argument_for(), columns, contains_column(), copy(), ddl_if(), dialect_kwargs, dialect_options, info, kwargs
Class signature
class sqlalchemy.schema.PrimaryKeyConstraint (sqlalchemy.schema.ColumnCollectionConstraint)
classmethod sqlalchemy.schema.PrimaryKeyConstraint.argument_for(dialect_name, argument_name, default)
inherited from the DialectKWArgs.argument_for() method of DialectKWArgs
Add a new kind of dialect-specific keyword argument for this class.
E.g.:
Index.argument_for("mydialect", "length", None)

some_index = Index("a", "b", mydialect_length=5)
The DialectKWArgs.argument_for() method is a per-argument way adding extra arguments to the DefaultDialect.construct_arguments dictionary. This dictionary provides a list of argument names accepted by various schema-level constructs on behalf of a dialect.
New dialects should typically specify this dictionary all at once as a data member of the dialect class. The use case for ad-hoc addition of argument names is typically for end-user code that is also using a custom compilation scheme which consumes the additional arguments.
Parameters:
• dialect_name – name of a dialect. The dialect must be locatable, else a NoSuchModuleError is raised. The dialect must also include an existing DefaultDialect.construct_arguments collection, indicating that it participates in the keyword-argument validation and default system, else ArgumentError is raised. If the dialect does not include this collection, then any keyword argument can be specified on behalf of this dialect already. All dialects packaged within SQLAlchemy include this collection, however for third party dialects, support may vary.
• argument_name – name of the parameter.
• default – default value of the parameter.
attribute sqlalchemy.schema.PrimaryKeyConstraint.columns: ReadOnlyColumnCollection[str, Column[Any]]
inherited from the ColumnCollectionMixin.columns attribute of ColumnCollectionMixin
A ColumnCollection representing the set of columns for this constraint.
method sqlalchemy.schema.PrimaryKeyConstraint.contains_column(col: Column[Any]) → bool
inherited from the ColumnCollectionConstraint.contains_column() method of ColumnCollectionConstraint
Return True if this constraint contains the given column.
Note that this object also contains an attribute .columns which is a ColumnCollection of Column objects.
method sqlalchemy.schema.PrimaryKeyConstraint.copy(*, target_table: Table | None = None, **kw: Any) → ColumnCollectionConstraint
inherited from the ColumnCollectionConstraint.copy() method of ColumnCollectionConstraint
Deprecated since version 1.4: The ColumnCollectionConstraint.copy() method is deprecated and will be removed in a future release.
method sqlalchemy.schema.PrimaryKeyConstraint.ddl_if(dialect: str | None = None, callable_: DDLIfCallable | None = None, state: Any | None = None) → Self
inherited from the HasConditionalDDL.ddl_if() method of HasConditionalDDL
apply a conditional DDL rule to this schema item.
These rules work in a similar manner to the ExecutableDDLElement.execute_if() callable, with the added feature that the criteria may be checked within the DDL compilation phase for a construct such as CreateTable. HasConditionalDDL.ddl_if() currently applies towards the Index construct as well as all Constraint constructs.
Parameters:
• dialect – string name of a dialect, or a tuple of string names to indicate multiple dialect types.
• callable_ – a callable that is constructed using the same form as that described in ExecutableDDLElement.execute_if.callable_.
• state – any arbitrary object that will be passed to the callable, if present.
Added in version 2.0.
See also
Controlling DDL Generation of Constraints and Indexes - background and usage examples
attribute sqlalchemy.schema.PrimaryKeyConstraint.dialect_kwargs
inherited from the DialectKWArgs.dialect_kwargs attribute of DialectKWArgs
A collection of keyword arguments specified as dialect-specific options to this construct.
The arguments are present here in their original <dialect>_<kwarg> format. Only arguments that were actually passed are included; unlike the DialectKWArgs.dialect_options collection, which contains all options known by this dialect including defaults.
The collection is also writable; keys are accepted of the form <dialect>_<kwarg> where the value will be assembled into the list of options.
See also
DialectKWArgs.dialect_options - nested dictionary form
attribute sqlalchemy.schema.PrimaryKeyConstraint.dialect_options
inherited from the DialectKWArgs.dialect_options attribute of DialectKWArgs
A collection of keyword arguments specified as dialect-specific options to this construct.
This is a two-level nested registry, keyed to <dialect_name> and <argument_name>. For example, the postgresql_where argument would be locatable as:
arg = my_object.dialect_options["postgresql"]["where"]
Added in version 0.9.2.
See also
DialectKWArgs.dialect_kwargs - flat dictionary form
attribute sqlalchemy.schema.PrimaryKeyConstraint.info
inherited from the SchemaItem.info attribute of SchemaItem
Info dictionary associated with the object, allowing user-defined data to be associated with this SchemaItem.
The dictionary is automatically generated when first accessed. It can also be specified in the constructor of some objects, such as Table and Column.
attribute sqlalchemy.schema.PrimaryKeyConstraint.kwargs
inherited from the DialectKWArgs.kwargs attribute of DialectKWArgs
A synonym for DialectKWArgs.dialect_kwargs.
class sqlalchemy.schema.UniqueConstraint
A table-level UNIQUE constraint.
Defines a single column or composite UNIQUE constraint. For a no-frills, single column constraint, adding unique=True to the Column definition is a shorthand equivalent for an unnamed, single column UniqueConstraint.
Members
__init__(), argument_for(), columns, contains_column(), copy(), ddl_if(), dialect_kwargs, dialect_options, info, kwargs
Class signature
class sqlalchemy.schema.UniqueConstraint (sqlalchemy.schema.ColumnCollectionConstraint)
method sqlalchemy.schema.UniqueConstraint.__init__(*columns: _DDLColumnArgument, name: _ConstraintNameArgument = None, deferrable: bool | None = None, initially: str | None = None, info: _InfoType | None = None, _autoattach: bool = True, _column_flag: bool = False, _gather_expressions: List[_DDLColumnArgument] | None = None, **dialect_kw: Any) → None
inherited from the sqlalchemy.schema.ColumnCollectionConstraint.__init__ method of ColumnCollectionConstraint
Parameters:
• *columns – A sequence of column names or Column objects.
• name – Optional, the in-database name of this constraint.
• deferrable – Optional bool. If set, emit DEFERRABLE or NOT DEFERRABLE when issuing DDL for this constraint.
• initially – Optional string. If set, emit INITIALLY <value> when issuing DDL for this constraint.
• **dialect_kw – other keyword arguments including dialect-specific arguments are propagated to the Constraint superclass.
classmethod sqlalchemy.schema.UniqueConstraint.argument_for(dialect_name, argument_name, default)
inherited from the DialectKWArgs.argument_for() method of DialectKWArgs
Add a new kind of dialect-specific keyword argument for this class.
E.g.:
Index.argument_for("mydialect", "length", None)

some_index = Index("a", "b", mydialect_length=5)
The DialectKWArgs.argument_for() method is a per-argument way adding extra arguments to the DefaultDialect.construct_arguments dictionary. This dictionary provides a list of argument names accepted by various schema-level constructs on behalf of a dialect.
New dialects should typically specify this dictionary all at once as a data member of the dialect class. The use case for ad-hoc addition of argument names is typically for end-user code that is also using a custom compilation scheme which consumes the additional arguments.
Parameters:
• dialect_name – name of a dialect. The dialect must be locatable, else a NoSuchModuleError is raised. The dialect must also include an existing DefaultDialect.construct_arguments collection, indicating that it participates in the keyword-argument validation and default system, else ArgumentError is raised. If the dialect does not include this collection, then any keyword argument can be specified on behalf of this dialect already. All dialects packaged within SQLAlchemy include this collection, however for third party dialects, support may vary.
• argument_name – name of the parameter.
• default – default value of the parameter.
attribute sqlalchemy.schema.UniqueConstraint.columns: ReadOnlyColumnCollection[str, Column[Any]]
inherited from the ColumnCollectionMixin.columns attribute of ColumnCollectionMixin
A ColumnCollection representing the set of columns for this constraint.
method sqlalchemy.schema.UniqueConstraint.contains_column(col: Column[Any]) → bool
inherited from the ColumnCollectionConstraint.contains_column() method of ColumnCollectionConstraint
Return True if this constraint contains the given column.
Note that this object also contains an attribute .columns which is a ColumnCollection of Column objects.
method sqlalchemy.schema.UniqueConstraint.copy(*, target_table: Table | None = None, **kw: Any) → ColumnCollectionConstraint
inherited from the ColumnCollectionConstraint.copy() method of ColumnCollectionConstraint
Deprecated since version 1.4: The ColumnCollectionConstraint.copy() method is deprecated and will be removed in a future release.
method sqlalchemy.schema.UniqueConstraint.ddl_if(dialect: str | None = None, callable_: DDLIfCallable | None = None, state: Any | None = None) → Self
inherited from the HasConditionalDDL.ddl_if() method of HasConditionalDDL
apply a conditional DDL rule to this schema item.
These rules work in a similar manner to the ExecutableDDLElement.execute_if() callable, with the added feature that the criteria may be checked within the DDL compilation phase for a construct such as CreateTable. HasConditionalDDL.ddl_if() currently applies towards the Index construct as well as all Constraint constructs.
Parameters:
• dialect – string name of a dialect, or a tuple of string names to indicate multiple dialect types.
• callable_ – a callable that is constructed using the same form as that described in ExecutableDDLElement.execute_if.callable_.
• state – any arbitrary object that will be passed to the callable, if present.
Added in version 2.0.
See also
Controlling DDL Generation of Constraints and Indexes - background and usage examples
attribute sqlalchemy.schema.UniqueConstraint.dialect_kwargs
inherited from the DialectKWArgs.dialect_kwargs attribute of DialectKWArgs
A collection of keyword arguments specified as dialect-specific options to this construct.
The arguments are present here in their original <dialect>_<kwarg> format. Only arguments that were actually passed are included; unlike the DialectKWArgs.dialect_options collection, which contains all options known by this dialect including defaults.
The collection is also writable; keys are accepted of the form <dialect>_<kwarg> where the value will be assembled into the list of options.
See also
DialectKWArgs.dialect_options - nested dictionary form
attribute sqlalchemy.schema.UniqueConstraint.dialect_options
inherited from the DialectKWArgs.dialect_options attribute of DialectKWArgs
A collection of keyword arguments specified as dialect-specific options to this construct.
This is a two-level nested registry, keyed to <dialect_name> and <argument_name>. For example, the postgresql_where argument would be locatable as:
arg = my_object.dialect_options["postgresql"]["where"]
Added in version 0.9.2.
See also
DialectKWArgs.dialect_kwargs - flat dictionary form
attribute sqlalchemy.schema.UniqueConstraint.info
inherited from the SchemaItem.info attribute of SchemaItem
Info dictionary associated with the object, allowing user-defined data to be associated with this SchemaItem.
The dictionary is automatically generated when first accessed. It can also be specified in the constructor of some objects, such as Table and Column.
attribute sqlalchemy.schema.UniqueConstraint.kwargs
inherited from the DialectKWArgs.kwargs attribute of DialectKWArgs
A synonym for DialectKWArgs.dialect_kwargs.
function sqlalchemy.schema.conv(value: str, quote: bool | None = None) → Any
Mark a string indicating that a name has already been converted by a naming convention.
This is a string subclass that indicates a name that should not be subject to any further naming conventions.
E.g. when we create a Constraint using a naming convention as follows:
m = MetaData(
    naming_convention={"ck": "ck_%(table_name)s_%(constraint_name)s"}
)
t = Table(
    "t", m, Column("x", Integer), CheckConstraint("x > 5", name="x5")
)
The name of the above constraint will be rendered as "ck_t_x5". That is, the existing name x5 is used in the naming convention as the constraint_name token.
In some situations, such as in migration scripts, we may be rendering the above CheckConstraint with a name that’s already been converted. In order to make sure the name isn’t double-modified, the new name is applied using the conv() marker. We can use this explicitly as follows:
m = MetaData(
    naming_convention={"ck": "ck_%(table_name)s_%(constraint_name)s"}
)
t = Table(
    "t",
    m,
    Column("x", Integer),
    CheckConstraint("x > 5", name=conv("ck_t_x5")),
)
Where above, the conv() marker indicates that the constraint name here is final, and the name will render as "ck_t_x5" and not "ck_t_ck_t_x5"
See also
Configuring Constraint Naming Conventions
Indexes
Indexes can be created anonymously (using an auto-generated name ix_<column label>) for a single column using the inline index keyword on Column, which also modifies the usage of unique to apply the uniqueness to the index itself, instead of adding a separate UNIQUE constraint. For indexes with specific names or which encompass more than one column, use the Index construct, which requires a name.
Below we illustrate a Table with several Index objects associated. The DDL for “CREATE INDEX” is issued right after the create statements for the table:
metadata_obj = MetaData()
mytable = Table(
    "mytable",
    metadata_obj,
    # an indexed column, with index "ix_mytable_col1"
    Column("col1", Integer, index=True),
    # a uniquely indexed column with index "ix_mytable_col2"
    Column("col2", Integer, index=True, unique=True),
    Column("col3", Integer),
    Column("col4", Integer),
    Column("col5", Integer),
    Column("col6", Integer),
)

# place an index on col3, col4
Index("idx_col34", mytable.c.col3, mytable.c.col4)

# place a unique index on col5, col6
Index("myindex", mytable.c.col5, mytable.c.col6, unique=True)

mytable.create(engine)
CREATE TABLE mytable (
    col1 INTEGER,
    col2 INTEGER,
    col3 INTEGER,
    col4 INTEGER,
    col5 INTEGER,
    col6 INTEGER
)
CREATE INDEX ix_mytable_col1 ON mytable (col1)
CREATE UNIQUE INDEX ix_mytable_col2 ON mytable (col2)
CREATE UNIQUE INDEX myindex ON mytable (col5, col6)
CREATE INDEX idx_col34 ON mytable (col3, col4)
Note in the example above, the Index construct is created externally to the table which it corresponds, using Column objects directly. Index also supports “inline” definition inside the Table, using string names to identify columns:
metadata_obj = MetaData()
mytable = Table(
    "mytable",
    metadata_obj,
    Column("col1", Integer),
    Column("col2", Integer),
    Column("col3", Integer),
    Column("col4", Integer),
    # place an index on col1, col2
    Index("idx_col12", "col1", "col2"),
    # place a unique index on col3, col4
    Index("idx_col34", "col3", "col4", unique=True),
)
The Index object also supports its own create() method:
i = Index("someindex", mytable.c.col5)
i.create(engine)
CREATE INDEX someindex ON mytable (col5)
Functional Indexes
Index supports SQL and function expressions, as supported by the target backend. To create an index against a column using a descending value, the ColumnElement.desc() modifier may be used:
from sqlalchemy import Index

Index("someindex", mytable.c.somecol.desc())
Or with a backend that supports functional indexes such as PostgreSQL, a “case insensitive” index can be created using the lower() function:
from sqlalchemy import func, Index

Index("someindex", func.lower(mytable.c.somecol))
Index API
Object NameDescriptionIndexA table-level INDEX.class sqlalchemy.schema.Index
A table-level INDEX.
Defines a composite (one or more column) INDEX.
E.g.:
sometable = Table(
    "sometable",
    metadata,
    Column("name", String(50)),
    Column("address", String(100)),
)

Index("some_index", sometable.c.name)
For a no-frills, single column index, adding Column also supports index=True:
sometable = Table(
    "sometable", metadata, Column("name", String(50), index=True)
)
For a composite index, multiple columns can be specified:
Index("some_index", sometable.c.name, sometable.c.address)
Functional indexes are supported as well, typically by using the func construct in conjunction with table-bound Column objects:
Index("some_index", func.lower(sometable.c.name))
An Index can also be manually associated with a Table, either through inline declaration or using Table.append_constraint(). When this approach is used, the names of the indexed columns can be specified as strings:
Table(
    "sometable",
    metadata,
    Column("name", String(50)),
    Column("address", String(100)),
    Index("some_index", "name", "address"),
)
To support functional or expression-based indexes in this form, the text() construct may be used:
from sqlalchemy import text

Table(
    "sometable",
    metadata,
    Column("name", String(50)),
    Column("address", String(100)),
    Index("some_index", text("lower(name)")),
)
See also
Indexes - General information on Index.
PostgreSQL-Specific Index Options - PostgreSQL-specific options available for the Index construct.
MySQL / MariaDB- Specific Index Options - MySQL-specific options available for the Index construct.
Clustered Index Support - MSSQL-specific options available for the Index construct.
Members
__init__(), argument_for(), create(), ddl_if(), dialect_kwargs, dialect_options, drop(), info, kwargs
Class signature
class sqlalchemy.schema.Index (sqlalchemy.sql.expression.DialectKWArgs, sqlalchemy.schema.ColumnCollectionMixin, sqlalchemy.schema.HasConditionalDDL, sqlalchemy.schema.SchemaItem)
method sqlalchemy.schema.Index.__init__(name: str | None, *expressions: _DDLColumnArgument, unique: bool = False, quote: bool | None = None, info: _InfoType | None = None, _table: Table | None = None, _column_flag: bool = False, **dialect_kw: Any) → None
Construct an index object.
Parameters:
• name – The name of the index
• *expressions – Column expressions to include in the index. The expressions are normally instances of Column, but may also be arbitrary SQL expressions which ultimately refer to a Column.
• unique=False – Keyword only argument; if True, create a unique index.
• quote=None – Keyword only argument; whether to apply quoting to the name of the index. Works in the same manner as that of Column.quote.
• info=None – Optional data dictionary which will be populated into the SchemaItem.info attribute of this object.
• **dialect_kw – Additional keyword arguments not mentioned above are dialect specific, and passed in the form <dialectname>_<argname>. See the documentation regarding an individual dialect at Dialects for detail on documented arguments.
classmethod sqlalchemy.schema.Index.argument_for(dialect_name, argument_name, default)
inherited from the DialectKWArgs.argument_for() method of DialectKWArgs
Add a new kind of dialect-specific keyword argument for this class.
E.g.:
Index.argument_for("mydialect", "length", None)

some_index = Index("a", "b", mydialect_length=5)
The DialectKWArgs.argument_for() method is a per-argument way adding extra arguments to the DefaultDialect.construct_arguments dictionary. This dictionary provides a list of argument names accepted by various schema-level constructs on behalf of a dialect.
New dialects should typically specify this dictionary all at once as a data member of the dialect class. The use case for ad-hoc addition of argument names is typically for end-user code that is also using a custom compilation scheme which consumes the additional arguments.
Parameters:
• dialect_name – name of a dialect. The dialect must be locatable, else a NoSuchModuleError is raised. The dialect must also include an existing DefaultDialect.construct_arguments collection, indicating that it participates in the keyword-argument validation and default system, else ArgumentError is raised. If the dialect does not include this collection, then any keyword argument can be specified on behalf of this dialect already. All dialects packaged within SQLAlchemy include this collection, however for third party dialects, support may vary.
• argument_name – name of the parameter.
• default – default value of the parameter.
method sqlalchemy.schema.Index.create(bind: _CreateDropBind, checkfirst: bool = False) → None
Issue a CREATE statement for this Index, using the given Connection or Engine` for connectivity.
See also
MetaData.create_all().
method sqlalchemy.schema.Index.ddl_if(dialect: str | None = None, callable_: DDLIfCallable | None = None, state: Any | None = None) → Self
inherited from the HasConditionalDDL.ddl_if() method of HasConditionalDDL
apply a conditional DDL rule to this schema item.
These rules work in a similar manner to the ExecutableDDLElement.execute_if() callable, with the added feature that the criteria may be checked within the DDL compilation phase for a construct such as CreateTable. HasConditionalDDL.ddl_if() currently applies towards the Index construct as well as all Constraint constructs.
Parameters:
• dialect – string name of a dialect, or a tuple of string names to indicate multiple dialect types.
• callable_ – a callable that is constructed using the same form as that described in ExecutableDDLElement.execute_if.callable_.
• state – any arbitrary object that will be passed to the callable, if present.
Added in version 2.0.
See also
Controlling DDL Generation of Constraints and Indexes - background and usage examples
attribute sqlalchemy.schema.Index.dialect_kwargs
inherited from the DialectKWArgs.dialect_kwargs attribute of DialectKWArgs
A collection of keyword arguments specified as dialect-specific options to this construct.
The arguments are present here in their original <dialect>_<kwarg> format. Only arguments that were actually passed are included; unlike the DialectKWArgs.dialect_options collection, which contains all options known by this dialect including defaults.
The collection is also writable; keys are accepted of the form <dialect>_<kwarg> where the value will be assembled into the list of options.
See also
DialectKWArgs.dialect_options - nested dictionary form
attribute sqlalchemy.schema.Index.dialect_options
inherited from the DialectKWArgs.dialect_options attribute of DialectKWArgs
A collection of keyword arguments specified as dialect-specific options to this construct.
This is a two-level nested registry, keyed to <dialect_name> and <argument_name>. For example, the postgresql_where argument would be locatable as:
arg = my_object.dialect_options["postgresql"]["where"]
Added in version 0.9.2.
See also
DialectKWArgs.dialect_kwargs - flat dictionary form
method sqlalchemy.schema.Index.drop(bind: _CreateDropBind, checkfirst: bool = False) → None
Issue a DROP statement for this Index, using the given Connection or Engine for connectivity.
See also
MetaData.drop_all().
attribute sqlalchemy.schema.Index.info
inherited from the SchemaItem.info attribute of SchemaItem
Info dictionary associated with the object, allowing user-defined data to be associated with this SchemaItem.
The dictionary is automatically generated when first accessed. It can also be specified in the constructor of some objects, such as Table and Column.
attribute sqlalchemy.schema.Index.kwargs
inherited from the DialectKWArgs.kwargs attribute of DialectKWArgs
A synonym for DialectKWArgs.dialect_kwargs.


Customizing DDL
In the preceding sections we’ve discussed a variety of schema constructs including Table, ForeignKeyConstraint, CheckConstraint, and Sequence. Throughout, we’ve relied upon the create() and create_all() methods of Table and MetaData in order to issue data definition language (DDL) for all constructs. When issued, a pre-determined order of operations is invoked, and DDL to create each table is created unconditionally including all constraints and other objects associated with it. For more complex scenarios where database-specific DDL is required, SQLAlchemy offers two techniques which can be used to add any DDL based on any condition, either accompanying the standard generation of tables or by itself.
Custom DDL
Custom DDL phrases are most easily achieved using the DDL construct. This construct works like all the other DDL elements except it accepts a string which is the text to be emitted:
event.listen(
    metadata,
    "after_create",
    DDL(
        "ALTER TABLE users ADD CONSTRAINT "
        "cst_user_name_length "
        " CHECK (length(user_name) >= 8)"
    ),
)
A more comprehensive method of creating libraries of DDL constructs is to use custom compilation - see Custom SQL Constructs and Compilation Extension for details.
Controlling DDL Sequences
The DDL construct introduced previously also has the ability to be invoked conditionally based on inspection of the database. This feature is available using the ExecutableDDLElement.execute_if() method. For example, if we wanted to create a trigger but only on the PostgreSQL backend, we could invoke this as:
mytable = Table(
    "mytable",
    metadata,
    Column("id", Integer, primary_key=True),
    Column("data", String(50)),
)

func = DDL(
    "CREATE FUNCTION my_func() "
    "RETURNS TRIGGER AS $$ "
    "BEGIN "
    "NEW.data := 'ins'; "
    "RETURN NEW; "
    "END; $$ LANGUAGE PLPGSQL"
)

trigger = DDL(
    "CREATE TRIGGER dt_ins BEFORE INSERT ON mytable "
    "FOR EACH ROW EXECUTE PROCEDURE my_func();"
)

event.listen(mytable, "after_create", func.execute_if(dialect="postgresql"))

event.listen(mytable, "after_create", trigger.execute_if(dialect="postgresql"))
The ExecutableDDLElement.execute_if.dialect keyword also accepts a tuple of string dialect names:
event.listen(
    mytable, "after_create", trigger.execute_if(dialect=("postgresql", "mysql"))
)
event.listen(
    mytable, "before_drop", trigger.execute_if(dialect=("postgresql", "mysql"))
)
The ExecutableDDLElement.execute_if() method can also work against a callable function that will receive the database connection in use. In the example below, we use this to conditionally create a CHECK constraint, first looking within the PostgreSQL catalogs to see if it exists:
def should_create(ddl, target, connection, **kw):
    row = connection.execute(
        "select conname from pg_constraint where conname='%s'" % ddl.element.name
    ).scalar()
    return not bool(row)


def should_drop(ddl, target, connection, **kw):
    return not should_create(ddl, target, connection, **kw)


event.listen(
    users,
    "after_create",
    DDL(
        "ALTER TABLE users ADD CONSTRAINT "
        "cst_user_name_length CHECK (length(user_name) >= 8)"
    ).execute_if(callable_=should_create),
)
event.listen(
    users,
    "before_drop",
    DDL("ALTER TABLE users DROP CONSTRAINT cst_user_name_length").execute_if(
        callable_=should_drop
    ),
)

users.create(engine)
CREATE TABLE users (
    user_id SERIAL NOT NULL,
    user_name VARCHAR(40) NOT NULL,
    PRIMARY KEY (user_id)
)

SELECT conname FROM pg_constraint WHERE conname='cst_user_name_length'
ALTER TABLE users ADD CONSTRAINT cst_user_name_length  CHECK (length(user_name) >= 8)
users.drop(engine)
SELECT conname FROM pg_constraint WHERE conname='cst_user_name_length'
ALTER TABLE users DROP CONSTRAINT cst_user_name_length
DROP TABLE users
Using the built-in DDLElement Classes
The sqlalchemy.schema package contains SQL expression constructs that provide DDL expressions, all of which extend from the common base ExecutableDDLElement. For example, to produce a CREATE TABLE statement, one can use the CreateTable construct:
from sqlalchemy.schema import CreateTable

with engine.connect() as conn:
    conn.execute(CreateTable(mytable))
CREATE TABLE mytable (
    col1 INTEGER,
    col2 INTEGER,
    col3 INTEGER,
    col4 INTEGER,
    col5 INTEGER,
    col6 INTEGER
)
Above, the CreateTable construct works like any other expression construct (such as select(), table.insert(), etc.). All of SQLAlchemy’s DDL oriented constructs are subclasses of the ExecutableDDLElement base class; this is the base of all the objects corresponding to CREATE and DROP as well as ALTER, not only in SQLAlchemy but in Alembic Migrations as well. A full reference of available constructs is in DDL Expression Constructs API.
User-defined DDL constructs may also be created as subclasses of ExecutableDDLElement itself. The documentation in Custom SQL Constructs and Compilation Extension has several examples of this.
Controlling DDL Generation of Constraints and Indexes
Added in version 2.0.
While the previously mentioned ExecutableDDLElement.execute_if() method is useful for custom DDL classes which need to invoke conditionally, there is also a common need for elements that are typically related to a particular Table, namely constraints and indexes, to also be subject to “conditional” rules, such as an index that includes features that are specific to a particular backend such as PostgreSQL or SQL Server. For this use case, the Constraint.ddl_if() and Index.ddl_if() methods may be used against constructs such as CheckConstraint, UniqueConstraint and Index, accepting the same arguments as the ExecutableDDLElement.execute_if() method in order to control whether or not their DDL will be emitted in terms of their parent Table object. These methods may be used inline when creating the definition for a Table (or similarly, when using the __table_args__ collection in an ORM declarative mapping), such as:
from sqlalchemy import CheckConstraint, Index
from sqlalchemy import MetaData, Table, Column
from sqlalchemy import Integer, String

meta = MetaData()

my_table = Table(
    "my_table",
    meta,
    Column("id", Integer, primary_key=True),
    Column("num", Integer),
    Column("data", String),
    Index("my_pg_index", "data").ddl_if(dialect="postgresql"),
    CheckConstraint("num > 5").ddl_if(dialect="postgresql"),
)
In the above example, the Table construct refers to both an Index and a CheckConstraint construct, both which indicate .ddl_if(dialect="postgresql"), which indicates that these elements will be included in the CREATE TABLE sequence only against the PostgreSQL dialect. If we run meta.create_all() against the SQLite dialect, for example, neither construct will be included:
>>> from sqlalchemy import create_engine
>>> sqlite_engine = create_engine("sqlite+pysqlite://", echo=True)
>>> meta.create_all(sqlite_engine)
BEGIN (implicit)
PRAGMA main.table_info("my_table")
[raw sql] ()
PRAGMA temp.table_info("my_table")
[raw sql] ()

CREATE TABLE my_table (
    id INTEGER NOT NULL,
    num INTEGER,
    data VARCHAR,
    PRIMARY KEY (id)
)
However, if we run the same commands against a PostgreSQL database, we will see inline DDL for the CHECK constraint as well as a separate CREATE statement emitted for the index:
>>> from sqlalchemy import create_engine
>>> postgresql_engine = create_engine(
...     "postgresql+psycopg2://scott:tiger@localhost/test", echo=True
... )
>>> meta.create_all(postgresql_engine)
BEGIN (implicit)
select relname from pg_class c join pg_namespace n on n.oid=c.relnamespace where pg_catalog.pg_table_is_visible(c.oid) and relname=%(name)s
[generated in 0.00009s] {'name': 'my_table'}

CREATE TABLE my_table (
    id SERIAL NOT NULL,
    num INTEGER,
    data VARCHAR,
    PRIMARY KEY (id),
    CHECK (num > 5)
)
[no key 0.00007s] {}
CREATE INDEX my_pg_index ON my_table (data)
[no key 0.00013s] {}
COMMIT
The Constraint.ddl_if() and Index.ddl_if() methods create an event hook that may be consulted not just at DDL execution time, as is the behavior with ExecutableDDLElement.execute_if(), but also within the SQL compilation phase of the CreateTable object, which is responsible for rendering the CHECK (num > 5) DDL inline within the CREATE TABLE statement. As such, the event hook that is received by the ddl_if.callable_() parameter has a richer argument set present, including that there is a dialect keyword argument passed, as well as an instance of DDLCompiler via the compiler keyword argument for the “inline rendering” portion of the sequence. The bind argument is not present when the event is triggered within the DDLCompiler sequence, so a modern event hook that wishes to inspect the database versioning information would best use the given Dialect object, such as to test PostgreSQL versioning:
def only_pg_14(ddl_element, target, bind, dialect, **kw):
    return dialect.name == "postgresql" and dialect.server_version_info >= (14,)


my_table = Table(
    "my_table",
    meta,
    Column("id", Integer, primary_key=True),
    Column("num", Integer),
    Column("data", String),
    Index("my_pg_index", "data").ddl_if(callable_=only_pg_14),
)
See also
Constraint.ddl_if()
Index.ddl_if()
DDL Expression Constructs API
Object NameDescription_CreateDropBaseBase class for DDL constructs that represent CREATE and DROP or equivalents.AddConstraintRepresent an ALTER TABLE ADD CONSTRAINT statement.BaseDDLElementThe root of DDL constructs, including those that are sub-elements within the “create table” and other processes.CreateColumnRepresent a Column as rendered in a CREATE TABLE statement, via the CreateTable construct.CreateIndexRepresent a CREATE INDEX statement.CreateSchemaRepresent a CREATE SCHEMA statement.CreateSequenceRepresent a CREATE SEQUENCE statement.CreateTableRepresent a CREATE TABLE statement.DDLA literal DDL statement.DropConstraintRepresent an ALTER TABLE DROP CONSTRAINT statement.DropIndexRepresent a DROP INDEX statement.DropSchemaRepresent a DROP SCHEMA statement.DropSequenceRepresent a DROP SEQUENCE statement.DropTableRepresent a DROP TABLE statement.ExecutableDDLElementBase class for standalone executable DDL expression constructs.sort_tables(tables[, skip_fn, extra_dependencies])Sort a collection of Table objects based on dependency.sort_tables_and_constraints(tables[, filter_fn, extra_dependencies, _warn_for_cycles])Sort a collection of Table / ForeignKeyConstraint objects.function sqlalchemy.schema.sort_tables(tables: Iterable[TableClause], skip_fn: Callable[[ForeignKeyConstraint], bool] | None = None, extra_dependencies: typing_Sequence[Tuple[TableClause, TableClause]] | None = None) → List[Table]
Sort a collection of Table objects based on dependency.
This is a dependency-ordered sort which will emit Table objects such that they will follow their dependent Table objects. Tables are dependent on another based on the presence of ForeignKeyConstraint objects as well as explicit dependencies added by Table.add_is_dependent_on().
Warning
The sort_tables() function cannot by itself accommodate automatic resolution of dependency cycles between tables, which are usually caused by mutually dependent foreign key constraints. When these cycles are detected, the foreign keys of these tables are omitted from consideration in the sort. A warning is emitted when this condition occurs, which will be an exception raise in a future release. Tables which are not part of the cycle will still be returned in dependency order.
To resolve these cycles, the ForeignKeyConstraint.use_alter parameter may be applied to those constraints which create a cycle. Alternatively, the sort_tables_and_constraints() function will automatically return foreign key constraints in a separate collection when cycles are detected so that they may be applied to a schema separately.
Changed in version 1.3.17: - a warning is emitted when sort_tables() cannot perform a proper sort due to cyclical dependencies. This will be an exception in a future release. Additionally, the sort will continue to return other tables not involved in the cycle in dependency order which was not the case previously.
Parameters:
• tables – a sequence of Table objects.
• skip_fn – optional callable which will be passed a ForeignKeyConstraint object; if it returns True, this constraint will not be considered as a dependency. Note this is different from the same parameter in sort_tables_and_constraints(), which is instead passed the owning ForeignKeyConstraint object.
• extra_dependencies – a sequence of 2-tuples of tables which will also be considered as dependent on each other.
See also
sort_tables_and_constraints()
MetaData.sorted_tables - uses this function to sort
function sqlalchemy.schema.sort_tables_and_constraints(tables, filter_fn=None, extra_dependencies=None, _warn_for_cycles=False)
Sort a collection of Table / ForeignKeyConstraint objects.
This is a dependency-ordered sort which will emit tuples of (Table, [ForeignKeyConstraint, ...]) such that each Table follows its dependent Table objects. Remaining ForeignKeyConstraint objects that are separate due to dependency rules not satisfied by the sort are emitted afterwards as (None, [ForeignKeyConstraint ...]).
Tables are dependent on another based on the presence of ForeignKeyConstraint objects, explicit dependencies added by Table.add_is_dependent_on(), as well as dependencies stated here using the sort_tables_and_constraints.skip_fn and/or sort_tables_and_constraints.extra_dependencies parameters.
Parameters:
• tables – a sequence of Table objects.
• filter_fn – optional callable which will be passed a ForeignKeyConstraint object, and returns a value based on whether this constraint should definitely be included or excluded as an inline constraint, or neither. If it returns False, the constraint will definitely be included as a dependency that cannot be subject to ALTER; if True, it will only be included as an ALTER result at the end. Returning None means the constraint is included in the table-based result unless it is detected as part of a dependency cycle.
• extra_dependencies – a sequence of 2-tuples of tables which will also be considered as dependent on each other.
See also
sort_tables()
class sqlalchemy.schema.BaseDDLElement
The root of DDL constructs, including those that are sub-elements within the “create table” and other processes.
Added in version 2.0.
Class signature
class sqlalchemy.schema.BaseDDLElement (sqlalchemy.sql.expression.ClauseElement)
class sqlalchemy.schema.ExecutableDDLElement
Base class for standalone executable DDL expression constructs.
This class is the base for the general purpose DDL class, as well as the various create/drop clause constructs such as CreateTable, DropTable, AddConstraint, etc.
Changed in version 2.0: ExecutableDDLElement is renamed from DDLElement, which still exists for backwards compatibility.
ExecutableDDLElement integrates closely with SQLAlchemy events, introduced in Events. An instance of one is itself an event receiving callable:
event.listen(
    users,
    "after_create",
    AddConstraint(constraint).execute_if(dialect="postgresql"),
)
See also
DDL
DDLEvents
Events
Controlling DDL Sequences
Members
__call__(), against(), execute_if()
Class signature
class sqlalchemy.schema.ExecutableDDLElement (sqlalchemy.sql.roles.DDLRole, sqlalchemy.sql.expression.Executable, sqlalchemy.schema.BaseDDLElement)
method sqlalchemy.schema.ExecutableDDLElement.__call__(target, bind, **kw)
Execute the DDL as a ddl_listener.
method sqlalchemy.schema.ExecutableDDLElement.against(target: SchemaItem) → Self
Return a copy of this ExecutableDDLElement which will include the given target.
This essentially applies the given item to the .target attribute of the returned ExecutableDDLElement object. This target is then usable by event handlers and compilation routines in order to provide services such as tokenization of a DDL string in terms of a particular Table.
When a ExecutableDDLElement object is established as an event handler for the DDLEvents.before_create() or DDLEvents.after_create() events, and the event then occurs for a given target such as a Constraint or Table, that target is established with a copy of the ExecutableDDLElement object using this method, which then proceeds to the ExecutableDDLElement.execute() method in order to invoke the actual DDL instruction.
Parameters:
target – a SchemaItem that will be the subject of a DDL operation.
Returns:
a copy of this ExecutableDDLElement with the .target attribute assigned to the given SchemaItem.
See also
DDL - uses tokenization against the “target” when processing the DDL string.
method sqlalchemy.schema.ExecutableDDLElement.execute_if(dialect: str | None = None, callable_: DDLIfCallable | None = None, state: Any | None = None) → Self
Return a callable that will execute this ExecutableDDLElement conditionally within an event handler.
Used to provide a wrapper for event listening:
event.listen(
    metadata,
    "before_create",
    DDL("my_ddl").execute_if(dialect="postgresql"),
)
Parameters:
• dialect – 
May be a string or tuple of strings. If a string, it will be compared to the name of the executing database dialect:
DDL("something").execute_if(dialect="postgresql")
If a tuple, specifies multiple dialect names:
DDL("something").execute_if(dialect=("postgresql", "mysql"))
• 
• callable_ – 
A callable, which will be invoked with three positional arguments as well as optional keyword arguments:
ddl:
This DDL element.
target:
The Table or MetaData object which is the target of this event. May be None if the DDL is executed explicitly.
bind:
The Connection being used for DDL execution. May be None if this construct is being created inline within a table, in which case compiler will be present.
tables:
Optional keyword argument - a list of Table objects which are to be created/ dropped within a MetaData.create_all() or drop_all() method call.
dialect:
keyword argument, but always present - the Dialect involved in the operation.
compiler:
keyword argument. Will be None for an engine level DDL invocation, but will refer to a DDLCompiler if this DDL element is being created inline within a table.
state:
Optional keyword argument - will be the state argument passed to this function.
checkfirst:
Keyword argument, will be True if the ‘checkfirst’ flag was set during the call to create(), create_all(), drop(), drop_all().
If the callable returns a True value, the DDL statement will be executed.
• state – any value which will be passed to the callable_ as the state keyword argument.
See also
SchemaItem.ddl_if()
DDLEvents
Events
class sqlalchemy.schema.DDL
A literal DDL statement.
Specifies literal SQL DDL to be executed by the database. DDL objects function as DDL event listeners, and can be subscribed to those events listed in DDLEvents, using either Table or MetaData objects as targets. Basic templating support allows a single DDL instance to handle repetitive tasks for multiple tables.
Examples:
from sqlalchemy import event, DDL

tbl = Table("users", metadata, Column("uid", Integer))
event.listen(tbl, "before_create", DDL("DROP TRIGGER users_trigger"))

spow = DDL("ALTER TABLE %(table)s SET secretpowers TRUE")
event.listen(tbl, "after_create", spow.execute_if(dialect="somedb"))

drop_spow = DDL("ALTER TABLE users SET secretpowers FALSE")
connection.execute(drop_spow)
When operating on Table events, the following statement string substitutions are available:
%(table)s  - the Table name, with any required quoting applied
%(schema)s - the schema name, with any required quoting applied
%(fullname)s - the Table name including schema, quoted if needed
The DDL’s “context”, if any, will be combined with the standard substitutions noted above. Keys present in the context will override the standard substitutions.
Members
__init__()
Class signature
class sqlalchemy.schema.DDL (sqlalchemy.schema.ExecutableDDLElement)
method sqlalchemy.schema.DDL.__init__(statement, context=None)
Create a DDL statement.
Parameters:
• statement – 
A string or unicode string to be executed. Statements will be processed with Python’s string formatting operator using a fixed set of string substitutions, as well as additional substitutions provided by the optional DDL.context parameter.
A literal ‘%’ in a statement must be escaped as ‘%%’.
SQL bind parameters are not available in DDL statements.
• context – Optional dictionary, defaults to None. These values will be available for use in string substitutions on the DDL statement.
See also
DDLEvents
Events
class sqlalchemy.schema._CreateDropBase
Base class for DDL constructs that represent CREATE and DROP or equivalents.
The common theme of _CreateDropBase is a single element attribute which refers to the element to be created or dropped.
Class signature
class sqlalchemy.schema._CreateDropBase (sqlalchemy.schema.ExecutableDDLElement, typing.Generic)
class sqlalchemy.schema.CreateTable
Represent a CREATE TABLE statement.
Members
__init__()
Class signature
class sqlalchemy.schema.CreateTable (sqlalchemy.schema._CreateBase)
method sqlalchemy.schema.CreateTable.__init__(element: Table, include_foreign_key_constraints: typing_Sequence[ForeignKeyConstraint] | None = None, if_not_exists: bool = False) → None
Create a CreateTable construct.
Parameters:
• element – a Table that’s the subject of the CREATE
• on – See the description for ‘on’ in DDL.
• include_foreign_key_constraints – optional sequence of ForeignKeyConstraint objects that will be included inline within the CREATE construct; if omitted, all foreign key constraints that do not specify use_alter=True are included.
• if_not_exists – 
if True, an IF NOT EXISTS operator will be applied to the construct.
Added in version 1.4.0b2.
class sqlalchemy.schema.DropTable
Represent a DROP TABLE statement.
Members
__init__()
Class signature
class sqlalchemy.schema.DropTable (sqlalchemy.schema._DropBase)
method sqlalchemy.schema.DropTable.__init__(element: Table, if_exists: bool = False) → None
Create a DropTable construct.
Parameters:
• element – a Table that’s the subject of the DROP.
• on – See the description for ‘on’ in DDL.
• if_exists – 
if True, an IF EXISTS operator will be applied to the construct.
Added in version 1.4.0b2.
class sqlalchemy.schema.CreateColumn
Represent a Column as rendered in a CREATE TABLE statement, via the CreateTable construct.
This is provided to support custom column DDL within the generation of CREATE TABLE statements, by using the compiler extension documented in Custom SQL Constructs and Compilation Extension to extend CreateColumn.
Typical integration is to examine the incoming Column object, and to redirect compilation if a particular flag or condition is found:
from sqlalchemy import schema
from sqlalchemy.ext.compiler import compiles


@compiles(schema.CreateColumn)
def compile(element, compiler, **kw):
    column = element.element

    if "special" not in column.info:
        return compiler.visit_create_column(element, **kw)

    text = "%s SPECIAL DIRECTIVE %s" % (
        column.name,
        compiler.type_compiler.process(column.type),
    )
    default = compiler.get_column_default_string(column)
    if default is not None:
        text += " DEFAULT " + default

    if not column.nullable:
        text += " NOT NULL"

    if column.constraints:
        text += " ".join(
            compiler.process(const) for const in column.constraints
        )
    return text
The above construct can be applied to a Table as follows:
from sqlalchemy import Table, Metadata, Column, Integer, String
from sqlalchemy import schema

metadata = MetaData()

table = Table(
    "mytable",
    MetaData(),
    Column("x", Integer, info={"special": True}, primary_key=True),
    Column("y", String(50)),
    Column("z", String(20), info={"special": True}),
)

metadata.create_all(conn)
Above, the directives we’ve added to the Column.info collection will be detected by our custom compilation scheme:
CREATE TABLE mytable (
        x SPECIAL DIRECTIVE INTEGER NOT NULL,
        y VARCHAR(50),
        z SPECIAL DIRECTIVE VARCHAR(20),
    PRIMARY KEY (x)
)
The CreateColumn construct can also be used to skip certain columns when producing a CREATE TABLE. This is accomplished by creating a compilation rule that conditionally returns None. This is essentially how to produce the same effect as using the system=True argument on Column, which marks a column as an implicitly-present “system” column.
For example, suppose we wish to produce a Table which skips rendering of the PostgreSQL xmin column against the PostgreSQL backend, but on other backends does render it, in anticipation of a triggered rule. A conditional compilation rule could skip this name only on PostgreSQL:
from sqlalchemy.schema import CreateColumn


@compiles(CreateColumn, "postgresql")
def skip_xmin(element, compiler, **kw):
    if element.element.name == "xmin":
        return None
    else:
        return compiler.visit_create_column(element, **kw)


my_table = Table(
    "mytable",
    metadata,
    Column("id", Integer, primary_key=True),
    Column("xmin", Integer),
)
Above, a CreateTable construct will generate a CREATE TABLE which only includes the id column in the string; the xmin column will be omitted, but only against the PostgreSQL backend.
Class signature
class sqlalchemy.schema.CreateColumn (sqlalchemy.schema.BaseDDLElement)
class sqlalchemy.schema.CreateSequence
Represent a CREATE SEQUENCE statement.
Class signature
class sqlalchemy.schema.CreateSequence (sqlalchemy.schema._CreateBase)
class sqlalchemy.schema.DropSequence
Represent a DROP SEQUENCE statement.
Class signature
class sqlalchemy.schema.DropSequence (sqlalchemy.schema._DropBase)
class sqlalchemy.schema.CreateIndex
Represent a CREATE INDEX statement.
Members
__init__()
Class signature
class sqlalchemy.schema.CreateIndex (sqlalchemy.schema._CreateBase)
method sqlalchemy.schema.CreateIndex.__init__(element: Index, if_not_exists: bool = False) → None
Create a Createindex construct.
Parameters:
• element – a Index that’s the subject of the CREATE.
• if_not_exists – 
if True, an IF NOT EXISTS operator will be applied to the construct.
Added in version 1.4.0b2.
class sqlalchemy.schema.DropIndex
Represent a DROP INDEX statement.
Members
__init__()
Class signature
class sqlalchemy.schema.DropIndex (sqlalchemy.schema._DropBase)
method sqlalchemy.schema.DropIndex.__init__(element: Index, if_exists: bool = False) → None
Create a DropIndex construct.
Parameters:
• element – a Index that’s the subject of the DROP.
• if_exists – 
if True, an IF EXISTS operator will be applied to the construct.
Added in version 1.4.0b2.
class sqlalchemy.schema.AddConstraint
Represent an ALTER TABLE ADD CONSTRAINT statement.
Members
__init__()
Class signature
class sqlalchemy.schema.AddConstraint (sqlalchemy.schema._CreateBase)
method sqlalchemy.schema.AddConstraint.__init__(element: Constraint, *, isolate_from_table: bool = True) → None
Construct a new AddConstraint construct.
Parameters:
• element – a Constraint object
• isolate_from_table – 
optional boolean, defaults to True. Has the effect of the incoming constraint being isolated from being included in a CREATE TABLE sequence when associated with a Table.
Added in version 2.0.39: - added AddConstraint.isolate_from_table, defaulting to True. Previously, the behavior of this parameter was implicitly turned on in all cases.
class sqlalchemy.schema.DropConstraint
Represent an ALTER TABLE DROP CONSTRAINT statement.
Members
__init__()
Class signature
class sqlalchemy.schema.DropConstraint (sqlalchemy.schema._DropBase)
method sqlalchemy.schema.DropConstraint.__init__(element: Constraint, *, cascade: bool = False, if_exists: bool = False, isolate_from_table: bool = True, **kw: Any) → None
Construct a new DropConstraint construct.
Parameters:
• element – a Constraint object
• cascade – optional boolean, indicates backend-specific “CASCADE CONSTRAINT” directive should be rendered if available
• if_exists – optional boolean, indicates backend-specific “IF EXISTS” directive should be rendered if available
• isolate_from_table – 
optional boolean, defaults to True. Has the effect of the incoming constraint being isolated from being included in a CREATE TABLE sequence when associated with a Table.
Added in version 2.0.39: - added DropConstraint.isolate_from_table, defaulting to True. Previously, the behavior of this parameter was implicitly turned on in all cases.
class sqlalchemy.schema.CreateSchema
Represent a CREATE SCHEMA statement.
The argument here is the string name of the schema.
Members
__init__()
Class signature
class sqlalchemy.schema.CreateSchema (sqlalchemy.schema._CreateBase)
method sqlalchemy.schema.CreateSchema.__init__(name: str, if_not_exists: bool = False) → None
Create a new CreateSchema construct.
class sqlalchemy.schema.DropSchema
Represent a DROP SCHEMA statement.
The argument here is the string name of the schema.
Members
__init__()
Class signature
class sqlalchemy.schema.DropSchema (sqlalchemy.schema._DropBase)
method sqlalchemy.schema.DropSchema.__init__(name: str, cascade: bool = False, if_exists: bool = False) → None
Create a new DropSchema construct.


SQL Datatype Objects
• The Type Hierarchy
o The “CamelCase” datatypes
o The “UPPERCASE” datatypes
o Backend-specific “UPPERCASE” datatypes
o Using “UPPERCASE” and Backend-specific types for multiple backends
o Generic “CamelCase” Types
• BigInteger
• Boolean
• Date
• DateTime
• Enum
• Double
• Float
• Integer
• Interval
• LargeBinary
• MatchType
• Numeric
• PickleType
• SchemaType
• SmallInteger
• String
• Text
• Time
• Unicode
• UnicodeText
• Uuid
o SQL Standard and Multiple Vendor “UPPERCASE” Types
• ARRAY
• BIGINT
• BINARY
• BLOB
• BOOLEAN
• CHAR
• CLOB
• DATE
• DATETIME
• DECIMAL
• DOUBLE
• DOUBLE_PRECISION
• FLOAT
• INT
• JSON
• INTEGER
• NCHAR
• NVARCHAR
• NUMERIC
• REAL
• SMALLINT
• TEXT
• TIME
• TIMESTAMP
• UUID
• VARBINARY
• VARCHAR
• Custom Types
o Overriding Type Compilation
o Augmenting Existing Types
• TypeDecorator
o TypeDecorator Recipes
• Coercing Encoded Strings to Unicode
• Rounding Numerics
• Store Timezone Aware Timestamps as Timezone Naive UTC
• Backend-agnostic GUID Type
• Marshal JSON Strings
o Applying SQL-level Bind/Result Processing
o Redefining and Creating New Operators
o Creating New Types
• UserDefinedType
o Working with Custom Types and Reflection
• Base Type API
o TypeEngine
• TypeEngine.Comparator
• TypeEngine.adapt()
• TypeEngine.as_generic()
• TypeEngine.bind_expression()
• TypeEngine.bind_processor()
• TypeEngine.coerce_compared_value()
• TypeEngine.column_expression()
• TypeEngine.comparator_factory
• TypeEngine.compare_values()
• TypeEngine.compile()
• TypeEngine.dialect_impl()
• TypeEngine.evaluates_none()
• TypeEngine.get_dbapi_type()
• TypeEngine.hashable
• TypeEngine.literal_processor()
• TypeEngine.python_type
• TypeEngine.render_bind_cast
• TypeEngine.render_literal_cast
• TypeEngine.result_processor()
• TypeEngine.should_evaluate_none
• TypeEngine.sort_key_function
• TypeEngine.with_variant()
o Concatenable
• Concatenable.Comparator
• Concatenable.comparator_factory
o Indexable
• Indexable.Comparator
• Indexable.comparator_factory
o NullType
o ExternalType
• ExternalType.cache_ok
o Variant
• Variant.with_variant()


The Type Hierarchy
SQLAlchemy provides abstractions for most common database data types, as well as several techniques for customization of datatypes.
Database types are represented using Python classes, all of which ultimately extend from the base type class known as TypeEngine. There are two general categories of datatypes, each of which express themselves within the typing hierarchy in different ways. The category used by an individual datatype class can be identified based on the use of two different naming conventions, which are “CamelCase” and “UPPERCASE”.
See also
Setting up MetaData with Table objects - in the SQLAlchemy Unified Tutorial. Illustrates the most rudimental use of TypeEngine type objects to define Table metadata and introduces the concept of type objects in tutorial form.
The “CamelCase” datatypes
The rudimental types have “CamelCase” names such as String, Numeric, Integer, and DateTime. All of the immediate subclasses of TypeEngine are “CamelCase” types. The “CamelCase” types are to the greatest degree possible database agnostic, meaning they can all be used on any database backend where they will behave in such a way as appropriate to that backend in order to produce the desired behavior.
An example of a straightforward “CamelCase” datatype is String. On most backends, using this datatype in a table specification will correspond to the VARCHAR database type being used on the target backend, delivering string values to and from the database, as in the example below:
from sqlalchemy import MetaData
from sqlalchemy import Table, Column, Integer, String

metadata_obj = MetaData()

user = Table(
    "user",
    metadata_obj,
    Column("user_name", String, primary_key=True),
    Column("email_address", String(60)),
)
When using a particular TypeEngine class in a Table definition or in any SQL expression overall, if no arguments are required it may be passed as the class itself, that is, without instantiating it with (). If arguments are needed, such as the length argument of 60 in the "email_address" column above, the type may be instantiated.
Another “CamelCase” datatype that expresses more backend-specific behavior is the Boolean datatype. Unlike String, which represents a string datatype that all databases have, not every backend has a real “boolean” datatype; some make use of integers or BIT values 0 and 1, some have boolean literal constants true and false while others dont. For this datatype, Boolean may render BOOLEAN on a backend such as PostgreSQL, BIT on the MySQL backend and SMALLINT on Oracle Database. As data is sent and received from the database using this type, based on the dialect in use it may be interpreting Python numeric or boolean values.
The typical SQLAlchemy application will likely wish to use primarily “CamelCase” types in the general case, as they will generally provide the best basic behavior and be automatically portable to all backends.
Reference for the general set of “CamelCase” datatypes is below at Generic “CamelCase” Types.
The “UPPERCASE” datatypes
In contrast to the “CamelCase” types are the “UPPERCASE” datatypes. These datatypes are always inherited from a particular “CamelCase” datatype, and always represent an exact datatype. When using an “UPPERCASE” datatype, the name of the type is always rendered exactly as given, without regard for whether or not the current backend supports it. Therefore the use of “UPPERCASE” types in a SQLAlchemy application indicates that specific datatypes are required, which then implies that the application would normally, without additional steps taken, be limited to those backends which use the type exactly as given. Examples of UPPERCASE types include VARCHAR, NUMERIC, INTEGER, and TIMESTAMP, which inherit directly from the previously mentioned “CamelCase” types String, Numeric, Integer, and DateTime, respectively.
The “UPPERCASE” datatypes that are part of sqlalchemy.types are common SQL types that typically expect to be available on at least two backends if not more.
Reference for the general set of “UPPERCASE” datatypes is below at SQL Standard and Multiple Vendor “UPPERCASE” Types.
Backend-specific “UPPERCASE” datatypes
Most databases also have their own datatypes that are either fully specific to those databases, or add additional arguments that are specific to those databases. For these datatypes, specific SQLAlchemy dialects provide backend-specific “UPPERCASE” datatypes, for a SQL type that has no analogue on other backends. Examples of backend-specific uppercase datatypes include PostgreSQL’s JSONB, SQL Server’s IMAGE and MySQL’s TINYTEXT.
Specific backends may also include “UPPERCASE” datatypes that extend the arguments available from that same “UPPERCASE” datatype as found in the sqlalchemy.types module. An example is when creating a MySQL string datatype, one might want to specify MySQL-specific arguments such as charset or national, which are available from the MySQL version of VARCHAR as the MySQL-only parameters VARCHAR.charset and VARCHAR.national.
API documentation for backend-specific types are in the dialect-specific documentation, listed at Dialects.
Using “UPPERCASE” and Backend-specific types for multiple backends
Reviewing the presence of “UPPERCASE” and “CamelCase” types leads to the natural use case of how to make use of “UPPERCASE” datatypes for backend-specific options, but only when that backend is in use. To tie together the database-agnostic “CamelCase” and backend-specific “UPPERCASE” systems, one makes use of the TypeEngine.with_variant() method in order to compose types together to work with specific behaviors on specific backends.
Such as, to use the String datatype, but when running on MySQL to make use of the VARCHAR.charset parameter of VARCHAR when the table is created on MySQL or MariaDB, TypeEngine.with_variant() may be used as below:
from sqlalchemy import MetaData
from sqlalchemy import Table, Column, Integer, String
from sqlalchemy.dialects.mysql import VARCHAR

metadata_obj = MetaData()

user = Table(
    "user",
    metadata_obj,
    Column("user_name", String(100), primary_key=True),
    Column(
        "bio",
        String(255).with_variant(VARCHAR(255, charset="utf8"), "mysql", "mariadb"),
    ),
)
In the above table definition, the "bio" column will have string-behaviors on all backends. On most backends it will render in DDL as VARCHAR. However on MySQL and MariaDB (indicated by database URLs that start with mysql or mariadb), it will render as VARCHAR(255) CHARACTER SET utf8.
See also
TypeEngine.with_variant() - additional usage examples and notes
Generic “CamelCase” Types
Generic types specify a column that can read, write and store a particular type of Python data. SQLAlchemy will choose the best database column type available on the target database when issuing a CREATE TABLE statement. For complete control over which column type is emitted in CREATE TABLE, such as VARCHAR see SQL Standard and Multiple Vendor “UPPERCASE” Types and the other sections of this chapter.
Object NameDescriptionBigIntegerA type for bigger int integers.BooleanA bool datatype.DateA type for datetime.date() objects.DateTimeA type for datetime.datetime() objects.DoubleA type for double FLOAT floating point types.EnumGeneric Enum Type.FloatType representing floating point types, such as FLOAT or REAL.IntegerA type for int integers.IntervalA type for datetime.timedelta() objects.LargeBinaryA type for large binary byte data.MatchTypeRefers to the return type of the MATCH operator.NumericBase for non-integer numeric types, such as NUMERIC, FLOAT, DECIMAL, and other variants.PickleTypeHolds Python objects, which are serialized using pickle.SchemaTypeAdd capabilities to a type which allow for schema-level DDL to be associated with a type.SmallIntegerA type for smaller int integers.StringThe base for all string and character types.TextA variably sized string type.TimeA type for datetime.time() objects.UnicodeA variable length Unicode string type.UnicodeTextAn unbounded-length Unicode string type.UuidRepresent a database agnostic UUID datatype.class sqlalchemy.types.BigInteger
A type for bigger int integers.
Typically generates a BIGINT in DDL, and otherwise acts like a normal Integer on the Python side.
Class signature
class sqlalchemy.types.BigInteger (sqlalchemy.types.Integer)
class sqlalchemy.types.Boolean
A bool datatype.
Boolean typically uses BOOLEAN or SMALLINT on the DDL side, and on the Python side deals in True or False.
The Boolean datatype currently has two levels of assertion that the values persisted are simple true/false values. For all backends, only the Python values None, True, False, 1 or 0 are accepted as parameter values. For those backends that don’t support a “native boolean” datatype, an option exists to also create a CHECK constraint on the target column
Changed in version 1.2: the Boolean datatype now asserts that incoming Python values are already in pure boolean form.
Members
__init__(), bind_processor(), literal_processor(), python_type, result_processor()
Class signature
class sqlalchemy.types.Boolean (sqlalchemy.types.SchemaType, sqlalchemy.types.Emulated, sqlalchemy.types.TypeEngine)
method sqlalchemy.types.Boolean.__init__(create_constraint: bool = False, name: str | None = None, _create_events: bool = True, _adapted_from: SchemaType | None = None)
Construct a Boolean.
Parameters:
• create_constraint – 
defaults to False. If the boolean is generated as an int/smallint, also create a CHECK constraint on the table that ensures 1 or 0 as a value.
Note
it is strongly recommended that the CHECK constraint have an explicit name in order to support schema-management concerns. This can be established either by setting the Boolean.name parameter or by setting up an appropriate naming convention; see Configuring Constraint Naming Conventions for background.
Changed in version 1.4: - this flag now defaults to False, meaning no CHECK constraint is generated for a non-native enumerated type.
• name – if a CHECK constraint is generated, specify the name of the constraint.
method sqlalchemy.types.Boolean.bind_processor(dialect)
Return a conversion function for processing bind values.
Returns a callable which will receive a bind parameter value as the sole positional argument and will return a value to send to the DB-API.
If processing is not necessary, the method should return None.
Tip
This method is only called relative to a dialect specific type object, which is often private to a dialect in use and is not the same type object as the public facing one, which means it’s not feasible to subclass a TypeEngine class in order to provide an alternate TypeEngine.bind_processor() method, unless subclassing the UserDefinedType class explicitly.
To provide alternate behavior for TypeEngine.bind_processor(), implement a TypeDecorator class and provide an implementation of TypeDecorator.process_bind_param().
See also
Augmenting Existing Types
Parameters:
dialect – Dialect instance in use.
method sqlalchemy.types.Boolean.literal_processor(dialect)
Return a conversion function for processing literal values that are to be rendered directly without using binds.
This function is used when the compiler makes use of the “literal_binds” flag, typically used in DDL generation as well as in certain scenarios where backends don’t accept bound parameters.
Returns a callable which will receive a literal Python value as the sole positional argument and will return a string representation to be rendered in a SQL statement.
Tip
This method is only called relative to a dialect specific type object, which is often private to a dialect in use and is not the same type object as the public facing one, which means it’s not feasible to subclass a TypeEngine class in order to provide an alternate TypeEngine.literal_processor() method, unless subclassing the UserDefinedType class explicitly.
To provide alternate behavior for TypeEngine.literal_processor(), implement a TypeDecorator class and provide an implementation of TypeDecorator.process_literal_param().
See also
Augmenting Existing Types
attribute sqlalchemy.types.Boolean.python_type
method sqlalchemy.types.Boolean.result_processor(dialect, coltype)
Return a conversion function for processing result row values.
Returns a callable which will receive a result row column value as the sole positional argument and will return a value to return to the user.
If processing is not necessary, the method should return None.
Tip
This method is only called relative to a dialect specific type object, which is often private to a dialect in use and is not the same type object as the public facing one, which means it’s not feasible to subclass a TypeEngine class in order to provide an alternate TypeEngine.result_processor() method, unless subclassing the UserDefinedType class explicitly.
To provide alternate behavior for TypeEngine.result_processor(), implement a TypeDecorator class and provide an implementation of TypeDecorator.process_result_value().
See also
Augmenting Existing Types
Parameters:
• dialect – Dialect instance in use.
• coltype – DBAPI coltype argument received in cursor.description.
class sqlalchemy.types.Date
A type for datetime.date() objects.
Members
get_dbapi_type(), literal_processor(), python_type
Class signature
class sqlalchemy.types.Date (sqlalchemy.types._RenderISO8601NoT, sqlalchemy.types.HasExpressionLookup, sqlalchemy.types.TypeEngine)
method sqlalchemy.types.Date.get_dbapi_type(dbapi)
Return the corresponding type object from the underlying DB-API, if any.
This can be useful for calling setinputsizes(), for example.
method sqlalchemy.types.Date.literal_processor(dialect)
Return a conversion function for processing literal values that are to be rendered directly without using binds.
This function is used when the compiler makes use of the “literal_binds” flag, typically used in DDL generation as well as in certain scenarios where backends don’t accept bound parameters.
Returns a callable which will receive a literal Python value as the sole positional argument and will return a string representation to be rendered in a SQL statement.
Tip
This method is only called relative to a dialect specific type object, which is often private to a dialect in use and is not the same type object as the public facing one, which means it’s not feasible to subclass a TypeEngine class in order to provide an alternate TypeEngine.literal_processor() method, unless subclassing the UserDefinedType class explicitly.
To provide alternate behavior for TypeEngine.literal_processor(), implement a TypeDecorator class and provide an implementation of TypeDecorator.process_literal_param().
See also
Augmenting Existing Types
attribute sqlalchemy.types.Date.python_type
class sqlalchemy.types.DateTime
A type for datetime.datetime() objects.
Date and time types return objects from the Python datetime module. Most DBAPIs have built in support for the datetime module, with the noted exception of SQLite. In the case of SQLite, date and time types are stored as strings which are then converted back to datetime objects when rows are returned.
For the time representation within the datetime type, some backends include additional options, such as timezone support and fractional seconds support. For fractional seconds, use the dialect-specific datatype, such as TIME. For timezone support, use at least the TIMESTAMP datatype, if not the dialect-specific datatype object.
Members
__init__(), get_dbapi_type(), literal_processor(), python_type
Class signature
class sqlalchemy.types.DateTime (sqlalchemy.types._RenderISO8601NoT, sqlalchemy.types.HasExpressionLookup, sqlalchemy.types.TypeEngine)
method sqlalchemy.types.DateTime.__init__(timezone: bool = False)
Construct a new DateTime.
Parameters:
timezone – boolean. Indicates that the datetime type should enable timezone support, if available on the base date/time-holding type only. It is recommended to make use of the TIMESTAMP datatype directly when using this flag, as some databases include separate generic date/time-holding types distinct from the timezone-capable TIMESTAMP datatype, such as Oracle Database.
method sqlalchemy.types.DateTime.get_dbapi_type(dbapi)
Return the corresponding type object from the underlying DB-API, if any.
This can be useful for calling setinputsizes(), for example.
method sqlalchemy.types.DateTime.literal_processor(dialect)
Return a conversion function for processing literal values that are to be rendered directly without using binds.
This function is used when the compiler makes use of the “literal_binds” flag, typically used in DDL generation as well as in certain scenarios where backends don’t accept bound parameters.
Returns a callable which will receive a literal Python value as the sole positional argument and will return a string representation to be rendered in a SQL statement.
Tip
This method is only called relative to a dialect specific type object, which is often private to a dialect in use and is not the same type object as the public facing one, which means it’s not feasible to subclass a TypeEngine class in order to provide an alternate TypeEngine.literal_processor() method, unless subclassing the UserDefinedType class explicitly.
To provide alternate behavior for TypeEngine.literal_processor(), implement a TypeDecorator class and provide an implementation of TypeDecorator.process_literal_param().
See also
Augmenting Existing Types
attribute sqlalchemy.types.DateTime.python_type
class sqlalchemy.types.Enum
Generic Enum Type.
The Enum type provides a set of possible string values which the column is constrained towards.
The Enum type will make use of the backend’s native “ENUM” type if one is available; otherwise, it uses a VARCHAR datatype. An option also exists to automatically produce a CHECK constraint when the VARCHAR (so called “non-native”) variant is produced; see the Enum.create_constraint flag.
The Enum type also provides in-Python validation of string values during both read and write operations. When reading a value from the database in a result set, the string value is always checked against the list of possible values and a LookupError is raised if no match is found. When passing a value to the database as a plain string within a SQL statement, if the Enum.validate_strings parameter is set to True, a LookupError is raised for any string value that’s not located in the given list of possible values; note that this impacts usage of LIKE expressions with enumerated values (an unusual use case).
The source of enumerated values may be a list of string values, or alternatively a PEP-435-compliant enumerated class. For the purposes of the Enum datatype, this class need only provide a __members__ method.
When using an enumerated class, the enumerated objects are used both for input and output, rather than strings as is the case with a plain-string enumerated type:
import enum
from sqlalchemy import Enum


class MyEnum(enum.Enum):
    one = 1
    two = 2
    three = 3


t = Table("data", MetaData(), Column("value", Enum(MyEnum)))

connection.execute(t.insert(), {"value": MyEnum.two})
assert connection.scalar(t.select()) is MyEnum.two
Above, the string names of each element, e.g. “one”, “two”, “three”, are persisted to the database; the values of the Python Enum, here indicated as integers, are not used; the value of each enum can therefore be any kind of Python object whether or not it is persistable.
In order to persist the values and not the names, the Enum.values_callable parameter may be used. The value of this parameter is a user-supplied callable, which is intended to be used with a PEP-435-compliant enumerated class and returns a list of string values to be persisted. For a simple enumeration that uses string values, a callable such as lambda x: [e.value for e in x] is sufficient.
See also
Using Python Enum or pep-586 Literal types in the type map - background on using the Enum datatype with the ORM’s ORM Annotated Declarative feature.
ENUM - PostgreSQL-specific type, which has additional functionality.
ENUM - MySQL-specific type
Members
__init__(), create(), drop()
Class signature
class sqlalchemy.types.Enum (sqlalchemy.types.String, sqlalchemy.types.SchemaType, sqlalchemy.types.Emulated, sqlalchemy.types.TypeEngine)
method sqlalchemy.types.Enum.__init__(*enums: str | Type[Enum], **kw: Any) → None
Construct an enum.
Keyword arguments which don’t apply to a specific backend are ignored by that backend.
Parameters:
• *enums – either exactly one PEP-435 compliant enumerated type or one or more string labels.
• create_constraint – 
defaults to False. When creating a non-native enumerated type, also build a CHECK constraint on the database against the valid values.
Note
it is strongly recommended that the CHECK constraint have an explicit name in order to support schema-management concerns. This can be established either by setting the Enum.name parameter or by setting up an appropriate naming convention; see Configuring Constraint Naming Conventions for background.
Changed in version 1.4: - this flag now defaults to False, meaning no CHECK constraint is generated for a non-native enumerated type.
• metadata – 
Associate this type directly with a MetaData object. For types that exist on the target database as an independent schema construct (PostgreSQL), this type will be created and dropped within create_all() and drop_all() operations. If the type is not associated with any MetaData object, it will associate itself with each Table in which it is used, and will be created when any of those individual tables are created, after a check is performed for its existence. The type is only dropped when drop_all() is called for that Table object’s metadata, however.
The value of the MetaData.schema parameter of the MetaData object, if set, will be used as the default value of the Enum.schema on this object if an explicit value is not otherwise supplied.
Changed in version 1.4.12: Enum inherits the MetaData.schema parameter of the MetaData object if present, when passed using the Enum.metadata parameter.
• name – The name of this type. This is required for PostgreSQL and any future supported database which requires an explicitly named type, or an explicitly named constraint in order to generate the type and/or a table that uses it. If a PEP-435 enumerated class was used, its name (converted to lower case) is used by default.
• native_enum – Use the database’s native ENUM type when available. Defaults to True. When False, uses VARCHAR + check constraint for all backends. When False, the VARCHAR length can be controlled with Enum.length; currently “length” is ignored if native_enum=True.
• length – 
Allows specifying a custom length for the VARCHAR when a non-native enumeration datatype is used. By default it uses the length of the longest value.
Changed in version 2.0.0: The Enum.length parameter is used unconditionally for VARCHAR rendering regardless of the Enum.native_enum parameter, for those backends where VARCHAR is used for enumerated datatypes.
• schema – 
Schema name of this type. For types that exist on the target database as an independent schema construct (PostgreSQL), this parameter specifies the named schema in which the type is present.
If not present, the schema name will be taken from the MetaData collection if passed as Enum.metadata, for a MetaData that includes the MetaData.schema parameter.
Changed in version 1.4.12: Enum inherits the MetaData.schema parameter of the MetaData object if present, when passed using the Enum.metadata parameter.
Otherwise, if the Enum.inherit_schema flag is set to True, the schema will be inherited from the associated Table object if any; when Enum.inherit_schema is at its default of False, the owning table’s schema is not used.
• quote – Set explicit quoting preferences for the type’s name.
• inherit_schema – When True, the “schema” from the owning Table will be copied to the “schema” attribute of this Enum, replacing whatever value was passed for the schema attribute. This also takes effect when using the Table.to_metadata() operation.
• validate_strings – when True, string values that are being passed to the database in a SQL statement will be checked for validity against the list of enumerated values. Unrecognized values will result in a LookupError being raised.
• values_callable – 
A callable which will be passed the PEP-435 compliant enumerated type, which should then return a list of string values to be persisted. This allows for alternate usages such as using the string value of an enum to be persisted to the database instead of its name. The callable must return the values to be persisted in the same order as iterating through the Enum’s __member__ attribute. For example lambda x: [i.value for i in x].
Added in version 1.2.3.
• sort_key_function – 
a Python callable which may be used as the “key” argument in the Python sorted() built-in. The SQLAlchemy ORM requires that primary key columns which are mapped must be sortable in some way. When using an unsortable enumeration object such as a Python 3 Enum object, this parameter may be used to set a default sort key function for the objects. By default, the database value of the enumeration is used as the sorting function.
Added in version 1.3.8.
• omit_aliases – 
A boolean that when true will remove aliases from pep 435 enums. defaults to True.
Changed in version 2.0: This parameter now defaults to True.
method sqlalchemy.types.Enum.create(bind: _CreateDropBind, checkfirst: bool = False) → None
inherited from the SchemaType.create() method of SchemaType
Issue CREATE DDL for this type, if applicable.
method sqlalchemy.types.Enum.drop(bind: _CreateDropBind, checkfirst: bool = False) → None
inherited from the SchemaType.drop() method of SchemaType
Issue DROP DDL for this type, if applicable.
class sqlalchemy.types.Double
A type for double FLOAT floating point types.
Typically generates a DOUBLE or DOUBLE_PRECISION in DDL, and otherwise acts like a normal Float on the Python side.
Added in version 2.0.
Class signature
class sqlalchemy.types.Double (sqlalchemy.types.Float)
class sqlalchemy.types.Float
Type representing floating point types, such as FLOAT or REAL.
This type returns Python float objects by default, unless the Float.asdecimal flag is set to True, in which case they are coerced to decimal.Decimal objects.
When a Float.precision is not provided in a Float type some backend may compile this type as an 8 bytes / 64 bit float datatype. To use a 4 bytes / 32 bit float datatype a precision <= 24 can usually be provided or the REAL type can be used. This is known to be the case in the PostgreSQL and MSSQL dialects that render the type as FLOAT that’s in both an alias of DOUBLE PRECISION. Other third party dialects may have similar behavior.
Members
__init__(), result_processor()
Class signature
class sqlalchemy.types.Float (sqlalchemy.types.Numeric)
method sqlalchemy.types.Float.__init__(precision: int | None = None, asdecimal: bool = False, decimal_return_scale: int | None = None)
Construct a Float.
Parameters:
• precision – 
the numeric precision for use in DDL CREATE TABLE. Backends should attempt to ensure this precision indicates a number of digits for the generic Float datatype.
Note
For the Oracle Database backend, the Float.precision parameter is not accepted when rendering DDL, as Oracle Database does not support float precision specified as a number of decimal places. Instead, use the Oracle Database-specific FLOAT datatype and specify the FLOAT.binary_precision parameter. This is new in version 2.0 of SQLAlchemy.
To create a database agnostic Float that separately specifies binary precision for Oracle Database, use TypeEngine.with_variant() as follows:
from sqlalchemy import Column
from sqlalchemy import Float
from sqlalchemy.dialects import oracle

Column(
    "float_data",
    Float(5).with_variant(oracle.FLOAT(binary_precision=16), "oracle"),
)
• 
• asdecimal – the same flag as that of Numeric, but defaults to False. Note that setting this flag to True results in floating point conversion.
• decimal_return_scale – Default scale to use when converting from floats to Python decimals. Floating point values will typically be much longer due to decimal inaccuracy, and most floating point database types don’t have a notion of “scale”, so by default the float type looks for the first ten decimal places when converting. Specifying this value will override that length. Note that the MySQL float types, which do include “scale”, will use “scale” as the default for decimal_return_scale, if not otherwise specified.
method sqlalchemy.types.Float.result_processor(dialect, coltype)
Return a conversion function for processing result row values.
Returns a callable which will receive a result row column value as the sole positional argument and will return a value to return to the user.
If processing is not necessary, the method should return None.
Tip
This method is only called relative to a dialect specific type object, which is often private to a dialect in use and is not the same type object as the public facing one, which means it’s not feasible to subclass a TypeEngine class in order to provide an alternate TypeEngine.result_processor() method, unless subclassing the UserDefinedType class explicitly.
To provide alternate behavior for TypeEngine.result_processor(), implement a TypeDecorator class and provide an implementation of TypeDecorator.process_result_value().
See also
Augmenting Existing Types
Parameters:
• dialect – Dialect instance in use.
• coltype – DBAPI coltype argument received in cursor.description.
class sqlalchemy.types.Integer
A type for int integers.
Members
get_dbapi_type(), literal_processor(), python_type
Class signature
class sqlalchemy.types.Integer (sqlalchemy.types.HasExpressionLookup, sqlalchemy.types.TypeEngine)
method sqlalchemy.types.Integer.get_dbapi_type(dbapi)
Return the corresponding type object from the underlying DB-API, if any.
This can be useful for calling setinputsizes(), for example.
method sqlalchemy.types.Integer.literal_processor(dialect)
Return a conversion function for processing literal values that are to be rendered directly without using binds.
This function is used when the compiler makes use of the “literal_binds” flag, typically used in DDL generation as well as in certain scenarios where backends don’t accept bound parameters.
Returns a callable which will receive a literal Python value as the sole positional argument and will return a string representation to be rendered in a SQL statement.
Tip
This method is only called relative to a dialect specific type object, which is often private to a dialect in use and is not the same type object as the public facing one, which means it’s not feasible to subclass a TypeEngine class in order to provide an alternate TypeEngine.literal_processor() method, unless subclassing the UserDefinedType class explicitly.
To provide alternate behavior for TypeEngine.literal_processor(), implement a TypeDecorator class and provide an implementation of TypeDecorator.process_literal_param().
See also
Augmenting Existing Types
attribute sqlalchemy.types.Integer.python_type
class sqlalchemy.types.Interval
A type for datetime.timedelta() objects.
The Interval type deals with datetime.timedelta objects. In PostgreSQL and Oracle Database, the native INTERVAL type is used; for others, the value is stored as a date which is relative to the “epoch” (Jan. 1, 1970).
Note that the Interval type does not currently provide date arithmetic operations on platforms which do not support interval types natively. Such operations usually require transformation of both sides of the expression (such as, conversion of both sides into integer epoch values first) which currently is a manual procedure (such as via expression.func).
Members
__init__(), adapt_to_emulated(), bind_processor(), cache_ok, coerce_compared_value(), comparator_factory, impl, python_type, result_processor()
Class signature
class sqlalchemy.types.Interval (sqlalchemy.types.Emulated, sqlalchemy.types._AbstractInterval, sqlalchemy.types.TypeDecorator)
class Comparator
Class signature
class sqlalchemy.types.Interval.Comparator (sqlalchemy.types.Comparator, sqlalchemy.types.Comparator)
method sqlalchemy.types.Interval.__init__(native: bool = True, second_precision: int | None = None, day_precision: int | None = None)
Construct an Interval object.
Parameters:
• native – when True, use the actual INTERVAL type provided by the database, if supported (currently PostgreSQL, Oracle Database). Otherwise, represent the interval data as an epoch value regardless.
• second_precision – For native interval types which support a “fractional seconds precision” parameter, i.e. Oracle Database and PostgreSQL
• day_precision – for native interval types which support a “day precision” parameter, i.e. Oracle Database.
method sqlalchemy.types.Interval.adapt_to_emulated(impltype, **kw)
Given an impl class, adapt this type to the impl assuming “emulated”.
The impl should also be an “emulated” version of this type, most likely the same class as this type itself.
e.g.: sqltypes.Enum adapts to the Enum class.
method sqlalchemy.types.Interval.bind_processor(dialect: Dialect) → _BindProcessorType[dt.timedelta]
Return a conversion function for processing bind values.
Returns a callable which will receive a bind parameter value as the sole positional argument and will return a value to send to the DB-API.
If processing is not necessary, the method should return None.
Tip
This method is only called relative to a dialect specific type object, which is often private to a dialect in use and is not the same type object as the public facing one, which means it’s not feasible to subclass a TypeEngine class in order to provide an alternate TypeEngine.bind_processor() method, unless subclassing the UserDefinedType class explicitly.
To provide alternate behavior for TypeEngine.bind_processor(), implement a TypeDecorator class and provide an implementation of TypeDecorator.process_bind_param().
See also
Augmenting Existing Types
Parameters:
dialect – Dialect instance in use.
attribute sqlalchemy.types.Interval.cache_ok: bool | None = True
Indicate if statements using this ExternalType are “safe to cache”.
The default value None will emit a warning and then not allow caching of a statement which includes this type. Set to False to disable statements using this type from being cached at all without a warning. When set to True, the object’s class and selected elements from its state will be used as part of the cache key. For example, using a TypeDecorator:
class MyType(TypeDecorator):
    impl = String

    cache_ok = True

    def __init__(self, choices):
        self.choices = tuple(choices)
        self.internal_only = True
The cache key for the above type would be equivalent to:
>>> MyType(["a", "b", "c"])._static_cache_key
(<class '__main__.MyType'>, ('choices', ('a', 'b', 'c')))
The caching scheme will extract attributes from the type that correspond to the names of parameters in the __init__() method. Above, the “choices” attribute becomes part of the cache key but “internal_only” does not, because there is no parameter named “internal_only”.
The requirements for cacheable elements is that they are hashable and also that they indicate the same SQL rendered for expressions using this type every time for a given cache value.
To accommodate for datatypes that refer to unhashable structures such as dictionaries, sets and lists, these objects can be made “cacheable” by assigning hashable structures to the attributes whose names correspond with the names of the arguments. For example, a datatype which accepts a dictionary of lookup values may publish this as a sorted series of tuples. Given a previously un-cacheable type as:
class LookupType(UserDefinedType):
    """a custom type that accepts a dictionary as a parameter.

    this is the non-cacheable version, as "self.lookup" is not
    hashable.

    """

    def __init__(self, lookup):
        self.lookup = lookup

    def get_col_spec(self, **kw):
        return "VARCHAR(255)"

    def bind_processor(self, dialect): ...  # works with "self.lookup" ...
Where “lookup” is a dictionary. The type will not be able to generate a cache key:
>>> type_ = LookupType({"a": 10, "b": 20})
>>> type_._static_cache_key
<stdin>:1: SAWarning: UserDefinedType LookupType({'a': 10, 'b': 20}) will not
produce a cache key because the ``cache_ok`` flag is not set to True.
Set this flag to True if this type object's state is safe to use
in a cache key, or False to disable this warning.
symbol('no_cache')
If we did set up such a cache key, it wouldn’t be usable. We would get a tuple structure that contains a dictionary inside of it, which cannot itself be used as a key in a “cache dictionary” such as SQLAlchemy’s statement cache, since Python dictionaries aren’t hashable:
>>> # set cache_ok = True
>>> type_.cache_ok = True

>>> # this is the cache key it would generate
>>> key = type_._static_cache_key
>>> key
(<class '__main__.LookupType'>, ('lookup', {'a': 10, 'b': 20}))

>>> # however this key is not hashable, will fail when used with
>>> # SQLAlchemy statement cache
>>> some_cache = {key: "some sql value"}
Traceback (most recent call last): File "<stdin>", line 1,
in <module> TypeError: unhashable type: 'dict'
The type may be made cacheable by assigning a sorted tuple of tuples to the “.lookup” attribute:
class LookupType(UserDefinedType):
    """a custom type that accepts a dictionary as a parameter.

    The dictionary is stored both as itself in a private variable,
    and published in a public variable as a sorted tuple of tuples,
    which is hashable and will also return the same value for any
    two equivalent dictionaries.  Note it assumes the keys and
    values of the dictionary are themselves hashable.

    """

    cache_ok = True

    def __init__(self, lookup):
        self._lookup = lookup

        # assume keys/values of "lookup" are hashable; otherwise
        # they would also need to be converted in some way here
        self.lookup = tuple((key, lookup[key]) for key in sorted(lookup))

    def get_col_spec(self, **kw):
        return "VARCHAR(255)"

    def bind_processor(self, dialect): ...  # works with "self._lookup" ...
Where above, the cache key for LookupType({"a": 10, "b": 20}) will be:
>>> LookupType({"a": 10, "b": 20})._static_cache_key
(<class '__main__.LookupType'>, ('lookup', (('a', 10), ('b', 20))))
Added in version 1.4.14: - added the cache_ok flag to allow some configurability of caching for TypeDecorator classes.
Added in version 1.4.28: - added the ExternalType mixin which generalizes the cache_ok flag to both the TypeDecorator and UserDefinedType classes.
See also
SQL Compilation Caching
method sqlalchemy.types.Interval.coerce_compared_value(op, value)
Suggest a type for a ‘coerced’ Python value in an expression.
Given an operator and value, gives the type a chance to return a type which the value should be coerced into.
The default behavior here is conservative; if the right-hand side is already coerced into a SQL type based on its Python type, it is usually left alone.
End-user functionality extension here should generally be via TypeDecorator, which provides more liberal behavior in that it defaults to coercing the other side of the expression into this type, thus applying special Python conversions above and beyond those needed by the DBAPI to both ides. It also provides the public method TypeDecorator.coerce_compared_value() which is intended for end-user customization of this behavior.
attribute sqlalchemy.types.Interval.comparator_factory
alias of Comparator
attribute sqlalchemy.types.Interval.impl
alias of DateTime
attribute sqlalchemy.types.Interval.python_type
method sqlalchemy.types.Interval.result_processor(dialect: Dialect, coltype: Any) → _ResultProcessorType[dt.timedelta]
Return a conversion function for processing result row values.
Returns a callable which will receive a result row column value as the sole positional argument and will return a value to return to the user.
If processing is not necessary, the method should return None.
Tip
This method is only called relative to a dialect specific type object, which is often private to a dialect in use and is not the same type object as the public facing one, which means it’s not feasible to subclass a TypeEngine class in order to provide an alternate TypeEngine.result_processor() method, unless subclassing the UserDefinedType class explicitly.
To provide alternate behavior for TypeEngine.result_processor(), implement a TypeDecorator class and provide an implementation of TypeDecorator.process_result_value().
See also
Augmenting Existing Types
Parameters:
• dialect – Dialect instance in use.
• coltype – DBAPI coltype argument received in cursor.description.
class sqlalchemy.types.LargeBinary
A type for large binary byte data.
The LargeBinary type corresponds to a large and/or unlengthed binary type for the target platform, such as BLOB on MySQL and BYTEA for PostgreSQL. It also handles the necessary conversions for the DBAPI.
Members
__init__()
Class signature
class sqlalchemy.types.LargeBinary (sqlalchemy.types._Binary)
method sqlalchemy.types.LargeBinary.__init__(length: int | None = None)
Construct a LargeBinary type.
Parameters:
length – optional, a length for the column for use in DDL statements, for those binary types that accept a length, such as the MySQL BLOB type.
class sqlalchemy.types.MatchType
Refers to the return type of the MATCH operator.
As the ColumnOperators.match() is probably the most open-ended operator in generic SQLAlchemy Core, we can’t assume the return type at SQL evaluation time, as MySQL returns a floating point, not a boolean, and other backends might do something different. So this type acts as a placeholder, currently subclassing Boolean. The type allows dialects to inject result-processing functionality if needed, and on MySQL will return floating-point values.
Class signature
class sqlalchemy.types.MatchType (sqlalchemy.types.Boolean)
class sqlalchemy.types.Numeric
Base for non-integer numeric types, such as NUMERIC, FLOAT, DECIMAL, and other variants.
The Numeric datatype when used directly will render DDL corresponding to precision numerics if available, such as NUMERIC(precision, scale). The Float subclass will attempt to render a floating-point datatype such as FLOAT(precision).
Numeric returns Python decimal.Decimal objects by default, based on the default value of True for the Numeric.asdecimal parameter. If this parameter is set to False, returned values are coerced to Python float objects.
The Float subtype, being more specific to floating point, defaults the Float.asdecimal flag to False so that the default Python datatype is float.
Note
When using a Numeric datatype against a database type that returns Python floating point values to the driver, the accuracy of the decimal conversion indicated by Numeric.asdecimal may be limited. The behavior of specific numeric/floating point datatypes is a product of the SQL datatype in use, the Python DBAPI in use, as well as strategies that may be present within the SQLAlchemy dialect in use. Users requiring specific precision/ scale are encouraged to experiment with the available datatypes in order to determine the best results.
Members
__init__(), bind_processor(), get_dbapi_type(), literal_processor(), python_type, result_processor()
Class signature
class sqlalchemy.types.Numeric (sqlalchemy.types.HasExpressionLookup, sqlalchemy.types.TypeEngine)
method sqlalchemy.types.Numeric.__init__(precision: int | None = None, scale: int | None = None, decimal_return_scale: int | None = None, asdecimal: bool = True)
Construct a Numeric.
Parameters:
• precision – the numeric precision for use in DDL CREATE TABLE.
• scale – the numeric scale for use in DDL CREATE TABLE.
• asdecimal – default True. Return whether or not values should be sent as Python Decimal objects, or as floats. Different DBAPIs send one or the other based on datatypes - the Numeric type will ensure that return values are one or the other across DBAPIs consistently.
• decimal_return_scale – Default scale to use when converting from floats to Python decimals. Floating point values will typically be much longer due to decimal inaccuracy, and most floating point database types don’t have a notion of “scale”, so by default the float type looks for the first ten decimal places when converting. Specifying this value will override that length. Types which do include an explicit “.scale” value, such as the base Numeric as well as the MySQL float types, will use the value of “.scale” as the default for decimal_return_scale, if not otherwise specified.
When using the Numeric type, care should be taken to ensure that the asdecimal setting is appropriate for the DBAPI in use - when Numeric applies a conversion from Decimal->float or float-> Decimal, this conversion incurs an additional performance overhead for all result columns received.
DBAPIs that return Decimal natively (e.g. psycopg2) will have better accuracy and higher performance with a setting of True, as the native translation to Decimal reduces the amount of floating- point issues at play, and the Numeric type itself doesn’t need to apply any further conversions. However, another DBAPI which returns floats natively will incur an additional conversion overhead, and is still subject to floating point data loss - in which case asdecimal=False will at least remove the extra conversion overhead.
method sqlalchemy.types.Numeric.bind_processor(dialect)
Return a conversion function for processing bind values.
Returns a callable which will receive a bind parameter value as the sole positional argument and will return a value to send to the DB-API.
If processing is not necessary, the method should return None.
Tip
This method is only called relative to a dialect specific type object, which is often private to a dialect in use and is not the same type object as the public facing one, which means it’s not feasible to subclass a TypeEngine class in order to provide an alternate TypeEngine.bind_processor() method, unless subclassing the UserDefinedType class explicitly.
To provide alternate behavior for TypeEngine.bind_processor(), implement a TypeDecorator class and provide an implementation of TypeDecorator.process_bind_param().
See also
Augmenting Existing Types
Parameters:
dialect – Dialect instance in use.
method sqlalchemy.types.Numeric.get_dbapi_type(dbapi)
Return the corresponding type object from the underlying DB-API, if any.
This can be useful for calling setinputsizes(), for example.
method sqlalchemy.types.Numeric.literal_processor(dialect)
Return a conversion function for processing literal values that are to be rendered directly without using binds.
This function is used when the compiler makes use of the “literal_binds” flag, typically used in DDL generation as well as in certain scenarios where backends don’t accept bound parameters.
Returns a callable which will receive a literal Python value as the sole positional argument and will return a string representation to be rendered in a SQL statement.
Tip
This method is only called relative to a dialect specific type object, which is often private to a dialect in use and is not the same type object as the public facing one, which means it’s not feasible to subclass a TypeEngine class in order to provide an alternate TypeEngine.literal_processor() method, unless subclassing the UserDefinedType class explicitly.
To provide alternate behavior for TypeEngine.literal_processor(), implement a TypeDecorator class and provide an implementation of TypeDecorator.process_literal_param().
See also
Augmenting Existing Types
attribute sqlalchemy.types.Numeric.python_type
method sqlalchemy.types.Numeric.result_processor(dialect, coltype)
Return a conversion function for processing result row values.
Returns a callable which will receive a result row column value as the sole positional argument and will return a value to return to the user.
If processing is not necessary, the method should return None.
Tip
This method is only called relative to a dialect specific type object, which is often private to a dialect in use and is not the same type object as the public facing one, which means it’s not feasible to subclass a TypeEngine class in order to provide an alternate TypeEngine.result_processor() method, unless subclassing the UserDefinedType class explicitly.
To provide alternate behavior for TypeEngine.result_processor(), implement a TypeDecorator class and provide an implementation of TypeDecorator.process_result_value().
See also
Augmenting Existing Types
Parameters:
• dialect – Dialect instance in use.
• coltype – DBAPI coltype argument received in cursor.description.
class sqlalchemy.types.PickleType
Holds Python objects, which are serialized using pickle.
PickleType builds upon the Binary type to apply Python’s pickle.dumps() to incoming objects, and pickle.loads() on the way out, allowing any pickleable Python object to be stored as a serialized binary field.
To allow ORM change events to propagate for elements associated with PickleType, see Mutation Tracking.
Members
__init__(), bind_processor(), cache_ok, compare_values(), impl, result_processor()
Class signature
class sqlalchemy.types.PickleType (sqlalchemy.types.TypeDecorator)
method sqlalchemy.types.PickleType.__init__(protocol: int = 5, pickler: Any = None, comparator: Callable[[Any, Any], bool] | None = None, impl: _TypeEngineArgument[Any] | None = None)
Construct a PickleType.
Parameters:
• protocol – defaults to pickle.HIGHEST_PROTOCOL.
• pickler – defaults to pickle. May be any object with pickle-compatible dumps and loads methods.
• comparator – a 2-arg callable predicate used to compare values of this type. If left as None, the Python “equals” operator is used to compare values.
• impl – 
A binary-storing TypeEngine class or instance to use in place of the default LargeBinary. For example the :class: _mysql.LONGBLOB class may be more effective when using MySQL.
Added in version 1.4.20.
method sqlalchemy.types.PickleType.bind_processor(dialect)
Provide a bound value processing function for the given Dialect.
This is the method that fulfills the TypeEngine contract for bound value conversion which normally occurs via the TypeEngine.bind_processor() method.
Note
User-defined subclasses of TypeDecorator should not implement this method, and should instead implement TypeDecorator.process_bind_param() so that the “inner” processing provided by the implementing type is maintained.
Parameters:
dialect – Dialect instance in use.
attribute sqlalchemy.types.PickleType.cache_ok: bool | None = True
Indicate if statements using this ExternalType are “safe to cache”.
The default value None will emit a warning and then not allow caching of a statement which includes this type. Set to False to disable statements using this type from being cached at all without a warning. When set to True, the object’s class and selected elements from its state will be used as part of the cache key. For example, using a TypeDecorator:
class MyType(TypeDecorator):
    impl = String

    cache_ok = True

    def __init__(self, choices):
        self.choices = tuple(choices)
        self.internal_only = True
The cache key for the above type would be equivalent to:
>>> MyType(["a", "b", "c"])._static_cache_key
(<class '__main__.MyType'>, ('choices', ('a', 'b', 'c')))
The caching scheme will extract attributes from the type that correspond to the names of parameters in the __init__() method. Above, the “choices” attribute becomes part of the cache key but “internal_only” does not, because there is no parameter named “internal_only”.
The requirements for cacheable elements is that they are hashable and also that they indicate the same SQL rendered for expressions using this type every time for a given cache value.
To accommodate for datatypes that refer to unhashable structures such as dictionaries, sets and lists, these objects can be made “cacheable” by assigning hashable structures to the attributes whose names correspond with the names of the arguments. For example, a datatype which accepts a dictionary of lookup values may publish this as a sorted series of tuples. Given a previously un-cacheable type as:
class LookupType(UserDefinedType):
    """a custom type that accepts a dictionary as a parameter.

    this is the non-cacheable version, as "self.lookup" is not
    hashable.

    """

    def __init__(self, lookup):
        self.lookup = lookup

    def get_col_spec(self, **kw):
        return "VARCHAR(255)"

    def bind_processor(self, dialect): ...  # works with "self.lookup" ...
Where “lookup” is a dictionary. The type will not be able to generate a cache key:
>>> type_ = LookupType({"a": 10, "b": 20})
>>> type_._static_cache_key
<stdin>:1: SAWarning: UserDefinedType LookupType({'a': 10, 'b': 20}) will not
produce a cache key because the ``cache_ok`` flag is not set to True.
Set this flag to True if this type object's state is safe to use
in a cache key, or False to disable this warning.
symbol('no_cache')
If we did set up such a cache key, it wouldn’t be usable. We would get a tuple structure that contains a dictionary inside of it, which cannot itself be used as a key in a “cache dictionary” such as SQLAlchemy’s statement cache, since Python dictionaries aren’t hashable:
>>> # set cache_ok = True
>>> type_.cache_ok = True

>>> # this is the cache key it would generate
>>> key = type_._static_cache_key
>>> key
(<class '__main__.LookupType'>, ('lookup', {'a': 10, 'b': 20}))

>>> # however this key is not hashable, will fail when used with
>>> # SQLAlchemy statement cache
>>> some_cache = {key: "some sql value"}
Traceback (most recent call last): File "<stdin>", line 1,
in <module> TypeError: unhashable type: 'dict'
The type may be made cacheable by assigning a sorted tuple of tuples to the “.lookup” attribute:
class LookupType(UserDefinedType):
    """a custom type that accepts a dictionary as a parameter.

    The dictionary is stored both as itself in a private variable,
    and published in a public variable as a sorted tuple of tuples,
    which is hashable and will also return the same value for any
    two equivalent dictionaries.  Note it assumes the keys and
    values of the dictionary are themselves hashable.

    """

    cache_ok = True

    def __init__(self, lookup):
        self._lookup = lookup

        # assume keys/values of "lookup" are hashable; otherwise
        # they would also need to be converted in some way here
        self.lookup = tuple((key, lookup[key]) for key in sorted(lookup))

    def get_col_spec(self, **kw):
        return "VARCHAR(255)"

    def bind_processor(self, dialect): ...  # works with "self._lookup" ...
Where above, the cache key for LookupType({"a": 10, "b": 20}) will be:
>>> LookupType({"a": 10, "b": 20})._static_cache_key
(<class '__main__.LookupType'>, ('lookup', (('a', 10), ('b', 20))))
Added in version 1.4.14: - added the cache_ok flag to allow some configurability of caching for TypeDecorator classes.
Added in version 1.4.28: - added the ExternalType mixin which generalizes the cache_ok flag to both the TypeDecorator and UserDefinedType classes.
See also
SQL Compilation Caching
method sqlalchemy.types.PickleType.compare_values(x, y)
Given two values, compare them for equality.
By default this calls upon TypeEngine.compare_values() of the underlying “impl”, which in turn usually uses the Python equals operator ==.
This function is used by the ORM to compare an original-loaded value with an intercepted “changed” value, to determine if a net change has occurred.
attribute sqlalchemy.types.PickleType.impl
alias of LargeBinary
method sqlalchemy.types.PickleType.result_processor(dialect, coltype)
Provide a result value processing function for the given Dialect.
This is the method that fulfills the TypeEngine contract for bound value conversion which normally occurs via the TypeEngine.result_processor() method.
Note
User-defined subclasses of TypeDecorator should not implement this method, and should instead implement TypeDecorator.process_result_value() so that the “inner” processing provided by the implementing type is maintained.
Parameters:
• dialect – Dialect instance in use.
• coltype – A SQLAlchemy data type
class sqlalchemy.types.SchemaType
Add capabilities to a type which allow for schema-level DDL to be associated with a type.
Supports types that must be explicitly created/dropped (i.e. PG ENUM type) as well as types that are complimented by table or schema level constraints, triggers, and other rules.
SchemaType classes can also be targets for the DDLEvents.before_parent_attach() and DDLEvents.after_parent_attach() events, where the events fire off surrounding the association of the type object with a parent Column.
See also
Enum
Boolean
Members
adapt(), copy(), create(), drop(), name
Class signature
class sqlalchemy.types.SchemaType (sqlalchemy.sql.expression.SchemaEventTarget, sqlalchemy.types.TypeEngineMixin)
method sqlalchemy.types.SchemaType.adapt(cls: Type[TypeEngine | TypeEngineMixin], **kw: Any) → TypeEngine
method sqlalchemy.types.SchemaType.copy(**kw)
method sqlalchemy.types.SchemaType.create(bind: _CreateDropBind, checkfirst: bool = False) → None
Issue CREATE DDL for this type, if applicable.
method sqlalchemy.types.SchemaType.drop(bind: _CreateDropBind, checkfirst: bool = False) → None
Issue DROP DDL for this type, if applicable.
attribute sqlalchemy.types.SchemaType.name: str | None
class sqlalchemy.types.SmallInteger
A type for smaller int integers.
Typically generates a SMALLINT in DDL, and otherwise acts like a normal Integer on the Python side.
Class signature
class sqlalchemy.types.SmallInteger (sqlalchemy.types.Integer)
class sqlalchemy.types.String
The base for all string and character types.
In SQL, corresponds to VARCHAR.
The length field is usually required when the String type is used within a CREATE TABLE statement, as VARCHAR requires a length on most databases.
Members
__init__(), bind_processor(), get_dbapi_type(), literal_processor(), python_type, result_processor()
Class signature
class sqlalchemy.types.String (sqlalchemy.types.Concatenable, sqlalchemy.types.TypeEngine)
method sqlalchemy.types.String.__init__(length: int | None = None, collation: str | None = None)
Create a string-holding type.
Parameters:
• length – optional, a length for the column for use in DDL and CAST expressions. May be safely omitted if no CREATE TABLE will be issued. Certain databases may require a length for use in DDL, and will raise an exception when the CREATE TABLE DDL is issued if a VARCHAR with no length is included. Whether the value is interpreted as bytes or characters is database specific.
• collation – 
Optional, a column-level collation for use in DDL and CAST expressions. Renders using the COLLATE keyword supported by SQLite, MySQL, and PostgreSQL. E.g.:
>>> from sqlalchemy import cast, select, String
>>> print(select(cast("some string", String(collation="utf8"))))
SELECT CAST(:param_1 AS VARCHAR COLLATE utf8) AS anon_1
• Note
In most cases, the Unicode or UnicodeText datatypes should be used for a Column that expects to store non-ascii data. These datatypes will ensure that the correct types are used on the database.
method sqlalchemy.types.String.bind_processor(dialect: Dialect) → _BindProcessorType[str] | None
Return a conversion function for processing bind values.
Returns a callable which will receive a bind parameter value as the sole positional argument and will return a value to send to the DB-API.
If processing is not necessary, the method should return None.
Tip
This method is only called relative to a dialect specific type object, which is often private to a dialect in use and is not the same type object as the public facing one, which means it’s not feasible to subclass a TypeEngine class in order to provide an alternate TypeEngine.bind_processor() method, unless subclassing the UserDefinedType class explicitly.
To provide alternate behavior for TypeEngine.bind_processor(), implement a TypeDecorator class and provide an implementation of TypeDecorator.process_bind_param().
See also
Augmenting Existing Types
Parameters:
dialect – Dialect instance in use.
method sqlalchemy.types.String.get_dbapi_type(dbapi)
Return the corresponding type object from the underlying DB-API, if any.
This can be useful for calling setinputsizes(), for example.
method sqlalchemy.types.String.literal_processor(dialect)
Return a conversion function for processing literal values that are to be rendered directly without using binds.
This function is used when the compiler makes use of the “literal_binds” flag, typically used in DDL generation as well as in certain scenarios where backends don’t accept bound parameters.
Returns a callable which will receive a literal Python value as the sole positional argument and will return a string representation to be rendered in a SQL statement.
Tip
This method is only called relative to a dialect specific type object, which is often private to a dialect in use and is not the same type object as the public facing one, which means it’s not feasible to subclass a TypeEngine class in order to provide an alternate TypeEngine.literal_processor() method, unless subclassing the UserDefinedType class explicitly.
To provide alternate behavior for TypeEngine.literal_processor(), implement a TypeDecorator class and provide an implementation of TypeDecorator.process_literal_param().
See also
Augmenting Existing Types
attribute sqlalchemy.types.String.python_type
method sqlalchemy.types.String.result_processor(dialect: Dialect, coltype: object) → _ResultProcessorType[str] | None
Return a conversion function for processing result row values.
Returns a callable which will receive a result row column value as the sole positional argument and will return a value to return to the user.
If processing is not necessary, the method should return None.
Tip
This method is only called relative to a dialect specific type object, which is often private to a dialect in use and is not the same type object as the public facing one, which means it’s not feasible to subclass a TypeEngine class in order to provide an alternate TypeEngine.result_processor() method, unless subclassing the UserDefinedType class explicitly.
To provide alternate behavior for TypeEngine.result_processor(), implement a TypeDecorator class and provide an implementation of TypeDecorator.process_result_value().
See also
Augmenting Existing Types
Parameters:
• dialect – Dialect instance in use.
• coltype – DBAPI coltype argument received in cursor.description.
class sqlalchemy.types.Text
A variably sized string type.
In SQL, usually corresponds to CLOB or TEXT. In general, TEXT objects do not have a length; while some databases will accept a length argument here, it will be rejected by others.
Class signature
class sqlalchemy.types.Text (sqlalchemy.types.String)
class sqlalchemy.types.Time
A type for datetime.time() objects.
Members
get_dbapi_type(), literal_processor(), python_type
Class signature
class sqlalchemy.types.Time (sqlalchemy.types._RenderISO8601NoT, sqlalchemy.types.HasExpressionLookup, sqlalchemy.types.TypeEngine)
method sqlalchemy.types.Time.get_dbapi_type(dbapi)
Return the corresponding type object from the underlying DB-API, if any.
This can be useful for calling setinputsizes(), for example.
method sqlalchemy.types.Time.literal_processor(dialect)
Return a conversion function for processing literal values that are to be rendered directly without using binds.
This function is used when the compiler makes use of the “literal_binds” flag, typically used in DDL generation as well as in certain scenarios where backends don’t accept bound parameters.
Returns a callable which will receive a literal Python value as the sole positional argument and will return a string representation to be rendered in a SQL statement.
Tip
This method is only called relative to a dialect specific type object, which is often private to a dialect in use and is not the same type object as the public facing one, which means it’s not feasible to subclass a TypeEngine class in order to provide an alternate TypeEngine.literal_processor() method, unless subclassing the UserDefinedType class explicitly.
To provide alternate behavior for TypeEngine.literal_processor(), implement a TypeDecorator class and provide an implementation of TypeDecorator.process_literal_param().
See also
Augmenting Existing Types
attribute sqlalchemy.types.Time.python_type
class sqlalchemy.types.Unicode
A variable length Unicode string type.
The Unicode type is a String subclass that assumes input and output strings that may contain non-ASCII characters, and for some backends implies an underlying column type that is explicitly supporting of non-ASCII data, such as NVARCHAR on Oracle Database and SQL Server. This will impact the output of CREATE TABLE statements and CAST functions at the dialect level.
The character encoding used by the Unicode type that is used to transmit and receive data to the database is usually determined by the DBAPI itself. All modern DBAPIs accommodate non-ASCII strings but may have different methods of managing database encodings; if necessary, this encoding should be configured as detailed in the notes for the target DBAPI in the Dialects section.
In modern SQLAlchemy, use of the Unicode datatype does not imply any encoding/decoding behavior within SQLAlchemy itself. In Python 3, all string objects are inherently Unicode capable, and SQLAlchemy does not produce bytestring objects nor does it accommodate a DBAPI that does not return Python Unicode objects in result sets for string values.
Warning
Some database backends, particularly SQL Server with pyodbc, are known to have undesirable behaviors regarding data that is noted as being of NVARCHAR type as opposed to VARCHAR, including datatype mismatch errors and non-use of indexes. See the section on DialectEvents.do_setinputsizes() for background on working around unicode character issues for backends like SQL Server with pyodbc as well as cx_Oracle.
See also
UnicodeText - unlengthed textual counterpart to Unicode.
DialectEvents.do_setinputsizes()
Class signature
class sqlalchemy.types.Unicode (sqlalchemy.types.String)
class sqlalchemy.types.UnicodeText
An unbounded-length Unicode string type.
See Unicode for details on the unicode behavior of this object.
Like Unicode, usage the UnicodeText type implies a unicode-capable type being used on the backend, such as NCLOB, NTEXT.
Class signature
class sqlalchemy.types.UnicodeText (sqlalchemy.types.Text)
class sqlalchemy.types.Uuid
Represent a database agnostic UUID datatype.
For backends that have no “native” UUID datatype, the value will make use of CHAR(32) and store the UUID as a 32-character alphanumeric hex string.
For backends which are known to support UUID directly or a similar uuid-storing datatype such as SQL Server’s UNIQUEIDENTIFIER, a “native” mode enabled by default allows these types will be used on those backends.
In its default mode of use, the Uuid datatype expects Python uuid objects, from the Python uuid module:
import uuid

from sqlalchemy import Uuid
from sqlalchemy import Table, Column, MetaData, String


metadata_obj = MetaData()

t = Table(
    "t",
    metadata_obj,
    Column("uuid_data", Uuid, primary_key=True),
    Column("other_data", String),
)

with engine.begin() as conn:
    conn.execute(
        t.insert(), {"uuid_data": uuid.uuid4(), "other_data": "some data"}
    )
To have the Uuid datatype work with string-based Uuids (e.g. 32 character hexadecimal strings), pass the Uuid.as_uuid parameter with the value False.
Added in version 2.0.
See also
UUID - represents exactly the UUID datatype without any backend-agnostic behaviors.
Members
__init__(), bind_processor(), coerce_compared_value(), literal_processor(), python_type, result_processor()
Class signature
class sqlalchemy.types.Uuid (sqlalchemy.types.Emulated, sqlalchemy.types.TypeEngine)
method sqlalchemy.types.Uuid.__init__(as_uuid: bool = True, native_uuid: bool = True)
Construct a Uuid type.
Parameters:
• as_uuid=True – 
if True, values will be interpreted as Python uuid objects, converting to/from string via the DBAPI.
• native_uuid=True – if True, backends that support either the UUID datatype directly, or a UUID-storing value (such as SQL Server’s UNIQUEIDENTIFIER will be used by those backends. If False, a CHAR(32) datatype will be used for all backends regardless of native support.
method sqlalchemy.types.Uuid.bind_processor(dialect: Dialect) → _BindProcessorType[_UUID_RETURN] | None
Return a conversion function for processing bind values.
Returns a callable which will receive a bind parameter value as the sole positional argument and will return a value to send to the DB-API.
If processing is not necessary, the method should return None.
Tip
This method is only called relative to a dialect specific type object, which is often private to a dialect in use and is not the same type object as the public facing one, which means it’s not feasible to subclass a TypeEngine class in order to provide an alternate TypeEngine.bind_processor() method, unless subclassing the UserDefinedType class explicitly.
To provide alternate behavior for TypeEngine.bind_processor(), implement a TypeDecorator class and provide an implementation of TypeDecorator.process_bind_param().
See also
Augmenting Existing Types
Parameters:
dialect – Dialect instance in use.
method sqlalchemy.types.Uuid.coerce_compared_value(op, value)
See TypeEngine.coerce_compared_value() for a description.
method sqlalchemy.types.Uuid.literal_processor(dialect)
Return a conversion function for processing literal values that are to be rendered directly without using binds.
This function is used when the compiler makes use of the “literal_binds” flag, typically used in DDL generation as well as in certain scenarios where backends don’t accept bound parameters.
Returns a callable which will receive a literal Python value as the sole positional argument and will return a string representation to be rendered in a SQL statement.
Tip
This method is only called relative to a dialect specific type object, which is often private to a dialect in use and is not the same type object as the public facing one, which means it’s not feasible to subclass a TypeEngine class in order to provide an alternate TypeEngine.literal_processor() method, unless subclassing the UserDefinedType class explicitly.
To provide alternate behavior for TypeEngine.literal_processor(), implement a TypeDecorator class and provide an implementation of TypeDecorator.process_literal_param().
See also
Augmenting Existing Types
attribute sqlalchemy.types.Uuid.python_type
method sqlalchemy.types.Uuid.result_processor(dialect, coltype)
Return a conversion function for processing result row values.
Returns a callable which will receive a result row column value as the sole positional argument and will return a value to return to the user.
If processing is not necessary, the method should return None.
Tip
This method is only called relative to a dialect specific type object, which is often private to a dialect in use and is not the same type object as the public facing one, which means it’s not feasible to subclass a TypeEngine class in order to provide an alternate TypeEngine.result_processor() method, unless subclassing the UserDefinedType class explicitly.
To provide alternate behavior for TypeEngine.result_processor(), implement a TypeDecorator class and provide an implementation of TypeDecorator.process_result_value().
See also
Augmenting Existing Types
Parameters:
• dialect – Dialect instance in use.
• coltype – DBAPI coltype argument received in cursor.description.
SQL Standard and Multiple Vendor “UPPERCASE” Types
This category of types refers to types that are either part of the SQL standard, or are potentially found within a subset of database backends. Unlike the “generic” types, the SQL standard/multi-vendor types have no guarantee of working on all backends, and will only work on those backends that explicitly support them by name. That is, the type will always emit its exact name in DDL with CREATE TABLE is issued.
Object NameDescriptionARRAYRepresent a SQL Array type.BIGINTThe SQL BIGINT type.BINARYThe SQL BINARY type.BLOBThe SQL BLOB type.BOOLEANThe SQL BOOLEAN type.CHARThe SQL CHAR type.CLOBThe CLOB type.DATEThe SQL DATE type.DATETIMEThe SQL DATETIME type.DECIMALThe SQL DECIMAL type.DOUBLEThe SQL DOUBLE type.DOUBLE_PRECISIONThe SQL DOUBLE PRECISION type.FLOATThe SQL FLOAT type.INTalias of INTEGERINTEGERThe SQL INT or INTEGER type.JSONRepresent a SQL JSON type.NCHARThe SQL NCHAR type.NUMERICThe SQL NUMERIC type.NVARCHARThe SQL NVARCHAR type.REALThe SQL REAL type.SMALLINTThe SQL SMALLINT type.TEXTThe SQL TEXT type.TIMEThe SQL TIME type.TIMESTAMPThe SQL TIMESTAMP type.UUIDRepresent the SQL UUID type.VARBINARYThe SQL VARBINARY type.VARCHARThe SQL VARCHAR type.class sqlalchemy.types.ARRAY
Represent a SQL Array type.
Note
This type serves as the basis for all ARRAY operations. However, currently only the PostgreSQL backend has support for SQL arrays in SQLAlchemy. It is recommended to use the PostgreSQL-specific sqlalchemy.dialects.postgresql.ARRAY type directly when using ARRAY types with PostgreSQL, as it provides additional operators specific to that backend.
ARRAY is part of the Core in support of various SQL standard functions such as array_agg which explicitly involve arrays; however, with the exception of the PostgreSQL backend and possibly some third-party dialects, no other SQLAlchemy built-in dialect has support for this type.
An ARRAY type is constructed given the “type” of element:
mytable = Table("mytable", metadata, Column("data", ARRAY(Integer)))
The above type represents an N-dimensional array, meaning a supporting backend such as PostgreSQL will interpret values with any number of dimensions automatically. To produce an INSERT construct that passes in a 1-dimensional array of integers:
connection.execute(mytable.insert(), {"data": [1, 2, 3]})
The ARRAY type can be constructed given a fixed number of dimensions:
mytable = Table(
    "mytable", metadata, Column("data", ARRAY(Integer, dimensions=2))
)
Sending a number of dimensions is optional, but recommended if the datatype is to represent arrays of more than one dimension. This number is used:
• When emitting the type declaration itself to the database, e.g. INTEGER[][]
• When translating Python values to database values, and vice versa, e.g. an ARRAY of Unicode objects uses this number to efficiently access the string values inside of array structures without resorting to per-row type inspection
• When used with the Python getitem accessor, the number of dimensions serves to define the kind of type that the [] operator should return, e.g. for an ARRAY of INTEGER with two dimensions:
• >>> expr = table.c.column[5]  # returns ARRAY(Integer, dimensions=1)
>>> expr = expr[6]  # returns Integer
For 1-dimensional arrays, an ARRAY instance with no dimension parameter will generally assume single-dimensional behaviors.
SQL expressions of type ARRAY have support for “index” and “slice” behavior. The [] operator produces expression constructs which will produce the appropriate SQL, both for SELECT statements:
select(mytable.c.data[5], mytable.c.data[2:7])
as well as UPDATE statements when the Update.values() method is used:
mytable.update().values(
    {mytable.c.data[5]: 7, mytable.c.data[2:7]: [1, 2, 3]}
)
Indexed access is one-based by default; for zero-based index conversion, set ARRAY.zero_indexes.
The ARRAY type also provides for the operators Comparator.any() and Comparator.all(). The PostgreSQL-specific version of ARRAY also provides additional operators.
Detecting Changes in ARRAY columns when using the ORM
The ARRAY type, when used with the SQLAlchemy ORM, does not detect in-place mutations to the array. In order to detect these, the sqlalchemy.ext.mutable extension must be used, using the MutableList class:
from sqlalchemy import ARRAY
from sqlalchemy.ext.mutable import MutableList


class SomeOrmClass(Base):
    # ...

    data = Column(MutableList.as_mutable(ARRAY(Integer)))
This extension will allow “in-place” changes such to the array such as .append() to produce events which will be detected by the unit of work. Note that changes to elements inside the array, including subarrays that are mutated in place, are not detected.
Alternatively, assigning a new array value to an ORM element that replaces the old one will always trigger a change event.
See also
sqlalchemy.dialects.postgresql.ARRAY
Members
__init__(), contains(), any(), all()
Class signature
class sqlalchemy.types.ARRAY (sqlalchemy.sql.expression.SchemaEventTarget, sqlalchemy.types.Indexable, sqlalchemy.types.Concatenable, sqlalchemy.types.TypeEngine)
method sqlalchemy.types.ARRAY.__init__(item_type: _TypeEngineArgument[_T], as_tuple: bool = False, dimensions: int | None = None, zero_indexes: bool = False)
Construct an ARRAY.
E.g.:
Column("myarray", ARRAY(Integer))
Arguments are:
Parameters:
• item_type – The data type of items of this array. Note that dimensionality is irrelevant here, so multi-dimensional arrays like INTEGER[][], are constructed as ARRAY(Integer), not as ARRAY(ARRAY(Integer)) or such.
• as_tuple=False – Specify whether return results should be converted to tuples from lists. This parameter is not generally needed as a Python list corresponds well to a SQL array.
• dimensions – if non-None, the ARRAY will assume a fixed number of dimensions. This impacts how the array is declared on the database, how it goes about interpreting Python and result values, as well as how expression behavior in conjunction with the “getitem” operator works. See the description at ARRAY for additional detail.
• zero_indexes=False – when True, index values will be converted between Python zero-based and SQL one-based indexes, e.g. a value of one will be added to all index values before passing to the database.
class Comparator
Define comparison operations for ARRAY.
More operators are available on the dialect-specific form of this type. See Comparator.
Class signature
class sqlalchemy.types.ARRAY.Comparator (sqlalchemy.types.Comparator, sqlalchemy.types.Comparator)
method sqlalchemy.types.ARRAY.Comparator.contains(*arg: Any, **kw: Any) → ColumnElement[bool]
ARRAY.contains() not implemented for the base ARRAY type. Use the dialect-specific ARRAY type.
See also
ARRAY - PostgreSQL specific version.
method sqlalchemy.types.ARRAY.Comparator.any(other: Any, operator: OperatorType | None = None) → ColumnElement[bool]
Return other operator ANY (array) clause.
Legacy Feature
This method is an ARRAY - specific construct that is now superseded by the any_() function, which features a different calling style. The any_() function is also mirrored at the method level via the ColumnOperators.any_() method.
Usage of array-specific Comparator.any() is as follows:
from sqlalchemy.sql import operators

conn.execute(
    select(table.c.data).where(table.c.data.any(7, operator=operators.lt))
)
Parameters:
• other – expression to be compared
• operator – an operator object from the sqlalchemy.sql.operators package, defaults to eq().
See also
any_()
Comparator.all()
method sqlalchemy.types.ARRAY.Comparator.all(other: Any, operator: OperatorType | None = None) → ColumnElement[bool]
Return other operator ALL (array) clause.
Legacy Feature
This method is an ARRAY - specific construct that is now superseded by the all_() function, which features a different calling style. The all_() function is also mirrored at the method level via the ColumnOperators.all_() method.
Usage of array-specific Comparator.all() is as follows:
from sqlalchemy.sql import operators

conn.execute(
    select(table.c.data).where(table.c.data.all(7, operator=operators.lt))
)
Parameters:
• other – expression to be compared
• operator – an operator object from the sqlalchemy.sql.operators package, defaults to eq().
See also
all_()
Comparator.any()
class sqlalchemy.types.BIGINT
The SQL BIGINT type.
See also
BigInteger - documentation for the base type.
Class signature
class sqlalchemy.types.BIGINT (sqlalchemy.types.BigInteger)
class sqlalchemy.types.BINARY
The SQL BINARY type.
Class signature
class sqlalchemy.types.BINARY (sqlalchemy.types._Binary)
class sqlalchemy.types.BLOB
The SQL BLOB type.
Members
__init__()
Class signature
class sqlalchemy.types.BLOB (sqlalchemy.types.LargeBinary)
method sqlalchemy.types.BLOB.__init__(length: int | None = None)
inherited from the sqlalchemy.types.LargeBinary.__init__ method of LargeBinary
Construct a LargeBinary type.
Parameters:
length – optional, a length for the column for use in DDL statements, for those binary types that accept a length, such as the MySQL BLOB type.
class sqlalchemy.types.BOOLEAN
The SQL BOOLEAN type.
Members
__init__()
Class signature
class sqlalchemy.types.BOOLEAN (sqlalchemy.types.Boolean)
method sqlalchemy.types.BOOLEAN.__init__(create_constraint: bool = False, name: str | None = None, _create_events: bool = True, _adapted_from: SchemaType | None = None)
inherited from the sqlalchemy.types.Boolean.__init__ method of Boolean
Construct a Boolean.
Parameters:
• create_constraint – 
defaults to False. If the boolean is generated as an int/smallint, also create a CHECK constraint on the table that ensures 1 or 0 as a value.
Note
it is strongly recommended that the CHECK constraint have an explicit name in order to support schema-management concerns. This can be established either by setting the Boolean.name parameter or by setting up an appropriate naming convention; see Configuring Constraint Naming Conventions for background.
Changed in version 1.4: - this flag now defaults to False, meaning no CHECK constraint is generated for a non-native enumerated type.
• name – if a CHECK constraint is generated, specify the name of the constraint.
class sqlalchemy.types.CHAR
The SQL CHAR type.
Members
__init__()
Class signature
class sqlalchemy.types.CHAR (sqlalchemy.types.String)
method sqlalchemy.types.CHAR.__init__(length: int | None = None, collation: str | None = None)
inherited from the sqlalchemy.types.String.__init__ method of String
Create a string-holding type.
Parameters:
• length – optional, a length for the column for use in DDL and CAST expressions. May be safely omitted if no CREATE TABLE will be issued. Certain databases may require a length for use in DDL, and will raise an exception when the CREATE TABLE DDL is issued if a VARCHAR with no length is included. Whether the value is interpreted as bytes or characters is database specific.
• collation – 
Optional, a column-level collation for use in DDL and CAST expressions. Renders using the COLLATE keyword supported by SQLite, MySQL, and PostgreSQL. E.g.:
>>> from sqlalchemy import cast, select, String
>>> print(select(cast("some string", String(collation="utf8"))))
SELECT CAST(:param_1 AS VARCHAR COLLATE utf8) AS anon_1
• Note
In most cases, the Unicode or UnicodeText datatypes should be used for a Column that expects to store non-ascii data. These datatypes will ensure that the correct types are used on the database.
class sqlalchemy.types.CLOB
The CLOB type.
This type is found in Oracle Database and Informix.
Members
__init__()
Class signature
class sqlalchemy.types.CLOB (sqlalchemy.types.Text)
method sqlalchemy.types.CLOB.__init__(length: int | None = None, collation: str | None = None)
inherited from the sqlalchemy.types.String.__init__ method of String
Create a string-holding type.
Parameters:
• length – optional, a length for the column for use in DDL and CAST expressions. May be safely omitted if no CREATE TABLE will be issued. Certain databases may require a length for use in DDL, and will raise an exception when the CREATE TABLE DDL is issued if a VARCHAR with no length is included. Whether the value is interpreted as bytes or characters is database specific.
• collation – 
Optional, a column-level collation for use in DDL and CAST expressions. Renders using the COLLATE keyword supported by SQLite, MySQL, and PostgreSQL. E.g.:
>>> from sqlalchemy import cast, select, String
>>> print(select(cast("some string", String(collation="utf8"))))
SELECT CAST(:param_1 AS VARCHAR COLLATE utf8) AS anon_1
• Note
In most cases, the Unicode or UnicodeText datatypes should be used for a Column that expects to store non-ascii data. These datatypes will ensure that the correct types are used on the database.
class sqlalchemy.types.DATE
The SQL DATE type.
Class signature
class sqlalchemy.types.DATE (sqlalchemy.types.Date)
class sqlalchemy.types.DATETIME
The SQL DATETIME type.
Members
__init__()
Class signature
class sqlalchemy.types.DATETIME (sqlalchemy.types.DateTime)
method sqlalchemy.types.DATETIME.__init__(timezone: bool = False)
inherited from the sqlalchemy.types.DateTime.__init__ method of DateTime
Construct a new DateTime.
Parameters:
timezone – boolean. Indicates that the datetime type should enable timezone support, if available on the base date/time-holding type only. It is recommended to make use of the TIMESTAMP datatype directly when using this flag, as some databases include separate generic date/time-holding types distinct from the timezone-capable TIMESTAMP datatype, such as Oracle Database.
class sqlalchemy.types.DECIMAL
The SQL DECIMAL type.
See also
Numeric - documentation for the base type.
Members
__init__()
Class signature
class sqlalchemy.types.DECIMAL (sqlalchemy.types.Numeric)
method sqlalchemy.types.DECIMAL.__init__(precision: int | None = None, scale: int | None = None, decimal_return_scale: int | None = None, asdecimal: bool = True)
inherited from the sqlalchemy.types.Numeric.__init__ method of Numeric
Construct a Numeric.
Parameters:
• precision – the numeric precision for use in DDL CREATE TABLE.
• scale – the numeric scale for use in DDL CREATE TABLE.
• asdecimal – default True. Return whether or not values should be sent as Python Decimal objects, or as floats. Different DBAPIs send one or the other based on datatypes - the Numeric type will ensure that return values are one or the other across DBAPIs consistently.
• decimal_return_scale – Default scale to use when converting from floats to Python decimals. Floating point values will typically be much longer due to decimal inaccuracy, and most floating point database types don’t have a notion of “scale”, so by default the float type looks for the first ten decimal places when converting. Specifying this value will override that length. Types which do include an explicit “.scale” value, such as the base Numeric as well as the MySQL float types, will use the value of “.scale” as the default for decimal_return_scale, if not otherwise specified.
When using the Numeric type, care should be taken to ensure that the asdecimal setting is appropriate for the DBAPI in use - when Numeric applies a conversion from Decimal->float or float-> Decimal, this conversion incurs an additional performance overhead for all result columns received.
DBAPIs that return Decimal natively (e.g. psycopg2) will have better accuracy and higher performance with a setting of True, as the native translation to Decimal reduces the amount of floating- point issues at play, and the Numeric type itself doesn’t need to apply any further conversions. However, another DBAPI which returns floats natively will incur an additional conversion overhead, and is still subject to floating point data loss - in which case asdecimal=False will at least remove the extra conversion overhead.
class sqlalchemy.types.DOUBLE
The SQL DOUBLE type.
Added in version 2.0.
See also
Double - documentation for the base type.
Members
__init__()
Class signature
class sqlalchemy.types.DOUBLE (sqlalchemy.types.Double)
method sqlalchemy.types.DOUBLE.__init__(precision: int | None = None, asdecimal: bool = False, decimal_return_scale: int | None = None)
inherited from the sqlalchemy.types.Float.__init__ method of Float
Construct a Float.
Parameters:
• precision – 
the numeric precision for use in DDL CREATE TABLE. Backends should attempt to ensure this precision indicates a number of digits for the generic Float datatype.
Note
For the Oracle Database backend, the Float.precision parameter is not accepted when rendering DDL, as Oracle Database does not support float precision specified as a number of decimal places. Instead, use the Oracle Database-specific FLOAT datatype and specify the FLOAT.binary_precision parameter. This is new in version 2.0 of SQLAlchemy.
To create a database agnostic Float that separately specifies binary precision for Oracle Database, use TypeEngine.with_variant() as follows:
from sqlalchemy import Column
from sqlalchemy import Float
from sqlalchemy.dialects import oracle

Column(
    "float_data",
    Float(5).with_variant(oracle.FLOAT(binary_precision=16), "oracle"),
)
• 
• asdecimal – the same flag as that of Numeric, but defaults to False. Note that setting this flag to True results in floating point conversion.
• decimal_return_scale – Default scale to use when converting from floats to Python decimals. Floating point values will typically be much longer due to decimal inaccuracy, and most floating point database types don’t have a notion of “scale”, so by default the float type looks for the first ten decimal places when converting. Specifying this value will override that length. Note that the MySQL float types, which do include “scale”, will use “scale” as the default for decimal_return_scale, if not otherwise specified.
class sqlalchemy.types.DOUBLE_PRECISION
The SQL DOUBLE PRECISION type.
Added in version 2.0.
See also
Double - documentation for the base type.
Members
__init__()
Class signature
class sqlalchemy.types.DOUBLE_PRECISION (sqlalchemy.types.Double)
method sqlalchemy.types.DOUBLE_PRECISION.__init__(precision: int | None = None, asdecimal: bool = False, decimal_return_scale: int | None = None)
inherited from the sqlalchemy.types.Float.__init__ method of Float
Construct a Float.
Parameters:
• precision – 
the numeric precision for use in DDL CREATE TABLE. Backends should attempt to ensure this precision indicates a number of digits for the generic Float datatype.
Note
For the Oracle Database backend, the Float.precision parameter is not accepted when rendering DDL, as Oracle Database does not support float precision specified as a number of decimal places. Instead, use the Oracle Database-specific FLOAT datatype and specify the FLOAT.binary_precision parameter. This is new in version 2.0 of SQLAlchemy.
To create a database agnostic Float that separately specifies binary precision for Oracle Database, use TypeEngine.with_variant() as follows:
from sqlalchemy import Column
from sqlalchemy import Float
from sqlalchemy.dialects import oracle

Column(
    "float_data",
    Float(5).with_variant(oracle.FLOAT(binary_precision=16), "oracle"),
)
• 
• asdecimal – the same flag as that of Numeric, but defaults to False. Note that setting this flag to True results in floating point conversion.
• decimal_return_scale – Default scale to use when converting from floats to Python decimals. Floating point values will typically be much longer due to decimal inaccuracy, and most floating point database types don’t have a notion of “scale”, so by default the float type looks for the first ten decimal places when converting. Specifying this value will override that length. Note that the MySQL float types, which do include “scale”, will use “scale” as the default for decimal_return_scale, if not otherwise specified.
class sqlalchemy.types.FLOAT
The SQL FLOAT type.
See also
Float - documentation for the base type.
Members
__init__()
Class signature
class sqlalchemy.types.FLOAT (sqlalchemy.types.Float)
method sqlalchemy.types.FLOAT.__init__(precision: int | None = None, asdecimal: bool = False, decimal_return_scale: int | None = None)
inherited from the sqlalchemy.types.Float.__init__ method of Float
Construct a Float.
Parameters:
• precision – 
the numeric precision for use in DDL CREATE TABLE. Backends should attempt to ensure this precision indicates a number of digits for the generic Float datatype.
Note
For the Oracle Database backend, the Float.precision parameter is not accepted when rendering DDL, as Oracle Database does not support float precision specified as a number of decimal places. Instead, use the Oracle Database-specific FLOAT datatype and specify the FLOAT.binary_precision parameter. This is new in version 2.0 of SQLAlchemy.
To create a database agnostic Float that separately specifies binary precision for Oracle Database, use TypeEngine.with_variant() as follows:
from sqlalchemy import Column
from sqlalchemy import Float
from sqlalchemy.dialects import oracle

Column(
    "float_data",
    Float(5).with_variant(oracle.FLOAT(binary_precision=16), "oracle"),
)
• 
• asdecimal – the same flag as that of Numeric, but defaults to False. Note that setting this flag to True results in floating point conversion.
• decimal_return_scale – Default scale to use when converting from floats to Python decimals. Floating point values will typically be much longer due to decimal inaccuracy, and most floating point database types don’t have a notion of “scale”, so by default the float type looks for the first ten decimal places when converting. Specifying this value will override that length. Note that the MySQL float types, which do include “scale”, will use “scale” as the default for decimal_return_scale, if not otherwise specified.
attribute sqlalchemy.types..sqlalchemy.types.INT
alias of INTEGER
class sqlalchemy.types.JSON
Represent a SQL JSON type.
Note
JSON is provided as a facade for vendor-specific JSON types. Since it supports JSON SQL operations, it only works on backends that have an actual JSON type, currently:
• PostgreSQL - see sqlalchemy.dialects.postgresql.JSON and sqlalchemy.dialects.postgresql.JSONB for backend-specific notes
• MySQL - see sqlalchemy.dialects.mysql.JSON for backend-specific notes
• SQLite as of version 3.9 - see sqlalchemy.dialects.sqlite.JSON for backend-specific notes
• Microsoft SQL Server 2016 and later - see sqlalchemy.dialects.mssql.JSON for backend-specific notes
JSON is part of the Core in support of the growing popularity of native JSON datatypes.
The JSON type stores arbitrary JSON format data, e.g.:
data_table = Table(
    "data_table",
    metadata,
    Column("id", Integer, primary_key=True),
    Column("data", JSON),
)

with engine.connect() as conn:
    conn.execute(
        data_table.insert(), {"data": {"key1": "value1", "key2": "value2"}}
    )
JSON-Specific Expression Operators
The JSON datatype provides these additional SQL operations:
• Keyed index operations:
data_table.c.data["some key"]
Integer index operations:
data_table.c.data[3]
Path index operations:
data_table.c.data[("key_1", "key_2", 5, ..., "key_n")]
Data casters for specific JSON element types, subsequent to an index or path operation being invoked:
data_table.c.data["some key"].as_integer()
• Added in version 1.3.11.
Additional operations may be available from the dialect-specific versions of JSON, such as sqlalchemy.dialects.postgresql.JSON and sqlalchemy.dialects.postgresql.JSONB which both offer additional PostgreSQL-specific operations.
Casting JSON Elements to Other Types
Index operations, i.e. those invoked by calling upon the expression using the Python bracket operator as in some_column['some key'], return an expression object whose type defaults to JSON by default, so that further JSON-oriented instructions may be called upon the result type. However, it is likely more common that an index operation is expected to return a specific scalar element, such as a string or integer. In order to provide access to these elements in a backend-agnostic way, a series of data casters are provided:
• Comparator.as_string() - return the element as a string
• Comparator.as_boolean() - return the element as a boolean
• Comparator.as_float() - return the element as a float
• Comparator.as_integer() - return the element as an integer
These data casters are implemented by supporting dialects in order to assure that comparisons to the above types will work as expected, such as:
# integer comparison
data_table.c.data["some_integer_key"].as_integer() == 5

# boolean comparison
data_table.c.data["some_boolean"].as_boolean() == True
Added in version 1.3.11: Added type-specific casters for the basic JSON data element types.
Note
The data caster functions are new in version 1.3.11, and supersede the previous documented approaches of using CAST; for reference, this looked like:
from sqlalchemy import cast, type_coerce
from sqlalchemy import String, JSON

cast(data_table.c.data["some_key"], String) == type_coerce(55, JSON)
The above case now works directly as:
data_table.c.data["some_key"].as_integer() == 5
For details on the previous comparison approach within the 1.3.x series, see the documentation for SQLAlchemy 1.2 or the included HTML files in the doc/ directory of the version’s distribution.
Detecting Changes in JSON columns when using the ORM
The JSON type, when used with the SQLAlchemy ORM, does not detect in-place mutations to the structure. In order to detect these, the sqlalchemy.ext.mutable extension must be used, most typically using the MutableDict class. This extension will allow “in-place” changes to the datastructure to produce events which will be detected by the unit of work. See the example at HSTORE for a simple example involving a dictionary.
Alternatively, assigning a JSON structure to an ORM element that replaces the old one will always trigger a change event.
Support for JSON null vs. SQL NULL
When working with NULL values, the JSON type recommends the use of two specific constants in order to differentiate between a column that evaluates to SQL NULL, e.g. no value, vs. the JSON-encoded string of "null". To insert or select against a value that is SQL NULL, use the constant null(). This symbol may be passed as a parameter value specifically when using the JSON datatype, which contains special logic that interprets this symbol to mean that the column value should be SQL NULL as opposed to JSON "null":
from sqlalchemy import null

conn.execute(table.insert(), {"json_value": null()})
To insert or select against a value that is JSON "null", use the constant JSON.NULL:
conn.execute(table.insert(), {"json_value": JSON.NULL})
The JSON type supports a flag JSON.none_as_null which when set to True will result in the Python constant None evaluating to the value of SQL NULL, and when set to False results in the Python constant None evaluating to the value of JSON "null". The Python value None may be used in conjunction with either JSON.NULL and null() in order to indicate NULL values, but care must be taken as to the value of the JSON.none_as_null in these cases.
Customizing the JSON Serializer
The JSON serializer and deserializer used by JSON defaults to Python’s json.dumps and json.loads functions; in the case of the psycopg2 dialect, psycopg2 may be using its own custom loader function.
In order to affect the serializer / deserializer, they are currently configurable at the create_engine() level via the create_engine.json_serializer and create_engine.json_deserializer parameters. For example, to turn off ensure_ascii:
engine = create_engine(
    "sqlite://",
    json_serializer=lambda obj: json.dumps(obj, ensure_ascii=False),
)
Changed in version 1.3.7: SQLite dialect’s json_serializer and json_deserializer parameters renamed from _json_serializer and _json_deserializer.
See also
sqlalchemy.dialects.postgresql.JSON
sqlalchemy.dialects.postgresql.JSONB
sqlalchemy.dialects.mysql.JSON
sqlalchemy.dialects.sqlite.JSON
Members
as_boolean(), as_float(), as_integer(), as_json(), as_numeric(), as_string(), bind_processor(), literal_processor(), NULL, __init__(), bind_processor(), comparator_factory, hashable, python_type, result_processor(), should_evaluate_none
Class signature
class sqlalchemy.types.JSON (sqlalchemy.types.Indexable, sqlalchemy.types.TypeEngine)
class Comparator
Define comparison operations for JSON.
Class signature
class sqlalchemy.types.JSON.Comparator (sqlalchemy.types.Comparator, sqlalchemy.types.Comparator)
method sqlalchemy.types.JSON.Comparator.as_boolean()
Consider an indexed value as boolean.
This is similar to using type_coerce, and will usually not apply a CAST().
e.g.:
stmt = select(mytable.c.json_column["some_data"].as_boolean()).where(
    mytable.c.json_column["some_data"].as_boolean() == True
)
Added in version 1.3.11.
method sqlalchemy.types.JSON.Comparator.as_float()
Consider an indexed value as float.
This is similar to using type_coerce, and will usually not apply a CAST().
e.g.:
stmt = select(mytable.c.json_column["some_data"].as_float()).where(
    mytable.c.json_column["some_data"].as_float() == 29.75
)
Added in version 1.3.11.
method sqlalchemy.types.JSON.Comparator.as_integer()
Consider an indexed value as integer.
This is similar to using type_coerce, and will usually not apply a CAST().
e.g.:
stmt = select(mytable.c.json_column["some_data"].as_integer()).where(
    mytable.c.json_column["some_data"].as_integer() == 5
)
Added in version 1.3.11.
method sqlalchemy.types.JSON.Comparator.as_json()
Consider an indexed value as JSON.
This is similar to using type_coerce, and will usually not apply a CAST().
e.g.:
stmt = select(mytable.c.json_column["some_data"].as_json())
This is typically the default behavior of indexed elements in any case.
Note that comparison of full JSON structures may not be supported by all backends.
Added in version 1.3.11.
method sqlalchemy.types.JSON.Comparator.as_numeric(precision, scale, asdecimal=True)
Consider an indexed value as numeric/decimal.
This is similar to using type_coerce, and will usually not apply a CAST().
e.g.:
stmt = select(mytable.c.json_column["some_data"].as_numeric(10, 6)).where(
    mytable.c.json_column["some_data"].as_numeric(10, 6) == 29.75
)
Added in version 1.4.0b2.
method sqlalchemy.types.JSON.Comparator.as_string()
Consider an indexed value as string.
This is similar to using type_coerce, and will usually not apply a CAST().
e.g.:
stmt = select(mytable.c.json_column["some_data"].as_string()).where(
    mytable.c.json_column["some_data"].as_string() == "some string"
)
Added in version 1.3.11.
class JSONElementType
Common function for index / path elements in a JSON expression.
Class signature
class sqlalchemy.types.JSON.JSONElementType (sqlalchemy.types.TypeEngine)
method sqlalchemy.types.JSON.JSONElementType.bind_processor(dialect: Dialect) → _BindProcessorType[Any]
Return a conversion function for processing bind values.
Returns a callable which will receive a bind parameter value as the sole positional argument and will return a value to send to the DB-API.
If processing is not necessary, the method should return None.
Tip
This method is only called relative to a dialect specific type object, which is often private to a dialect in use and is not the same type object as the public facing one, which means it’s not feasible to subclass a TypeEngine class in order to provide an alternate TypeEngine.bind_processor() method, unless subclassing the UserDefinedType class explicitly.
To provide alternate behavior for TypeEngine.bind_processor(), implement a TypeDecorator class and provide an implementation of TypeDecorator.process_bind_param().
See also
Augmenting Existing Types
Parameters:
dialect – Dialect instance in use.
method sqlalchemy.types.JSON.JSONElementType.literal_processor(dialect: Dialect) → _LiteralProcessorType[Any]
Return a conversion function for processing literal values that are to be rendered directly without using binds.
This function is used when the compiler makes use of the “literal_binds” flag, typically used in DDL generation as well as in certain scenarios where backends don’t accept bound parameters.
Returns a callable which will receive a literal Python value as the sole positional argument and will return a string representation to be rendered in a SQL statement.
Tip
This method is only called relative to a dialect specific type object, which is often private to a dialect in use and is not the same type object as the public facing one, which means it’s not feasible to subclass a TypeEngine class in order to provide an alternate TypeEngine.literal_processor() method, unless subclassing the UserDefinedType class explicitly.
To provide alternate behavior for TypeEngine.literal_processor(), implement a TypeDecorator class and provide an implementation of TypeDecorator.process_literal_param().
See also
Augmenting Existing Types
class JSONIndexType
Placeholder for the datatype of a JSON index value.
This allows execution-time processing of JSON index values for special syntaxes.
Class signature
class sqlalchemy.types.JSON.JSONIndexType (sqlalchemy.types.JSONElementType)
class JSONIntIndexType
Placeholder for the datatype of a JSON index value.
This allows execution-time processing of JSON index values for special syntaxes.
Class signature
class sqlalchemy.types.JSON.JSONIntIndexType (sqlalchemy.types.JSONIndexType)
class JSONPathType
Placeholder type for JSON path operations.
This allows execution-time processing of a path-based index value into a specific SQL syntax.
Class signature
class sqlalchemy.types.JSON.JSONPathType (sqlalchemy.types.JSONElementType)
class JSONStrIndexType
Placeholder for the datatype of a JSON index value.
This allows execution-time processing of JSON index values for special syntaxes.
Class signature
class sqlalchemy.types.JSON.JSONStrIndexType (sqlalchemy.types.JSONIndexType)
attribute sqlalchemy.types.JSON.NULL = symbol('JSON_NULL')
Describe the json value of NULL.
This value is used to force the JSON value of "null" to be used as the value. A value of Python None will be recognized either as SQL NULL or JSON "null", based on the setting of the JSON.none_as_null flag; the JSON.NULL constant can be used to always resolve to JSON "null" regardless of this setting. This is in contrast to the null() construct, which always resolves to SQL NULL. E.g.:
from sqlalchemy import null
from sqlalchemy.dialects.postgresql import JSON

# will *always* insert SQL NULL
obj1 = MyObject(json_value=null())

# will *always* insert JSON string "null"
obj2 = MyObject(json_value=JSON.NULL)

session.add_all([obj1, obj2])
session.commit()
In order to set JSON NULL as a default value for a column, the most transparent method is to use text():
Table(
    "my_table", metadata, Column("json_data", JSON, default=text("'null'"))
)
While it is possible to use JSON.NULL in this context, the JSON.NULL value will be returned as the value of the column, which in the context of the ORM or other repurposing of the default value, may not be desirable. Using a SQL expression means the value will be re-fetched from the database within the context of retrieving generated defaults.
method sqlalchemy.types.JSON.__init__(none_as_null: bool = False)
Construct a JSON type.
Parameters:
none_as_null=False – 
if True, persist the value None as a SQL NULL value, not the JSON encoding of null. Note that when this flag is False, the null() construct can still be used to persist a NULL value, which may be passed directly as a parameter value that is specially interpreted by the JSON type as SQL NULL:
from sqlalchemy import null

conn.execute(table.insert(), {"data": null()})
Note
JSON.none_as_null does not apply to the values passed to Column.default and Column.server_default; a value of None passed for these parameters means “no default present”.
Additionally, when used in SQL comparison expressions, the Python value None continues to refer to SQL null, and not JSON NULL. The JSON.none_as_null flag refers explicitly to the persistence of the value within an INSERT or UPDATE statement. The JSON.NULL value should be used for SQL expressions that wish to compare to JSON null.
See also
JSON.NULL
method sqlalchemy.types.JSON.bind_processor(dialect)
Return a conversion function for processing bind values.
Returns a callable which will receive a bind parameter value as the sole positional argument and will return a value to send to the DB-API.
If processing is not necessary, the method should return None.
Tip
This method is only called relative to a dialect specific type object, which is often private to a dialect in use and is not the same type object as the public facing one, which means it’s not feasible to subclass a TypeEngine class in order to provide an alternate TypeEngine.bind_processor() method, unless subclassing the UserDefinedType class explicitly.
To provide alternate behavior for TypeEngine.bind_processor(), implement a TypeDecorator class and provide an implementation of TypeDecorator.process_bind_param().
See also
Augmenting Existing Types
Parameters:
dialect – Dialect instance in use.
attribute sqlalchemy.types.JSON.comparator_factory
alias of Comparator
attribute sqlalchemy.types.JSON.hashable = False
Flag, if False, means values from this type aren’t hashable.
Used by the ORM when uniquing result lists.
attribute sqlalchemy.types.JSON.python_type
method sqlalchemy.types.JSON.result_processor(dialect, coltype)
Return a conversion function for processing result row values.
Returns a callable which will receive a result row column value as the sole positional argument and will return a value to return to the user.
If processing is not necessary, the method should return None.
Tip
This method is only called relative to a dialect specific type object, which is often private to a dialect in use and is not the same type object as the public facing one, which means it’s not feasible to subclass a TypeEngine class in order to provide an alternate TypeEngine.result_processor() method, unless subclassing the UserDefinedType class explicitly.
To provide alternate behavior for TypeEngine.result_processor(), implement a TypeDecorator class and provide an implementation of TypeDecorator.process_result_value().
See also
Augmenting Existing Types
Parameters:
• dialect – Dialect instance in use.
• coltype – DBAPI coltype argument received in cursor.description.
attribute sqlalchemy.types.JSON.should_evaluate_none: bool
If True, the Python constant None is considered to be handled explicitly by this type.
The ORM uses this flag to indicate that a positive value of None is passed to the column in an INSERT statement, rather than omitting the column from the INSERT statement which has the effect of firing off column-level defaults. It also allows types which have special behavior for Python None, such as a JSON type, to indicate that they’d like to handle the None value explicitly.
To set this flag on an existing type, use the TypeEngine.evaluates_none() method.
See also
TypeEngine.evaluates_none()
class sqlalchemy.types.INTEGER
The SQL INT or INTEGER type.
See also
Integer - documentation for the base type.
Class signature
class sqlalchemy.types.INTEGER (sqlalchemy.types.Integer)
class sqlalchemy.types.NCHAR
The SQL NCHAR type.
Members
__init__()
Class signature
class sqlalchemy.types.NCHAR (sqlalchemy.types.Unicode)
method sqlalchemy.types.NCHAR.__init__(length: int | None = None, collation: str | None = None)
inherited from the sqlalchemy.types.String.__init__ method of String
Create a string-holding type.
Parameters:
• length – optional, a length for the column for use in DDL and CAST expressions. May be safely omitted if no CREATE TABLE will be issued. Certain databases may require a length for use in DDL, and will raise an exception when the CREATE TABLE DDL is issued if a VARCHAR with no length is included. Whether the value is interpreted as bytes or characters is database specific.
• collation – 
Optional, a column-level collation for use in DDL and CAST expressions. Renders using the COLLATE keyword supported by SQLite, MySQL, and PostgreSQL. E.g.:
>>> from sqlalchemy import cast, select, String
>>> print(select(cast("some string", String(collation="utf8"))))
SELECT CAST(:param_1 AS VARCHAR COLLATE utf8) AS anon_1
• Note
In most cases, the Unicode or UnicodeText datatypes should be used for a Column that expects to store non-ascii data. These datatypes will ensure that the correct types are used on the database.
class sqlalchemy.types.NVARCHAR
The SQL NVARCHAR type.
Members
__init__()
Class signature
class sqlalchemy.types.NVARCHAR (sqlalchemy.types.Unicode)
method sqlalchemy.types.NVARCHAR.__init__(length: int | None = None, collation: str | None = None)
inherited from the sqlalchemy.types.String.__init__ method of String
Create a string-holding type.
Parameters:
• length – optional, a length for the column for use in DDL and CAST expressions. May be safely omitted if no CREATE TABLE will be issued. Certain databases may require a length for use in DDL, and will raise an exception when the CREATE TABLE DDL is issued if a VARCHAR with no length is included. Whether the value is interpreted as bytes or characters is database specific.
• collation – 
Optional, a column-level collation for use in DDL and CAST expressions. Renders using the COLLATE keyword supported by SQLite, MySQL, and PostgreSQL. E.g.:
>>> from sqlalchemy import cast, select, String
>>> print(select(cast("some string", String(collation="utf8"))))
SELECT CAST(:param_1 AS VARCHAR COLLATE utf8) AS anon_1
• Note
In most cases, the Unicode or UnicodeText datatypes should be used for a Column that expects to store non-ascii data. These datatypes will ensure that the correct types are used on the database.
class sqlalchemy.types.NUMERIC
The SQL NUMERIC type.
See also
Numeric - documentation for the base type.
Members
__init__()
Class signature
class sqlalchemy.types.NUMERIC (sqlalchemy.types.Numeric)
method sqlalchemy.types.NUMERIC.__init__(precision: int | None = None, scale: int | None = None, decimal_return_scale: int | None = None, asdecimal: bool = True)
inherited from the sqlalchemy.types.Numeric.__init__ method of Numeric
Construct a Numeric.
Parameters:
• precision – the numeric precision for use in DDL CREATE TABLE.
• scale – the numeric scale for use in DDL CREATE TABLE.
• asdecimal – default True. Return whether or not values should be sent as Python Decimal objects, or as floats. Different DBAPIs send one or the other based on datatypes - the Numeric type will ensure that return values are one or the other across DBAPIs consistently.
• decimal_return_scale – Default scale to use when converting from floats to Python decimals. Floating point values will typically be much longer due to decimal inaccuracy, and most floating point database types don’t have a notion of “scale”, so by default the float type looks for the first ten decimal places when converting. Specifying this value will override that length. Types which do include an explicit “.scale” value, such as the base Numeric as well as the MySQL float types, will use the value of “.scale” as the default for decimal_return_scale, if not otherwise specified.
When using the Numeric type, care should be taken to ensure that the asdecimal setting is appropriate for the DBAPI in use - when Numeric applies a conversion from Decimal->float or float-> Decimal, this conversion incurs an additional performance overhead for all result columns received.
DBAPIs that return Decimal natively (e.g. psycopg2) will have better accuracy and higher performance with a setting of True, as the native translation to Decimal reduces the amount of floating- point issues at play, and the Numeric type itself doesn’t need to apply any further conversions. However, another DBAPI which returns floats natively will incur an additional conversion overhead, and is still subject to floating point data loss - in which case asdecimal=False will at least remove the extra conversion overhead.
class sqlalchemy.types.REAL
The SQL REAL type.
See also
Float - documentation for the base type.
Members
__init__()
Class signature
class sqlalchemy.types.REAL (sqlalchemy.types.Float)
method sqlalchemy.types.REAL.__init__(precision: int | None = None, asdecimal: bool = False, decimal_return_scale: int | None = None)
inherited from the sqlalchemy.types.Float.__init__ method of Float
Construct a Float.
Parameters:
• precision – 
the numeric precision for use in DDL CREATE TABLE. Backends should attempt to ensure this precision indicates a number of digits for the generic Float datatype.
Note
For the Oracle Database backend, the Float.precision parameter is not accepted when rendering DDL, as Oracle Database does not support float precision specified as a number of decimal places. Instead, use the Oracle Database-specific FLOAT datatype and specify the FLOAT.binary_precision parameter. This is new in version 2.0 of SQLAlchemy.
To create a database agnostic Float that separately specifies binary precision for Oracle Database, use TypeEngine.with_variant() as follows:
from sqlalchemy import Column
from sqlalchemy import Float
from sqlalchemy.dialects import oracle

Column(
    "float_data",
    Float(5).with_variant(oracle.FLOAT(binary_precision=16), "oracle"),
)
• 
• asdecimal – the same flag as that of Numeric, but defaults to False. Note that setting this flag to True results in floating point conversion.
• decimal_return_scale – Default scale to use when converting from floats to Python decimals. Floating point values will typically be much longer due to decimal inaccuracy, and most floating point database types don’t have a notion of “scale”, so by default the float type looks for the first ten decimal places when converting. Specifying this value will override that length. Note that the MySQL float types, which do include “scale”, will use “scale” as the default for decimal_return_scale, if not otherwise specified.
class sqlalchemy.types.SMALLINT
The SQL SMALLINT type.
See also
SmallInteger - documentation for the base type.
Class signature
class sqlalchemy.types.SMALLINT (sqlalchemy.types.SmallInteger)
class sqlalchemy.types.TEXT
The SQL TEXT type.
Members
__init__()
Class signature
class sqlalchemy.types.TEXT (sqlalchemy.types.Text)
method sqlalchemy.types.TEXT.__init__(length: int | None = None, collation: str | None = None)
inherited from the sqlalchemy.types.String.__init__ method of String
Create a string-holding type.
Parameters:
• length – optional, a length for the column for use in DDL and CAST expressions. May be safely omitted if no CREATE TABLE will be issued. Certain databases may require a length for use in DDL, and will raise an exception when the CREATE TABLE DDL is issued if a VARCHAR with no length is included. Whether the value is interpreted as bytes or characters is database specific.
• collation – 
Optional, a column-level collation for use in DDL and CAST expressions. Renders using the COLLATE keyword supported by SQLite, MySQL, and PostgreSQL. E.g.:
>>> from sqlalchemy import cast, select, String
>>> print(select(cast("some string", String(collation="utf8"))))
SELECT CAST(:param_1 AS VARCHAR COLLATE utf8) AS anon_1
• Note
In most cases, the Unicode or UnicodeText datatypes should be used for a Column that expects to store non-ascii data. These datatypes will ensure that the correct types are used on the database.
class sqlalchemy.types.TIME
The SQL TIME type.
Class signature
class sqlalchemy.types.TIME (sqlalchemy.types.Time)
class sqlalchemy.types.TIMESTAMP
The SQL TIMESTAMP type.
TIMESTAMP datatypes have support for timezone storage on some backends, such as PostgreSQL and Oracle Database. Use the TIMESTAMP.timezone argument in order to enable “TIMESTAMP WITH TIMEZONE” for these backends.
Members
__init__(), get_dbapi_type()
Class signature
class sqlalchemy.types.TIMESTAMP (sqlalchemy.types.DateTime)
method sqlalchemy.types.TIMESTAMP.__init__(timezone: bool = False)
Construct a new TIMESTAMP.
Parameters:
timezone – boolean. Indicates that the TIMESTAMP type should enable timezone support, if available on the target database. On a per-dialect basis is similar to “TIMESTAMP WITH TIMEZONE”. If the target database does not support timezones, this flag is ignored.
method sqlalchemy.types.TIMESTAMP.get_dbapi_type(dbapi)
Return the corresponding type object from the underlying DB-API, if any.
This can be useful for calling setinputsizes(), for example.
class sqlalchemy.types.UUID
Represent the SQL UUID type.
This is the SQL-native form of the Uuid database agnostic datatype, and is backwards compatible with the previous PostgreSQL-only version of UUID.
The UUID datatype only works on databases that have a SQL datatype named UUID. It will not function for backends which don’t have this exact-named type, including SQL Server. For backend-agnostic UUID values with native support, including for SQL Server’s UNIQUEIDENTIFIER datatype, use the Uuid datatype.
Added in version 2.0.
See also
Uuid
Members
__init__()
Class signature
class sqlalchemy.types.UUID (sqlalchemy.types.Uuid, sqlalchemy.types.NativeForEmulated)
method sqlalchemy.types.UUID.__init__(as_uuid: bool = True)
Construct a UUID type.
Parameters:
as_uuid=True – 
if True, values will be interpreted as Python uuid objects, converting to/from string via the DBAPI.
class sqlalchemy.types.VARBINARY
The SQL VARBINARY type.
Class signature
class sqlalchemy.types.VARBINARY (sqlalchemy.types._Binary)
class sqlalchemy.types.VARCHAR
The SQL VARCHAR type.
Members
__init__()
Class signature
class sqlalchemy.types.VARCHAR (sqlalchemy.types.String)
method sqlalchemy.types.VARCHAR.__init__(length: int | None = None, collation: str | None = None)
inherited from the sqlalchemy.types.String.__init__ method of String
Create a string-holding type.
Parameters:
• length – optional, a length for the column for use in DDL and CAST expressions. May be safely omitted if no CREATE TABLE will be issued. Certain databases may require a length for use in DDL, and will raise an exception when the CREATE TABLE DDL is issued if a VARCHAR with no length is included. Whether the value is interpreted as bytes or characters is database specific.
• collation – 
Optional, a column-level collation for use in DDL and CAST expressions. Renders using the COLLATE keyword supported by SQLite, MySQL, and PostgreSQL. E.g.:
>>> from sqlalchemy import cast, select, String
>>> print(select(cast("some string", String(collation="utf8"))))
SELECT CAST(:param_1 AS VARCHAR COLLATE utf8) AS anon_1
• Note
In most cases, the Unicode or UnicodeText datatypes should be used for a Column that expects to store non-ascii data. These datatypes will ensure that the correct types are used on the database.


Custom Types
A variety of methods exist to redefine the behavior of existing types as well as to provide new ones.
Overriding Type Compilation
A frequent need is to force the “string” version of a type, that is the one rendered in a CREATE TABLE statement or other SQL function like CAST, to be changed. For example, an application may want to force the rendering of BINARY for all platforms except for one, in which it wants BLOB to be rendered. Usage of an existing generic type, in this case LargeBinary, is preferred for most use cases. But to control types more accurately, a compilation directive that is per-dialect can be associated with any type:
from sqlalchemy.ext.compiler import compiles
from sqlalchemy.types import BINARY


@compiles(BINARY, "sqlite")
def compile_binary_sqlite(type_, compiler, **kw):
    return "BLOB"
The above code allows the usage of BINARY, which will produce the string BINARY against all backends except SQLite, in which case it will produce BLOB.
See the section Changing Compilation of Types, a subsection of Custom SQL Constructs and Compilation Extension, for additional examples.
Augmenting Existing Types
The TypeDecorator allows the creation of custom types which add bind-parameter and result-processing behavior to an existing type object. It is used when additional in-Python marshalling of data to and/or from the database is required.
Note
The bind- and result-processing of TypeDecorator is in addition to the processing already performed by the hosted type, which is customized by SQLAlchemy on a per-DBAPI basis to perform processing specific to that DBAPI. While it is possible to replace this handling for a given type through direct subclassing, it is never needed in practice and SQLAlchemy no longer supports this as a public use case.
ORM Tip
The TypeDecorator can be used to provide a consistent means of converting some type of value as it is passed into and out of the database. When using the ORM, a similar technique exists for converting user data from arbitrary formats which is to use the validates() decorator. This technique may be more appropriate when data coming into an ORM model needs to be normalized in some way that is specific to the business case and isn’t as generic as a datatype.
Object NameDescriptionTypeDecoratorAllows the creation of types which add additional functionality to an existing type.class sqlalchemy.types.TypeDecorator
Allows the creation of types which add additional functionality to an existing type.
This method is preferred to direct subclassing of SQLAlchemy’s built-in types as it ensures that all required functionality of the underlying type is kept in place.
Typical usage:
import sqlalchemy.types as types


class MyType(types.TypeDecorator):
    """Prefixes Unicode values with "PREFIX:" on the way in and
    strips it off on the way out.
    """

    impl = types.Unicode

    cache_ok = True

    def process_bind_param(self, value, dialect):
        return "PREFIX:" + value

    def process_result_value(self, value, dialect):
        return value[7:]

    def copy(self, **kw):
        return MyType(self.impl.length)
The class-level impl attribute is required, and can reference any TypeEngine class. Alternatively, the load_dialect_impl() method can be used to provide different type classes based on the dialect given; in this case, the impl variable can reference TypeEngine as a placeholder.
The TypeDecorator.cache_ok class-level flag indicates if this custom TypeDecorator is safe to be used as part of a cache key. This flag defaults to None which will initially generate a warning when the SQL compiler attempts to generate a cache key for a statement that uses this type. If the TypeDecorator is not guaranteed to produce the same bind/result behavior and SQL generation every time, this flag should be set to False; otherwise if the class produces the same behavior each time, it may be set to True. See TypeDecorator.cache_ok for further notes on how this works.
Types that receive a Python type that isn’t similar to the ultimate type used may want to define the TypeDecorator.coerce_compared_value() method. This is used to give the expression system a hint when coercing Python objects into bind parameters within expressions. Consider this expression:
mytable.c.somecol + datetime.date(2009, 5, 15)
Above, if “somecol” is an Integer variant, it makes sense that we’re doing date arithmetic, where above is usually interpreted by databases as adding a number of days to the given date. The expression system does the right thing by not attempting to coerce the “date()” value into an integer-oriented bind parameter.
However, in the case of TypeDecorator, we are usually changing an incoming Python type to something new - TypeDecorator by default will “coerce” the non-typed side to be the same type as itself. Such as below, we define an “epoch” type that stores a date value as an integer:
class MyEpochType(types.TypeDecorator):
    impl = types.Integer

    cache_ok = True

    epoch = datetime.date(1970, 1, 1)

    def process_bind_param(self, value, dialect):
        return (value - self.epoch).days

    def process_result_value(self, value, dialect):
        return self.epoch + timedelta(days=value)
Our expression of somecol + date with the above type will coerce the “date” on the right side to also be treated as MyEpochType.
This behavior can be overridden via the TypeDecorator.coerce_compared_value() method, which returns a type that should be used for the value of the expression. Below we set it such that an integer value will be treated as an Integer, and any other value is assumed to be a date and will be treated as a MyEpochType:
def coerce_compared_value(self, op, value):
    if isinstance(value, int):
        return Integer()
    else:
        return self
Warning
Note that the behavior of coerce_compared_value is not inherited by default from that of the base type. If the TypeDecorator is augmenting a type that requires special logic for certain types of operators, this method must be overridden. A key example is when decorating the JSON and JSONB types; the default rules of TypeEngine.coerce_compared_value() should be used in order to deal with operators like index operations:
from sqlalchemy import JSON
from sqlalchemy import TypeDecorator


class MyJsonType(TypeDecorator):
    impl = JSON

    cache_ok = True

    def coerce_compared_value(self, op, value):
        return self.impl.coerce_compared_value(op, value)
Without the above step, index operations such as mycol['foo'] will cause the index value 'foo' to be JSON encoded.
Similarly, when working with the ARRAY datatype, the type coercion for index operations (e.g. mycol[5]) is also handled by TypeDecorator.coerce_compared_value(), where again a simple override is sufficient unless special rules are needed for particular operators:
from sqlalchemy import ARRAY
from sqlalchemy import TypeDecorator


class MyArrayType(TypeDecorator):
    impl = ARRAY

    cache_ok = True

    def coerce_compared_value(self, op, value):
        return self.impl.coerce_compared_value(op, value)
Members
cache_ok, operate(), reverse_operate(), __init__(), bind_expression(), bind_processor(), coerce_compared_value(), coerce_to_is_types, column_expression(), comparator_factory, compare_values(), copy(), get_dbapi_type(), literal_processor(), load_dialect_impl(), process_bind_param(), process_literal_param(), process_result_value(), result_processor(), sort_key_function, type_engine()
Class signature
class sqlalchemy.types.TypeDecorator (sqlalchemy.sql.expression.SchemaEventTarget, sqlalchemy.types.ExternalType, sqlalchemy.types.TypeEngine)
attribute sqlalchemy.types.TypeDecorator.cache_ok: bool | None = None
inherited from the ExternalType.cache_ok attribute of ExternalType
Indicate if statements using this ExternalType are “safe to cache”.
The default value None will emit a warning and then not allow caching of a statement which includes this type. Set to False to disable statements using this type from being cached at all without a warning. When set to True, the object’s class and selected elements from its state will be used as part of the cache key. For example, using a TypeDecorator:
class MyType(TypeDecorator):
    impl = String

    cache_ok = True

    def __init__(self, choices):
        self.choices = tuple(choices)
        self.internal_only = True
The cache key for the above type would be equivalent to:
>>> MyType(["a", "b", "c"])._static_cache_key
(<class '__main__.MyType'>, ('choices', ('a', 'b', 'c')))
The caching scheme will extract attributes from the type that correspond to the names of parameters in the __init__() method. Above, the “choices” attribute becomes part of the cache key but “internal_only” does not, because there is no parameter named “internal_only”.
The requirements for cacheable elements is that they are hashable and also that they indicate the same SQL rendered for expressions using this type every time for a given cache value.
To accommodate for datatypes that refer to unhashable structures such as dictionaries, sets and lists, these objects can be made “cacheable” by assigning hashable structures to the attributes whose names correspond with the names of the arguments. For example, a datatype which accepts a dictionary of lookup values may publish this as a sorted series of tuples. Given a previously un-cacheable type as:
class LookupType(UserDefinedType):
    """a custom type that accepts a dictionary as a parameter.

    this is the non-cacheable version, as "self.lookup" is not
    hashable.

    """

    def __init__(self, lookup):
        self.lookup = lookup

    def get_col_spec(self, **kw):
        return "VARCHAR(255)"

    def bind_processor(self, dialect): ...  # works with "self.lookup" ...
Where “lookup” is a dictionary. The type will not be able to generate a cache key:
>>> type_ = LookupType({"a": 10, "b": 20})
>>> type_._static_cache_key
<stdin>:1: SAWarning: UserDefinedType LookupType({'a': 10, 'b': 20}) will not
produce a cache key because the ``cache_ok`` flag is not set to True.
Set this flag to True if this type object's state is safe to use
in a cache key, or False to disable this warning.
symbol('no_cache')
If we did set up such a cache key, it wouldn’t be usable. We would get a tuple structure that contains a dictionary inside of it, which cannot itself be used as a key in a “cache dictionary” such as SQLAlchemy’s statement cache, since Python dictionaries aren’t hashable:
>>> # set cache_ok = True
>>> type_.cache_ok = True

>>> # this is the cache key it would generate
>>> key = type_._static_cache_key
>>> key
(<class '__main__.LookupType'>, ('lookup', {'a': 10, 'b': 20}))

>>> # however this key is not hashable, will fail when used with
>>> # SQLAlchemy statement cache
>>> some_cache = {key: "some sql value"}
Traceback (most recent call last): File "<stdin>", line 1,
in <module> TypeError: unhashable type: 'dict'
The type may be made cacheable by assigning a sorted tuple of tuples to the “.lookup” attribute:
class LookupType(UserDefinedType):
    """a custom type that accepts a dictionary as a parameter.

    The dictionary is stored both as itself in a private variable,
    and published in a public variable as a sorted tuple of tuples,
    which is hashable and will also return the same value for any
    two equivalent dictionaries.  Note it assumes the keys and
    values of the dictionary are themselves hashable.

    """

    cache_ok = True

    def __init__(self, lookup):
        self._lookup = lookup

        # assume keys/values of "lookup" are hashable; otherwise
        # they would also need to be converted in some way here
        self.lookup = tuple((key, lookup[key]) for key in sorted(lookup))

    def get_col_spec(self, **kw):
        return "VARCHAR(255)"

    def bind_processor(self, dialect): ...  # works with "self._lookup" ...
Where above, the cache key for LookupType({"a": 10, "b": 20}) will be:
>>> LookupType({"a": 10, "b": 20})._static_cache_key
(<class '__main__.LookupType'>, ('lookup', (('a', 10), ('b', 20))))
Added in version 1.4.14: - added the cache_ok flag to allow some configurability of caching for TypeDecorator classes.
Added in version 1.4.28: - added the ExternalType mixin which generalizes the cache_ok flag to both the TypeDecorator and UserDefinedType classes.
See also
SQL Compilation Caching
class Comparator
A Comparator that is specific to TypeDecorator.
User-defined TypeDecorator classes should not typically need to modify this.
Class signature
class sqlalchemy.types.TypeDecorator.Comparator (sqlalchemy.types.Comparator)
method sqlalchemy.types.TypeDecorator.Comparator.operate(op: OperatorType, *other: Any, **kwargs: Any) → ColumnElement[_CT]
Operate on an argument.
This is the lowest level of operation, raises NotImplementedError by default.
Overriding this on a subclass can allow common behavior to be applied to all operations. For example, overriding ColumnOperators to apply func.lower() to the left and right side:
class MyComparator(ColumnOperators):
    def operate(self, op, other, **kwargs):
        return op(func.lower(self), func.lower(other), **kwargs)
Parameters:
• op – Operator callable.
• *other – the ‘other’ side of the operation. Will be a single scalar for most operations.
• **kwargs – modifiers. These may be passed by special operators such as ColumnOperators.contains().
method sqlalchemy.types.TypeDecorator.Comparator.reverse_operate(op: OperatorType, other: Any, **kwargs: Any) → ColumnElement[_CT]
Reverse operate on an argument.
Usage is the same as operate().
method sqlalchemy.types.TypeDecorator.__init__(*args: Any, **kwargs: Any)
Construct a TypeDecorator.
Arguments sent here are passed to the constructor of the class assigned to the impl class level attribute, assuming the impl is a callable, and the resulting object is assigned to the self.impl instance attribute (thus overriding the class attribute of the same name).
If the class level impl is not a callable (the unusual case), it will be assigned to the same instance attribute ‘as-is’, ignoring those arguments passed to the constructor.
Subclasses can override this to customize the generation of self.impl entirely.
method sqlalchemy.types.TypeDecorator.bind_expression(bindparam: BindParameter[_T]) → ColumnElement[_T] | None
Given a bind value (i.e. a BindParameter instance), return a SQL expression which will typically wrap the given parameter.
Note
This method is called during the SQL compilation phase of a statement, when rendering a SQL string. It is not necessarily called against specific values, and should not be confused with the TypeDecorator.process_bind_param() method, which is the more typical method that processes the actual value passed to a particular parameter at statement execution time.
Subclasses of TypeDecorator can override this method to provide custom bind expression behavior for the type. This implementation will replace that of the underlying implementation type.
method sqlalchemy.types.TypeDecorator.bind_processor(dialect: Dialect) → _BindProcessorType[_T] | None
Provide a bound value processing function for the given Dialect.
This is the method that fulfills the TypeEngine contract for bound value conversion which normally occurs via the TypeEngine.bind_processor() method.
Note
User-defined subclasses of TypeDecorator should not implement this method, and should instead implement TypeDecorator.process_bind_param() so that the “inner” processing provided by the implementing type is maintained.
Parameters:
dialect – Dialect instance in use.
method sqlalchemy.types.TypeDecorator.coerce_compared_value(op: OperatorType | None, value: Any) → Any
Suggest a type for a ‘coerced’ Python value in an expression.
By default, returns self. This method is called by the expression system when an object using this type is on the left or right side of an expression against a plain Python object which does not yet have a SQLAlchemy type assigned:
expr = table.c.somecolumn + 35
Where above, if somecolumn uses this type, this method will be called with the value operator.add and 35. The return value is whatever SQLAlchemy type should be used for 35 for this particular operation.
attribute sqlalchemy.types.TypeDecorator.coerce_to_is_types: Sequence[Type[Any]] = (<class 'NoneType'>,)
Specify those Python types which should be coerced at the expression level to “IS <constant>” when compared using == (and same for IS NOT in conjunction with !=).
For most SQLAlchemy types, this includes NoneType, as well as bool.
TypeDecorator modifies this list to only include NoneType, as typedecorator implementations that deal with boolean types are common.
Custom TypeDecorator classes can override this attribute to return an empty tuple, in which case no values will be coerced to constants.
method sqlalchemy.types.TypeDecorator.column_expression(column: ColumnElement[_T]) → ColumnElement[_T] | None
Given a SELECT column expression, return a wrapping SQL expression.
Note
This method is called during the SQL compilation phase of a statement, when rendering a SQL string. It is not called against specific values, and should not be confused with the TypeDecorator.process_result_value() method, which is the more typical method that processes the actual value returned in a result row subsequent to statement execution time.
Subclasses of TypeDecorator can override this method to provide custom column expression behavior for the type. This implementation will replace that of the underlying implementation type.
See the description of TypeEngine.column_expression() for a complete description of the method’s use.
attribute sqlalchemy.types.TypeDecorator.comparator_factory: _ComparatorFactory[Any]
A Comparator class which will apply to operations performed by owning ColumnElement objects.
The comparator_factory attribute is a hook consulted by the core expression system when column and SQL expression operations are performed. When a Comparator class is associated with this attribute, it allows custom re-definition of all existing operators, as well as definition of new operators. Existing operators include those provided by Python operator overloading such as ColumnOperators.__add__() and ColumnOperators.__eq__(), those provided as standard attributes of ColumnOperators such as ColumnOperators.like() and ColumnOperators.in_().
Rudimentary usage of this hook is allowed through simple subclassing of existing types, or alternatively by using TypeDecorator. See the documentation section Redefining and Creating New Operators for examples.
method sqlalchemy.types.TypeDecorator.compare_values(x: Any, y: Any) → bool
Given two values, compare them for equality.
By default this calls upon TypeEngine.compare_values() of the underlying “impl”, which in turn usually uses the Python equals operator ==.
This function is used by the ORM to compare an original-loaded value with an intercepted “changed” value, to determine if a net change has occurred.
method sqlalchemy.types.TypeDecorator.copy(**kw: Any) → Self
Produce a copy of this TypeDecorator instance.
This is a shallow copy and is provided to fulfill part of the TypeEngine contract. It usually does not need to be overridden unless the user-defined TypeDecorator has local state that should be deep-copied.
method sqlalchemy.types.TypeDecorator.get_dbapi_type(dbapi: DBAPIModule) → Any | None
Return the DBAPI type object represented by this TypeDecorator.
By default this calls upon TypeEngine.get_dbapi_type() of the underlying “impl”.
method sqlalchemy.types.TypeDecorator.literal_processor(dialect: Dialect) → _LiteralProcessorType[_T] | None
Provide a literal processing function for the given Dialect.
This is the method that fulfills the TypeEngine contract for literal value conversion which normally occurs via the TypeEngine.literal_processor() method.
Note
User-defined subclasses of TypeDecorator should not implement this method, and should instead implement TypeDecorator.process_literal_param() so that the “inner” processing provided by the implementing type is maintained.
method sqlalchemy.types.TypeDecorator.load_dialect_impl(dialect: Dialect) → TypeEngine[Any]
Return a TypeEngine object corresponding to a dialect.
This is an end-user override hook that can be used to provide differing types depending on the given dialect. It is used by the TypeDecorator implementation of type_engine() to help determine what type should ultimately be returned for a given TypeDecorator.
By default returns self.impl.
method sqlalchemy.types.TypeDecorator.process_bind_param(value: _T | None, dialect: Dialect) → Any
Receive a bound parameter value to be converted.
Custom subclasses of TypeDecorator should override this method to provide custom behaviors for incoming data values. This method is called at statement execution time and is passed the literal Python data value which is to be associated with a bound parameter in the statement.
The operation could be anything desired to perform custom behavior, such as transforming or serializing data. This could also be used as a hook for validating logic.
Parameters:
• value – Data to operate upon, of any type expected by this method in the subclass. Can be None.
• dialect – the Dialect in use.
See also
Augmenting Existing Types
TypeDecorator.process_result_value()
method sqlalchemy.types.TypeDecorator.process_literal_param(value: _T | None, dialect: Dialect) → str
Receive a literal parameter value to be rendered inline within a statement.
Note
This method is called during the SQL compilation phase of a statement, when rendering a SQL string. Unlike other SQL compilation methods, it is passed a specific Python value to be rendered as a string. However it should not be confused with the TypeDecorator.process_bind_param() method, which is the more typical method that processes the actual value passed to a particular parameter at statement execution time.
Custom subclasses of TypeDecorator should override this method to provide custom behaviors for incoming data values that are in the special case of being rendered as literals.
The returned string will be rendered into the output string.
method sqlalchemy.types.TypeDecorator.process_result_value(value: Any | None, dialect: Dialect) → _T | None
Receive a result-row column value to be converted.
Custom subclasses of TypeDecorator should override this method to provide custom behaviors for data values being received in result rows coming from the database. This method is called at result fetching time and is passed the literal Python data value that’s extracted from a database result row.
The operation could be anything desired to perform custom behavior, such as transforming or deserializing data.
Parameters:
• value – Data to operate upon, of any type expected by this method in the subclass. Can be None.
• dialect – the Dialect in use.
See also
Augmenting Existing Types
TypeDecorator.process_bind_param()
method sqlalchemy.types.TypeDecorator.result_processor(dialect: Dialect, coltype: Any) → _ResultProcessorType[_T] | None
Provide a result value processing function for the given Dialect.
This is the method that fulfills the TypeEngine contract for bound value conversion which normally occurs via the TypeEngine.result_processor() method.
Note
User-defined subclasses of TypeDecorator should not implement this method, and should instead implement TypeDecorator.process_result_value() so that the “inner” processing provided by the implementing type is maintained.
Parameters:
• dialect – Dialect instance in use.
• coltype – A SQLAlchemy data type
attribute sqlalchemy.types.TypeDecorator.sort_key_function: Callable[[Any], Any] | None
A sorting function that can be passed as the key to sorted.
The default value of None indicates that the values stored by this type are self-sorting.
Added in version 1.3.8.
method sqlalchemy.types.TypeDecorator.type_engine(dialect: Dialect) → TypeEngine[Any]
Return a dialect-specific TypeEngine instance for this TypeDecorator.
In most cases this returns a dialect-adapted form of the TypeEngine type represented by self.impl. Makes usage of dialect_impl(). Behavior can be customized here by overriding load_dialect_impl().
TypeDecorator Recipes
A few key TypeDecorator recipes follow.
Coercing Encoded Strings to Unicode
A common source of confusion regarding the Unicode type is that it is intended to deal only with Python unicode objects on the Python side, meaning values passed to it as bind parameters must be of the form u'some string' if using Python 2 and not 3. The encoding/decoding functions it performs are only to suit what the DBAPI in use requires, and are primarily a private implementation detail.
The use case of a type that can safely receive Python bytestrings, that is strings that contain non-ASCII characters and are not u'' objects in Python 2, can be achieved using a TypeDecorator which coerces as needed:
from sqlalchemy.types import TypeDecorator, Unicode


class CoerceUTF8(TypeDecorator):
    """Safely coerce Python bytestrings to Unicode
    before passing off to the database."""

    impl = Unicode

    def process_bind_param(self, value, dialect):
        if isinstance(value, str):
            value = value.decode("utf-8")
        return value
Rounding Numerics
Some database connectors like those of SQL Server choke if a Decimal is passed with too many decimal places. Here’s a recipe that rounds them down:
from sqlalchemy.types import TypeDecorator, Numeric
from decimal import Decimal


class SafeNumeric(TypeDecorator):
    """Adds quantization to Numeric."""

    impl = Numeric

    def __init__(self, *arg, **kw):
        TypeDecorator.__init__(self, *arg, **kw)
        self.quantize_int = -self.impl.scale
        self.quantize = Decimal(10) ** self.quantize_int

    def process_bind_param(self, value, dialect):
        if isinstance(value, Decimal) and value.as_tuple()[2] < self.quantize_int:
            value = value.quantize(self.quantize)
        return value
Store Timezone Aware Timestamps as Timezone Naive UTC
Timestamps in databases should always be stored in a timezone-agnostic way. For most databases, this means ensuring a timestamp is first in the UTC timezone before it is stored, then storing it as timezone-naive (that is, without any timezone associated with it; UTC is assumed to be the “implicit” timezone). Alternatively, database-specific types like PostgreSQLs “TIMESTAMP WITH TIMEZONE” are often preferred for their richer functionality; however, storing as plain UTC will work on all databases and drivers. When a timezone-intelligent database type is not an option or is not preferred, the TypeDecorator can be used to create a datatype that convert timezone aware timestamps into timezone naive and back again. Below, Python’s built-in datetime.timezone.utc timezone is used to normalize and denormalize:
import datetime


class TZDateTime(TypeDecorator):
    impl = DateTime
    cache_ok = True

    def process_bind_param(self, value, dialect):
        if value is not None:
            if not value.tzinfo or value.tzinfo.utcoffset(value) is None:
                raise TypeError("tzinfo is required")
            value = value.astimezone(datetime.timezone.utc).replace(tzinfo=None)
        return value

    def process_result_value(self, value, dialect):
        if value is not None:
            value = value.replace(tzinfo=datetime.timezone.utc)
        return value
Backend-agnostic GUID Type
Note
Since version 2.0 the built-in Uuid type that behaves similarly should be preferred. This example is presented just as an example of a type decorator that receives and returns python objects.
Receives and returns Python uuid() objects. Uses the PG UUID type when using PostgreSQL, UNIQUEIDENTIFIER when using MSSQL, CHAR(32) on other backends, storing them in stringified format. The GUIDHyphens version stores the value with hyphens instead of just the hex string, using a CHAR(36) type:
from operator import attrgetter
from sqlalchemy.types import TypeDecorator, CHAR
from sqlalchemy.dialects.mssql import UNIQUEIDENTIFIER
from sqlalchemy.dialects.postgresql import UUID
import uuid


class GUID(TypeDecorator):
    """Platform-independent GUID type.

    Uses PostgreSQL's UUID type or MSSQL's UNIQUEIDENTIFIER,
    otherwise uses CHAR(32), storing as stringified hex values.

    """

    impl = CHAR
    cache_ok = True

    _default_type = CHAR(32)
    _uuid_as_str = attrgetter("hex")

    def load_dialect_impl(self, dialect):
        if dialect.name == "postgresql":
            return dialect.type_descriptor(UUID())
        elif dialect.name == "mssql":
            return dialect.type_descriptor(UNIQUEIDENTIFIER())
        else:
            return dialect.type_descriptor(self._default_type)

    def process_bind_param(self, value, dialect):
        if value is None or dialect.name in ("postgresql", "mssql"):
            return value
        else:
            if not isinstance(value, uuid.UUID):
                value = uuid.UUID(value)
            return self._uuid_as_str(value)

    def process_result_value(self, value, dialect):
        if value is None:
            return value
        else:
            if not isinstance(value, uuid.UUID):
                value = uuid.UUID(value)
            return value


class GUIDHyphens(GUID):
    """Platform-independent GUID type.

    Uses PostgreSQL's UUID type or MSSQL's UNIQUEIDENTIFIER,
    otherwise uses CHAR(36), storing as stringified uuid values.

    """

    _default_type = CHAR(36)
    _uuid_as_str = str
Linking Python uuid.UUID to the Custom Type for ORM mappings
When declaring ORM mappings using Annotated Declarative Table mappings, the custom GUID type defined above may be associated with the Python uuid.UUID datatype by adding it to the type annotation map, which is typically defined on the DeclarativeBase class:
import uuid
from sqlalchemy.orm import DeclarativeBase, Mapped, mapped_column


class Base(DeclarativeBase):
    type_annotation_map = {
        uuid.UUID: GUID,
    }
With the above configuration, ORM mapped classes which extend from Base may refer to Python uuid.UUID in annotations which will make use of GUID automatically:
class MyModel(Base):
    __tablename__ = "my_table"

    id: Mapped[uuid.UUID] = mapped_column(primary_key=True)
See also
Customizing the Type Map
Marshal JSON Strings
This type uses simplejson to marshal Python data structures to/from JSON. Can be modified to use Python’s builtin json encoder:
from sqlalchemy.types import TypeDecorator, VARCHAR
import json


class JSONEncodedDict(TypeDecorator):
    """Represents an immutable structure as a json-encoded string.

    Usage:

        JSONEncodedDict(255)

    """

    impl = VARCHAR

    cache_ok = True

    def process_bind_param(self, value, dialect):
        if value is not None:
            value = json.dumps(value)

        return value

    def process_result_value(self, value, dialect):
        if value is not None:
            value = json.loads(value)
        return value
Adding Mutability
The ORM by default will not detect “mutability” on such a type as above - meaning, in-place changes to values will not be detected and will not be flushed. Without further steps, you instead would need to replace the existing value with a new one on each parent object to detect changes:
obj.json_value["key"] = "value"  # will *not* be detected by the ORM

obj.json_value = {"key": "value"}  # *will* be detected by the ORM
The above limitation may be fine, as many applications may not require that the values are ever mutated once created. For those which do have this requirement, support for mutability is best applied using the sqlalchemy.ext.mutable extension. For a dictionary-oriented JSON structure, we can apply this as:
json_type = MutableDict.as_mutable(JSONEncodedDict)


class MyClass(Base):
    #  ...

    json_data = Column(json_type)
See also
Mutation Tracking
Dealing with Comparison Operations
The default behavior of TypeDecorator is to coerce the “right hand side” of any expression into the same type. For a type like JSON, this means that any operator used must make sense in terms of JSON. For some cases, users may wish for the type to behave like JSON in some circumstances, and as plain text in others. One example is if one wanted to handle the LIKE operator for the JSON type. LIKE makes no sense against a JSON structure, but it does make sense against the underlying textual representation. To get at this with a type like JSONEncodedDict, we need to coerce the column to a textual form using cast() or type_coerce() before attempting to use this operator:
from sqlalchemy import type_coerce, String

stmt = select(my_table).where(type_coerce(my_table.c.json_data, String).like("%foo%"))
TypeDecorator provides a built-in system for working up type translations like these based on operators. If we wanted to frequently use the LIKE operator with our JSON object interpreted as a string, we can build it into the type by overriding the TypeDecorator.coerce_compared_value() method:
from sqlalchemy.sql import operators
from sqlalchemy import String


class JSONEncodedDict(TypeDecorator):
    impl = VARCHAR

    cache_ok = True

    def coerce_compared_value(self, op, value):
        if op in (operators.like_op, operators.not_like_op):
            return String()
        else:
            return self

    def process_bind_param(self, value, dialect):
        if value is not None:
            value = json.dumps(value)

        return value

    def process_result_value(self, value, dialect):
        if value is not None:
            value = json.loads(value)
        return value
Above is just one approach to handling an operator like “LIKE”. Other applications may wish to raise NotImplementedError for operators that have no meaning with a JSON object such as “LIKE”, rather than automatically coercing to text.
Applying SQL-level Bind/Result Processing
As seen in the section Augmenting Existing Types, SQLAlchemy allows Python functions to be invoked both when parameters are sent to a statement, as well as when result rows are loaded from the database, to apply transformations to the values as they are sent to or from the database. It is also possible to define SQL-level transformations as well. The rationale here is when only the relational database contains a particular series of functions that are necessary to coerce incoming and outgoing data between an application and persistence format. Examples include using database-defined encryption/decryption functions, as well as stored procedures that handle geographic data.
Any TypeEngine, UserDefinedType or TypeDecorator subclass can include implementations of TypeEngine.bind_expression() and/or TypeEngine.column_expression(), which when defined to return a non-None value should return a ColumnElement expression to be injected into the SQL statement, either surrounding bound parameters or a column expression.
Tip
As SQL-level result processing features are intended to assist with coercing data from a SELECT statement into result rows in Python, the TypeEngine.column_expression() conversion method is applied only to the outermost columns clause in a SELECT; it does not apply to columns rendered inside of subqueries, as these column expressions are not directly delivered to a result. The expression should not be applied to both, as this would lead to double-conversion of columns, and the “outermost” level rather than the “innermost” level is used so that conversion routines don’t interfere with the internal expressions used by the statement, and so that only data that’s outgoing to a result row is actually subject to conversion, which is consistent with the result row processing functionality provided by TypeDecorator.process_result_value().
For example, to build a Geometry type which will apply the PostGIS function ST_GeomFromText to all outgoing values and the function ST_AsText to all incoming data, we can create our own subclass of UserDefinedType which provides these methods in conjunction with func:
from sqlalchemy import func
from sqlalchemy.types import UserDefinedType


class Geometry(UserDefinedType):
    def get_col_spec(self):
        return "GEOMETRY"

    def bind_expression(self, bindvalue):
        return func.ST_GeomFromText(bindvalue, type_=self)

    def column_expression(self, col):
        return func.ST_AsText(col, type_=self)
We can apply the Geometry type into Table metadata and use it in a select() construct:
geometry = Table(
    "geometry",
    metadata,
    Column("geom_id", Integer, primary_key=True),
    Column("geom_data", Geometry),
)

print(
    select(geometry).where(
        geometry.c.geom_data == "LINESTRING(189412 252431,189631 259122)"
    )
)
The resulting SQL embeds both functions as appropriate. ST_AsText is applied to the columns clause so that the return value is run through the function before passing into a result set, and ST_GeomFromText is run on the bound parameter so that the passed-in value is converted:
SELECT geometry.geom_id, ST_AsText(geometry.geom_data) AS geom_data_1
FROM geometry
WHERE geometry.geom_data = ST_GeomFromText(:geom_data_2)
The TypeEngine.column_expression() method interacts with the mechanics of the compiler such that the SQL expression does not interfere with the labeling of the wrapped expression. Such as, if we rendered a select() against a label() of our expression, the string label is moved to the outside of the wrapped expression:
print(select(geometry.c.geom_data.label("my_data")))
Output:
SELECT ST_AsText(geometry.geom_data) AS my_data
FROM geometry
Another example is we decorate BYTEA to provide a PGPString, which will make use of the PostgreSQL pgcrypto extension to encrypt/decrypt values transparently:
from sqlalchemy import (
    create_engine,
    String,
    select,
    func,
    MetaData,
    Table,
    Column,
    type_coerce,
    TypeDecorator,
)

from sqlalchemy.dialects.postgresql import BYTEA


class PGPString(TypeDecorator):
    impl = BYTEA

    cache_ok = True

    def __init__(self, passphrase):
        super(PGPString, self).__init__()

        self.passphrase = passphrase

    def bind_expression(self, bindvalue):
        # convert the bind's type from PGPString to
        # String, so that it's passed to psycopg2 as is without
        # a dbapi.Binary wrapper
        bindvalue = type_coerce(bindvalue, String)
        return func.pgp_sym_encrypt(bindvalue, self.passphrase)

    def column_expression(self, col):
        return func.pgp_sym_decrypt(col, self.passphrase)


metadata_obj = MetaData()
message = Table(
    "message",
    metadata_obj,
    Column("username", String(50)),
    Column("message", PGPString("this is my passphrase")),
)

engine = create_engine("postgresql+psycopg2://scott:tiger@localhost/test", echo=True)
with engine.begin() as conn:
    metadata_obj.create_all(conn)

    conn.execute(
        message.insert(),
        {"username": "some user", "message": "this is my message"},
    )

    print(
        conn.scalar(select(message.c.message).where(message.c.username == "some user"))
    )
The pgp_sym_encrypt and pgp_sym_decrypt functions are applied to the INSERT and SELECT statements:
INSERT INTO message (username, message)
  VALUES (%(username)s, pgp_sym_encrypt(%(message)s, %(pgp_sym_encrypt_1)s))
  -- {'username': 'some user', 'message': 'this is my message',
  --  'pgp_sym_encrypt_1': 'this is my passphrase'}

SELECT pgp_sym_decrypt(message.message, %(pgp_sym_decrypt_1)s) AS message_1
  FROM message
  WHERE message.username = %(username_1)s
  -- {'pgp_sym_decrypt_1': 'this is my passphrase', 'username_1': 'some user'}
Redefining and Creating New Operators
SQLAlchemy Core defines a fixed set of expression operators available to all column expressions. Some of these operations have the effect of overloading Python’s built-in operators; examples of such operators include ColumnOperators.__eq__() (table.c.somecolumn == 'foo'), ColumnOperators.__invert__() (~table.c.flag), and ColumnOperators.__add__() (table.c.x + table.c.y). Other operators are exposed as explicit methods on column expressions, such as ColumnOperators.in_() (table.c.value.in_(['x', 'y'])) and ColumnOperators.like() (table.c.value.like('%ed%')).
When the need arises for a SQL operator that isn’t directly supported by the already supplied methods above, the most expedient way to produce this operator is to use the Operators.op() method on any SQL expression object; this method is given a string representing the SQL operator to render, and the return value is a Python callable that accepts any arbitrary right-hand side expression:
>>> from sqlalchemy import column
>>> expr = column("x").op(">>")(column("y"))
>>> print(expr)
x >> y
When making use of custom SQL types, there is also a means of implementing custom operators as above that are automatically present upon any column expression that makes use of that column type, without the need to directly call Operators.op() each time the operator is to be used.
To achieve this, a SQL expression construct consults the TypeEngine object associated with the construct in order to determine the behavior of the built-in operators as well as to look for new methods that may have been invoked. TypeEngine defines a “comparison” object implemented by the Comparator class to provide the base behavior for SQL operators, and many specific types provide their own sub-implementations of this class. User-defined Comparator implementations can be built directly into a simple subclass of a particular type in order to override or define new operations. Below, we create a Integer subclass which overrides the ColumnOperators.__add__() operator, which in turn uses Operators.op() to produce the custom SQL itself:
from sqlalchemy import Integer


class MyInt(Integer):
    class comparator_factory(Integer.Comparator):
        def __add__(self, other):
            return self.op("goofy")(other)
The above configuration creates a new class MyInt, which establishes the TypeEngine.comparator_factory attribute as referring to a new class, subclassing the Comparator class associated with the Integer type.
Usage:
>>> sometable = Table("sometable", metadata, Column("data", MyInt))
>>> print(sometable.c.data + 5)
sometable.data goofy :data_1
The implementation for ColumnOperators.__add__() is consulted by an owning SQL expression, by instantiating the Comparator with itself as the expr attribute. This attribute may be used when the implementation needs to refer to the originating ColumnElement object directly:
from sqlalchemy import Integer


class MyInt(Integer):
    class comparator_factory(Integer.Comparator):
        def __add__(self, other):
            return func.special_addition(self.expr, other)
New methods added to a Comparator are exposed on an owning SQL expression object using a dynamic lookup scheme, which exposes methods added to Comparator onto the owning ColumnElement expression construct. For example, to add a log() function to integers:
from sqlalchemy import Integer, func


class MyInt(Integer):
    class comparator_factory(Integer.Comparator):
        def log(self, other):
            return func.log(self.expr, other)
Using the above type:
>>> print(sometable.c.data.log(5))
log(:log_1, :log_2)
When using Operators.op() for comparison operations that return a boolean result, the Operators.op.is_comparison flag should be set to True:
class MyInt(Integer):
    class comparator_factory(Integer.Comparator):
        def is_frobnozzled(self, other):
            return self.op("--is_frobnozzled->", is_comparison=True)(other)
Unary operations are also possible. For example, to add an implementation of the PostgreSQL factorial operator, we combine the UnaryExpression construct along with a custom_op to produce the factorial expression:
from sqlalchemy import Integer
from sqlalchemy.sql.expression import UnaryExpression
from sqlalchemy.sql import operators


class MyInteger(Integer):
    class comparator_factory(Integer.Comparator):
        def factorial(self):
            return UnaryExpression(
                self.expr, modifier=operators.custom_op("!"), type_=MyInteger
            )
Using the above type:
>>> from sqlalchemy.sql import column
>>> print(column("x", MyInteger).factorial())
x !
See also
Operators.op()
TypeEngine.comparator_factory
Creating New Types
The UserDefinedType class is provided as a simple base class for defining entirely new database types. Use this to represent native database types not known by SQLAlchemy. If only Python translation behavior is needed, use TypeDecorator instead.
Object NameDescriptionUserDefinedTypeBase for user defined types.class sqlalchemy.types.UserDefinedType
Base for user defined types.
This should be the base of new types. Note that for most cases, TypeDecorator is probably more appropriate:
import sqlalchemy.types as types


class MyType(types.UserDefinedType):
    cache_ok = True

    def __init__(self, precision=8):
        self.precision = precision

    def get_col_spec(self, **kw):
        return "MYTYPE(%s)" % self.precision

    def bind_processor(self, dialect):
        def process(value):
            return value

        return process

    def result_processor(self, dialect, coltype):
        def process(value):
            return value

        return process
Once the type is made, it’s immediately usable:
table = Table(
    "foo",
    metadata_obj,
    Column("id", Integer, primary_key=True),
    Column("data", MyType(16)),
)
The get_col_spec() method will in most cases receive a keyword argument type_expression which refers to the owning expression of the type as being compiled, such as a Column or cast() construct. This keyword is only sent if the method accepts keyword arguments (e.g. **kw) in its argument signature; introspection is used to check for this in order to support legacy forms of this function.
The UserDefinedType.cache_ok class-level flag indicates if this custom UserDefinedType is safe to be used as part of a cache key. This flag defaults to None which will initially generate a warning when the SQL compiler attempts to generate a cache key for a statement that uses this type. If the UserDefinedType is not guaranteed to produce the same bind/result behavior and SQL generation every time, this flag should be set to False; otherwise if the class produces the same behavior each time, it may be set to True. See UserDefinedType.cache_ok for further notes on how this works.
Added in version 1.4.28: Generalized the ExternalType.cache_ok flag so that it is available for both TypeDecorator as well as UserDefinedType.
Members
cache_ok, coerce_compared_value(), ensure_kwarg
Class signature
class sqlalchemy.types.UserDefinedType (sqlalchemy.types.ExternalType, sqlalchemy.types.TypeEngineMixin, sqlalchemy.types.TypeEngine, sqlalchemy.util.langhelpers.EnsureKWArg)
attribute sqlalchemy.types.UserDefinedType.cache_ok: bool | None = None
inherited from the ExternalType.cache_ok attribute of ExternalType
Indicate if statements using this ExternalType are “safe to cache”.
The default value None will emit a warning and then not allow caching of a statement which includes this type. Set to False to disable statements using this type from being cached at all without a warning. When set to True, the object’s class and selected elements from its state will be used as part of the cache key. For example, using a TypeDecorator:
class MyType(TypeDecorator):
    impl = String

    cache_ok = True

    def __init__(self, choices):
        self.choices = tuple(choices)
        self.internal_only = True
The cache key for the above type would be equivalent to:
>>> MyType(["a", "b", "c"])._static_cache_key
(<class '__main__.MyType'>, ('choices', ('a', 'b', 'c')))
The caching scheme will extract attributes from the type that correspond to the names of parameters in the __init__() method. Above, the “choices” attribute becomes part of the cache key but “internal_only” does not, because there is no parameter named “internal_only”.
The requirements for cacheable elements is that they are hashable and also that they indicate the same SQL rendered for expressions using this type every time for a given cache value.
To accommodate for datatypes that refer to unhashable structures such as dictionaries, sets and lists, these objects can be made “cacheable” by assigning hashable structures to the attributes whose names correspond with the names of the arguments. For example, a datatype which accepts a dictionary of lookup values may publish this as a sorted series of tuples. Given a previously un-cacheable type as:
class LookupType(UserDefinedType):
    """a custom type that accepts a dictionary as a parameter.

    this is the non-cacheable version, as "self.lookup" is not
    hashable.

    """

    def __init__(self, lookup):
        self.lookup = lookup

    def get_col_spec(self, **kw):
        return "VARCHAR(255)"

    def bind_processor(self, dialect): ...  # works with "self.lookup" ...
Where “lookup” is a dictionary. The type will not be able to generate a cache key:
>>> type_ = LookupType({"a": 10, "b": 20})
>>> type_._static_cache_key
<stdin>:1: SAWarning: UserDefinedType LookupType({'a': 10, 'b': 20}) will not
produce a cache key because the ``cache_ok`` flag is not set to True.
Set this flag to True if this type object's state is safe to use
in a cache key, or False to disable this warning.
symbol('no_cache')
If we did set up such a cache key, it wouldn’t be usable. We would get a tuple structure that contains a dictionary inside of it, which cannot itself be used as a key in a “cache dictionary” such as SQLAlchemy’s statement cache, since Python dictionaries aren’t hashable:
>>> # set cache_ok = True
>>> type_.cache_ok = True

>>> # this is the cache key it would generate
>>> key = type_._static_cache_key
>>> key
(<class '__main__.LookupType'>, ('lookup', {'a': 10, 'b': 20}))

>>> # however this key is not hashable, will fail when used with
>>> # SQLAlchemy statement cache
>>> some_cache = {key: "some sql value"}
Traceback (most recent call last): File "<stdin>", line 1,
in <module> TypeError: unhashable type: 'dict'
The type may be made cacheable by assigning a sorted tuple of tuples to the “.lookup” attribute:
class LookupType(UserDefinedType):
    """a custom type that accepts a dictionary as a parameter.

    The dictionary is stored both as itself in a private variable,
    and published in a public variable as a sorted tuple of tuples,
    which is hashable and will also return the same value for any
    two equivalent dictionaries.  Note it assumes the keys and
    values of the dictionary are themselves hashable.

    """

    cache_ok = True

    def __init__(self, lookup):
        self._lookup = lookup

        # assume keys/values of "lookup" are hashable; otherwise
        # they would also need to be converted in some way here
        self.lookup = tuple((key, lookup[key]) for key in sorted(lookup))

    def get_col_spec(self, **kw):
        return "VARCHAR(255)"

    def bind_processor(self, dialect): ...  # works with "self._lookup" ...
Where above, the cache key for LookupType({"a": 10, "b": 20}) will be:
>>> LookupType({"a": 10, "b": 20})._static_cache_key
(<class '__main__.LookupType'>, ('lookup', (('a', 10), ('b', 20))))
Added in version 1.4.14: - added the cache_ok flag to allow some configurability of caching for TypeDecorator classes.
Added in version 1.4.28: - added the ExternalType mixin which generalizes the cache_ok flag to both the TypeDecorator and UserDefinedType classes.
See also
SQL Compilation Caching
method sqlalchemy.types.UserDefinedType.coerce_compared_value(op: OperatorType | None, value: Any) → TypeEngine[Any]
Suggest a type for a ‘coerced’ Python value in an expression.
Default behavior for UserDefinedType is the same as that of TypeDecorator; by default it returns self, assuming the compared value should be coerced into the same type as this one. See TypeDecorator.coerce_compared_value() for more detail.
attribute sqlalchemy.types.UserDefinedType.ensure_kwarg: str = 'get_col_spec'
a regular expression that indicates method names for which the method should accept **kw arguments.
The class will scan for methods matching the name template and decorate them if necessary to ensure **kw parameters are accepted.
Working with Custom Types and Reflection
It is important to note that database types which are modified to have additional in-Python behaviors, including types based on TypeDecorator as well as other user-defined subclasses of datatypes, do not have any representation within a database schema. When using database the introspection features described at Reflecting Database Objects, SQLAlchemy makes use of a fixed mapping which links the datatype information reported by a database server to a SQLAlchemy datatype object. For example, if we look inside of a PostgreSQL schema at the definition for a particular database column, we might receive back the string "VARCHAR". SQLAlchemy’s PostgreSQL dialect has a hardcoded mapping which links the string name "VARCHAR" to the SQLAlchemy VARCHAR class, and that’s how when we emit a statement like Table('my_table', m, autoload_with=engine), the Column object within it would have an instance of VARCHAR present inside of it.
The implication of this is that if a Table object makes use of type objects that don’t correspond directly to the database-native type name, if we create a new Table object against a new MetaData collection for this database table elsewhere using reflection, it will not have this datatype. For example:
>>> from sqlalchemy import (
...     Table,
...     Column,
...     MetaData,
...     create_engine,
...     PickleType,
...     Integer,
... )
>>> metadata = MetaData()
>>> my_table = Table(
...     "my_table", metadata, Column("id", Integer), Column("data", PickleType)
... )
>>> engine = create_engine("sqlite://", echo="debug")
>>> my_table.create(engine)
INFO sqlalchemy.engine.base.Engine
CREATE TABLE my_table (
    id INTEGER,
    data BLOB
)
Above, we made use of PickleType, which is a TypeDecorator that works on top of the LargeBinary datatype, which on SQLite corresponds to the database type BLOB. In the CREATE TABLE, we see that the BLOB datatype is used. The SQLite database knows nothing about the PickleType we’ve used.
If we look at the datatype of my_table.c.data.type, as this is a Python object that was created by us directly, it is PickleType:
>>> my_table.c.data.type
PickleType()
However, if we create another instance of Table using reflection, the use of PickleType is not represented in the SQLite database we’ve created; we instead get back BLOB:
>>> metadata_two = MetaData()
>>> my_reflected_table = Table("my_table", metadata_two, autoload_with=engine)
INFO sqlalchemy.engine.base.Engine PRAGMA main.table_info("my_table")
INFO sqlalchemy.engine.base.Engine ()
DEBUG sqlalchemy.engine.base.Engine Col ('cid', 'name', 'type', 'notnull', 'dflt_value', 'pk')
DEBUG sqlalchemy.engine.base.Engine Row (0, 'id', 'INTEGER', 0, None, 0)
DEBUG sqlalchemy.engine.base.Engine Row (1, 'data', 'BLOB', 0, None, 0)

>>> my_reflected_table.c.data.type
BLOB()
Typically, when an application defines explicit Table metadata with custom types, there is no need to use table reflection because the necessary Table metadata is already present. However, for the case where an application, or a combination of them, need to make use of both explicit Table metadata which includes custom, Python-level datatypes, as well as Table objects which set up their Column objects as reflected from the database, which nevertheless still need to exhibit the additional Python behaviors of the custom datatypes, additional steps must be taken to allow this.
The most straightforward is to override specific columns as described at Overriding Reflected Columns. In this technique, we simply use reflection in combination with explicit Column objects for those columns for which we want to use a custom or decorated datatype:
>>> metadata_three = MetaData()
>>> my_reflected_table = Table(
...     "my_table",
...     metadata_three,
...     Column("data", PickleType),
...     autoload_with=engine,
... )
The my_reflected_table object above is reflected, and will load the definition of the “id” column from the SQLite database. But for the “data” column, we’ve overridden the reflected object with an explicit Column definition that includes our desired in-Python datatype, the PickleType. The reflection process will leave this Column object intact:
>>> my_reflected_table.c.data.type
PickleType()
A more elaborate way to convert from database-native type objects to custom datatypes is to use the DDLEvents.column_reflect() event handler. If for example we knew that we wanted all BLOB datatypes to in fact be PickleType, we could set up a rule across the board:
from sqlalchemy import BLOB
from sqlalchemy import event
from sqlalchemy import PickleType
from sqlalchemy import Table


@event.listens_for(Table, "column_reflect")
def _setup_pickletype(inspector, table, column_info):
    if isinstance(column_info["type"], BLOB):
        column_info["type"] = PickleType()
When the above code is invoked before any table reflection occurs (note also it should be invoked only once in the application, as it is a global rule), upon reflecting any Table that includes a column with a BLOB datatype, the resulting datatype will be stored in the Column object as PickleType.
In practice, the above event-based approach would likely have additional rules in order to affect only those columns where the datatype is important, such as a lookup table of table names and possibly column names, or other heuristics in order to accurately determine which columns should be established with an in Python datatype.


Base Type API
Object NameDescriptionConcatenableA mixin that marks a type as supporting ‘concatenation’, typically strings.ExternalTypemixin that defines attributes and behaviors specific to third-party datatypes.IndexableA mixin that marks a type as supporting indexing operations, such as array or JSON structures.NullTypeAn unknown type.TypeEngineThe ultimate base class for all SQL datatypes.Variantdeprecated. symbol is present for backwards-compatibility with workaround recipes, however this actual type should not be used.class sqlalchemy.types.TypeEngine
The ultimate base class for all SQL datatypes.
Common subclasses of TypeEngine include String, Integer, and Boolean.
For an overview of the SQLAlchemy typing system, see SQL Datatype Objects.
See also
SQL Datatype Objects
Members
operate(), reverse_operate(), adapt(), as_generic(), bind_expression(), bind_processor(), coerce_compared_value(), column_expression(), comparator_factory, compare_values(), compile(), dialect_impl(), evaluates_none(), get_dbapi_type(), hashable, literal_processor(), python_type, render_bind_cast, render_literal_cast, result_processor(), should_evaluate_none, sort_key_function, with_variant()
Class signature
class sqlalchemy.types.TypeEngine (sqlalchemy.sql.visitors.Visitable, typing.Generic)
class Comparator
Base class for custom comparison operations defined at the type level. See TypeEngine.comparator_factory.
Class signature
class sqlalchemy.types.TypeEngine.Comparator (sqlalchemy.sql.expression.ColumnOperators, typing.Generic)
method sqlalchemy.types.TypeEngine.Comparator.operate(op: OperatorType, *other: Any, **kwargs: Any) → ColumnElement[Any]
Operate on an argument.
This is the lowest level of operation, raises NotImplementedError by default.
Overriding this on a subclass can allow common behavior to be applied to all operations. For example, overriding ColumnOperators to apply func.lower() to the left and right side:
class MyComparator(ColumnOperators):
    def operate(self, op, other, **kwargs):
        return op(func.lower(self), func.lower(other), **kwargs)
Parameters:
• op – Operator callable.
• *other – the ‘other’ side of the operation. Will be a single scalar for most operations.
• **kwargs – modifiers. These may be passed by special operators such as ColumnOperators.contains().
method sqlalchemy.types.TypeEngine.Comparator.reverse_operate(op: OperatorType, other: Any, **kwargs: Any) → ColumnElement[_CT]
Reverse operate on an argument.
Usage is the same as operate().
method sqlalchemy.types.TypeEngine.adapt(cls: Type[TypeEngine | TypeEngineMixin], **kw: Any) → TypeEngine
Produce an “adapted” form of this type, given an “impl” class to work with.
This method is used internally to associate generic types with “implementation” types that are specific to a particular dialect.
method sqlalchemy.types.TypeEngine.as_generic(allow_nulltype: bool = False) → TypeEngine
Return an instance of the generic type corresponding to this type using heuristic rule. The method may be overridden if this heuristic rule is not sufficient.
>>> from sqlalchemy.dialects.mysql import INTEGER
>>> INTEGER(display_width=4).as_generic()
Integer()
>>> from sqlalchemy.dialects.mysql import NVARCHAR
>>> NVARCHAR(length=100).as_generic()
Unicode(length=100)
Added in version 1.4.0b2.
See also
Reflecting with Database-Agnostic Types - describes the use of TypeEngine.as_generic() in conjunction with the DDLEvents.column_reflect() event, which is its intended use.
method sqlalchemy.types.TypeEngine.bind_expression(bindvalue: BindParameter[_T]) → ColumnElement[_T] | None
Given a bind value (i.e. a BindParameter instance), return a SQL expression in its place.
This is typically a SQL function that wraps the existing bound parameter within the statement. It is used for special data types that require literals being wrapped in some special database function in order to coerce an application-level value into a database-specific format. It is the SQL analogue of the TypeEngine.bind_processor() method.
This method is called during the SQL compilation phase of a statement, when rendering a SQL string. It is not called against specific values.
Note that this method, when implemented, should always return the exact same structure, without any conditional logic, as it may be used in an executemany() call against an arbitrary number of bound parameter sets.
Note
This method is only called relative to a dialect specific type object, which is often private to a dialect in use and is not the same type object as the public facing one, which means it’s not feasible to subclass a TypeEngine class in order to provide an alternate TypeEngine.bind_expression() method, unless subclassing the UserDefinedType class explicitly.
To provide alternate behavior for TypeEngine.bind_expression(), implement a TypeDecorator class and provide an implementation of TypeDecorator.bind_expression().
See also
Augmenting Existing Types
See also
Applying SQL-level Bind/Result Processing
method sqlalchemy.types.TypeEngine.bind_processor(dialect: Dialect) → _BindProcessorType[_T] | None
Return a conversion function for processing bind values.
Returns a callable which will receive a bind parameter value as the sole positional argument and will return a value to send to the DB-API.
If processing is not necessary, the method should return None.
Tip
This method is only called relative to a dialect specific type object, which is often private to a dialect in use and is not the same type object as the public facing one, which means it’s not feasible to subclass a TypeEngine class in order to provide an alternate TypeEngine.bind_processor() method, unless subclassing the UserDefinedType class explicitly.
To provide alternate behavior for TypeEngine.bind_processor(), implement a TypeDecorator class and provide an implementation of TypeDecorator.process_bind_param().
See also
Augmenting Existing Types
Parameters:
dialect – Dialect instance in use.
method sqlalchemy.types.TypeEngine.coerce_compared_value(op: OperatorType | None, value: Any) → TypeEngine[Any]
Suggest a type for a ‘coerced’ Python value in an expression.
Given an operator and value, gives the type a chance to return a type which the value should be coerced into.
The default behavior here is conservative; if the right-hand side is already coerced into a SQL type based on its Python type, it is usually left alone.
End-user functionality extension here should generally be via TypeDecorator, which provides more liberal behavior in that it defaults to coercing the other side of the expression into this type, thus applying special Python conversions above and beyond those needed by the DBAPI to both ides. It also provides the public method TypeDecorator.coerce_compared_value() which is intended for end-user customization of this behavior.
method sqlalchemy.types.TypeEngine.column_expression(colexpr: ColumnElement[_T]) → ColumnElement[_T] | None
Given a SELECT column expression, return a wrapping SQL expression.
This is typically a SQL function that wraps a column expression as rendered in the columns clause of a SELECT statement. It is used for special data types that require columns to be wrapped in some special database function in order to coerce the value before being sent back to the application. It is the SQL analogue of the TypeEngine.result_processor() method.
Note
The column_expression() method is applied only to the outermost columns clause of a SELECT statement, that is, the columns that are to be delivered directly into the returned result rows. It does not apply to the columns clause inside of subqueries. This necessarily avoids double conversions against the column and only runs the conversion when ready to be returned to the client.
This method is called during the SQL compilation phase of a statement, when rendering a SQL string. It is not called against specific values.
Tip
This method is only called relative to a dialect specific type object, which is often private to a dialect in use and is not the same type object as the public facing one, which means it’s not feasible to subclass a TypeEngine class in order to provide an alternate TypeEngine.column_expression() method, unless subclassing the UserDefinedType class explicitly.
To provide alternate behavior for TypeEngine.column_expression(), implement a TypeDecorator class and provide an implementation of TypeDecorator.column_expression().
See also
Augmenting Existing Types
See also
Applying SQL-level Bind/Result Processing
attribute sqlalchemy.types.TypeEngine.comparator_factory
alias of Comparator
method sqlalchemy.types.TypeEngine.compare_values(x: Any, y: Any) → bool
Compare two values for equality.
method sqlalchemy.types.TypeEngine.compile(dialect: Dialect | None = None) → str
Produce a string-compiled form of this TypeEngine.
When called with no arguments, uses a “default” dialect to produce a string result.
Parameters:
dialect – a Dialect instance.
method sqlalchemy.types.TypeEngine.dialect_impl(dialect: Dialect) → TypeEngine[_T]
Return a dialect-specific implementation for this TypeEngine.
method sqlalchemy.types.TypeEngine.evaluates_none() → Self
Return a copy of this type which has the should_evaluate_none flag set to True.
E.g.:
Table(
    "some_table",
    metadata,
    Column(
        String(50).evaluates_none(),
        nullable=True,
        server_default="no value",
    ),
)
The ORM uses this flag to indicate that a positive value of None is passed to the column in an INSERT statement, rather than omitting the column from the INSERT statement which has the effect of firing off column-level defaults. It also allows for types which have special behavior associated with the Python None value to indicate that the value doesn’t necessarily translate into SQL NULL; a prime example of this is a JSON type which may wish to persist the JSON value 'null'.
In all cases, the actual NULL SQL value can be always be persisted in any column by using the null SQL construct in an INSERT statement or associated with an ORM-mapped attribute.
Note
The “evaluates none” flag does not apply to a value of None passed to Column.default or Column.server_default; in these cases, None still means “no default”.
See also
Forcing NULL on a column with a default - in the ORM documentation
JSON.none_as_null - PostgreSQL JSON interaction with this flag.
TypeEngine.should_evaluate_none - class-level flag
method sqlalchemy.types.TypeEngine.get_dbapi_type(dbapi: DBAPIModule) → Any | None
Return the corresponding type object from the underlying DB-API, if any.
This can be useful for calling setinputsizes(), for example.
attribute sqlalchemy.types.TypeEngine.hashable = True
Flag, if False, means values from this type aren’t hashable.
Used by the ORM when uniquing result lists.
method sqlalchemy.types.TypeEngine.literal_processor(dialect: Dialect) → _LiteralProcessorType[_T] | None
Return a conversion function for processing literal values that are to be rendered directly without using binds.
This function is used when the compiler makes use of the “literal_binds” flag, typically used in DDL generation as well as in certain scenarios where backends don’t accept bound parameters.
Returns a callable which will receive a literal Python value as the sole positional argument and will return a string representation to be rendered in a SQL statement.
Tip
This method is only called relative to a dialect specific type object, which is often private to a dialect in use and is not the same type object as the public facing one, which means it’s not feasible to subclass a TypeEngine class in order to provide an alternate TypeEngine.literal_processor() method, unless subclassing the UserDefinedType class explicitly.
To provide alternate behavior for TypeEngine.literal_processor(), implement a TypeDecorator class and provide an implementation of TypeDecorator.process_literal_param().
See also
Augmenting Existing Types
attribute sqlalchemy.types.TypeEngine.python_type
Return the Python type object expected to be returned by instances of this type, if known.
Basically, for those types which enforce a return type, or are known across the board to do such for all common DBAPIs (like int for example), will return that type.
If a return type is not defined, raises NotImplementedError.
Note that any type also accommodates NULL in SQL which means you can also get back None from any type in practice.
attribute sqlalchemy.types.TypeEngine.render_bind_cast = False
Render bind casts for BindTyping.RENDER_CASTS mode.
If True, this type (usually a dialect level impl type) signals to the compiler that a cast should be rendered around a bound parameter for this type.
Added in version 2.0.
See also
BindTyping
attribute sqlalchemy.types.TypeEngine.render_literal_cast = False
render casts when rendering a value as an inline literal, e.g. with TypeEngine.literal_processor().
Added in version 2.0.
method sqlalchemy.types.TypeEngine.result_processor(dialect: Dialect, coltype: object) → _ResultProcessorType[_T] | None
Return a conversion function for processing result row values.
Returns a callable which will receive a result row column value as the sole positional argument and will return a value to return to the user.
If processing is not necessary, the method should return None.
Tip
This method is only called relative to a dialect specific type object, which is often private to a dialect in use and is not the same type object as the public facing one, which means it’s not feasible to subclass a TypeEngine class in order to provide an alternate TypeEngine.result_processor() method, unless subclassing the UserDefinedType class explicitly.
To provide alternate behavior for TypeEngine.result_processor(), implement a TypeDecorator class and provide an implementation of TypeDecorator.process_result_value().
See also
Augmenting Existing Types
Parameters:
• dialect – Dialect instance in use.
• coltype – DBAPI coltype argument received in cursor.description.
attribute sqlalchemy.types.TypeEngine.should_evaluate_none: bool = False
If True, the Python constant None is considered to be handled explicitly by this type.
The ORM uses this flag to indicate that a positive value of None is passed to the column in an INSERT statement, rather than omitting the column from the INSERT statement which has the effect of firing off column-level defaults. It also allows types which have special behavior for Python None, such as a JSON type, to indicate that they’d like to handle the None value explicitly.
To set this flag on an existing type, use the TypeEngine.evaluates_none() method.
See also
TypeEngine.evaluates_none()
attribute sqlalchemy.types.TypeEngine.sort_key_function: Callable[[Any], Any] | None = None
A sorting function that can be passed as the key to sorted.
The default value of None indicates that the values stored by this type are self-sorting.
Added in version 1.3.8.
method sqlalchemy.types.TypeEngine.with_variant(type_: _TypeEngineArgument[Any], *dialect_names: str) → Self
Produce a copy of this type object that will utilize the given type when applied to the dialect of the given name.
e.g.:
from sqlalchemy.types import String
from sqlalchemy.dialects import mysql

string_type = String()

string_type = string_type.with_variant(
    mysql.VARCHAR(collation="foo"), "mysql", "mariadb"
)
The variant mapping indicates that when this type is interpreted by a specific dialect, it will instead be transmuted into the given type, rather than using the primary type.
Changed in version 2.0: the TypeEngine.with_variant() method now works with a TypeEngine object “in place”, returning a copy of the original type rather than returning a wrapping object; the Variant class is no longer used.
Parameters:
• type_ – a TypeEngine that will be selected as a variant from the originating type, when a dialect of the given name is in use.
• *dialect_names – 
one or more base names of the dialect which uses this type. (i.e. 'postgresql', 'mysql', etc.)
Changed in version 2.0: multiple dialect names can be specified for one variant.
See also
Using “UPPERCASE” and Backend-specific types for multiple backends - illustrates the use of TypeEngine.with_variant().
class sqlalchemy.types.Concatenable
A mixin that marks a type as supporting ‘concatenation’, typically strings.
Members
comparator_factory
Class signature
class sqlalchemy.types.Concatenable (sqlalchemy.types.TypeEngineMixin)
class Comparator
Class signature
class sqlalchemy.types.Concatenable.Comparator (sqlalchemy.types.Comparator)
attribute sqlalchemy.types.Concatenable.comparator_factory
alias of Comparator
class sqlalchemy.types.Indexable
A mixin that marks a type as supporting indexing operations, such as array or JSON structures.
Members
comparator_factory
Class signature
class sqlalchemy.types.Indexable (sqlalchemy.types.TypeEngineMixin)
class Comparator
Class signature
class sqlalchemy.types.Indexable.Comparator (sqlalchemy.types.Comparator)
attribute sqlalchemy.types.Indexable.comparator_factory
alias of Comparator
class sqlalchemy.types.NullType
An unknown type.
NullType is used as a default type for those cases where a type cannot be determined, including:
• During table reflection, when the type of a column is not recognized by the Dialect
• When constructing SQL expressions using plain Python objects of unknown types (e.g. somecolumn == my_special_object)
• When a new Column is created, and the given type is passed as None or is not passed at all.
The NullType can be used within SQL expression invocation without issue, it just has no behavior either at the expression construction level or at the bind-parameter/result processing level. NullType will result in a CompileError if the compiler is asked to render the type itself, such as if it is used in a cast() operation or within a schema creation operation such as that invoked by MetaData.create_all() or the CreateTable construct.
Class signature
class sqlalchemy.types.NullType (sqlalchemy.types.TypeEngine)
class sqlalchemy.types.ExternalType
mixin that defines attributes and behaviors specific to third-party datatypes.
“Third party” refers to datatypes that are defined outside the scope of SQLAlchemy within either end-user application code or within external extensions to SQLAlchemy.
Subclasses currently include TypeDecorator and UserDefinedType.
Added in version 1.4.28.
Members
cache_ok
Class signature
class sqlalchemy.types.ExternalType (sqlalchemy.types.TypeEngineMixin)
attribute sqlalchemy.types.ExternalType.cache_ok: bool | None = None
Indicate if statements using this ExternalType are “safe to cache”.
The default value None will emit a warning and then not allow caching of a statement which includes this type. Set to False to disable statements using this type from being cached at all without a warning. When set to True, the object’s class and selected elements from its state will be used as part of the cache key. For example, using a TypeDecorator:
class MyType(TypeDecorator):
    impl = String

    cache_ok = True

    def __init__(self, choices):
        self.choices = tuple(choices)
        self.internal_only = True
The cache key for the above type would be equivalent to:
>>> MyType(["a", "b", "c"])._static_cache_key
(<class '__main__.MyType'>, ('choices', ('a', 'b', 'c')))
The caching scheme will extract attributes from the type that correspond to the names of parameters in the __init__() method. Above, the “choices” attribute becomes part of the cache key but “internal_only” does not, because there is no parameter named “internal_only”.
The requirements for cacheable elements is that they are hashable and also that they indicate the same SQL rendered for expressions using this type every time for a given cache value.
To accommodate for datatypes that refer to unhashable structures such as dictionaries, sets and lists, these objects can be made “cacheable” by assigning hashable structures to the attributes whose names correspond with the names of the arguments. For example, a datatype which accepts a dictionary of lookup values may publish this as a sorted series of tuples. Given a previously un-cacheable type as:
class LookupType(UserDefinedType):
    """a custom type that accepts a dictionary as a parameter.

    this is the non-cacheable version, as "self.lookup" is not
    hashable.

    """

    def __init__(self, lookup):
        self.lookup = lookup

    def get_col_spec(self, **kw):
        return "VARCHAR(255)"

    def bind_processor(self, dialect): ...  # works with "self.lookup" ...
Where “lookup” is a dictionary. The type will not be able to generate a cache key:
>>> type_ = LookupType({"a": 10, "b": 20})
>>> type_._static_cache_key
<stdin>:1: SAWarning: UserDefinedType LookupType({'a': 10, 'b': 20}) will not
produce a cache key because the ``cache_ok`` flag is not set to True.
Set this flag to True if this type object's state is safe to use
in a cache key, or False to disable this warning.
symbol('no_cache')
If we did set up such a cache key, it wouldn’t be usable. We would get a tuple structure that contains a dictionary inside of it, which cannot itself be used as a key in a “cache dictionary” such as SQLAlchemy’s statement cache, since Python dictionaries aren’t hashable:
>>> # set cache_ok = True
>>> type_.cache_ok = True

>>> # this is the cache key it would generate
>>> key = type_._static_cache_key
>>> key
(<class '__main__.LookupType'>, ('lookup', {'a': 10, 'b': 20}))

>>> # however this key is not hashable, will fail when used with
>>> # SQLAlchemy statement cache
>>> some_cache = {key: "some sql value"}
Traceback (most recent call last): File "<stdin>", line 1,
in <module> TypeError: unhashable type: 'dict'
The type may be made cacheable by assigning a sorted tuple of tuples to the “.lookup” attribute:
class LookupType(UserDefinedType):
    """a custom type that accepts a dictionary as a parameter.

    The dictionary is stored both as itself in a private variable,
    and published in a public variable as a sorted tuple of tuples,
    which is hashable and will also return the same value for any
    two equivalent dictionaries.  Note it assumes the keys and
    values of the dictionary are themselves hashable.

    """

    cache_ok = True

    def __init__(self, lookup):
        self._lookup = lookup

        # assume keys/values of "lookup" are hashable; otherwise
        # they would also need to be converted in some way here
        self.lookup = tuple((key, lookup[key]) for key in sorted(lookup))

    def get_col_spec(self, **kw):
        return "VARCHAR(255)"

    def bind_processor(self, dialect): ...  # works with "self._lookup" ...
Where above, the cache key for LookupType({"a": 10, "b": 20}) will be:
>>> LookupType({"a": 10, "b": 20})._static_cache_key
(<class '__main__.LookupType'>, ('lookup', (('a', 10), ('b', 20))))
Added in version 1.4.14: - added the cache_ok flag to allow some configurability of caching for TypeDecorator classes.
Added in version 1.4.28: - added the ExternalType mixin which generalizes the cache_ok flag to both the TypeDecorator and UserDefinedType classes.
See also
SQL Compilation Caching
class sqlalchemy.types.Variant
deprecated. symbol is present for backwards-compatibility with workaround recipes, however this actual type should not be used.
Members
with_variant()
Class signature
class sqlalchemy.types.Variant (sqlalchemy.types.TypeDecorator)
method sqlalchemy.types.Variant.with_variant(type_: _TypeEngineArgument[Any], *dialect_names: str) → Self
inherited from the TypeEngine.with_variant() method of TypeEngine
Produce a copy of this type object that will utilize the given type when applied to the dialect of the given name.
e.g.:
from sqlalchemy.types import String
from sqlalchemy.dialects import mysql

string_type = String()

string_type = string_type.with_variant(
    mysql.VARCHAR(collation="foo"), "mysql", "mariadb"
)
The variant mapping indicates that when this type is interpreted by a specific dialect, it will instead be transmuted into the given type, rather than using the primary type.
Changed in version 2.0: the TypeEngine.with_variant() method now works with a TypeEngine object “in place”, returning a copy of the original type rather than returning a wrapping object; the Variant class is no longer used.
Parameters:
• type_ – a TypeEngine that will be selected as a variant from the originating type, when a dialect of the given name is in use.
• *dialect_names – 
one or more base names of the dialect which uses this type. (i.e. 'postgresql', 'mysql', etc.)
Changed in version 2.0: multiple dialect names can be specified for one variant.
See also
Using “UPPERCASE” and Backend-specific types for multiple backends - illustrates the use of TypeEngine.with_variant().

Core API Basics
• Events
o Event Registration
o Named Argument Styles
o Targets
o Modifiers
o Events and Multiprocessing
o Event Reference
o API Reference
• Runtime Inspection API
o inspect()
o Available Inspection Targets
• Core Exceptions
o AmbiguousForeignKeysError
o ArgumentError
o AwaitRequired
o Base20DeprecationWarning
o CircularDependencyError
o CompileError
o ConstraintColumnNotFoundError
o DBAPIError
o DataError
o DatabaseError
o DisconnectionError
o DontWrapMixin
o DuplicateColumnError
o HasDescriptionCode
o IdentifierError
o IllegalStateChangeError
o IntegrityError
o InterfaceError
o InternalError
o InvalidRequestError
o InvalidatePoolError
o LegacyAPIWarning
o MissingGreenlet
o MovedIn20Warning
o MultipleResultsFound
o NoForeignKeysError
o NoInspectionAvailable
o NoReferenceError
o NoReferencedColumnError
o NoReferencedTableError
o NoResultFound
o NoSuchColumnError
o NoSuchModuleError
o NoSuchTableError
o NotSupportedError
o ObjectNotExecutableError
o OperationalError
o PendingRollbackError
o ProgrammingError
o ResourceClosedError
o SADeprecationWarning
o SAPendingDeprecationWarning
o SATestSuiteWarning
o SAWarning
o SQLAlchemyError
o StatementError
o TimeoutError
o UnboundExecutionError
o UnreflectableTableError
o UnsupportedCompilationError
• Core Internals
o BindTyping
o Compiled
o DBAPIConnection
o DBAPICursor
o DBAPIType
o DDLCompiler
o DefaultDialect
o Dialect
o DefaultExecutionContext
o ExecutionContext
o ExpandedState
o GenericTypeCompiler
o Identified
o IdentifierPreparer
o SQLCompiler
o StrSQLCompiler
o AdaptedConnection


Events
SQLAlchemy includes an event API which publishes a wide variety of hooks into the internals of both SQLAlchemy Core and ORM.
Event Registration
Subscribing to an event occurs through a single API point, the listen() function, or alternatively the listens_for() decorator. These functions accept a target, a string identifier which identifies the event to be intercepted, and a user-defined listening function. Additional positional and keyword arguments to these two functions may be supported by specific types of events, which may specify alternate interfaces for the given event function, or provide instructions regarding secondary event targets based on the given target.
The name of an event and the argument signature of a corresponding listener function is derived from a class bound specification method, which exists bound to a marker class that’s described in the documentation. For example, the documentation for PoolEvents.connect() indicates that the event name is "connect" and that a user-defined listener function should receive two positional arguments:
from sqlalchemy.event import listen
from sqlalchemy.pool import Pool


def my_on_connect(dbapi_con, connection_record):
    print("New DBAPI connection:", dbapi_con)


listen(Pool, "connect", my_on_connect)
To listen with the listens_for() decorator looks like:
from sqlalchemy.event import listens_for
from sqlalchemy.pool import Pool


@listens_for(Pool, "connect")
def my_on_connect(dbapi_con, connection_record):
    print("New DBAPI connection:", dbapi_con)
Named Argument Styles
There are some varieties of argument styles which can be accepted by listener functions. Taking the example of PoolEvents.connect(), this function is documented as receiving dbapi_connection and connection_record arguments. We can opt to receive these arguments by name, by establishing a listener function that accepts **keyword arguments, by passing named=True to either listen() or listens_for():
from sqlalchemy.event import listens_for
from sqlalchemy.pool import Pool


@listens_for(Pool, "connect", named=True)
def my_on_connect(**kw):
    print("New DBAPI connection:", kw["dbapi_connection"])
When using named argument passing, the names listed in the function argument specification will be used as keys in the dictionary.
Named style passes all arguments by name regardless of the function signature, so specific arguments may be listed as well, in any order, as long as the names match up:
from sqlalchemy.event import listens_for
from sqlalchemy.pool import Pool


@listens_for(Pool, "connect", named=True)
def my_on_connect(dbapi_connection, **kw):
    print("New DBAPI connection:", dbapi_connection)
    print("Connection record:", kw["connection_record"])
Above, the presence of **kw tells listens_for() that arguments should be passed to the function by name, rather than positionally.
Targets
The listen() function is very flexible regarding targets. It generally accepts classes, instances of those classes, and related classes or objects from which the appropriate target can be derived. For example, the above mentioned "connect" event accepts Engine classes and objects as well as Pool classes and objects:
from sqlalchemy.event import listen
from sqlalchemy.pool import Pool, QueuePool
from sqlalchemy import create_engine
from sqlalchemy.engine import Engine
import psycopg2


def connect():
    return psycopg2.connect(user="ed", host="127.0.0.1", dbname="test")


my_pool = QueuePool(connect)
my_engine = create_engine("postgresql+psycopg2://ed@localhost/test")

# associate listener with all instances of Pool
listen(Pool, "connect", my_on_connect)

# associate listener with all instances of Pool
# via the Engine class
listen(Engine, "connect", my_on_connect)

# associate listener with my_pool
listen(my_pool, "connect", my_on_connect)

# associate listener with my_engine.pool
listen(my_engine, "connect", my_on_connect)
Modifiers
Some listeners allow modifiers to be passed to listen(). These modifiers sometimes provide alternate calling signatures for listeners. Such as with ORM events, some event listeners can have a return value which modifies the subsequent handling. By default, no listener ever requires a return value, but by passing retval=True this value can be supported:
def validate_phone(target, value, oldvalue, initiator):
    """Strip non-numeric characters from a phone number"""

    return re.sub(r"\D", "", value)


# setup listener on UserContact.phone attribute, instructing
# it to use the return value
listen(UserContact.phone, "set", validate_phone, retval=True)
Events and Multiprocessing
SQLAlchemy’s event hooks are implemented with Python functions and objects, so events propagate via Python function calls. Python multiprocessing follows the same way we think about OS multiprocessing, such as a parent process forking a child process, thus we can describe the SQLAlchemy event system’s behavior using the same model.
Event hooks registered in a parent process will be present in new child processes that are forked from that parent after the hooks have been registered, since the child process starts with a copy of all existing Python structures from the parent when spawned. Child processes that already exist before the hooks are registered will not receive those new event hooks, as changes made to Python structures in a parent process do not propagate to child processes.
For the events themselves, these are Python function calls, which do not have any ability to propagate between processes. SQLAlchemy’s event system does not implement any inter-process communication. It is possible to implement event hooks that use Python inter-process messaging within them, however this would need to be implemented by the user.
Event Reference
Both SQLAlchemy Core and SQLAlchemy ORM feature a wide variety of event hooks:
• Core Events - these are described in Core Events and include event hooks specific to connection pool lifecycle, SQL statement execution, transaction lifecycle, and schema creation and teardown.
• ORM Events - these are described in ORM Events, and include event hooks specific to class and attribute instrumentation, object initialization hooks, attribute on-change hooks, session state, flush, and commit hooks, mapper initialization, object/result population, and per-instance persistence hooks.
API Reference
Object NameDescriptioncontains(target, identifier, fn)Return True if the given target/ident/fn is set up to listen.listen(target, identifier, fn, *args, **kw)Register a listener function for the given target.listens_for(target, identifier, *args, **kw)Decorate a function as a listener for the given target + identifier.remove(target, identifier, fn)Remove an event listener.function sqlalchemy.event.listen(target: Any, identifier: str, fn: Callable[[...], Any], *args: Any, **kw: Any) → None
Register a listener function for the given target.
The listen() function is part of the primary interface for the SQLAlchemy event system, documented at Events.
e.g.:
from sqlalchemy import event
from sqlalchemy.schema import UniqueConstraint


def unique_constraint_name(const, table):
    const.name = "uq_%s_%s" % (table.name, list(const.columns)[0].name)


event.listen(
    UniqueConstraint, "after_parent_attach", unique_constraint_name
)
Parameters:
• insert (bool) – The default behavior for event handlers is to append the decorated user defined function to an internal list of registered event listeners upon discovery. If a user registers a function with insert=True, SQLAlchemy will insert (prepend) the function to the internal list upon discovery. This feature is not typically used or recommended by the SQLAlchemy maintainers, but is provided to ensure certain user defined functions can run before others, such as when Changing the sql_mode in MySQL.
• named (bool) – When using named argument passing, the names listed in the function argument specification will be used as keys in the dictionary. See Named Argument Styles.
• once (bool) – Private/Internal API usage. Deprecated. This parameter would provide that an event function would run only once per given target. It does not however imply automatic de-registration of the listener function; associating an arbitrarily high number of listeners without explicitly removing them will cause memory to grow unbounded even if once=True is specified.
• propagate (bool) – The propagate kwarg is available when working with ORM instrumentation and mapping events. See MapperEvents and MapperEvents.before_mapper_configured() for examples.
• retval (bool) – 
This flag applies only to specific event listeners, each of which includes documentation explaining when it should be used. By default, no listener ever requires a return value. However, some listeners do support special behaviors for return values, and include in their documentation that the retval=True flag is necessary for a return value to be processed.
Event listener suites that make use of listen.retval include ConnectionEvents and AttributeEvents.
Note
The listen() function cannot be called at the same time that the target event is being run. This has implications for thread safety, and also means an event cannot be added from inside the listener function for itself. The list of events to be run are present inside of a mutable collection that can’t be changed during iteration.
Event registration and removal is not intended to be a “high velocity” operation; it is a configurational operation. For systems that need to quickly associate and deassociate with events at high scale, use a mutable structure that is handled from inside of a single listener.
See also
listens_for()
remove()
function sqlalchemy.event.listens_for(target: Any, identifier: str, *args: Any, **kw: Any) → Callable[[Callable[[...], Any]], Callable[[...], Any]]
Decorate a function as a listener for the given target + identifier.
The listens_for() decorator is part of the primary interface for the SQLAlchemy event system, documented at Events.
This function generally shares the same kwargs as listen().
e.g.:
from sqlalchemy import event
from sqlalchemy.schema import UniqueConstraint


@event.listens_for(UniqueConstraint, "after_parent_attach")
def unique_constraint_name(const, table):
    const.name = "uq_%s_%s" % (table.name, list(const.columns)[0].name)
A given function can also be invoked for only the first invocation of the event using the once argument:
@event.listens_for(Mapper, "before_configure", once=True)
def on_config():
    do_config()
Warning
The once argument does not imply automatic de-registration of the listener function after it has been invoked a first time; a listener entry will remain associated with the target object. Associating an arbitrarily high number of listeners without explicitly removing them will cause memory to grow unbounded even if once=True is specified.
See also
listen() - general description of event listening
function sqlalchemy.event.remove(target: Any, identifier: str, fn: Callable[[...], Any]) → None
Remove an event listener.
The arguments here should match exactly those which were sent to listen(); all the event registration which proceeded as a result of this call will be reverted by calling remove() with the same arguments.
e.g.:
# if a function was registered like this...
@event.listens_for(SomeMappedClass, "before_insert", propagate=True)
def my_listener_function(*arg):
    pass


# ... it's removed like this
event.remove(SomeMappedClass, "before_insert", my_listener_function)
Above, the listener function associated with SomeMappedClass was also propagated to subclasses of SomeMappedClass; the remove() function will revert all of these operations.
Note
The remove() function cannot be called at the same time that the target event is being run. This has implications for thread safety, and also means an event cannot be removed from inside the listener function for itself. The list of events to be run are present inside of a mutable collection that can’t be changed during iteration.
Event registration and removal is not intended to be a “high velocity” operation; it is a configurational operation. For systems that need to quickly associate and deassociate with events at high scale, use a mutable structure that is handled from inside of a single listener.
See also
listen()
function sqlalchemy.event.contains(target: Any, identifier: str, fn: Callable[[...], Any]) → bool
Return True if the given target/ident/fn is set up to listen.


Runtime Inspection API
The inspection module provides the inspect() function, which delivers runtime information about a wide variety of SQLAlchemy objects, both within the Core as well as the ORM.
The inspect() function is the entry point to SQLAlchemy’s public API for viewing the configuration and construction of in-memory objects. Depending on the type of object passed to inspect(), the return value will either be a related object which provides a known interface, or in many cases it will return the object itself.
The rationale for inspect() is twofold. One is that it replaces the need to be aware of a large variety of “information getting” functions in SQLAlchemy, such as Inspector.from_engine() (deprecated in 1.4), instance_state(), class_mapper(), and others. The other is that the return value of inspect() is guaranteed to obey a documented API, thus allowing third party tools which build on top of SQLAlchemy configurations to be constructed in a forwards-compatible way.
Object NameDescriptioninspect(subject[, raiseerr])Produce an inspection object for the given target.function sqlalchemy.inspect(subject: Any, raiseerr: bool = True) → Any
Produce an inspection object for the given target.
The returned value in some cases may be the same object as the one given, such as if a Mapper object is passed. In other cases, it will be an instance of the registered inspection type for the given object, such as if an Engine is passed, an Inspector object is returned.
Parameters:
• subject – the subject to be inspected.
• raiseerr – When True, if the given subject does not correspond to a known SQLAlchemy inspected type, sqlalchemy.exc.NoInspectionAvailable is raised. If False, None is returned.
Available Inspection Targets
Below is a listing of many of the most common inspection targets.
• Connectable (i.e. Engine, Connection) - returns an Inspector object.
• ClauseElement - all SQL expression components, including Table, Column, serve as their own inspection objects, meaning any of these objects passed to inspect() return themselves.
• object - an object given will be checked by the ORM for a mapping - if so, an InstanceState is returned representing the mapped state of the object. The InstanceState also provides access to per attribute state via the AttributeState interface as well as the per-flush “history” of any attribute via the History object.
See also
Inspection of Mapped Instances
• type (i.e. a class) - a class given will be checked by the ORM for a mapping - if so, a Mapper for that class is returned.
See also
Inspection of Mapper objects
• mapped attribute - passing a mapped attribute to inspect(), such as inspect(MyClass.some_attribute), returns a QueryableAttribute object, which is the descriptor associated with a mapped class. This descriptor refers to a MapperProperty, which is usually an instance of ColumnProperty or RelationshipProperty, via its QueryableAttribute.property attribute.
• AliasedClass - returns an AliasedInsp object.


Core Exceptions
Exceptions used with SQLAlchemy.
The base exception class is SQLAlchemyError. Exceptions which are raised as a result of DBAPI exceptions are all subclasses of DBAPIError.
exception sqlalchemy.exc.AmbiguousForeignKeysError
Raised when more than one foreign key matching can be located between two selectables during a join.
Class signature
class sqlalchemy.exc.AmbiguousForeignKeysError (sqlalchemy.exc.ArgumentError)
exception sqlalchemy.exc.ArgumentError
Raised when an invalid or conflicting function argument is supplied.
This error generally corresponds to construction time state errors.
Class signature
class sqlalchemy.exc.ArgumentError (sqlalchemy.exc.SQLAlchemyError)
exception sqlalchemy.exc.AwaitRequired
Error raised by the async greenlet spawn if no async operation was awaited when it required one.
Class signature
class sqlalchemy.exc.AwaitRequired (sqlalchemy.exc.InvalidRequestError)
exception sqlalchemy.exc.Base20DeprecationWarning
Issued for usage of APIs specifically deprecated or legacy in SQLAlchemy 2.0.
See also
The <some function> in SQLAlchemy 2.0 will no longer <something>.
SQLAlchemy 2.0 Deprecations Mode
Class signature
class sqlalchemy.exc.Base20DeprecationWarning (sqlalchemy.exc.SADeprecationWarning)
attribute sqlalchemy.exc.Base20DeprecationWarning.deprecated_since: str | None = '1.4'
Indicates the version that started raising this deprecation warning
exception sqlalchemy.exc.CircularDependencyError
Raised by topological sorts when a circular dependency is detected.
There are two scenarios where this error occurs:
• In a Session flush operation, if two objects are mutually dependent on each other, they can not be inserted or deleted via INSERT or DELETE statements alone; an UPDATE will be needed to post-associate or pre-deassociate one of the foreign key constrained values. The post_update flag described at Rows that point to themselves / Mutually Dependent Rows can resolve this cycle.
• In a MetaData.sorted_tables operation, two ForeignKey or ForeignKeyConstraint objects mutually refer to each other. Apply the use_alter=True flag to one or both, see Creating/Dropping Foreign Key Constraints via ALTER.
Class signature
class sqlalchemy.exc.CircularDependencyError (sqlalchemy.exc.SQLAlchemyError)
method sqlalchemy.exc.CircularDependencyError.__init__(message: str, cycles: Any, edges: Any, msg: str | None = None, code: str | None = None)
exception sqlalchemy.exc.CompileError
Raised when an error occurs during SQL compilation
Class signature
class sqlalchemy.exc.CompileError (sqlalchemy.exc.SQLAlchemyError)
exception sqlalchemy.exc.ConstraintColumnNotFoundError
raised when a constraint refers to a string column name that is not present in the table being constrained.
Added in version 2.0.
Class signature
class sqlalchemy.exc.ConstraintColumnNotFoundError (sqlalchemy.exc.ArgumentError)
exception sqlalchemy.exc.DBAPIError
Raised when the execution of a database operation fails.
Wraps exceptions raised by the DB-API underlying the database operation. Driver-specific implementations of the standard DB-API exception types are wrapped by matching sub-types of SQLAlchemy’s DBAPIError when possible. DB-API’s Error type maps to DBAPIError in SQLAlchemy, otherwise the names are identical. Note that there is no guarantee that different DB-API implementations will raise the same exception type for any given error condition.
DBAPIError features StatementError.statement and StatementError.params attributes which supply context regarding the specifics of the statement which had an issue, for the typical case when the error was raised within the context of emitting a SQL statement.
The wrapped exception object is available in the StatementError.orig attribute. Its type and properties are DB-API implementation specific.
Class signature
class sqlalchemy.exc.DBAPIError (sqlalchemy.exc.StatementError)
method sqlalchemy.exc.DBAPIError.__init__(statement: str | None, params: _AnyExecuteParams | None, orig: BaseException, hide_parameters: bool = False, connection_invalidated: bool = False, code: str | None = None, ismulti: bool | None = None)
exception sqlalchemy.exc.DataError
Wraps a DB-API DataError.
Class signature
class sqlalchemy.exc.DataError (sqlalchemy.exc.DatabaseError)
exception sqlalchemy.exc.DatabaseError
Wraps a DB-API DatabaseError.
Class signature
class sqlalchemy.exc.DatabaseError (sqlalchemy.exc.DBAPIError)
exception sqlalchemy.exc.DisconnectionError
A disconnect is detected on a raw DB-API connection.
This error is raised and consumed internally by a connection pool. It can be raised by the PoolEvents.checkout() event so that the host pool forces a retry; the exception will be caught three times in a row before the pool gives up and raises InvalidRequestError regarding the connection attempt.
Class signature
class sqlalchemy.exc.DisconnectionError (sqlalchemy.exc.SQLAlchemyError)
Object NameDescriptionDontWrapMixinA mixin class which, when applied to a user-defined Exception class, will not be wrapped inside of StatementError if the error is emitted within the process of executing a statement.HasDescriptionCodehelper which adds ‘code’ as an attribute and ‘_code_str’ as a methodclass sqlalchemy.exc.DontWrapMixin
A mixin class which, when applied to a user-defined Exception class, will not be wrapped inside of StatementError if the error is emitted within the process of executing a statement.
E.g.:
from sqlalchemy.exc import DontWrapMixin


class MyCustomException(Exception, DontWrapMixin):
    pass


class MySpecialType(TypeDecorator):
    impl = String

    def process_bind_param(self, value, dialect):
        if value == "invalid":
            raise MyCustomException("invalid!")
exception sqlalchemy.exc.DuplicateColumnError
a Column is being added to a Table that would replace another Column, without appropriate parameters to allow this in place.
Added in version 2.0.0b4.
Class signature
class sqlalchemy.exc.DuplicateColumnError (sqlalchemy.exc.ArgumentError)
class sqlalchemy.exc.HasDescriptionCode
helper which adds ‘code’ as an attribute and ‘_code_str’ as a method
exception sqlalchemy.exc.IdentifierError
Raised when a schema name is beyond the max character limit
Class signature
class sqlalchemy.exc.IdentifierError (sqlalchemy.exc.SQLAlchemyError)
exception sqlalchemy.exc.IllegalStateChangeError
An object that tracks state encountered an illegal state change of some kind.
Added in version 2.0.
Class signature
class sqlalchemy.exc.IllegalStateChangeError (sqlalchemy.exc.InvalidRequestError)
exception sqlalchemy.exc.IntegrityError
Wraps a DB-API IntegrityError.
Class signature
class sqlalchemy.exc.IntegrityError (sqlalchemy.exc.DatabaseError)
exception sqlalchemy.exc.InterfaceError
Wraps a DB-API InterfaceError.
Class signature
class sqlalchemy.exc.InterfaceError (sqlalchemy.exc.DBAPIError)
exception sqlalchemy.exc.InternalError
Wraps a DB-API InternalError.
Class signature
class sqlalchemy.exc.InternalError (sqlalchemy.exc.DatabaseError)
exception sqlalchemy.exc.InvalidRequestError
SQLAlchemy was asked to do something it can’t do.
This error generally corresponds to runtime state errors.
Class signature
class sqlalchemy.exc.InvalidRequestError (sqlalchemy.exc.SQLAlchemyError)
exception sqlalchemy.exc.InvalidatePoolError
Raised when the connection pool should invalidate all stale connections.
A subclass of DisconnectionError that indicates that the disconnect situation encountered on the connection probably means the entire pool should be invalidated, as the database has been restarted.
This exception will be handled otherwise the same way as DisconnectionError, allowing three attempts to reconnect before giving up.
Added in version 1.2.
Class signature
class sqlalchemy.exc.InvalidatePoolError (sqlalchemy.exc.DisconnectionError)
exception sqlalchemy.exc.LegacyAPIWarning
indicates an API that is in ‘legacy’ status, a long term deprecation.
Class signature
class sqlalchemy.exc.LegacyAPIWarning (sqlalchemy.exc.Base20DeprecationWarning)
exception sqlalchemy.exc.MissingGreenlet
Error raised by the async greenlet await_ if called while not inside the greenlet spawn context.
Class signature
class sqlalchemy.exc.MissingGreenlet (sqlalchemy.exc.InvalidRequestError)
exception sqlalchemy.exc.MovedIn20Warning
Subtype of RemovedIn20Warning to indicate an API that moved only.
Class signature
class sqlalchemy.exc.MovedIn20Warning (sqlalchemy.exc.Base20DeprecationWarning)
exception sqlalchemy.exc.MultipleResultsFound
A single database result was required but more than one were found.
Changed in version 1.4: This exception is now part of the sqlalchemy.exc module in Core, moved from the ORM. The symbol remains importable from sqlalchemy.orm.exc.
Class signature
class sqlalchemy.exc.MultipleResultsFound (sqlalchemy.exc.InvalidRequestError)
exception sqlalchemy.exc.NoForeignKeysError
Raised when no foreign keys can be located between two selectables during a join.
Class signature
class sqlalchemy.exc.NoForeignKeysError (sqlalchemy.exc.ArgumentError)
exception sqlalchemy.exc.NoInspectionAvailable
A subject passed to sqlalchemy.inspection.inspect() produced no context for inspection.
Class signature
class sqlalchemy.exc.NoInspectionAvailable (sqlalchemy.exc.InvalidRequestError)
exception sqlalchemy.exc.NoReferenceError
Raised by ForeignKey to indicate a reference cannot be resolved.
Class signature
class sqlalchemy.exc.NoReferenceError (sqlalchemy.exc.InvalidRequestError)
exception sqlalchemy.exc.NoReferencedColumnError
Raised by ForeignKey when the referred Column cannot be located.
Class signature
class sqlalchemy.exc.NoReferencedColumnError (sqlalchemy.exc.NoReferenceError)
method sqlalchemy.exc.NoReferencedColumnError.__init__(message: str, tname: str, cname: str)
exception sqlalchemy.exc.NoReferencedTableError
Raised by ForeignKey when the referred Table cannot be located.
Class signature
class sqlalchemy.exc.NoReferencedTableError (sqlalchemy.exc.NoReferenceError)
method sqlalchemy.exc.NoReferencedTableError.__init__(message: str, tname: str)
exception sqlalchemy.exc.NoResultFound
A database result was required but none was found.
Changed in version 1.4: This exception is now part of the sqlalchemy.exc module in Core, moved from the ORM. The symbol remains importable from sqlalchemy.orm.exc.
Class signature
class sqlalchemy.exc.NoResultFound (sqlalchemy.exc.InvalidRequestError)
exception sqlalchemy.exc.NoSuchColumnError
A nonexistent column is requested from a Row.
Class signature
class sqlalchemy.exc.NoSuchColumnError (sqlalchemy.exc.InvalidRequestError, builtins.KeyError)
exception sqlalchemy.exc.NoSuchModuleError
Raised when a dynamically-loaded module (usually a database dialect) of a particular name cannot be located.
Class signature
class sqlalchemy.exc.NoSuchModuleError (sqlalchemy.exc.ArgumentError)
exception sqlalchemy.exc.NoSuchTableError
Table does not exist or is not visible to a connection.
Class signature
class sqlalchemy.exc.NoSuchTableError (sqlalchemy.exc.InvalidRequestError)
exception sqlalchemy.exc.NotSupportedError
Wraps a DB-API NotSupportedError.
Class signature
class sqlalchemy.exc.NotSupportedError (sqlalchemy.exc.DatabaseError)
exception sqlalchemy.exc.ObjectNotExecutableError
Raised when an object is passed to .execute() that can’t be executed as SQL.
Class signature
class sqlalchemy.exc.ObjectNotExecutableError (sqlalchemy.exc.ArgumentError)
method sqlalchemy.exc.ObjectNotExecutableError.__init__(target: Any)
exception sqlalchemy.exc.OperationalError
Wraps a DB-API OperationalError.
Class signature
class sqlalchemy.exc.OperationalError (sqlalchemy.exc.DatabaseError)
exception sqlalchemy.exc.PendingRollbackError
A transaction has failed and needs to be rolled back before continuing.
Added in version 1.4.
Class signature
class sqlalchemy.exc.PendingRollbackError (sqlalchemy.exc.InvalidRequestError)
exception sqlalchemy.exc.ProgrammingError
Wraps a DB-API ProgrammingError.
Class signature
class sqlalchemy.exc.ProgrammingError (sqlalchemy.exc.DatabaseError)
exception sqlalchemy.exc.ResourceClosedError
An operation was requested from a connection, cursor, or other object that’s in a closed state.
Class signature
class sqlalchemy.exc.ResourceClosedError (sqlalchemy.exc.InvalidRequestError)
exception sqlalchemy.exc.SADeprecationWarning
Issued for usage of deprecated APIs.
Class signature
class sqlalchemy.exc.SADeprecationWarning (sqlalchemy.exc.HasDescriptionCode, builtins.DeprecationWarning)
attribute sqlalchemy.exc.SADeprecationWarning.deprecated_since: str | None = None
Indicates the version that started raising this deprecation warning
exception sqlalchemy.exc.SAPendingDeprecationWarning
A similar warning as SADeprecationWarning, this warning is not used in modern versions of SQLAlchemy.
Class signature
class sqlalchemy.exc.SAPendingDeprecationWarning (builtins.PendingDeprecationWarning)
attribute sqlalchemy.exc.SAPendingDeprecationWarning.deprecated_since: str | None = None
Indicates the version that started raising this deprecation warning
exception sqlalchemy.exc.SATestSuiteWarning
warning for a condition detected during tests that is non-fatal
Currently outside of SAWarning so that we can work around tools like Alembic doing the wrong thing with warnings.
Class signature
class sqlalchemy.exc.SATestSuiteWarning (builtins.Warning)
exception sqlalchemy.exc.SAWarning
Issued at runtime.
Class signature
class sqlalchemy.exc.SAWarning (sqlalchemy.exc.HasDescriptionCode, builtins.RuntimeWarning)
exception sqlalchemy.exc.SQLAlchemyError
Generic error class.
Class signature
class sqlalchemy.exc.SQLAlchemyError (sqlalchemy.exc.HasDescriptionCode, builtins.Exception)
exception sqlalchemy.exc.StatementError
An error occurred during execution of a SQL statement.
StatementError wraps the exception raised during execution, and features statement and params attributes which supply context regarding the specifics of the statement which had an issue.
The wrapped exception object is available in the orig attribute.
Class signature
class sqlalchemy.exc.StatementError (sqlalchemy.exc.SQLAlchemyError)
method sqlalchemy.exc.StatementError.__init__(message: str, statement: str | None, params: _AnyExecuteParams | None, orig: BaseException | None, hide_parameters: bool = False, code: str | None = None, ismulti: bool | None = None)
attribute sqlalchemy.exc.StatementError.ismulti: bool | None = None
multi parameter passed to repr_params(). None is meaningful.
attribute sqlalchemy.exc.StatementError.orig: BaseException | None = None
The original exception that was thrown.
attribute sqlalchemy.exc.StatementError.params: _AnyExecuteParams | None = None
The parameter list being used when this exception occurred.
attribute sqlalchemy.exc.StatementError.statement: str | None = None
The string SQL statement being invoked when this exception occurred.
exception sqlalchemy.exc.TimeoutError
Raised when a connection pool times out on getting a connection.
Class signature
class sqlalchemy.exc.TimeoutError (sqlalchemy.exc.SQLAlchemyError)
exception sqlalchemy.exc.UnboundExecutionError
SQL was attempted without a database connection to execute it on.
Class signature
class sqlalchemy.exc.UnboundExecutionError (sqlalchemy.exc.InvalidRequestError)
exception sqlalchemy.exc.UnreflectableTableError
Table exists but can’t be reflected for some reason.
Added in version 1.2.
Class signature
class sqlalchemy.exc.UnreflectableTableError (sqlalchemy.exc.InvalidRequestError)
exception sqlalchemy.exc.UnsupportedCompilationError
Raised when an operation is not supported by the given compiler.
See also
How do I render SQL expressions as strings, possibly with bound parameters inlined?
Compiler StrSQLCompiler can’t render element of type <element type>
Class signature
class sqlalchemy.exc.UnsupportedCompilationError (sqlalchemy.exc.CompileError)
method sqlalchemy.exc.UnsupportedCompilationError.__init__(compiler: Compiled | TypeCompiler, element_type: Type[ClauseElement], message: str | None = None)


Core Internals
Some key internal constructs are listed here.
Object NameDescriptionAdaptedConnectionInterface of an adapted connection object to support the DBAPI protocol.BindTypingDefine different methods of passing typing information for bound parameters in a statement to the database driver.CompiledRepresent a compiled SQL or DDL expression.DBAPIConnectionprotocol representing a PEP 249 database connection.DBAPICursorprotocol representing a PEP 249 database cursor.DBAPITypeprotocol representing a PEP 249 database type.DDLCompilerDefaultDialectDefault implementation of DialectDefaultExecutionContextDialectDefine the behavior of a specific database and DB-API combination.ExecutionContextA messenger object for a Dialect that corresponds to a single execution.ExpandedStaterepresents state to use when producing “expanded” and “post compile” bound parameters for a statement.GenericTypeCompilerIdentifiedIdentifierPreparerHandle quoting and case-folding of identifiers based on options.SQLCompilerDefault implementation of Compiled.StrSQLCompilerA SQLCompiler subclass which allows a small selection of non-standard SQL features to render into a string value.class sqlalchemy.engine.BindTyping
Define different methods of passing typing information for bound parameters in a statement to the database driver.
Added in version 2.0.
Members
NONE, RENDER_CASTS, SETINPUTSIZES
Class signature
class sqlalchemy.engine.BindTyping (enum.Enum)
attribute sqlalchemy.engine.BindTyping.NONE = 1
No steps are taken to pass typing information to the database driver.
This is the default behavior for databases such as SQLite, MySQL / MariaDB, SQL Server.
attribute sqlalchemy.engine.BindTyping.RENDER_CASTS = 3
Render casts or other directives in the SQL string.
This method is used for all PostgreSQL dialects, including asyncpg, pg8000, psycopg, psycopg2. Dialects which implement this can choose which kinds of datatypes are explicitly cast in SQL statements and which aren’t.
When RENDER_CASTS is used, the compiler will invoke the SQLCompiler.render_bind_cast() method for the rendered string representation of each BindParameter object whose dialect-level type sets the TypeEngine.render_bind_cast attribute.
The SQLCompiler.render_bind_cast() is also used to render casts for one form of “insertmanyvalues” query, when both InsertmanyvaluesSentinelOpts.USE_INSERT_FROM_SELECT and InsertmanyvaluesSentinelOpts.RENDER_SELECT_COL_CASTS are set, where the casts are applied to the intermediary columns e.g. “INSERT INTO t (a, b, c) SELECT p0::TYP, p1::TYP, p2::TYP ” “FROM (VALUES (?, ?), (?, ?), …)”.
Added in version 2.0.10: - SQLCompiler.render_bind_cast() is now used within some elements of the “insertmanyvalues” implementation.
attribute sqlalchemy.engine.BindTyping.SETINPUTSIZES = 2
Use the pep-249 setinputsizes method.
This is only implemented for DBAPIs that support this method and for which the SQLAlchemy dialect has the appropriate infrastructure for that dialect set up. Current dialects include python-oracledb, cx_Oracle as well as optional support for SQL Server using pyodbc.
When using setinputsizes, dialects also have a means of only using the method for certain datatypes using include/exclude lists.
When SETINPUTSIZES is used, the Dialect.do_set_input_sizes() method is called for each statement executed which has bound parameters.
class sqlalchemy.engine.Compiled
Represent a compiled SQL or DDL expression.
Members
__init__(), cache_key, compile_state, construct_params(), dml_compile_state, execution_options, params, sql_compiler, state, statement, string
The __str__ method of the Compiled object should produce the actual text of the statement. Compiled objects are specific to their underlying database dialect, and also may or may not be specific to the columns referenced within a particular set of bind parameters. In no case should the Compiled object be dependent on the actual values of those bind parameters, even though it may reference those values as defaults.
method sqlalchemy.engine.Compiled.__init__(dialect: Dialect, statement: ClauseElement | None, schema_translate_map: SchemaTranslateMapType | None = None, render_schema_translate: bool = False, compile_kwargs: Mapping[str, Any] = {})
Construct a new Compiled object.
Parameters:
• dialect – Dialect to compile against.
• statement – ClauseElement to be compiled.
• schema_translate_map – 
dictionary of schema names to be translated when forming the resultant SQL
See also
Translation of Schema Names
• compile_kwargs – additional kwargs that will be passed to the initial call to Compiled.process().
attribute sqlalchemy.engine.Compiled.cache_key: CacheKey | None = None
The CacheKey that was generated ahead of creating this Compiled object.
This is used for routines that need access to the original CacheKey instance generated when the Compiled instance was first cached, typically in order to reconcile the original list of BindParameter objects with a per-statement list that’s generated on each call.
attribute sqlalchemy.engine.Compiled.compile_state: CompileState | None = None
Optional CompileState object that maintains additional state used by the compiler.
Major executable objects such as Insert, Update, Delete, Select will generate this state when compiled in order to calculate additional information about the object. For the top level object that is to be executed, the state can be stored here where it can also have applicability towards result set processing.
Added in version 1.4.
method sqlalchemy.engine.Compiled.construct_params(params: _CoreSingleExecuteParams | None = None, extracted_parameters: Sequence[BindParameter[Any]] | None = None, escape_names: bool = True) → _MutableCoreSingleExecuteParams | None
Return the bind params for this compiled object.
Parameters:
params – a dict of string/object pairs whose values will override bind values compiled in to the statement.
attribute sqlalchemy.engine.Compiled.dml_compile_state: CompileState | None = None
Optional CompileState assigned at the same point that .isinsert, .isupdate, or .isdelete is assigned.
This will normally be the same object as .compile_state, with the exception of cases like the ORMFromStatementCompileState object.
Added in version 1.4.40.
attribute sqlalchemy.engine.Compiled.execution_options: _ExecuteOptions = {}
Execution options propagated from the statement. In some cases, sub-elements of the statement can modify these.
attribute sqlalchemy.engine.Compiled.params
Return the bind params for this compiled object.
attribute sqlalchemy.engine.Compiled.sql_compiler
Return a Compiled that is capable of processing SQL expressions.
If this compiler is one, it would likely just return ‘self’.
attribute sqlalchemy.engine.Compiled.state: CompilerState
description of the compiler’s state
attribute sqlalchemy.engine.Compiled.statement: ClauseElement | None = None
The statement to compile.
attribute sqlalchemy.engine.Compiled.string: str = ''
The string representation of the statement
class sqlalchemy.engine.interfaces.DBAPIConnection
protocol representing a PEP 249 database connection.
Added in version 2.0.
See also
Connection Objects - in PEP 249
Members
close(), commit(), cursor(), rollback()
Class signature
class sqlalchemy.engine.interfaces.DBAPIConnection (typing.Protocol)
method sqlalchemy.engine.interfaces.DBAPIConnection.close() → None
method sqlalchemy.engine.interfaces.DBAPIConnection.commit() → None
method sqlalchemy.engine.interfaces.DBAPIConnection.cursor(*args: Any, **kwargs: Any) → DBAPICursor
method sqlalchemy.engine.interfaces.DBAPIConnection.rollback() → None
class sqlalchemy.engine.interfaces.DBAPICursor
protocol representing a PEP 249 database cursor.
Added in version 2.0.
See also
Cursor Objects - in PEP 249
Members
arraysize, callproc(), close(), description, execute(), executemany(), fetchall(), fetchmany(), fetchone(), lastrowid, nextset(), rowcount, setinputsizes(), setoutputsize()
Class signature
class sqlalchemy.engine.interfaces.DBAPICursor (typing.Protocol)
attribute sqlalchemy.engine.interfaces.DBAPICursor.arraysize: int
method sqlalchemy.engine.interfaces.DBAPICursor.callproc(procname: str, parameters: Sequence[Any] = Ellipsis) → Any
method sqlalchemy.engine.interfaces.DBAPICursor.close() → None
attribute sqlalchemy.engine.interfaces.DBAPICursor.description
The description attribute of the Cursor.
See also
cursor.description - in PEP 249
method sqlalchemy.engine.interfaces.DBAPICursor.execute(operation: Any, parameters: Sequence[Any] | Mapping[str, Any] | None = None) → Any
method sqlalchemy.engine.interfaces.DBAPICursor.executemany(operation: Any, parameters: Sequence[Sequence[Any]] | Sequence[Mapping[str, Any]]) → Any
method sqlalchemy.engine.interfaces.DBAPICursor.fetchall() → Sequence[Any]
method sqlalchemy.engine.interfaces.DBAPICursor.fetchmany(size: int = Ellipsis) → Sequence[Any]
method sqlalchemy.engine.interfaces.DBAPICursor.fetchone() → Any | None
attribute sqlalchemy.engine.interfaces.DBAPICursor.lastrowid: int
method sqlalchemy.engine.interfaces.DBAPICursor.nextset() → bool | None
attribute sqlalchemy.engine.interfaces.DBAPICursor.rowcount
method sqlalchemy.engine.interfaces.DBAPICursor.setinputsizes(sizes: Sequence[Any]) → None
method sqlalchemy.engine.interfaces.DBAPICursor.setoutputsize(size: Any, column: Any) → None
class sqlalchemy.engine.interfaces.DBAPIType
protocol representing a PEP 249 database type.
Added in version 2.0.
See also
Type Objects - in PEP 249
Class signature
class sqlalchemy.engine.interfaces.DBAPIType (typing.Protocol)
class sqlalchemy.sql.compiler.DDLCompiler
Members
__init__(), cache_key, compile_state, construct_params(), define_constraint_remote_table(), dml_compile_state, execution_options, params, sql_compiler, state, statement, string
Class signature
class sqlalchemy.sql.compiler.DDLCompiler (sqlalchemy.sql.compiler.Compiled)
method sqlalchemy.sql.compiler.DDLCompiler.__init__(dialect: Dialect, statement: ClauseElement | None, schema_translate_map: SchemaTranslateMapType | None = None, render_schema_translate: bool = False, compile_kwargs: Mapping[str, Any] = {})
inherited from the sqlalchemy.sql.compiler.Compiled.__init__ method of Compiled
Construct a new Compiled object.
Parameters:
• dialect – Dialect to compile against.
• statement – ClauseElement to be compiled.
• schema_translate_map – 
dictionary of schema names to be translated when forming the resultant SQL
See also
Translation of Schema Names
• compile_kwargs – additional kwargs that will be passed to the initial call to Compiled.process().
attribute sqlalchemy.sql.compiler.DDLCompiler.cache_key: CacheKey | None = None
inherited from the Compiled.cache_key attribute of Compiled
The CacheKey that was generated ahead of creating this Compiled object.
This is used for routines that need access to the original CacheKey instance generated when the Compiled instance was first cached, typically in order to reconcile the original list of BindParameter objects with a per-statement list that’s generated on each call.
attribute sqlalchemy.sql.compiler.DDLCompiler.compile_state: CompileState | None = None
inherited from the Compiled.compile_state attribute of Compiled
Optional CompileState object that maintains additional state used by the compiler.
Major executable objects such as Insert, Update, Delete, Select will generate this state when compiled in order to calculate additional information about the object. For the top level object that is to be executed, the state can be stored here where it can also have applicability towards result set processing.
Added in version 1.4.
method sqlalchemy.sql.compiler.DDLCompiler.construct_params(params: _CoreSingleExecuteParams | None = None, extracted_parameters: Sequence[BindParameter[Any]] | None = None, escape_names: bool = True) → _MutableCoreSingleExecuteParams | None
Return the bind params for this compiled object.
Parameters:
params – a dict of string/object pairs whose values will override bind values compiled in to the statement.
method sqlalchemy.sql.compiler.DDLCompiler.define_constraint_remote_table(constraint, table, preparer)
Format the remote table clause of a CREATE CONSTRAINT clause.
attribute sqlalchemy.sql.compiler.DDLCompiler.dml_compile_state: CompileState | None = None
inherited from the Compiled.dml_compile_state attribute of Compiled
Optional CompileState assigned at the same point that .isinsert, .isupdate, or .isdelete is assigned.
This will normally be the same object as .compile_state, with the exception of cases like the ORMFromStatementCompileState object.
Added in version 1.4.40.
attribute sqlalchemy.sql.compiler.DDLCompiler.execution_options: _ExecuteOptions = {}
inherited from the Compiled.execution_options attribute of Compiled
Execution options propagated from the statement. In some cases, sub-elements of the statement can modify these.
attribute sqlalchemy.sql.compiler.DDLCompiler.params
inherited from the Compiled.params attribute of Compiled
Return the bind params for this compiled object.
attribute sqlalchemy.sql.compiler.DDLCompiler.sql_compiler
attribute sqlalchemy.sql.compiler.DDLCompiler.state: CompilerState
description of the compiler’s state
attribute sqlalchemy.sql.compiler.DDLCompiler.statement: ClauseElement | None = None
inherited from the Compiled.statement attribute of Compiled
The statement to compile.
attribute sqlalchemy.sql.compiler.DDLCompiler.string: str = ''
inherited from the Compiled.string attribute of Compiled
The string representation of the statement
class sqlalchemy.engine.default.DefaultDialect
Default implementation of Dialect
Members
bind_typing, colspecs, connect(), construct_arguments, create_connect_args(), create_xid(), cte_follows_insert, dbapi, dbapi_exception_translation_map, ddl_compiler, default_isolation_level, default_metavalue_token, default_schema_name, default_sequence_base, delete_executemany_returning, delete_returning, delete_returning_multifrom, denormalize_name(), div_is_floordiv, do_begin(), do_begin_twophase(), do_close(), do_commit(), do_commit_twophase(), do_execute(), do_execute_no_params(), do_executemany(), do_ping(), do_prepare_twophase(), do_recover_twophase(), do_release_savepoint(), do_rollback(), do_rollback_to_savepoint(), do_rollback_twophase(), do_savepoint(), do_set_input_sizes(), do_terminate(), driver, engine_config_types, engine_created(), exclude_set_input_sizes, execute_sequence_format, execution_ctx_cls, favor_returning_over_lastrowid, full_returning, get_async_dialect_cls(), get_check_constraints(), get_columns(), get_default_isolation_level(), get_dialect_cls(), get_dialect_pool_class(), get_driver_connection(), get_foreign_keys(), get_indexes(), get_isolation_level(), get_isolation_level_values(), get_materialized_view_names(), get_multi_check_constraints(), get_multi_columns(), get_multi_foreign_keys(), get_multi_indexes(), get_multi_pk_constraint(), get_multi_table_comment(), get_multi_table_options(), get_multi_unique_constraints(), get_pk_constraint(), get_schema_names(), get_sequence_names(), get_table_comment(), get_table_names(), get_table_options(), get_temp_table_names(), get_temp_view_names(), get_unique_constraints(), get_view_definition(), get_view_names(), has_index(), has_schema(), has_sequence(), has_table(), has_terminate, identifier_preparer, import_dbapi(), include_set_input_sizes, initialize(), inline_comments, insert_executemany_returning, insert_executemany_returning_sort_by_parameter_order, insert_returning, insertmanyvalues_implicit_sentinel, insertmanyvalues_max_parameters, insertmanyvalues_page_size, is_async, is_disconnect(), label_length, load_provisioning(), loaded_dbapi, max_constraint_name_length, max_identifier_length, max_index_name_length, name, normalize_name(), on_connect(), on_connect_url(), paramstyle, positional, preexecute_autoincrement_sequences, preparer, reflection_options, reset_isolation_level(), returns_native_bytes, sequences_optional, server_side_cursors, server_version_info, set_connection_execution_options(), set_engine_execution_options(), set_isolation_level(), statement_compiler, supports_alter, supports_comments, supports_constraint_comments, supports_default_metavalue, supports_default_values, supports_empty_insert, supports_identity_columns, supports_multivalues_insert, supports_native_boolean, supports_native_decimal, supports_native_enum, supports_native_uuid, supports_sane_multi_rowcount, supports_sane_rowcount, supports_sane_rowcount_returning, supports_sequences, supports_server_side_cursors, supports_simple_order_by_label, supports_statement_cache, tuple_in_values, type_compiler, type_compiler_cls, type_compiler_instance, type_descriptor(), update_executemany_returning, update_returning, update_returning_multifrom, use_insertmanyvalues, use_insertmanyvalues_wo_returning, validate_identifier()
Class signature
class sqlalchemy.engine.default.DefaultDialect (sqlalchemy.engine.interfaces.Dialect)
attribute sqlalchemy.engine.default.DefaultDialect.bind_typing = 1
define a means of passing typing information to the database and/or driver for bound parameters.
See BindTyping for values.
Added in version 2.0.
attribute sqlalchemy.engine.default.DefaultDialect.colspecs: MutableMapping[Type[TypeEngine[Any]], Type[TypeEngine[Any]]] = {}
A dictionary of TypeEngine classes from sqlalchemy.types mapped to subclasses that are specific to the dialect class. This dictionary is class-level only and is not accessed from the dialect instance itself.
method sqlalchemy.engine.default.DefaultDialect.connect(*cargs: Any, **cparams: Any) → DBAPIConnection
Establish a connection using this dialect’s DBAPI.
The default implementation of this method is:
def connect(self, *cargs, **cparams):
    return self.dbapi.connect(*cargs, **cparams)
The *cargs, **cparams parameters are generated directly from this dialect’s Dialect.create_connect_args() method.
This method may be used for dialects that need to perform programmatic per-connection steps when a new connection is procured from the DBAPI.
Parameters:
• *cargs – positional parameters returned from the Dialect.create_connect_args() method
• **cparams – keyword parameters returned from the Dialect.create_connect_args() method.
Returns:
a DBAPI connection, typically from the PEP 249 module level .connect() function.
See also
Dialect.create_connect_args()
Dialect.on_connect()
attribute sqlalchemy.engine.default.DefaultDialect.construct_arguments: List[Tuple[Type[SchemaItem | ClauseElement], Mapping[str, Any]]] | None = None
inherited from the Dialect.construct_arguments attribute of Dialect
Optional set of argument specifiers for various SQLAlchemy constructs, typically schema items.
To implement, establish as a series of tuples, as in:
construct_arguments = [
    (schema.Index, {"using": False, "where": None, "ops": None}),
]
If the above construct is established on the PostgreSQL dialect, the Index construct will now accept the keyword arguments postgresql_using, postgresql_where, nad postgresql_ops. Any other argument specified to the constructor of Index which is prefixed with postgresql_ will raise ArgumentError.
A dialect which does not include a construct_arguments member will not participate in the argument validation system. For such a dialect, any argument name is accepted by all participating constructs, within the namespace of arguments prefixed with that dialect name. The rationale here is so that third-party dialects that haven’t yet implemented this feature continue to function in the old way.
See also
DialectKWArgs - implementing base class which consumes DefaultDialect.construct_arguments
method sqlalchemy.engine.default.DefaultDialect.create_connect_args(url: URL) → ConnectArgsType
Build DB-API compatible connection arguments.
Given a URL object, returns a tuple consisting of a (*args, **kwargs) suitable to send directly to the dbapi’s connect function. The arguments are sent to the Dialect.connect() method which then runs the DBAPI-level connect() function.
The method typically makes use of the URL.translate_connect_args() method in order to generate a dictionary of options.
The default implementation is:
def create_connect_args(self, url):
    opts = url.translate_connect_args()
    opts.update(url.query)
    return ([], opts)
Parameters:
url – a URL object
Returns:
a tuple of (*args, **kwargs) which will be passed to the Dialect.connect() method.
See also
URL.translate_connect_args()
method sqlalchemy.engine.default.DefaultDialect.create_xid()
Create a random two-phase transaction ID.
This id will be passed to do_begin_twophase(), do_rollback_twophase(), do_commit_twophase(). Its format is unspecified.
attribute sqlalchemy.engine.default.DefaultDialect.cte_follows_insert: bool = False
target database, when given a CTE with an INSERT statement, needs the CTE to be below the INSERT
attribute sqlalchemy.engine.default.DefaultDialect.dbapi: DBAPIModule | None
A reference to the DBAPI module object itself.
SQLAlchemy dialects import DBAPI modules using the classmethod Dialect.import_dbapi(). The rationale is so that any dialect module can be imported and used to generate SQL statements without the need for the actual DBAPI driver to be installed. Only when an Engine is constructed using create_engine() does the DBAPI get imported; at that point, the creation process will assign the DBAPI module to this attribute.
Dialects should therefore implement Dialect.import_dbapi() which will import the necessary module and return it, and then refer to self.dbapi in dialect code in order to refer to the DBAPI module contents.
Changed in version The: Dialect.dbapi attribute is exclusively used as the per-Dialect-instance reference to the DBAPI module. The previous not-fully-documented .Dialect.dbapi() classmethod is deprecated and replaced by Dialect.import_dbapi().
attribute sqlalchemy.engine.default.DefaultDialect.dbapi_exception_translation_map: Mapping[str, str] = {}
inherited from the Dialect.dbapi_exception_translation_map attribute of Dialect
A dictionary of names that will contain as values the names of pep-249 exceptions (“IntegrityError”, “OperationalError”, etc) keyed to alternate class names, to support the case where a DBAPI has exception classes that aren’t named as they are referred to (e.g. IntegrityError = MyException). In the vast majority of cases this dictionary is empty.
attribute sqlalchemy.engine.default.DefaultDialect.ddl_compiler
alias of DDLCompiler
attribute sqlalchemy.engine.default.DefaultDialect.default_isolation_level: IsolationLevel | None
the isolation that is implicitly present on new connections
attribute sqlalchemy.engine.default.DefaultDialect.default_metavalue_token: str = 'DEFAULT'
for INSERT… VALUES (DEFAULT) syntax, the token to put in the parenthesis.
attribute sqlalchemy.engine.default.DefaultDialect.default_schema_name: str | None = None
the name of the default schema. This value is only available for supporting dialects, and is typically populated during the initial connection to the database.
attribute sqlalchemy.engine.default.DefaultDialect.default_sequence_base: int = 1
the default value that will be rendered as the “START WITH” portion of a CREATE SEQUENCE DDL statement.
attribute sqlalchemy.engine.default.DefaultDialect.delete_executemany_returning: bool = False
dialect supports DELETE..RETURNING with executemany.
attribute sqlalchemy.engine.default.DefaultDialect.delete_returning: bool = False
if the dialect supports RETURNING with DELETE
Added in version 2.0.
attribute sqlalchemy.engine.default.DefaultDialect.delete_returning_multifrom: bool = False
if the dialect supports RETURNING with DELETE..FROM
Added in version 2.0.
method sqlalchemy.engine.default.DefaultDialect.denormalize_name(name)
convert the given name to a case insensitive identifier for the backend if it is an all-lowercase name.
This method is only used if the dialect defines requires_name_normalize=True.
attribute sqlalchemy.engine.default.DefaultDialect.div_is_floordiv: bool = True
target database treats the / division operator as “floor division”
method sqlalchemy.engine.default.DefaultDialect.do_begin(dbapi_connection)
Provide an implementation of connection.begin(), given a DB-API connection.
The DBAPI has no dedicated “begin” method and it is expected that transactions are implicit. This hook is provided for those DBAPIs that might need additional help in this area.
Parameters:
dbapi_connection – a DBAPI connection, typically proxied within a ConnectionFairy.
method sqlalchemy.engine.default.DefaultDialect.do_begin_twophase(connection: Connection, xid: Any) → None
inherited from the Dialect.do_begin_twophase() method of Dialect
Begin a two phase transaction on the given connection.
Parameters:
• connection – a Connection.
• xid – xid
method sqlalchemy.engine.default.DefaultDialect.do_close(dbapi_connection)
Provide an implementation of connection.close(), given a DBAPI connection.
This hook is called by the Pool when a connection has been detached from the pool, or is being returned beyond the normal capacity of the pool.
method sqlalchemy.engine.default.DefaultDialect.do_commit(dbapi_connection)
Provide an implementation of connection.commit(), given a DB-API connection.
Parameters:
dbapi_connection – a DBAPI connection, typically proxied within a ConnectionFairy.
method sqlalchemy.engine.default.DefaultDialect.do_commit_twophase(connection: Connection, xid: Any, is_prepared: bool = True, recover: bool = False) → None
inherited from the Dialect.do_commit_twophase() method of Dialect
Commit a two phase transaction on the given connection.
Parameters:
• connection – a Connection.
• xid – xid
• is_prepared – whether or not TwoPhaseTransaction.prepare() was called.
• recover – if the recover flag was passed.
method sqlalchemy.engine.default.DefaultDialect.do_execute(cursor, statement, parameters, context=None)
Provide an implementation of cursor.execute(statement, parameters).
method sqlalchemy.engine.default.DefaultDialect.do_execute_no_params(cursor, statement, context=None)
Provide an implementation of cursor.execute(statement).
The parameter collection should not be sent.
method sqlalchemy.engine.default.DefaultDialect.do_executemany(cursor, statement, parameters, context=None)
Provide an implementation of cursor.executemany(statement, parameters).
method sqlalchemy.engine.default.DefaultDialect.do_ping(dbapi_connection: DBAPIConnection) → bool
ping the DBAPI connection and return True if the connection is usable.
method sqlalchemy.engine.default.DefaultDialect.do_prepare_twophase(connection: Connection, xid: Any) → None
inherited from the Dialect.do_prepare_twophase() method of Dialect
Prepare a two phase transaction on the given connection.
Parameters:
• connection – a Connection.
• xid – xid
method sqlalchemy.engine.default.DefaultDialect.do_recover_twophase(connection: Connection) → List[Any]
inherited from the Dialect.do_recover_twophase() method of Dialect
Recover list of uncommitted prepared two phase transaction identifiers on the given connection.
Parameters:
connection – a Connection.
method sqlalchemy.engine.default.DefaultDialect.do_release_savepoint(connection, name)
Release the named savepoint on a connection.
Parameters:
• connection – a Connection.
• name – savepoint name.
method sqlalchemy.engine.default.DefaultDialect.do_rollback(dbapi_connection)
Provide an implementation of connection.rollback(), given a DB-API connection.
Parameters:
dbapi_connection – a DBAPI connection, typically proxied within a ConnectionFairy.
method sqlalchemy.engine.default.DefaultDialect.do_rollback_to_savepoint(connection, name)
Rollback a connection to the named savepoint.
Parameters:
• connection – a Connection.
• name – savepoint name.
method sqlalchemy.engine.default.DefaultDialect.do_rollback_twophase(connection: Connection, xid: Any, is_prepared: bool = True, recover: bool = False) → None
inherited from the Dialect.do_rollback_twophase() method of Dialect
Rollback a two phase transaction on the given connection.
Parameters:
• connection – a Connection.
• xid – xid
• is_prepared – whether or not TwoPhaseTransaction.prepare() was called.
• recover – if the recover flag was passed.
method sqlalchemy.engine.default.DefaultDialect.do_savepoint(connection, name)
Create a savepoint with the given name.
Parameters:
• connection – a Connection.
• name – savepoint name.
method sqlalchemy.engine.default.DefaultDialect.do_set_input_sizes(cursor: DBAPICursor, list_of_tuples: _GenericSetInputSizesType, context: ExecutionContext) → Any
inherited from the Dialect.do_set_input_sizes() method of Dialect
invoke the cursor.setinputsizes() method with appropriate arguments
This hook is called if the Dialect.bind_typing attribute is set to the BindTyping.SETINPUTSIZES value. Parameter data is passed in a list of tuples (paramname, dbtype, sqltype), where paramname is the key of the parameter in the statement, dbtype is the DBAPI datatype and sqltype is the SQLAlchemy type. The order of tuples is in the correct parameter order.
Added in version 1.4.
Changed in version 2.0: - setinputsizes mode is now enabled by setting Dialect.bind_typing to BindTyping.SETINPUTSIZES. Dialects which accept a use_setinputsizes parameter should set this value appropriately.
method sqlalchemy.engine.default.DefaultDialect.do_terminate(dbapi_connection)
Provide an implementation of connection.close() that tries as much as possible to not block, given a DBAPI connection.
In the vast majority of cases this just calls .close(), however for some asyncio dialects may call upon different API features.
This hook is called by the Pool when a connection is being recycled or has been invalidated.
Added in version 1.4.41.
attribute sqlalchemy.engine.default.DefaultDialect.driver: str
identifying name for the dialect’s DBAPI
attribute sqlalchemy.engine.default.DefaultDialect.engine_config_types: Mapping[str, Any] = {'echo': <function bool_or_str.<locals>.bool_or_value>, 'echo_pool': <function bool_or_str.<locals>.bool_or_value>, 'future': <function asbool>, 'max_overflow': <function asint>, 'pool_recycle': <function asint>, 'pool_size': <function asint>, 'pool_timeout': <function asint>}
a mapping of string keys that can be in an engine config linked to type conversion functions.
classmethod sqlalchemy.engine.default.DefaultDialect.engine_created(engine: Engine) → None
inherited from the Dialect.engine_created() method of Dialect
A convenience hook called before returning the final Engine.
If the dialect returned a different class from the get_dialect_cls() method, then the hook is called on both classes, first on the dialect class returned by the get_dialect_cls() method and then on the class on which the method was called.
The hook should be used by dialects and/or wrappers to apply special events to the engine or its components. In particular, it allows a dialect-wrapping class to apply dialect-level events.
attribute sqlalchemy.engine.default.DefaultDialect.exclude_set_input_sizes: Set[Any] | None = None
set of DBAPI type objects that should be excluded in automatic cursor.setinputsizes() calls.
This is only used if bind_typing is BindTyping.SET_INPUT_SIZES
attribute sqlalchemy.engine.default.DefaultDialect.execute_sequence_format
alias of tuple
attribute sqlalchemy.engine.default.DefaultDialect.execution_ctx_cls
alias of DefaultExecutionContext
attribute sqlalchemy.engine.default.DefaultDialect.favor_returning_over_lastrowid: bool = False
for backends that support both a lastrowid and a RETURNING insert strategy, favor RETURNING for simple single-int pk inserts.
cursor.lastrowid tends to be more performant on most backends.
attribute sqlalchemy.engine.default.DefaultDialect.full_returning
Deprecated since version 2.0: full_returning is deprecated, please use insert_returning, update_returning, delete_returning
classmethod sqlalchemy.engine.default.DefaultDialect.get_async_dialect_cls(url: URL) → Type[Dialect]
inherited from the Dialect.get_async_dialect_cls() method of Dialect
Given a URL, return the Dialect that will be used by an async engine.
By default this is an alias of Dialect.get_dialect_cls() and just returns the cls. It may be used if a dialect provides both a sync and async version under the same name, like the psycopg driver.
Added in version 2.
See also
Dialect.get_dialect_cls()
method sqlalchemy.engine.default.DefaultDialect.get_check_constraints(connection: Connection, table_name: str, schema: str | None = None, **kw: Any) → List[ReflectedCheckConstraint]
inherited from the Dialect.get_check_constraints() method of Dialect
Return information about check constraints in table_name.
Given a string table_name and an optional string schema, return check constraint information as a list of dicts corresponding to the ReflectedCheckConstraint dictionary.
This is an internal dialect method. Applications should use Inspector.get_check_constraints().
method sqlalchemy.engine.default.DefaultDialect.get_columns(connection: Connection, table_name: str, schema: str | None = None, **kw: Any) → List[ReflectedColumn]
inherited from the Dialect.get_columns() method of Dialect
Return information about columns in table_name.
Given a Connection, a string table_name, and an optional string schema, return column information as a list of dictionaries corresponding to the ReflectedColumn dictionary.
This is an internal dialect method. Applications should use Inspector.get_columns().
method sqlalchemy.engine.default.DefaultDialect.get_default_isolation_level(dbapi_conn)
Given a DBAPI connection, return its isolation level, or a default isolation level if one cannot be retrieved.
May be overridden by subclasses in order to provide a “fallback” isolation level for databases that cannot reliably retrieve the actual isolation level.
By default, calls the Interfaces.get_isolation_level() method, propagating any exceptions raised.
Added in version 1.3.22.
classmethod sqlalchemy.engine.default.DefaultDialect.get_dialect_cls(url: URL) → Type[Dialect]
inherited from the Dialect.get_dialect_cls() method of Dialect
Given a URL, return the Dialect that will be used.
This is a hook that allows an external plugin to provide functionality around an existing dialect, by allowing the plugin to be loaded from the url based on an entrypoint, and then the plugin returns the actual dialect to be used.
By default this just returns the cls.
method sqlalchemy.engine.default.DefaultDialect.get_dialect_pool_class(url: URL) → Type[Pool]
return a Pool class to use for a given URL
method sqlalchemy.engine.default.DefaultDialect.get_driver_connection(connection: DBAPIConnection) → Any
Returns the connection object as returned by the external driver package.
For normal dialects that use a DBAPI compliant driver this call will just return the connection passed as argument. For dialects that instead adapt a non DBAPI compliant driver, like when adapting an asyncio driver, this call will return the connection-like object as returned by the driver.
Added in version 1.4.24.
method sqlalchemy.engine.default.DefaultDialect.get_foreign_keys(connection: Connection, table_name: str, schema: str | None = None, **kw: Any) → List[ReflectedForeignKeyConstraint]
inherited from the Dialect.get_foreign_keys() method of Dialect
Return information about foreign_keys in table_name.
Given a Connection, a string table_name, and an optional string schema, return foreign key information as a list of dicts corresponding to the ReflectedForeignKeyConstraint dictionary.
This is an internal dialect method. Applications should use Inspector.get_foreign_keys().
method sqlalchemy.engine.default.DefaultDialect.get_indexes(connection: Connection, table_name: str, schema: str | None = None, **kw: Any) → List[ReflectedIndex]
inherited from the Dialect.get_indexes() method of Dialect
Return information about indexes in table_name.
Given a Connection, a string table_name and an optional string schema, return index information as a list of dictionaries corresponding to the ReflectedIndex dictionary.
This is an internal dialect method. Applications should use Inspector.get_indexes().
method sqlalchemy.engine.default.DefaultDialect.get_isolation_level(dbapi_connection: DBAPIConnection) → Literal['SERIALIZABLE', 'REPEATABLE READ', 'READ COMMITTED', 'READ UNCOMMITTED', 'AUTOCOMMIT']
inherited from the Dialect.get_isolation_level() method of Dialect
Given a DBAPI connection, return its isolation level.
When working with a Connection object, the corresponding DBAPI connection may be procured using the Connection.connection accessor.
Note that this is a dialect-level method which is used as part of the implementation of the Connection and Engine isolation level facilities; these APIs should be preferred for most typical use cases.
See also
Connection.get_isolation_level() - view current level
Connection.default_isolation_level - view default level
Connection.execution_options.isolation_level - set per Connection isolation level
create_engine.isolation_level - set per Engine isolation level
method sqlalchemy.engine.default.DefaultDialect.get_isolation_level_values(dbapi_conn: DBAPIConnection) → Sequence[Literal['SERIALIZABLE', 'REPEATABLE READ', 'READ COMMITTED', 'READ UNCOMMITTED', 'AUTOCOMMIT']]
inherited from the Dialect.get_isolation_level_values() method of Dialect
return a sequence of string isolation level names that are accepted by this dialect.
The available names should use the following conventions:
• use UPPERCASE names. isolation level methods will accept lowercase names but these are normalized into UPPERCASE before being passed along to the dialect.
• separate words should be separated by spaces, not underscores, e.g. REPEATABLE READ. isolation level names will have underscores converted to spaces before being passed along to the dialect.
• The names for the four standard isolation names to the extent that they are supported by the backend should be READ UNCOMMITTED, READ COMMITTED, REPEATABLE READ, SERIALIZABLE
• if the dialect supports an autocommit option it should be provided using the isolation level name AUTOCOMMIT.
• Other isolation modes may also be present, provided that they are named in UPPERCASE and use spaces not underscores.
This function is used so that the default dialect can check that a given isolation level parameter is valid, else raises an ArgumentError.
A DBAPI connection is passed to the method, in the unlikely event that the dialect needs to interrogate the connection itself to determine this list, however it is expected that most backends will return a hardcoded list of values. If the dialect supports “AUTOCOMMIT”, that value should also be present in the sequence returned.
The method raises NotImplementedError by default. If a dialect does not implement this method, then the default dialect will not perform any checking on a given isolation level value before passing it onto the Dialect.set_isolation_level() method. This is to allow backwards-compatibility with third party dialects that may not yet be implementing this method.
Added in version 2.0.
method sqlalchemy.engine.default.DefaultDialect.get_materialized_view_names(connection: Connection, schema: str | None = None, **kw: Any) → List[str]
inherited from the Dialect.get_materialized_view_names() method of Dialect
Return a list of all materialized view names available in the database.
This is an internal dialect method. Applications should use Inspector.get_materialized_view_names().
Parameters:
schema – 
schema name to query, if not the default schema.
Added in version 2.0.
method sqlalchemy.engine.default.DefaultDialect.get_multi_check_constraints(connection, **kw)
Return information about check constraints in all tables in the given schema.
This is an internal dialect method. Applications should use Inspector.get_multi_check_constraints().
Note
The DefaultDialect provides a default implementation that will call the single table method for each object returned by Dialect.get_table_names(), Dialect.get_view_names() or Dialect.get_materialized_view_names() depending on the provided kind. Dialects that want to support a faster implementation should implement this method.
Added in version 2.0.
method sqlalchemy.engine.default.DefaultDialect.get_multi_columns(connection, **kw)
Return information about columns in all tables in the given schema.
This is an internal dialect method. Applications should use Inspector.get_multi_columns().
Note
The DefaultDialect provides a default implementation that will call the single table method for each object returned by Dialect.get_table_names(), Dialect.get_view_names() or Dialect.get_materialized_view_names() depending on the provided kind. Dialects that want to support a faster implementation should implement this method.
Added in version 2.0.
method sqlalchemy.engine.default.DefaultDialect.get_multi_foreign_keys(connection, **kw)
Return information about foreign_keys in all tables in the given schema.
This is an internal dialect method. Applications should use Inspector.get_multi_foreign_keys().
Note
The DefaultDialect provides a default implementation that will call the single table method for each object returned by Dialect.get_table_names(), Dialect.get_view_names() or Dialect.get_materialized_view_names() depending on the provided kind. Dialects that want to support a faster implementation should implement this method.
Added in version 2.0.
method sqlalchemy.engine.default.DefaultDialect.get_multi_indexes(connection, **kw)
Return information about indexes in in all tables in the given schema.
This is an internal dialect method. Applications should use Inspector.get_multi_indexes().
Note
The DefaultDialect provides a default implementation that will call the single table method for each object returned by Dialect.get_table_names(), Dialect.get_view_names() or Dialect.get_materialized_view_names() depending on the provided kind. Dialects that want to support a faster implementation should implement this method.
Added in version 2.0.
method sqlalchemy.engine.default.DefaultDialect.get_multi_pk_constraint(connection, **kw)
Return information about primary key constraints in all tables in the given schema.
This is an internal dialect method. Applications should use Inspector.get_multi_pk_constraint().
Note
The DefaultDialect provides a default implementation that will call the single table method for each object returned by Dialect.get_table_names(), Dialect.get_view_names() or Dialect.get_materialized_view_names() depending on the provided kind. Dialects that want to support a faster implementation should implement this method.
Added in version 2.0.
method sqlalchemy.engine.default.DefaultDialect.get_multi_table_comment(connection, **kw)
Return information about the table comment in all tables in the given schema.
This is an internal dialect method. Applications should use Inspector.get_multi_table_comment().
Note
The DefaultDialect provides a default implementation that will call the single table method for each object returned by Dialect.get_table_names(), Dialect.get_view_names() or Dialect.get_materialized_view_names() depending on the provided kind. Dialects that want to support a faster implementation should implement this method.
Added in version 2.0.
method sqlalchemy.engine.default.DefaultDialect.get_multi_table_options(connection, **kw)
Return a dictionary of options specified when the tables in the given schema were created.
This is an internal dialect method. Applications should use Inspector.get_multi_table_options().
Note
The DefaultDialect provides a default implementation that will call the single table method for each object returned by Dialect.get_table_names(), Dialect.get_view_names() or Dialect.get_materialized_view_names() depending on the provided kind. Dialects that want to support a faster implementation should implement this method.
Added in version 2.0.
method sqlalchemy.engine.default.DefaultDialect.get_multi_unique_constraints(connection, **kw)
Return information about unique constraints in all tables in the given schema.
This is an internal dialect method. Applications should use Inspector.get_multi_unique_constraints().
Note
The DefaultDialect provides a default implementation that will call the single table method for each object returned by Dialect.get_table_names(), Dialect.get_view_names() or Dialect.get_materialized_view_names() depending on the provided kind. Dialects that want to support a faster implementation should implement this method.
Added in version 2.0.
method sqlalchemy.engine.default.DefaultDialect.get_pk_constraint(connection: Connection, table_name: str, schema: str | None = None, **kw: Any) → ReflectedPrimaryKeyConstraint
inherited from the Dialect.get_pk_constraint() method of Dialect
Return information about the primary key constraint on table_name`.
Given a Connection, a string table_name, and an optional string schema, return primary key information as a dictionary corresponding to the ReflectedPrimaryKeyConstraint dictionary.
This is an internal dialect method. Applications should use Inspector.get_pk_constraint().
method sqlalchemy.engine.default.DefaultDialect.get_schema_names(connection: Connection, **kw: Any) → List[str]
inherited from the Dialect.get_schema_names() method of Dialect
Return a list of all schema names available in the database.
This is an internal dialect method. Applications should use Inspector.get_schema_names().
method sqlalchemy.engine.default.DefaultDialect.get_sequence_names(connection: Connection, schema: str | None = None, **kw: Any) → List[str]
inherited from the Dialect.get_sequence_names() method of Dialect
Return a list of all sequence names available in the database.
This is an internal dialect method. Applications should use Inspector.get_sequence_names().
Parameters:
schema – schema name to query, if not the default schema.
Added in version 1.4.
method sqlalchemy.engine.default.DefaultDialect.get_table_comment(connection: Connection, table_name: str, schema: str | None = None, **kw: Any) → ReflectedTableComment
inherited from the Dialect.get_table_comment() method of Dialect
Return the “comment” for the table identified by table_name.
Given a string table_name and an optional string schema, return table comment information as a dictionary corresponding to the ReflectedTableComment dictionary.
This is an internal dialect method. Applications should use Inspector.get_table_comment().
Raise:
NotImplementedError for dialects that don’t support comments.
Added in version 1.2.
method sqlalchemy.engine.default.DefaultDialect.get_table_names(connection: Connection, schema: str | None = None, **kw: Any) → List[str]
inherited from the Dialect.get_table_names() method of Dialect
Return a list of table names for schema.
This is an internal dialect method. Applications should use Inspector.get_table_names().
method sqlalchemy.engine.default.DefaultDialect.get_table_options(connection: Connection, table_name: str, schema: str | None = None, **kw: Any) → Dict[str, Any]
inherited from the Dialect.get_table_options() method of Dialect
Return a dictionary of options specified when table_name was created.
This is an internal dialect method. Applications should use Inspector.get_table_options().
method sqlalchemy.engine.default.DefaultDialect.get_temp_table_names(connection: Connection, schema: str | None = None, **kw: Any) → List[str]
inherited from the Dialect.get_temp_table_names() method of Dialect
Return a list of temporary table names on the given connection, if supported by the underlying backend.
This is an internal dialect method. Applications should use Inspector.get_temp_table_names().
method sqlalchemy.engine.default.DefaultDialect.get_temp_view_names(connection: Connection, schema: str | None = None, **kw: Any) → List[str]
inherited from the Dialect.get_temp_view_names() method of Dialect
Return a list of temporary view names on the given connection, if supported by the underlying backend.
This is an internal dialect method. Applications should use Inspector.get_temp_view_names().
method sqlalchemy.engine.default.DefaultDialect.get_unique_constraints(connection: Connection, table_name: str, schema: str | None = None, **kw: Any) → List[ReflectedUniqueConstraint]
inherited from the Dialect.get_unique_constraints() method of Dialect
Return information about unique constraints in table_name.
Given a string table_name and an optional string schema, return unique constraint information as a list of dicts corresponding to the ReflectedUniqueConstraint dictionary.
This is an internal dialect method. Applications should use Inspector.get_unique_constraints().
method sqlalchemy.engine.default.DefaultDialect.get_view_definition(connection: Connection, view_name: str, schema: str | None = None, **kw: Any) → str
inherited from the Dialect.get_view_definition() method of Dialect
Return plain or materialized view definition.
This is an internal dialect method. Applications should use Inspector.get_view_definition().
Given a Connection, a string view_name, and an optional string schema, return the view definition.
method sqlalchemy.engine.default.DefaultDialect.get_view_names(connection: Connection, schema: str | None = None, **kw: Any) → List[str]
inherited from the Dialect.get_view_names() method of Dialect
Return a list of all non-materialized view names available in the database.
This is an internal dialect method. Applications should use Inspector.get_view_names().
Parameters:
schema – schema name to query, if not the default schema.
method sqlalchemy.engine.default.DefaultDialect.has_index(connection, table_name, index_name, schema=None, **kw)
Check the existence of a particular index name in the database.
Given a Connection object, a string table_name and string index name, return True if an index of the given name on the given table exists, False otherwise.
The DefaultDialect implements this in terms of the Dialect.has_table() and Dialect.get_indexes() methods, however dialects can implement a more performant version.
This is an internal dialect method. Applications should use Inspector.has_index().
Added in version 1.4.
method sqlalchemy.engine.default.DefaultDialect.has_schema(connection: Connection, schema_name: str, **kw: Any) → bool
Check the existence of a particular schema name in the database.
Given a Connection object, a string schema_name, return True if a schema of the given exists, False otherwise.
The DefaultDialect implements this by checking the presence of schema_name among the schemas returned by Dialect.get_schema_names(), however dialects can implement a more performant version.
This is an internal dialect method. Applications should use Inspector.has_schema().
Added in version 2.0.
method sqlalchemy.engine.default.DefaultDialect.has_sequence(connection: Connection, sequence_name: str, schema: str | None = None, **kw: Any) → bool
inherited from the Dialect.has_sequence() method of Dialect
Check the existence of a particular sequence in the database.
Given a Connection object and a string sequence_name, return True if the given sequence exists in the database, False otherwise.
This is an internal dialect method. Applications should use Inspector.has_sequence().
method sqlalchemy.engine.default.DefaultDialect.has_table(connection: Connection, table_name: str, schema: str | None = None, **kw: Any) → bool
inherited from the Dialect.has_table() method of Dialect
For internal dialect use, check the existence of a particular table or view in the database.
Given a Connection object, a string table_name and optional schema name, return True if the given table exists in the database, False otherwise.
This method serves as the underlying implementation of the public facing Inspector.has_table() method, and is also used internally to implement the “checkfirst” behavior for methods like Table.create() and MetaData.create_all().
Note
This method is used internally by SQLAlchemy, and is published so that third-party dialects may provide an implementation. It is not the public API for checking for table presence. Please use the Inspector.has_table() method.
Changed in version 2.0::: Dialect.has_table() now formally supports checking for additional table-like objects:
• any type of views (plain or materialized)
• temporary tables of any kind
Previously, these two checks were not formally specified and different dialects would vary in their behavior. The dialect testing suite now includes tests for all of these object types, and dialects to the degree that the backing database supports views or temporary tables should seek to support locating these objects for full compliance.
attribute sqlalchemy.engine.default.DefaultDialect.has_terminate: bool = False
Whether or not this dialect has a separate “terminate” implementation that does not block or require awaiting.
attribute sqlalchemy.engine.default.DefaultDialect.identifier_preparer: IdentifierPreparer
This element will refer to an instance of IdentifierPreparer once a DefaultDialect has been constructed.
classmethod sqlalchemy.engine.default.DefaultDialect.import_dbapi() → DBAPIModule
inherited from the Dialect.import_dbapi() method of Dialect
Import the DBAPI module that is used by this dialect.
The Python module object returned here will be assigned as an instance variable to a constructed dialect under the name .dbapi.
Changed in version 2.0: The Dialect.import_dbapi() class method is renamed from the previous method .Dialect.dbapi(), which would be replaced at dialect instantiation time by the DBAPI module itself, thus using the same name in two different ways. If a .Dialect.dbapi() classmethod is present on a third-party dialect, it will be used and a deprecation warning will be emitted.
attribute sqlalchemy.engine.default.DefaultDialect.include_set_input_sizes: Set[Any] | None = None
set of DBAPI type objects that should be included in automatic cursor.setinputsizes() calls.
This is only used if bind_typing is BindTyping.SET_INPUT_SIZES
method sqlalchemy.engine.default.DefaultDialect.initialize(connection: Connection) → None
Called during strategized creation of the dialect with a connection.
Allows dialects to configure options based on server version info or other properties.
The connection passed here is a SQLAlchemy Connection object, with full capabilities.
The initialize() method of the base dialect should be called via super().
Note
as of SQLAlchemy 1.4, this method is called before any Dialect.on_connect() hooks are called.
attribute sqlalchemy.engine.default.DefaultDialect.inline_comments: bool = False
Indicates the dialect supports comment DDL that’s inline with the definition of a Table or Column. If False, this implies that ALTER must be used to set table and column comments.
attribute sqlalchemy.engine.default.DefaultDialect.insert_executemany_returning: bool
dialect / driver / database supports some means of providing INSERT…RETURNING support when dialect.do_executemany() is used.
attribute sqlalchemy.engine.default.DefaultDialect.insert_executemany_returning_sort_by_parameter_order: bool
dialect / driver / database supports some means of providing INSERT…RETURNING support when dialect.do_executemany() is used along with the Insert.returning.sort_by_parameter_order parameter being set.
attribute sqlalchemy.engine.default.DefaultDialect.insert_returning: bool = False
if the dialect supports RETURNING with INSERT
Added in version 2.0.
attribute sqlalchemy.engine.default.DefaultDialect.insertmanyvalues_implicit_sentinel: InsertmanyvaluesSentinelOpts = symbol('NOT_SUPPORTED')
Options indicating the database supports a form of bulk INSERT where the autoincrement integer primary key can be reliably used as an ordering for INSERTed rows.
Added in version 2.0.10.
See also
Correlating RETURNING rows to parameter sets
attribute sqlalchemy.engine.default.DefaultDialect.insertmanyvalues_max_parameters: int = 32700
Alternate to insertmanyvalues_page_size, will additionally limit page size based on number of parameters total in the statement.
attribute sqlalchemy.engine.default.DefaultDialect.insertmanyvalues_page_size: int = 1000
Number of rows to render into an individual INSERT..VALUES() statement for ExecuteStyle.INSERTMANYVALUES executions.
The default dialect defaults this to 1000.
Added in version 2.0.
See also
Connection.execution_options.insertmanyvalues_page_size - execution option available on Connection, statements
attribute sqlalchemy.engine.default.DefaultDialect.is_async: bool = False
Whether or not this dialect is intended for asyncio use.
method sqlalchemy.engine.default.DefaultDialect.is_disconnect(e: DBAPIModule.Error, connection: pool.PoolProxiedConnection | interfaces.DBAPIConnection | None, cursor: interfaces.DBAPICursor | None) → bool
Return True if the given DB-API error indicates an invalid connection
attribute sqlalchemy.engine.default.DefaultDialect.label_length: int | None
optional user-defined max length for SQL labels
classmethod sqlalchemy.engine.default.DefaultDialect.load_provisioning()
set up the provision.py module for this dialect.
For dialects that include a provision.py module that sets up provisioning followers, this method should initiate that process.
A typical implementation would be:
@classmethod
def load_provisioning(cls):
    __import__("mydialect.provision")
The default method assumes a module named provision.py inside the owning package of the current dialect, based on the __module__ attribute:
@classmethod
def load_provisioning(cls):
    package = ".".join(cls.__module__.split(".")[0:-1])
    try:
        __import__(package + ".provision")
    except ImportError:
        pass
Added in version 1.3.14.
attribute sqlalchemy.engine.default.DefaultDialect.loaded_dbapi
attribute sqlalchemy.engine.default.DefaultDialect.max_constraint_name_length: int | None = None
The maximum length of constraint names if different from max_identifier_length.
attribute sqlalchemy.engine.default.DefaultDialect.max_identifier_length: int = 9999
The maximum length of identifier names.
attribute sqlalchemy.engine.default.DefaultDialect.max_index_name_length: int | None = None
The maximum length of index names if different from max_identifier_length.
attribute sqlalchemy.engine.default.DefaultDialect.name: str = 'default'
identifying name for the dialect from a DBAPI-neutral point of view (i.e. ‘sqlite’)
method sqlalchemy.engine.default.DefaultDialect.normalize_name(name)
convert the given name to lowercase if it is detected as case insensitive.
This method is only used if the dialect defines requires_name_normalize=True.
method sqlalchemy.engine.default.DefaultDialect.on_connect() → Callable[[Any], None] | None
return a callable which sets up a newly created DBAPI connection.
The callable should accept a single argument “conn” which is the DBAPI connection itself. The inner callable has no return value.
E.g.:
class MyDialect(default.DefaultDialect):
    # ...

    def on_connect(self):
        def do_on_connect(connection):
            connection.execute("SET SPECIAL FLAGS etc")

        return do_on_connect
This is used to set dialect-wide per-connection options such as isolation modes, Unicode modes, etc.
The “do_on_connect” callable is invoked by using the PoolEvents.connect() event hook, then unwrapping the DBAPI connection and passing it into the callable.
Changed in version 1.4: the on_connect hook is no longer called twice for the first connection of a dialect. The on_connect hook is still called before the Dialect.initialize() method however.
Changed in version 1.4.3: the on_connect hook is invoked from a new method on_connect_url that passes the URL that was used to create the connect args. Dialects can implement on_connect_url instead of on_connect if they need the URL object that was used for the connection in order to get additional context.
If None is returned, no event listener is generated.
Returns:
a callable that accepts a single DBAPI connection as an argument, or None.
See also
Dialect.connect() - allows the DBAPI connect() sequence itself to be controlled.
Dialect.on_connect_url() - supersedes Dialect.on_connect() to also receive the URL object in context.
method sqlalchemy.engine.default.DefaultDialect.on_connect_url(url: URL) → Callable[[Any], Any] | None
inherited from the Dialect.on_connect_url() method of Dialect
return a callable which sets up a newly created DBAPI connection.
This method is a new hook that supersedes the Dialect.on_connect() method when implemented by a dialect. When not implemented by a dialect, it invokes the Dialect.on_connect() method directly to maintain compatibility with existing dialects. There is no deprecation for Dialect.on_connect() expected.
The callable should accept a single argument “conn” which is the DBAPI connection itself. The inner callable has no return value.
E.g.:
class MyDialect(default.DefaultDialect):
    # ...

    def on_connect_url(self, url):
        def do_on_connect(connection):
            connection.execute("SET SPECIAL FLAGS etc")

        return do_on_connect
This is used to set dialect-wide per-connection options such as isolation modes, Unicode modes, etc.
This method differs from Dialect.on_connect() in that it is passed the URL object that’s relevant to the connect args. Normally the only way to get this is from the Dialect.on_connect() hook is to look on the Engine itself, however this URL object may have been replaced by plugins.
Note
The default implementation of Dialect.on_connect_url() is to invoke the Dialect.on_connect() method. Therefore if a dialect implements this method, the Dialect.on_connect() method will not be called unless the overriding dialect calls it directly from here.
Added in version 1.4.3: added Dialect.on_connect_url() which normally calls into Dialect.on_connect().
Parameters:
url – a URL object representing the URL that was passed to the Dialect.create_connect_args() method.
Returns:
a callable that accepts a single DBAPI connection as an argument, or None.
See also
Dialect.on_connect()
attribute sqlalchemy.engine.default.DefaultDialect.paramstyle: str
the paramstyle to be used (some DB-APIs support multiple paramstyles).
attribute sqlalchemy.engine.default.DefaultDialect.positional: bool
True if the paramstyle for this Dialect is positional.
attribute sqlalchemy.engine.default.DefaultDialect.preexecute_autoincrement_sequences: bool = False
True if ‘implicit’ primary key functions must be executed separately in order to get their value, if RETURNING is not used.
This is currently oriented towards PostgreSQL when the implicit_returning=False parameter is used on a Table object.
attribute sqlalchemy.engine.default.DefaultDialect.preparer
alias of IdentifierPreparer
attribute sqlalchemy.engine.default.DefaultDialect.reflection_options: Sequence[str] = ()
inherited from the Dialect.reflection_options attribute of Dialect
Sequence of string names indicating keyword arguments that can be established on a Table object which will be passed as “reflection options” when using Table.autoload_with.
Current example is “oracle_resolve_synonyms” in the Oracle Database dialects.
method sqlalchemy.engine.default.DefaultDialect.reset_isolation_level(dbapi_conn)
Given a DBAPI connection, revert its isolation to the default.
Note that this is a dialect-level method which is used as part of the implementation of the Connection and Engine isolation level facilities; these APIs should be preferred for most typical use cases.
See also
Connection.get_isolation_level() - view current level
Connection.default_isolation_level - view default level
Connection.execution_options.isolation_level - set per Connection isolation level
create_engine.isolation_level - set per Engine isolation level
attribute sqlalchemy.engine.default.DefaultDialect.returns_native_bytes: bool = False
indicates if Python bytes() objects are returned natively by the driver for SQL “binary” datatypes.
Added in version 2.0.11.
attribute sqlalchemy.engine.default.DefaultDialect.sequences_optional: bool = False
If True, indicates if the Sequence.optional parameter on the Sequence construct should signal to not generate a CREATE SEQUENCE. Applies only to dialects that support sequences. Currently used only to allow PostgreSQL SERIAL to be used on a column that specifies Sequence() for usage on other backends.
attribute sqlalchemy.engine.default.DefaultDialect.server_side_cursors: bool = False
deprecated; indicates if the dialect should attempt to use server side cursors by default
attribute sqlalchemy.engine.default.DefaultDialect.server_version_info: Tuple[Any, ...] | None = None
a tuple containing a version number for the DB backend in use.
This value is only available for supporting dialects, and is typically populated during the initial connection to the database.
method sqlalchemy.engine.default.DefaultDialect.set_connection_execution_options(connection: Connection, opts: Mapping[str, Any]) → None
Establish execution options for a given connection.
This is implemented by DefaultDialect in order to implement the Connection.execution_options.isolation_level execution option. Dialects can intercept various execution options which may need to modify state on a particular DBAPI connection.
Added in version 1.4.
method sqlalchemy.engine.default.DefaultDialect.set_engine_execution_options(engine: Engine, opts: Mapping[str, Any]) → None
Establish execution options for a given engine.
This is implemented by DefaultDialect to establish event hooks for new Connection instances created by the given Engine which will then invoke the Dialect.set_connection_execution_options() method for that connection.
method sqlalchemy.engine.default.DefaultDialect.set_isolation_level(dbapi_connection: DBAPIConnection, level: Literal['SERIALIZABLE', 'REPEATABLE READ', 'READ COMMITTED', 'READ UNCOMMITTED', 'AUTOCOMMIT']) → None
inherited from the Dialect.set_isolation_level() method of Dialect
Given a DBAPI connection, set its isolation level.
Note that this is a dialect-level method which is used as part of the implementation of the Connection and Engine isolation level facilities; these APIs should be preferred for most typical use cases.
If the dialect also implements the Dialect.get_isolation_level_values() method, then the given level is guaranteed to be one of the string names within that sequence, and the method will not need to anticipate a lookup failure.
See also
Connection.get_isolation_level() - view current level
Connection.default_isolation_level - view default level
Connection.execution_options.isolation_level - set per Connection isolation level
create_engine.isolation_level - set per Engine isolation level
attribute sqlalchemy.engine.default.DefaultDialect.statement_compiler
alias of SQLCompiler
attribute sqlalchemy.engine.default.DefaultDialect.supports_alter: bool = True
True if the database supports ALTER TABLE - used only for generating foreign key constraints in certain circumstances
attribute sqlalchemy.engine.default.DefaultDialect.supports_comments: bool = False
Indicates the dialect supports comment DDL on tables and columns.
attribute sqlalchemy.engine.default.DefaultDialect.supports_constraint_comments: bool = False
Indicates if the dialect supports comment DDL on constraints.
Added in version 2.0.
attribute sqlalchemy.engine.default.DefaultDialect.supports_default_metavalue: bool = False
dialect supports INSERT… VALUES (DEFAULT) syntax
attribute sqlalchemy.engine.default.DefaultDialect.supports_default_values: bool = False
dialect supports INSERT… DEFAULT VALUES syntax
attribute sqlalchemy.engine.default.DefaultDialect.supports_empty_insert: bool = True
dialect supports INSERT () VALUES ()
attribute sqlalchemy.engine.default.DefaultDialect.supports_identity_columns: bool = False
target database supports IDENTITY
attribute sqlalchemy.engine.default.DefaultDialect.supports_multivalues_insert: bool = False
Target database supports INSERT…VALUES with multiple value sets, i.e. INSERT INTO table (cols) VALUES (…), (…), (…), …
attribute sqlalchemy.engine.default.DefaultDialect.supports_native_boolean: bool = False
Indicates if the dialect supports a native boolean construct. This will prevent Boolean from generating a CHECK constraint when that type is used.
attribute sqlalchemy.engine.default.DefaultDialect.supports_native_decimal: bool = False
indicates if Decimal objects are handled and returned for precision numeric types, or if floats are returned
attribute sqlalchemy.engine.default.DefaultDialect.supports_native_enum: bool = False
Indicates if the dialect supports a native ENUM construct. This will prevent Enum from generating a CHECK constraint when that type is used in “native” mode.
attribute sqlalchemy.engine.default.DefaultDialect.supports_native_uuid: bool = False
indicates if Python UUID() objects are handled natively by the driver for SQL UUID datatypes.
Added in version 2.0.
attribute sqlalchemy.engine.default.DefaultDialect.supports_sane_multi_rowcount: bool = True
Indicate whether the dialect properly implements rowcount for UPDATE and DELETE statements when executed via executemany.
attribute sqlalchemy.engine.default.DefaultDialect.supports_sane_rowcount: bool = True
Indicate whether the dialect properly implements rowcount for UPDATE and DELETE statements.
attribute sqlalchemy.engine.default.DefaultDialect.supports_sane_rowcount_returning
True if this dialect supports sane rowcount even if RETURNING is in use.
For dialects that don’t support RETURNING, this is synonymous with supports_sane_rowcount.
attribute sqlalchemy.engine.default.DefaultDialect.supports_sequences: bool = False
Indicates if the dialect supports CREATE SEQUENCE or similar.
attribute sqlalchemy.engine.default.DefaultDialect.supports_server_side_cursors: generic_fn_descriptor[bool] | bool = False
indicates if the dialect supports server side cursors
attribute sqlalchemy.engine.default.DefaultDialect.supports_simple_order_by_label: bool = True
target database supports ORDER BY <labelname>, where <labelname> refers to a label in the columns clause of the SELECT
attribute sqlalchemy.engine.default.DefaultDialect.supports_statement_cache: bool = True
indicates if this dialect supports caching.
All dialects that are compatible with statement caching should set this flag to True directly on each dialect class and subclass that supports it. SQLAlchemy tests that this flag is locally present on each dialect subclass before it will use statement caching. This is to provide safety for legacy or new dialects that are not yet fully tested to be compliant with SQL statement caching.
Added in version 1.4.5.
See also
Caching for Third Party Dialects
attribute sqlalchemy.engine.default.DefaultDialect.tuple_in_values: bool = False
target database supports tuple IN, i.e. (x, y) IN ((q, p), (r, z))
attribute sqlalchemy.engine.default.DefaultDialect.type_compiler: Any
legacy; this is a TypeCompiler class at the class level, a TypeCompiler instance at the instance level.
Refer to type_compiler_instance instead.
attribute sqlalchemy.engine.default.DefaultDialect.type_compiler_cls
alias of GenericTypeCompiler
attribute sqlalchemy.engine.default.DefaultDialect.type_compiler_instance: TypeCompiler
instance of a Compiled class used to compile SQL type objects
Added in version 2.0.
method sqlalchemy.engine.default.DefaultDialect.type_descriptor(typeobj)
Provide a database-specific TypeEngine object, given the generic object which comes from the types module.
This method looks for a dictionary called colspecs as a class or instance-level variable, and passes on to adapt_type().
attribute sqlalchemy.engine.default.DefaultDialect.update_executemany_returning: bool = False
dialect supports UPDATE..RETURNING with executemany.
attribute sqlalchemy.engine.default.DefaultDialect.update_returning: bool = False
if the dialect supports RETURNING with UPDATE
Added in version 2.0.
attribute sqlalchemy.engine.default.DefaultDialect.update_returning_multifrom: bool = False
if the dialect supports RETURNING with UPDATE..FROM
Added in version 2.0.
attribute sqlalchemy.engine.default.DefaultDialect.use_insertmanyvalues: bool = False
if True, indicates “insertmanyvalues” functionality should be used to allow for insert_executemany_returning behavior, if possible.
In practice, setting this to True means:
if supports_multivalues_insert, insert_returning and use_insertmanyvalues are all True, the SQL compiler will produce an INSERT that will be interpreted by the DefaultDialect as an ExecuteStyle.INSERTMANYVALUES execution that allows for INSERT of many rows with RETURNING by rewriting a single-row INSERT statement to have multiple VALUES clauses, also executing the statement multiple times for a series of batches when large numbers of rows are given.
The parameter is False for the default dialect, and is set to True for SQLAlchemy internal dialects SQLite, MySQL/MariaDB, PostgreSQL, SQL Server. It remains at False for Oracle Database, which provides native “executemany with RETURNING” support and also does not support supports_multivalues_insert. For MySQL/MariaDB, those MySQL dialects that don’t support RETURNING will not report insert_executemany_returning as True.
Added in version 2.0.
See also
“Insert Many Values” Behavior for INSERT statements
attribute sqlalchemy.engine.default.DefaultDialect.use_insertmanyvalues_wo_returning: bool = False
if True, and use_insertmanyvalues is also True, INSERT statements that don’t include RETURNING will also use “insertmanyvalues”.
Added in version 2.0.
See also
“Insert Many Values” Behavior for INSERT statements
method sqlalchemy.engine.default.DefaultDialect.validate_identifier(ident: str) → None
Validates an identifier name, raising an exception if invalid
class sqlalchemy.engine.Dialect
Define the behavior of a specific database and DB-API combination.
Any aspect of metadata definition, SQL query generation, execution, result-set handling, or anything else which varies between databases is defined under the general category of the Dialect. The Dialect acts as a factory for other database-specific object implementations including ExecutionContext, Compiled, DefaultGenerator, and TypeEngine.
Note
Third party dialects should not subclass Dialect directly. Instead, subclass DefaultDialect or descendant class.
Members
bind_typing, colspecs, connect(), construct_arguments, create_connect_args(), create_xid(), cte_follows_insert, dbapi, dbapi_exception_translation_map, ddl_compiler, default_isolation_level, default_metavalue_token, default_schema_name, default_sequence_base, delete_executemany_returning, delete_returning, delete_returning_multifrom, denormalize_name(), div_is_floordiv, do_begin(), do_begin_twophase(), do_close(), do_commit(), do_commit_twophase(), do_execute(), do_execute_no_params(), do_executemany(), do_ping(), do_prepare_twophase(), do_recover_twophase(), do_release_savepoint(), do_rollback(), do_rollback_to_savepoint(), do_rollback_twophase(), do_savepoint(), do_set_input_sizes(), do_terminate(), driver, engine_config_types, engine_created(), exclude_set_input_sizes, execute_sequence_format, execution_ctx_cls, favor_returning_over_lastrowid, get_async_dialect_cls(), get_check_constraints(), get_columns(), get_default_isolation_level(), get_dialect_cls(), get_dialect_pool_class(), get_driver_connection(), get_foreign_keys(), get_indexes(), get_isolation_level(), get_isolation_level_values(), get_materialized_view_names(), get_multi_check_constraints(), get_multi_columns(), get_multi_foreign_keys(), get_multi_indexes(), get_multi_pk_constraint(), get_multi_table_comment(), get_multi_table_options(), get_multi_unique_constraints(), get_pk_constraint(), get_schema_names(), get_sequence_names(), get_table_comment(), get_table_names(), get_table_options(), get_temp_table_names(), get_temp_view_names(), get_unique_constraints(), get_view_definition(), get_view_names(), has_index(), has_schema(), has_sequence(), has_table(), has_terminate, identifier_preparer, import_dbapi(), include_set_input_sizes, initialize(), inline_comments, insert_executemany_returning, insert_executemany_returning_sort_by_parameter_order, insert_returning, insertmanyvalues_implicit_sentinel, insertmanyvalues_max_parameters, insertmanyvalues_page_size, is_async, is_disconnect(), label_length, load_provisioning(), loaded_dbapi, max_constraint_name_length, max_identifier_length, max_index_name_length, name, normalize_name(), on_connect(), on_connect_url(), paramstyle, positional, preexecute_autoincrement_sequences, preparer, reflection_options, reset_isolation_level(), returns_native_bytes, sequences_optional, server_side_cursors, server_version_info, set_connection_execution_options(), set_engine_execution_options(), set_isolation_level(), statement_compiler, supports_alter, supports_comments, supports_constraint_comments, supports_default_metavalue, supports_default_values, supports_empty_insert, supports_identity_columns, supports_multivalues_insert, supports_native_boolean, supports_native_decimal, supports_native_enum, supports_native_uuid, supports_sane_multi_rowcount, supports_sane_rowcount, supports_sequences, supports_server_side_cursors, supports_simple_order_by_label, supports_statement_cache, tuple_in_values, type_compiler, type_compiler_cls, type_compiler_instance, type_descriptor(), update_executemany_returning, update_returning, update_returning_multifrom, use_insertmanyvalues, use_insertmanyvalues_wo_returning, validate_identifier()
Class signature
class sqlalchemy.engine.Dialect (sqlalchemy.event.registry.EventTarget)
attribute sqlalchemy.engine.Dialect.bind_typing = 1
define a means of passing typing information to the database and/or driver for bound parameters.
See BindTyping for values.
Added in version 2.0.
attribute sqlalchemy.engine.Dialect.colspecs: MutableMapping[Type[TypeEngine[Any]], Type[TypeEngine[Any]]]
A dictionary of TypeEngine classes from sqlalchemy.types mapped to subclasses that are specific to the dialect class. This dictionary is class-level only and is not accessed from the dialect instance itself.
method sqlalchemy.engine.Dialect.connect(*cargs: Any, **cparams: Any) → DBAPIConnection
Establish a connection using this dialect’s DBAPI.
The default implementation of this method is:
def connect(self, *cargs, **cparams):
    return self.dbapi.connect(*cargs, **cparams)
The *cargs, **cparams parameters are generated directly from this dialect’s Dialect.create_connect_args() method.
This method may be used for dialects that need to perform programmatic per-connection steps when a new connection is procured from the DBAPI.
Parameters:
• *cargs – positional parameters returned from the Dialect.create_connect_args() method
• **cparams – keyword parameters returned from the Dialect.create_connect_args() method.
Returns:
a DBAPI connection, typically from the PEP 249 module level .connect() function.
See also
Dialect.create_connect_args()
Dialect.on_connect()
attribute sqlalchemy.engine.Dialect.construct_arguments: List[Tuple[Type[SchemaItem | ClauseElement], Mapping[str, Any]]] | None = None
Optional set of argument specifiers for various SQLAlchemy constructs, typically schema items.
To implement, establish as a series of tuples, as in:
construct_arguments = [
    (schema.Index, {"using": False, "where": None, "ops": None}),
]
If the above construct is established on the PostgreSQL dialect, the Index construct will now accept the keyword arguments postgresql_using, postgresql_where, nad postgresql_ops. Any other argument specified to the constructor of Index which is prefixed with postgresql_ will raise ArgumentError.
A dialect which does not include a construct_arguments member will not participate in the argument validation system. For such a dialect, any argument name is accepted by all participating constructs, within the namespace of arguments prefixed with that dialect name. The rationale here is so that third-party dialects that haven’t yet implemented this feature continue to function in the old way.
See also
DialectKWArgs - implementing base class which consumes DefaultDialect.construct_arguments
method sqlalchemy.engine.Dialect.create_connect_args(url: URL) → ConnectArgsType
Build DB-API compatible connection arguments.
Given a URL object, returns a tuple consisting of a (*args, **kwargs) suitable to send directly to the dbapi’s connect function. The arguments are sent to the Dialect.connect() method which then runs the DBAPI-level connect() function.
The method typically makes use of the URL.translate_connect_args() method in order to generate a dictionary of options.
The default implementation is:
def create_connect_args(self, url):
    opts = url.translate_connect_args()
    opts.update(url.query)
    return ([], opts)
Parameters:
url – a URL object
Returns:
a tuple of (*args, **kwargs) which will be passed to the Dialect.connect() method.
See also
URL.translate_connect_args()
method sqlalchemy.engine.Dialect.create_xid() → Any
Create a two-phase transaction ID.
This id will be passed to do_begin_twophase(), do_rollback_twophase(), do_commit_twophase(). Its format is unspecified.
attribute sqlalchemy.engine.Dialect.cte_follows_insert: bool
target database, when given a CTE with an INSERT statement, needs the CTE to be below the INSERT
attribute sqlalchemy.engine.Dialect.dbapi: DBAPIModule | None
A reference to the DBAPI module object itself.
SQLAlchemy dialects import DBAPI modules using the classmethod Dialect.import_dbapi(). The rationale is so that any dialect module can be imported and used to generate SQL statements without the need for the actual DBAPI driver to be installed. Only when an Engine is constructed using create_engine() does the DBAPI get imported; at that point, the creation process will assign the DBAPI module to this attribute.
Dialects should therefore implement Dialect.import_dbapi() which will import the necessary module and return it, and then refer to self.dbapi in dialect code in order to refer to the DBAPI module contents.
Changed in version The: Dialect.dbapi attribute is exclusively used as the per-Dialect-instance reference to the DBAPI module. The previous not-fully-documented .Dialect.dbapi() classmethod is deprecated and replaced by Dialect.import_dbapi().
attribute sqlalchemy.engine.Dialect.dbapi_exception_translation_map: Mapping[str, str] = {}
A dictionary of names that will contain as values the names of pep-249 exceptions (“IntegrityError”, “OperationalError”, etc) keyed to alternate class names, to support the case where a DBAPI has exception classes that aren’t named as they are referred to (e.g. IntegrityError = MyException). In the vast majority of cases this dictionary is empty.
attribute sqlalchemy.engine.Dialect.ddl_compiler: Type[DDLCompiler]
a Compiled class used to compile DDL statements
attribute sqlalchemy.engine.Dialect.default_isolation_level: IsolationLevel | None
the isolation that is implicitly present on new connections
attribute sqlalchemy.engine.Dialect.default_metavalue_token: str = 'DEFAULT'
for INSERT… VALUES (DEFAULT) syntax, the token to put in the parenthesis.
E.g. for SQLite this is the keyword “NULL”.
attribute sqlalchemy.engine.Dialect.default_schema_name: str | None
the name of the default schema. This value is only available for supporting dialects, and is typically populated during the initial connection to the database.
attribute sqlalchemy.engine.Dialect.default_sequence_base: int
the default value that will be rendered as the “START WITH” portion of a CREATE SEQUENCE DDL statement.
attribute sqlalchemy.engine.Dialect.delete_executemany_returning: bool
dialect supports DELETE..RETURNING with executemany.
attribute sqlalchemy.engine.Dialect.delete_returning: bool
if the dialect supports RETURNING with DELETE
Added in version 2.0.
attribute sqlalchemy.engine.Dialect.delete_returning_multifrom: bool
if the dialect supports RETURNING with DELETE..FROM
Added in version 2.0.
method sqlalchemy.engine.Dialect.denormalize_name(name: str) → str
convert the given name to a case insensitive identifier for the backend if it is an all-lowercase name.
This method is only used if the dialect defines requires_name_normalize=True.
attribute sqlalchemy.engine.Dialect.div_is_floordiv: bool
target database treats the / division operator as “floor division”
method sqlalchemy.engine.Dialect.do_begin(dbapi_connection: PoolProxiedConnection) → None
Provide an implementation of connection.begin(), given a DB-API connection.
The DBAPI has no dedicated “begin” method and it is expected that transactions are implicit. This hook is provided for those DBAPIs that might need additional help in this area.
Parameters:
dbapi_connection – a DBAPI connection, typically proxied within a ConnectionFairy.
method sqlalchemy.engine.Dialect.do_begin_twophase(connection: Connection, xid: Any) → None
Begin a two phase transaction on the given connection.
Parameters:
• connection – a Connection.
• xid – xid
method sqlalchemy.engine.Dialect.do_close(dbapi_connection: DBAPIConnection) → None
Provide an implementation of connection.close(), given a DBAPI connection.
This hook is called by the Pool when a connection has been detached from the pool, or is being returned beyond the normal capacity of the pool.
method sqlalchemy.engine.Dialect.do_commit(dbapi_connection: PoolProxiedConnection) → None
Provide an implementation of connection.commit(), given a DB-API connection.
Parameters:
dbapi_connection – a DBAPI connection, typically proxied within a ConnectionFairy.
method sqlalchemy.engine.Dialect.do_commit_twophase(connection: Connection, xid: Any, is_prepared: bool = True, recover: bool = False) → None
Commit a two phase transaction on the given connection.
Parameters:
• connection – a Connection.
• xid – xid
• is_prepared – whether or not TwoPhaseTransaction.prepare() was called.
• recover – if the recover flag was passed.
method sqlalchemy.engine.Dialect.do_execute(cursor: DBAPICursor, statement: str, parameters: Sequence[Any] | Mapping[str, Any] | None, context: ExecutionContext | None = None) → None
Provide an implementation of cursor.execute(statement, parameters).
method sqlalchemy.engine.Dialect.do_execute_no_params(cursor: DBAPICursor, statement: str, context: ExecutionContext | None = None) → None
Provide an implementation of cursor.execute(statement).
The parameter collection should not be sent.
method sqlalchemy.engine.Dialect.do_executemany(cursor: DBAPICursor, statement: str, parameters: Sequence[Sequence[Any]] | Sequence[Mapping[str, Any]], context: ExecutionContext | None = None) → None
Provide an implementation of cursor.executemany(statement, parameters).
method sqlalchemy.engine.Dialect.do_ping(dbapi_connection: DBAPIConnection) → bool
ping the DBAPI connection and return True if the connection is usable.
method sqlalchemy.engine.Dialect.do_prepare_twophase(connection: Connection, xid: Any) → None
Prepare a two phase transaction on the given connection.
Parameters:
• connection – a Connection.
• xid – xid
method sqlalchemy.engine.Dialect.do_recover_twophase(connection: Connection) → List[Any]
Recover list of uncommitted prepared two phase transaction identifiers on the given connection.
Parameters:
connection – a Connection.
method sqlalchemy.engine.Dialect.do_release_savepoint(connection: Connection, name: str) → None
Release the named savepoint on a connection.
Parameters:
• connection – a Connection.
• name – savepoint name.
method sqlalchemy.engine.Dialect.do_rollback(dbapi_connection: PoolProxiedConnection) → None
Provide an implementation of connection.rollback(), given a DB-API connection.
Parameters:
dbapi_connection – a DBAPI connection, typically proxied within a ConnectionFairy.
method sqlalchemy.engine.Dialect.do_rollback_to_savepoint(connection: Connection, name: str) → None
Rollback a connection to the named savepoint.
Parameters:
• connection – a Connection.
• name – savepoint name.
method sqlalchemy.engine.Dialect.do_rollback_twophase(connection: Connection, xid: Any, is_prepared: bool = True, recover: bool = False) → None
Rollback a two phase transaction on the given connection.
Parameters:
• connection – a Connection.
• xid – xid
• is_prepared – whether or not TwoPhaseTransaction.prepare() was called.
• recover – if the recover flag was passed.
method sqlalchemy.engine.Dialect.do_savepoint(connection: Connection, name: str) → None
Create a savepoint with the given name.
Parameters:
• connection – a Connection.
• name – savepoint name.
method sqlalchemy.engine.Dialect.do_set_input_sizes(cursor: DBAPICursor, list_of_tuples: _GenericSetInputSizesType, context: ExecutionContext) → Any
invoke the cursor.setinputsizes() method with appropriate arguments
This hook is called if the Dialect.bind_typing attribute is set to the BindTyping.SETINPUTSIZES value. Parameter data is passed in a list of tuples (paramname, dbtype, sqltype), where paramname is the key of the parameter in the statement, dbtype is the DBAPI datatype and sqltype is the SQLAlchemy type. The order of tuples is in the correct parameter order.
Added in version 1.4.
Changed in version 2.0: - setinputsizes mode is now enabled by setting Dialect.bind_typing to BindTyping.SETINPUTSIZES. Dialects which accept a use_setinputsizes parameter should set this value appropriately.
method sqlalchemy.engine.Dialect.do_terminate(dbapi_connection: DBAPIConnection) → None
Provide an implementation of connection.close() that tries as much as possible to not block, given a DBAPI connection.
In the vast majority of cases this just calls .close(), however for some asyncio dialects may call upon different API features.
This hook is called by the Pool when a connection is being recycled or has been invalidated.
Added in version 1.4.41.
attribute sqlalchemy.engine.Dialect.driver: str
identifying name for the dialect’s DBAPI
attribute sqlalchemy.engine.Dialect.engine_config_types: Mapping[str, Any]
a mapping of string keys that can be in an engine config linked to type conversion functions.
classmethod sqlalchemy.engine.Dialect.engine_created(engine: Engine) → None
A convenience hook called before returning the final Engine.
If the dialect returned a different class from the get_dialect_cls() method, then the hook is called on both classes, first on the dialect class returned by the get_dialect_cls() method and then on the class on which the method was called.
The hook should be used by dialects and/or wrappers to apply special events to the engine or its components. In particular, it allows a dialect-wrapping class to apply dialect-level events.
attribute sqlalchemy.engine.Dialect.exclude_set_input_sizes: Set[Any] | None
set of DBAPI type objects that should be excluded in automatic cursor.setinputsizes() calls.
This is only used if bind_typing is BindTyping.SET_INPUT_SIZES
attribute sqlalchemy.engine.Dialect.execute_sequence_format: Type[Tuple[Any, ...]] | Type[Tuple[List[Any]]]
either the ‘tuple’ or ‘list’ type, depending on what cursor.execute() accepts for the second argument (they vary).
attribute sqlalchemy.engine.Dialect.execution_ctx_cls: Type[ExecutionContext]
a ExecutionContext class used to handle statement execution
attribute sqlalchemy.engine.Dialect.favor_returning_over_lastrowid: bool
for backends that support both a lastrowid and a RETURNING insert strategy, favor RETURNING for simple single-int pk inserts.
cursor.lastrowid tends to be more performant on most backends.
classmethod sqlalchemy.engine.Dialect.get_async_dialect_cls(url: URL) → Type[Dialect]
Given a URL, return the Dialect that will be used by an async engine.
By default this is an alias of Dialect.get_dialect_cls() and just returns the cls. It may be used if a dialect provides both a sync and async version under the same name, like the psycopg driver.
Added in version 2.
See also
Dialect.get_dialect_cls()
method sqlalchemy.engine.Dialect.get_check_constraints(connection: Connection, table_name: str, schema: str | None = None, **kw: Any) → List[ReflectedCheckConstraint]
Return information about check constraints in table_name.
Given a string table_name and an optional string schema, return check constraint information as a list of dicts corresponding to the ReflectedCheckConstraint dictionary.
This is an internal dialect method. Applications should use Inspector.get_check_constraints().
method sqlalchemy.engine.Dialect.get_columns(connection: Connection, table_name: str, schema: str | None = None, **kw: Any) → List[ReflectedColumn]
Return information about columns in table_name.
Given a Connection, a string table_name, and an optional string schema, return column information as a list of dictionaries corresponding to the ReflectedColumn dictionary.
This is an internal dialect method. Applications should use Inspector.get_columns().
method sqlalchemy.engine.Dialect.get_default_isolation_level(dbapi_conn: DBAPIConnection) → Literal['SERIALIZABLE', 'REPEATABLE READ', 'READ COMMITTED', 'READ UNCOMMITTED', 'AUTOCOMMIT']
Given a DBAPI connection, return its isolation level, or a default isolation level if one cannot be retrieved.
This method may only raise NotImplementedError and must not raise any other exception, as it is used implicitly upon first connect.
The method must return a value for a dialect that supports isolation level settings, as this level is what will be reverted towards when a per-connection isolation level change is made.
The method defaults to using the Dialect.get_isolation_level() method unless overridden by a dialect.
Added in version 1.3.22.
classmethod sqlalchemy.engine.Dialect.get_dialect_cls(url: URL) → Type[Dialect]
Given a URL, return the Dialect that will be used.
This is a hook that allows an external plugin to provide functionality around an existing dialect, by allowing the plugin to be loaded from the url based on an entrypoint, and then the plugin returns the actual dialect to be used.
By default this just returns the cls.
method sqlalchemy.engine.Dialect.get_dialect_pool_class(url: URL) → Type[Pool]
return a Pool class to use for a given URL
method sqlalchemy.engine.Dialect.get_driver_connection(connection: DBAPIConnection) → Any
Returns the connection object as returned by the external driver package.
For normal dialects that use a DBAPI compliant driver this call will just return the connection passed as argument. For dialects that instead adapt a non DBAPI compliant driver, like when adapting an asyncio driver, this call will return the connection-like object as returned by the driver.
Added in version 1.4.24.
method sqlalchemy.engine.Dialect.get_foreign_keys(connection: Connection, table_name: str, schema: str | None = None, **kw: Any) → List[ReflectedForeignKeyConstraint]
Return information about foreign_keys in table_name.
Given a Connection, a string table_name, and an optional string schema, return foreign key information as a list of dicts corresponding to the ReflectedForeignKeyConstraint dictionary.
This is an internal dialect method. Applications should use Inspector.get_foreign_keys().
method sqlalchemy.engine.Dialect.get_indexes(connection: Connection, table_name: str, schema: str | None = None, **kw: Any) → List[ReflectedIndex]
Return information about indexes in table_name.
Given a Connection, a string table_name and an optional string schema, return index information as a list of dictionaries corresponding to the ReflectedIndex dictionary.
This is an internal dialect method. Applications should use Inspector.get_indexes().
method sqlalchemy.engine.Dialect.get_isolation_level(dbapi_connection: DBAPIConnection) → Literal['SERIALIZABLE', 'REPEATABLE READ', 'READ COMMITTED', 'READ UNCOMMITTED', 'AUTOCOMMIT']
Given a DBAPI connection, return its isolation level.
When working with a Connection object, the corresponding DBAPI connection may be procured using the Connection.connection accessor.
Note that this is a dialect-level method which is used as part of the implementation of the Connection and Engine isolation level facilities; these APIs should be preferred for most typical use cases.
See also
Connection.get_isolation_level() - view current level
Connection.default_isolation_level - view default level
Connection.execution_options.isolation_level - set per Connection isolation level
create_engine.isolation_level - set per Engine isolation level
method sqlalchemy.engine.Dialect.get_isolation_level_values(dbapi_conn: DBAPIConnection) → Sequence[Literal['SERIALIZABLE', 'REPEATABLE READ', 'READ COMMITTED', 'READ UNCOMMITTED', 'AUTOCOMMIT']]
return a sequence of string isolation level names that are accepted by this dialect.
The available names should use the following conventions:
• use UPPERCASE names. isolation level methods will accept lowercase names but these are normalized into UPPERCASE before being passed along to the dialect.
• separate words should be separated by spaces, not underscores, e.g. REPEATABLE READ. isolation level names will have underscores converted to spaces before being passed along to the dialect.
• The names for the four standard isolation names to the extent that they are supported by the backend should be READ UNCOMMITTED, READ COMMITTED, REPEATABLE READ, SERIALIZABLE
• if the dialect supports an autocommit option it should be provided using the isolation level name AUTOCOMMIT.
• Other isolation modes may also be present, provided that they are named in UPPERCASE and use spaces not underscores.
This function is used so that the default dialect can check that a given isolation level parameter is valid, else raises an ArgumentError.
A DBAPI connection is passed to the method, in the unlikely event that the dialect needs to interrogate the connection itself to determine this list, however it is expected that most backends will return a hardcoded list of values. If the dialect supports “AUTOCOMMIT”, that value should also be present in the sequence returned.
The method raises NotImplementedError by default. If a dialect does not implement this method, then the default dialect will not perform any checking on a given isolation level value before passing it onto the Dialect.set_isolation_level() method. This is to allow backwards-compatibility with third party dialects that may not yet be implementing this method.
Added in version 2.0.
method sqlalchemy.engine.Dialect.get_materialized_view_names(connection: Connection, schema: str | None = None, **kw: Any) → List[str]
Return a list of all materialized view names available in the database.
This is an internal dialect method. Applications should use Inspector.get_materialized_view_names().
Parameters:
schema – 
schema name to query, if not the default schema.
Added in version 2.0.
method sqlalchemy.engine.Dialect.get_multi_check_constraints(connection: Connection, *, schema: str | None = None, filter_names: Collection[str] | None = None, **kw: Any) → Iterable[Tuple[TableKey, List[ReflectedCheckConstraint]]]
Return information about check constraints in all tables in the given schema.
This is an internal dialect method. Applications should use Inspector.get_multi_check_constraints().
Note
The DefaultDialect provides a default implementation that will call the single table method for each object returned by Dialect.get_table_names(), Dialect.get_view_names() or Dialect.get_materialized_view_names() depending on the provided kind. Dialects that want to support a faster implementation should implement this method.
Added in version 2.0.
method sqlalchemy.engine.Dialect.get_multi_columns(connection: Connection, *, schema: str | None = None, filter_names: Collection[str] | None = None, **kw: Any) → Iterable[Tuple[TableKey, List[ReflectedColumn]]]
Return information about columns in all tables in the given schema.
This is an internal dialect method. Applications should use Inspector.get_multi_columns().
Note
The DefaultDialect provides a default implementation that will call the single table method for each object returned by Dialect.get_table_names(), Dialect.get_view_names() or Dialect.get_materialized_view_names() depending on the provided kind. Dialects that want to support a faster implementation should implement this method.
Added in version 2.0.
method sqlalchemy.engine.Dialect.get_multi_foreign_keys(connection: Connection, *, schema: str | None = None, filter_names: Collection[str] | None = None, **kw: Any) → Iterable[Tuple[TableKey, List[ReflectedForeignKeyConstraint]]]
Return information about foreign_keys in all tables in the given schema.
This is an internal dialect method. Applications should use Inspector.get_multi_foreign_keys().
Note
The DefaultDialect provides a default implementation that will call the single table method for each object returned by Dialect.get_table_names(), Dialect.get_view_names() or Dialect.get_materialized_view_names() depending on the provided kind. Dialects that want to support a faster implementation should implement this method.
Added in version 2.0.
method sqlalchemy.engine.Dialect.get_multi_indexes(connection: Connection, *, schema: str | None = None, filter_names: Collection[str] | None = None, **kw: Any) → Iterable[Tuple[TableKey, List[ReflectedIndex]]]
Return information about indexes in in all tables in the given schema.
This is an internal dialect method. Applications should use Inspector.get_multi_indexes().
Note
The DefaultDialect provides a default implementation that will call the single table method for each object returned by Dialect.get_table_names(), Dialect.get_view_names() or Dialect.get_materialized_view_names() depending on the provided kind. Dialects that want to support a faster implementation should implement this method.
Added in version 2.0.
method sqlalchemy.engine.Dialect.get_multi_pk_constraint(connection: Connection, *, schema: str | None = None, filter_names: Collection[str] | None = None, **kw: Any) → Iterable[Tuple[TableKey, ReflectedPrimaryKeyConstraint]]
Return information about primary key constraints in all tables in the given schema.
This is an internal dialect method. Applications should use Inspector.get_multi_pk_constraint().
Note
The DefaultDialect provides a default implementation that will call the single table method for each object returned by Dialect.get_table_names(), Dialect.get_view_names() or Dialect.get_materialized_view_names() depending on the provided kind. Dialects that want to support a faster implementation should implement this method.
Added in version 2.0.
method sqlalchemy.engine.Dialect.get_multi_table_comment(connection: Connection, *, schema: str | None = None, filter_names: Collection[str] | None = None, **kw: Any) → Iterable[Tuple[TableKey, ReflectedTableComment]]
Return information about the table comment in all tables in the given schema.
This is an internal dialect method. Applications should use Inspector.get_multi_table_comment().
Note
The DefaultDialect provides a default implementation that will call the single table method for each object returned by Dialect.get_table_names(), Dialect.get_view_names() or Dialect.get_materialized_view_names() depending on the provided kind. Dialects that want to support a faster implementation should implement this method.
Added in version 2.0.
method sqlalchemy.engine.Dialect.get_multi_table_options(connection: Connection, *, schema: str | None = None, filter_names: Collection[str] | None = None, **kw: Any) → Iterable[Tuple[TableKey, Dict[str, Any]]]
Return a dictionary of options specified when the tables in the given schema were created.
This is an internal dialect method. Applications should use Inspector.get_multi_table_options().
Note
The DefaultDialect provides a default implementation that will call the single table method for each object returned by Dialect.get_table_names(), Dialect.get_view_names() or Dialect.get_materialized_view_names() depending on the provided kind. Dialects that want to support a faster implementation should implement this method.
Added in version 2.0.
method sqlalchemy.engine.Dialect.get_multi_unique_constraints(connection: Connection, *, schema: str | None = None, filter_names: Collection[str] | None = None, **kw: Any) → Iterable[Tuple[TableKey, List[ReflectedUniqueConstraint]]]
Return information about unique constraints in all tables in the given schema.
This is an internal dialect method. Applications should use Inspector.get_multi_unique_constraints().
Note
The DefaultDialect provides a default implementation that will call the single table method for each object returned by Dialect.get_table_names(), Dialect.get_view_names() or Dialect.get_materialized_view_names() depending on the provided kind. Dialects that want to support a faster implementation should implement this method.
Added in version 2.0.
method sqlalchemy.engine.Dialect.get_pk_constraint(connection: Connection, table_name: str, schema: str | None = None, **kw: Any) → ReflectedPrimaryKeyConstraint
Return information about the primary key constraint on table_name`.
Given a Connection, a string table_name, and an optional string schema, return primary key information as a dictionary corresponding to the ReflectedPrimaryKeyConstraint dictionary.
This is an internal dialect method. Applications should use Inspector.get_pk_constraint().
method sqlalchemy.engine.Dialect.get_schema_names(connection: Connection, **kw: Any) → List[str]
Return a list of all schema names available in the database.
This is an internal dialect method. Applications should use Inspector.get_schema_names().
method sqlalchemy.engine.Dialect.get_sequence_names(connection: Connection, schema: str | None = None, **kw: Any) → List[str]
Return a list of all sequence names available in the database.
This is an internal dialect method. Applications should use Inspector.get_sequence_names().
Parameters:
schema – schema name to query, if not the default schema.
Added in version 1.4.
method sqlalchemy.engine.Dialect.get_table_comment(connection: Connection, table_name: str, schema: str | None = None, **kw: Any) → ReflectedTableComment
Return the “comment” for the table identified by table_name.
Given a string table_name and an optional string schema, return table comment information as a dictionary corresponding to the ReflectedTableComment dictionary.
This is an internal dialect method. Applications should use Inspector.get_table_comment().
Raise:
NotImplementedError for dialects that don’t support comments.
Added in version 1.2.
method sqlalchemy.engine.Dialect.get_table_names(connection: Connection, schema: str | None = None, **kw: Any) → List[str]
Return a list of table names for schema.
This is an internal dialect method. Applications should use Inspector.get_table_names().
method sqlalchemy.engine.Dialect.get_table_options(connection: Connection, table_name: str, schema: str | None = None, **kw: Any) → Dict[str, Any]
Return a dictionary of options specified when table_name was created.
This is an internal dialect method. Applications should use Inspector.get_table_options().
method sqlalchemy.engine.Dialect.get_temp_table_names(connection: Connection, schema: str | None = None, **kw: Any) → List[str]
Return a list of temporary table names on the given connection, if supported by the underlying backend.
This is an internal dialect method. Applications should use Inspector.get_temp_table_names().
method sqlalchemy.engine.Dialect.get_temp_view_names(connection: Connection, schema: str | None = None, **kw: Any) → List[str]
Return a list of temporary view names on the given connection, if supported by the underlying backend.
This is an internal dialect method. Applications should use Inspector.get_temp_view_names().
method sqlalchemy.engine.Dialect.get_unique_constraints(connection: Connection, table_name: str, schema: str | None = None, **kw: Any) → List[ReflectedUniqueConstraint]
Return information about unique constraints in table_name.
Given a string table_name and an optional string schema, return unique constraint information as a list of dicts corresponding to the ReflectedUniqueConstraint dictionary.
This is an internal dialect method. Applications should use Inspector.get_unique_constraints().
method sqlalchemy.engine.Dialect.get_view_definition(connection: Connection, view_name: str, schema: str | None = None, **kw: Any) → str
Return plain or materialized view definition.
This is an internal dialect method. Applications should use Inspector.get_view_definition().
Given a Connection, a string view_name, and an optional string schema, return the view definition.
method sqlalchemy.engine.Dialect.get_view_names(connection: Connection, schema: str | None = None, **kw: Any) → List[str]
Return a list of all non-materialized view names available in the database.
This is an internal dialect method. Applications should use Inspector.get_view_names().
Parameters:
schema – schema name to query, if not the default schema.
method sqlalchemy.engine.Dialect.has_index(connection: Connection, table_name: str, index_name: str, schema: str | None = None, **kw: Any) → bool
Check the existence of a particular index name in the database.
Given a Connection object, a string table_name and string index name, return True if an index of the given name on the given table exists, False otherwise.
The DefaultDialect implements this in terms of the Dialect.has_table() and Dialect.get_indexes() methods, however dialects can implement a more performant version.
This is an internal dialect method. Applications should use Inspector.has_index().
Added in version 1.4.
method sqlalchemy.engine.Dialect.has_schema(connection: Connection, schema_name: str, **kw: Any) → bool
Check the existence of a particular schema name in the database.
Given a Connection object, a string schema_name, return True if a schema of the given exists, False otherwise.
The DefaultDialect implements this by checking the presence of schema_name among the schemas returned by Dialect.get_schema_names(), however dialects can implement a more performant version.
This is an internal dialect method. Applications should use Inspector.has_schema().
Added in version 2.0.
method sqlalchemy.engine.Dialect.has_sequence(connection: Connection, sequence_name: str, schema: str | None = None, **kw: Any) → bool
Check the existence of a particular sequence in the database.
Given a Connection object and a string sequence_name, return True if the given sequence exists in the database, False otherwise.
This is an internal dialect method. Applications should use Inspector.has_sequence().
method sqlalchemy.engine.Dialect.has_table(connection: Connection, table_name: str, schema: str | None = None, **kw: Any) → bool
For internal dialect use, check the existence of a particular table or view in the database.
Given a Connection object, a string table_name and optional schema name, return True if the given table exists in the database, False otherwise.
This method serves as the underlying implementation of the public facing Inspector.has_table() method, and is also used internally to implement the “checkfirst” behavior for methods like Table.create() and MetaData.create_all().
Note
This method is used internally by SQLAlchemy, and is published so that third-party dialects may provide an implementation. It is not the public API for checking for table presence. Please use the Inspector.has_table() method.
Changed in version 2.0::: Dialect.has_table() now formally supports checking for additional table-like objects:
• any type of views (plain or materialized)
• temporary tables of any kind
Previously, these two checks were not formally specified and different dialects would vary in their behavior. The dialect testing suite now includes tests for all of these object types, and dialects to the degree that the backing database supports views or temporary tables should seek to support locating these objects for full compliance.
attribute sqlalchemy.engine.Dialect.has_terminate: bool
Whether or not this dialect has a separate “terminate” implementation that does not block or require awaiting.
attribute sqlalchemy.engine.Dialect.identifier_preparer: IdentifierPreparer
This element will refer to an instance of IdentifierPreparer once a DefaultDialect has been constructed.
classmethod sqlalchemy.engine.Dialect.import_dbapi() → DBAPIModule
Import the DBAPI module that is used by this dialect.
The Python module object returned here will be assigned as an instance variable to a constructed dialect under the name .dbapi.
Changed in version 2.0: The Dialect.import_dbapi() class method is renamed from the previous method .Dialect.dbapi(), which would be replaced at dialect instantiation time by the DBAPI module itself, thus using the same name in two different ways. If a .Dialect.dbapi() classmethod is present on a third-party dialect, it will be used and a deprecation warning will be emitted.
attribute sqlalchemy.engine.Dialect.include_set_input_sizes: Set[Any] | None
set of DBAPI type objects that should be included in automatic cursor.setinputsizes() calls.
This is only used if bind_typing is BindTyping.SET_INPUT_SIZES
method sqlalchemy.engine.Dialect.initialize(connection: Connection) → None
Called during strategized creation of the dialect with a connection.
Allows dialects to configure options based on server version info or other properties.
The connection passed here is a SQLAlchemy Connection object, with full capabilities.
The initialize() method of the base dialect should be called via super().
Note
as of SQLAlchemy 1.4, this method is called before any Dialect.on_connect() hooks are called.
attribute sqlalchemy.engine.Dialect.inline_comments: bool
Indicates the dialect supports comment DDL that’s inline with the definition of a Table or Column. If False, this implies that ALTER must be used to set table and column comments.
attribute sqlalchemy.engine.Dialect.insert_executemany_returning: bool
dialect / driver / database supports some means of providing INSERT…RETURNING support when dialect.do_executemany() is used.
attribute sqlalchemy.engine.Dialect.insert_executemany_returning_sort_by_parameter_order: bool
dialect / driver / database supports some means of providing INSERT…RETURNING support when dialect.do_executemany() is used along with the Insert.returning.sort_by_parameter_order parameter being set.
attribute sqlalchemy.engine.Dialect.insert_returning: bool
if the dialect supports RETURNING with INSERT
Added in version 2.0.
attribute sqlalchemy.engine.Dialect.insertmanyvalues_implicit_sentinel: InsertmanyvaluesSentinelOpts
Options indicating the database supports a form of bulk INSERT where the autoincrement integer primary key can be reliably used as an ordering for INSERTed rows.
Added in version 2.0.10.
See also
Correlating RETURNING rows to parameter sets
attribute sqlalchemy.engine.Dialect.insertmanyvalues_max_parameters: int
Alternate to insertmanyvalues_page_size, will additionally limit page size based on number of parameters total in the statement.
attribute sqlalchemy.engine.Dialect.insertmanyvalues_page_size: int
Number of rows to render into an individual INSERT..VALUES() statement for ExecuteStyle.INSERTMANYVALUES executions.
The default dialect defaults this to 1000.
Added in version 2.0.
See also
Connection.execution_options.insertmanyvalues_page_size - execution option available on Connection, statements
attribute sqlalchemy.engine.Dialect.is_async: bool
Whether or not this dialect is intended for asyncio use.
method sqlalchemy.engine.Dialect.is_disconnect(e: Error, connection: PoolProxiedConnection | DBAPIConnection | None, cursor: DBAPICursor | None) → bool
Return True if the given DB-API error indicates an invalid connection
attribute sqlalchemy.engine.Dialect.label_length: int | None
optional user-defined max length for SQL labels
classmethod sqlalchemy.engine.Dialect.load_provisioning() → None
set up the provision.py module for this dialect.
For dialects that include a provision.py module that sets up provisioning followers, this method should initiate that process.
A typical implementation would be:
@classmethod
def load_provisioning(cls):
    __import__("mydialect.provision")
The default method assumes a module named provision.py inside the owning package of the current dialect, based on the __module__ attribute:
@classmethod
def load_provisioning(cls):
    package = ".".join(cls.__module__.split(".")[0:-1])
    try:
        __import__(package + ".provision")
    except ImportError:
        pass
Added in version 1.3.14.
attribute sqlalchemy.engine.Dialect.loaded_dbapi
same as .dbapi, but is never None; will raise an error if no DBAPI was set up.
Added in version 2.0.
attribute sqlalchemy.engine.Dialect.max_constraint_name_length: int | None
The maximum length of constraint names if different from max_identifier_length.
attribute sqlalchemy.engine.Dialect.max_identifier_length: int
The maximum length of identifier names.
attribute sqlalchemy.engine.Dialect.max_index_name_length: int | None
The maximum length of index names if different from max_identifier_length.
attribute sqlalchemy.engine.Dialect.name: str
identifying name for the dialect from a DBAPI-neutral point of view (i.e. ‘sqlite’)
method sqlalchemy.engine.Dialect.normalize_name(name: str) → str
convert the given name to lowercase if it is detected as case insensitive.
This method is only used if the dialect defines requires_name_normalize=True.
method sqlalchemy.engine.Dialect.on_connect() → Callable[[Any], None] | None
return a callable which sets up a newly created DBAPI connection.
The callable should accept a single argument “conn” which is the DBAPI connection itself. The inner callable has no return value.
E.g.:
class MyDialect(default.DefaultDialect):
    # ...

    def on_connect(self):
        def do_on_connect(connection):
            connection.execute("SET SPECIAL FLAGS etc")

        return do_on_connect
This is used to set dialect-wide per-connection options such as isolation modes, Unicode modes, etc.
The “do_on_connect” callable is invoked by using the PoolEvents.connect() event hook, then unwrapping the DBAPI connection and passing it into the callable.
Changed in version 1.4: the on_connect hook is no longer called twice for the first connection of a dialect. The on_connect hook is still called before the Dialect.initialize() method however.
Changed in version 1.4.3: the on_connect hook is invoked from a new method on_connect_url that passes the URL that was used to create the connect args. Dialects can implement on_connect_url instead of on_connect if they need the URL object that was used for the connection in order to get additional context.
If None is returned, no event listener is generated.
Returns:
a callable that accepts a single DBAPI connection as an argument, or None.
See also
Dialect.connect() - allows the DBAPI connect() sequence itself to be controlled.
Dialect.on_connect_url() - supersedes Dialect.on_connect() to also receive the URL object in context.
method sqlalchemy.engine.Dialect.on_connect_url(url: URL) → Callable[[Any], Any] | None
return a callable which sets up a newly created DBAPI connection.
This method is a new hook that supersedes the Dialect.on_connect() method when implemented by a dialect. When not implemented by a dialect, it invokes the Dialect.on_connect() method directly to maintain compatibility with existing dialects. There is no deprecation for Dialect.on_connect() expected.
The callable should accept a single argument “conn” which is the DBAPI connection itself. The inner callable has no return value.
E.g.:
class MyDialect(default.DefaultDialect):
    # ...

    def on_connect_url(self, url):
        def do_on_connect(connection):
            connection.execute("SET SPECIAL FLAGS etc")

        return do_on_connect
This is used to set dialect-wide per-connection options such as isolation modes, Unicode modes, etc.
This method differs from Dialect.on_connect() in that it is passed the URL object that’s relevant to the connect args. Normally the only way to get this is from the Dialect.on_connect() hook is to look on the Engine itself, however this URL object may have been replaced by plugins.
Note
The default implementation of Dialect.on_connect_url() is to invoke the Dialect.on_connect() method. Therefore if a dialect implements this method, the Dialect.on_connect() method will not be called unless the overriding dialect calls it directly from here.
Added in version 1.4.3: added Dialect.on_connect_url() which normally calls into Dialect.on_connect().
Parameters:
url – a URL object representing the URL that was passed to the Dialect.create_connect_args() method.
Returns:
a callable that accepts a single DBAPI connection as an argument, or None.
See also
Dialect.on_connect()
attribute sqlalchemy.engine.Dialect.paramstyle: str
the paramstyle to be used (some DB-APIs support multiple paramstyles).
attribute sqlalchemy.engine.Dialect.positional: bool
True if the paramstyle for this Dialect is positional.
attribute sqlalchemy.engine.Dialect.preexecute_autoincrement_sequences: bool
True if ‘implicit’ primary key functions must be executed separately in order to get their value, if RETURNING is not used.
This is currently oriented towards PostgreSQL when the implicit_returning=False parameter is used on a Table object.
attribute sqlalchemy.engine.Dialect.preparer: Type[IdentifierPreparer]
a IdentifierPreparer class used to quote identifiers.
attribute sqlalchemy.engine.Dialect.reflection_options: Sequence[str] = ()
Sequence of string names indicating keyword arguments that can be established on a Table object which will be passed as “reflection options” when using Table.autoload_with.
Current example is “oracle_resolve_synonyms” in the Oracle Database dialects.
method sqlalchemy.engine.Dialect.reset_isolation_level(dbapi_connection: DBAPIConnection) → None
Given a DBAPI connection, revert its isolation to the default.
Note that this is a dialect-level method which is used as part of the implementation of the Connection and Engine isolation level facilities; these APIs should be preferred for most typical use cases.
See also
Connection.get_isolation_level() - view current level
Connection.default_isolation_level - view default level
Connection.execution_options.isolation_level - set per Connection isolation level
create_engine.isolation_level - set per Engine isolation level
attribute sqlalchemy.engine.Dialect.returns_native_bytes: bool
indicates if Python bytes() objects are returned natively by the driver for SQL “binary” datatypes.
Added in version 2.0.11.
attribute sqlalchemy.engine.Dialect.sequences_optional: bool
If True, indicates if the Sequence.optional parameter on the Sequence construct should signal to not generate a CREATE SEQUENCE. Applies only to dialects that support sequences. Currently used only to allow PostgreSQL SERIAL to be used on a column that specifies Sequence() for usage on other backends.
attribute sqlalchemy.engine.Dialect.server_side_cursors: bool
deprecated; indicates if the dialect should attempt to use server side cursors by default
attribute sqlalchemy.engine.Dialect.server_version_info: Tuple[Any, ...] | None
a tuple containing a version number for the DB backend in use.
This value is only available for supporting dialects, and is typically populated during the initial connection to the database.
method sqlalchemy.engine.Dialect.set_connection_execution_options(connection: Connection, opts: CoreExecuteOptionsParameter) → None
Establish execution options for a given connection.
This is implemented by DefaultDialect in order to implement the Connection.execution_options.isolation_level execution option. Dialects can intercept various execution options which may need to modify state on a particular DBAPI connection.
Added in version 1.4.
method sqlalchemy.engine.Dialect.set_engine_execution_options(engine: Engine, opts: CoreExecuteOptionsParameter) → None
Establish execution options for a given engine.
This is implemented by DefaultDialect to establish event hooks for new Connection instances created by the given Engine which will then invoke the Dialect.set_connection_execution_options() method for that connection.
method sqlalchemy.engine.Dialect.set_isolation_level(dbapi_connection: DBAPIConnection, level: Literal['SERIALIZABLE', 'REPEATABLE READ', 'READ COMMITTED', 'READ UNCOMMITTED', 'AUTOCOMMIT']) → None
Given a DBAPI connection, set its isolation level.
Note that this is a dialect-level method which is used as part of the implementation of the Connection and Engine isolation level facilities; these APIs should be preferred for most typical use cases.
If the dialect also implements the Dialect.get_isolation_level_values() method, then the given level is guaranteed to be one of the string names within that sequence, and the method will not need to anticipate a lookup failure.
See also
Connection.get_isolation_level() - view current level
Connection.default_isolation_level - view default level
Connection.execution_options.isolation_level - set per Connection isolation level
create_engine.isolation_level - set per Engine isolation level
attribute sqlalchemy.engine.Dialect.statement_compiler: Type[SQLCompiler]
a Compiled class used to compile SQL statements
attribute sqlalchemy.engine.Dialect.supports_alter: bool
True if the database supports ALTER TABLE - used only for generating foreign key constraints in certain circumstances
attribute sqlalchemy.engine.Dialect.supports_comments: bool
Indicates the dialect supports comment DDL on tables and columns.
attribute sqlalchemy.engine.Dialect.supports_constraint_comments: bool
Indicates if the dialect supports comment DDL on constraints.
Added in version 2.0.
attribute sqlalchemy.engine.Dialect.supports_default_metavalue: bool
dialect supports INSERT…(col) VALUES (DEFAULT) syntax.
Most databases support this in some way, e.g. SQLite supports it using VALUES (NULL). MS SQL Server supports the syntax also however is the only included dialect where we have this disabled, as MSSQL does not support the field for the IDENTITY column, which is usually where we like to make use of the feature.
attribute sqlalchemy.engine.Dialect.supports_default_values: bool
dialect supports INSERT… DEFAULT VALUES syntax
attribute sqlalchemy.engine.Dialect.supports_empty_insert: bool
dialect supports INSERT () VALUES (), i.e. a plain INSERT with no columns in it.
This is not usually supported; an “empty” insert is typically suited using either “INSERT..DEFAULT VALUES” or “INSERT … (col) VALUES (DEFAULT)”.
attribute sqlalchemy.engine.Dialect.supports_identity_columns: bool
target database supports IDENTITY
attribute sqlalchemy.engine.Dialect.supports_multivalues_insert: bool
Target database supports INSERT…VALUES with multiple value sets, i.e. INSERT INTO table (cols) VALUES (…), (…), (…), …
attribute sqlalchemy.engine.Dialect.supports_native_boolean: bool
Indicates if the dialect supports a native boolean construct. This will prevent Boolean from generating a CHECK constraint when that type is used.
attribute sqlalchemy.engine.Dialect.supports_native_decimal: bool
indicates if Decimal objects are handled and returned for precision numeric types, or if floats are returned
attribute sqlalchemy.engine.Dialect.supports_native_enum: bool
Indicates if the dialect supports a native ENUM construct. This will prevent Enum from generating a CHECK constraint when that type is used in “native” mode.
attribute sqlalchemy.engine.Dialect.supports_native_uuid: bool
indicates if Python UUID() objects are handled natively by the driver for SQL UUID datatypes.
Added in version 2.0.
attribute sqlalchemy.engine.Dialect.supports_sane_multi_rowcount: bool
Indicate whether the dialect properly implements rowcount for UPDATE and DELETE statements when executed via executemany.
attribute sqlalchemy.engine.Dialect.supports_sane_rowcount: bool
Indicate whether the dialect properly implements rowcount for UPDATE and DELETE statements.
attribute sqlalchemy.engine.Dialect.supports_sequences: bool
Indicates if the dialect supports CREATE SEQUENCE or similar.
attribute sqlalchemy.engine.Dialect.supports_server_side_cursors: generic_fn_descriptor[bool] | bool
indicates if the dialect supports server side cursors
attribute sqlalchemy.engine.Dialect.supports_simple_order_by_label: bool
target database supports ORDER BY <labelname>, where <labelname> refers to a label in the columns clause of the SELECT
attribute sqlalchemy.engine.Dialect.supports_statement_cache: bool = True
indicates if this dialect supports caching.
All dialects that are compatible with statement caching should set this flag to True directly on each dialect class and subclass that supports it. SQLAlchemy tests that this flag is locally present on each dialect subclass before it will use statement caching. This is to provide safety for legacy or new dialects that are not yet fully tested to be compliant with SQL statement caching.
Added in version 1.4.5.
See also
Caching for Third Party Dialects
attribute sqlalchemy.engine.Dialect.tuple_in_values: bool
target database supports tuple IN, i.e. (x, y) IN ((q, p), (r, z))
attribute sqlalchemy.engine.Dialect.type_compiler: Any
legacy; this is a TypeCompiler class at the class level, a TypeCompiler instance at the instance level.
Refer to type_compiler_instance instead.
attribute sqlalchemy.engine.Dialect.type_compiler_cls: ClassVar[Type[TypeCompiler]]
a Compiled class used to compile SQL type objects
Added in version 2.0.
attribute sqlalchemy.engine.Dialect.type_compiler_instance: TypeCompiler
instance of a Compiled class used to compile SQL type objects
Added in version 2.0.
method sqlalchemy.engine.Dialect.type_descriptor(typeobj: TypeEngine[_T]) → TypeEngine[_T]
Transform a generic type to a dialect-specific type.
Dialect classes will usually use the adapt_type() function in the types module to accomplish this.
The returned result is cached per dialect class so can contain no dialect-instance state.
attribute sqlalchemy.engine.Dialect.update_executemany_returning: bool
dialect supports UPDATE..RETURNING with executemany.
attribute sqlalchemy.engine.Dialect.update_returning: bool
if the dialect supports RETURNING with UPDATE
Added in version 2.0.
attribute sqlalchemy.engine.Dialect.update_returning_multifrom: bool
if the dialect supports RETURNING with UPDATE..FROM
Added in version 2.0.
attribute sqlalchemy.engine.Dialect.use_insertmanyvalues: bool
if True, indicates “insertmanyvalues” functionality should be used to allow for insert_executemany_returning behavior, if possible.
In practice, setting this to True means:
if supports_multivalues_insert, insert_returning and use_insertmanyvalues are all True, the SQL compiler will produce an INSERT that will be interpreted by the DefaultDialect as an ExecuteStyle.INSERTMANYVALUES execution that allows for INSERT of many rows with RETURNING by rewriting a single-row INSERT statement to have multiple VALUES clauses, also executing the statement multiple times for a series of batches when large numbers of rows are given.
The parameter is False for the default dialect, and is set to True for SQLAlchemy internal dialects SQLite, MySQL/MariaDB, PostgreSQL, SQL Server. It remains at False for Oracle Database, which provides native “executemany with RETURNING” support and also does not support supports_multivalues_insert. For MySQL/MariaDB, those MySQL dialects that don’t support RETURNING will not report insert_executemany_returning as True.
Added in version 2.0.
See also
“Insert Many Values” Behavior for INSERT statements
attribute sqlalchemy.engine.Dialect.use_insertmanyvalues_wo_returning: bool
if True, and use_insertmanyvalues is also True, INSERT statements that don’t include RETURNING will also use “insertmanyvalues”.
Added in version 2.0.
See also
“Insert Many Values” Behavior for INSERT statements
method sqlalchemy.engine.Dialect.validate_identifier(ident: str) → None
Validates an identifier name, raising an exception if invalid
class sqlalchemy.engine.default.DefaultExecutionContext
Members
compiled, connection, create_cursor(), current_parameters, cursor, dialect, engine, execute_style, executemany, execution_options, fetchall_for_returning(), get_current_parameters(), get_lastrowid(), get_out_parameter_values(), get_result_processor(), handle_dbapi_exception(), invoked_statement, isinsert, isupdate, lastrow_has_defaults(), no_parameters, parameters, post_exec(), postfetch_cols, pre_exec(), prefetch_cols, root_connection
Class signature
class sqlalchemy.engine.default.DefaultExecutionContext (sqlalchemy.engine.interfaces.ExecutionContext)
attribute sqlalchemy.engine.default.DefaultExecutionContext.compiled: Compiled | None = None
if passed to constructor, sqlalchemy.engine.base.Compiled object being executed
attribute sqlalchemy.engine.default.DefaultExecutionContext.connection: Connection
Connection object which can be freely used by default value generators to execute SQL. This Connection should reference the same underlying connection/transactional resources of root_connection.
method sqlalchemy.engine.default.DefaultExecutionContext.create_cursor() → DBAPICursor
Return a new cursor generated from this ExecutionContext’s connection.
Some dialects may wish to change the behavior of connection.cursor(), such as postgresql which may return a PG “server side” cursor.
attribute sqlalchemy.engine.default.DefaultExecutionContext.current_parameters: _CoreSingleExecuteParams | None = None
A dictionary of parameters applied to the current row.
This attribute is only available in the context of a user-defined default generation function, e.g. as described at Context-Sensitive Default Functions. It consists of a dictionary which includes entries for each column/value pair that is to be part of the INSERT or UPDATE statement. The keys of the dictionary will be the key value of each Column, which is usually synonymous with the name.
Note that the DefaultExecutionContext.current_parameters attribute does not accommodate for the “multi-values” feature of the Insert.values() method. The DefaultExecutionContext.get_current_parameters() method should be preferred.
See also
DefaultExecutionContext.get_current_parameters()
Context-Sensitive Default Functions
attribute sqlalchemy.engine.default.DefaultExecutionContext.cursor: DBAPICursor
DB-API cursor procured from the connection
attribute sqlalchemy.engine.default.DefaultExecutionContext.dialect: Dialect
dialect which created this ExecutionContext.
attribute sqlalchemy.engine.default.DefaultExecutionContext.engine: Engine
engine which the Connection is associated with
attribute sqlalchemy.engine.default.DefaultExecutionContext.execute_style: ExecuteStyle = 0
the style of DBAPI cursor method that will be used to execute a statement.
Added in version 2.0.
attribute sqlalchemy.engine.default.DefaultExecutionContext.executemany: bool
True if the context has a list of more than one parameter set.
Historically this attribute links to whether cursor.execute() or cursor.executemany() will be used. It also can now mean that “insertmanyvalues” may be used which indicates one or more cursor.execute() calls.
attribute sqlalchemy.engine.default.DefaultExecutionContext.execution_options: _ExecuteOptions = {}
Execution options associated with the current statement execution
method sqlalchemy.engine.default.DefaultExecutionContext.fetchall_for_returning(cursor)
For a RETURNING result, deliver cursor.fetchall() from the DBAPI cursor.
This is a dialect-specific hook for dialects that have special considerations when calling upon the rows delivered for a “RETURNING” statement. Default implementation is cursor.fetchall().
This hook is currently used only by the insertmanyvalues feature. Dialects that don’t set use_insertmanyvalues=True don’t need to consider this hook.
Added in version 2.0.10.
method sqlalchemy.engine.default.DefaultExecutionContext.get_current_parameters(isolate_multiinsert_groups=True)
Return a dictionary of parameters applied to the current row.
This method can only be used in the context of a user-defined default generation function, e.g. as described at Context-Sensitive Default Functions. When invoked, a dictionary is returned which includes entries for each column/value pair that is part of the INSERT or UPDATE statement. The keys of the dictionary will be the key value of each Column, which is usually synonymous with the name.
Parameters:
isolate_multiinsert_groups=True – indicates that multi-valued INSERT constructs created using Insert.values() should be handled by returning only the subset of parameters that are local to the current column default invocation. When False, the raw parameters of the statement are returned including the naming convention used in the case of multi-valued INSERT.
Added in version 1.2: added DefaultExecutionContext.get_current_parameters() which provides more functionality over the existing DefaultExecutionContext.current_parameters attribute.
See also
DefaultExecutionContext.current_parameters
Context-Sensitive Default Functions
method sqlalchemy.engine.default.DefaultExecutionContext.get_lastrowid()
return self.cursor.lastrowid, or equivalent, after an INSERT.
This may involve calling special cursor functions, issuing a new SELECT on the cursor (or a new one), or returning a stored value that was calculated within post_exec().
This function will only be called for dialects which support “implicit” primary key generation, keep preexecute_autoincrement_sequences set to False, and when no explicit id value was bound to the statement.
The function is called once for an INSERT statement that would need to return the last inserted primary key for those dialects that make use of the lastrowid concept. In these cases, it is called directly after ExecutionContext.post_exec().
method sqlalchemy.engine.default.DefaultExecutionContext.get_out_parameter_values(names)
Return a sequence of OUT parameter values from a cursor.
For dialects that support OUT parameters, this method will be called when there is a SQLCompiler object which has the SQLCompiler.has_out_parameters flag set. This flag in turn will be set to True if the statement itself has BindParameter objects that have the .isoutparam flag set which are consumed by the SQLCompiler.visit_bindparam() method. If the dialect compiler produces BindParameter objects with .isoutparam set which are not handled by SQLCompiler.visit_bindparam(), it should set this flag explicitly.
The list of names that were rendered for each bound parameter is passed to the method. The method should then return a sequence of values corresponding to the list of parameter objects. Unlike in previous SQLAlchemy versions, the values can be the raw values from the DBAPI; the execution context will apply the appropriate type handler based on what’s present in self.compiled.binds and update the values. The processed dictionary will then be made available via the .out_parameters collection on the result object. Note that SQLAlchemy 1.4 has multiple kinds of result object as part of the 2.0 transition.
Added in version 1.4: - added ExecutionContext.get_out_parameter_values(), which is invoked automatically by the DefaultExecutionContext when there are BindParameter objects with the .isoutparam flag set. This replaces the practice of setting out parameters within the now-removed get_result_proxy() method.
method sqlalchemy.engine.default.DefaultExecutionContext.get_result_processor(type_, colname, coltype)
Return a ‘result processor’ for a given type as present in cursor.description.
This has a default implementation that dialects can override for context-sensitive result type handling.
method sqlalchemy.engine.default.DefaultExecutionContext.handle_dbapi_exception(e)
Receive a DBAPI exception which occurred upon execute, result fetch, etc.
attribute sqlalchemy.engine.default.DefaultExecutionContext.invoked_statement: Executable | None = None
The Executable statement object that was given in the first place.
This should be structurally equivalent to compiled.statement, but not necessarily the same object as in a caching scenario the compiled form will have been extracted from the cache.
attribute sqlalchemy.engine.default.DefaultExecutionContext.isinsert: bool = False
True if the statement is an INSERT.
attribute sqlalchemy.engine.default.DefaultExecutionContext.isupdate: bool = False
True if the statement is an UPDATE.
method sqlalchemy.engine.default.DefaultExecutionContext.lastrow_has_defaults()
Return True if the last INSERT or UPDATE row contained inlined or database-side defaults.
attribute sqlalchemy.engine.default.DefaultExecutionContext.no_parameters: bool
True if the execution style does not use parameters
attribute sqlalchemy.engine.default.DefaultExecutionContext.parameters: _DBAPIMultiExecuteParams
bind parameters passed to the execute() or exec_driver_sql() methods.
These are always stored as a list of parameter entries. A single-element list corresponds to a cursor.execute() call and a multiple-element list corresponds to cursor.executemany(), except in the case of ExecuteStyle.INSERTMANYVALUES which will use cursor.execute() one or more times.
method sqlalchemy.engine.default.DefaultExecutionContext.post_exec()
Called after the execution of a compiled statement.
If a compiled statement was passed to this ExecutionContext, the last_insert_ids, last_inserted_params, etc. datamembers should be available after this method completes.
attribute sqlalchemy.engine.default.DefaultExecutionContext.postfetch_cols: util.generic_fn_descriptor[Sequence[Column[Any]] | None]
a list of Column objects for which a server-side default or inline SQL expression value was fired off. Applies to inserts and updates.
method sqlalchemy.engine.default.DefaultExecutionContext.pre_exec()
Called before an execution of a compiled statement.
If a compiled statement was passed to this ExecutionContext, the statement and parameters datamembers must be initialized after this statement is complete.
attribute sqlalchemy.engine.default.DefaultExecutionContext.prefetch_cols: util.generic_fn_descriptor[Sequence[Column[Any]] | None]
a list of Column objects for which a client-side default was fired off. Applies to inserts and updates.
attribute sqlalchemy.engine.default.DefaultExecutionContext.root_connection: Connection
Connection object which is the source of this ExecutionContext.
class sqlalchemy.engine.ExecutionContext
Members
compiled, connection, create_cursor(), cursor, dialect, engine, execute_style, executemany, execution_options, fetchall_for_returning(), fire_sequence(), get_out_parameter_values(), get_rowcount(), handle_dbapi_exception(), invoked_statement, isinsert, isupdate, lastrow_has_defaults(), no_parameters, parameters, post_exec(), postfetch_cols, pre_exec(), prefetch_cols, root_connection, statement
A messenger object for a Dialect that corresponds to a single execution.
attribute sqlalchemy.engine.ExecutionContext.compiled: Compiled | None
if passed to constructor, sqlalchemy.engine.base.Compiled object being executed
attribute sqlalchemy.engine.ExecutionContext.connection: Connection
Connection object which can be freely used by default value generators to execute SQL. This Connection should reference the same underlying connection/transactional resources of root_connection.
method sqlalchemy.engine.ExecutionContext.create_cursor() → DBAPICursor
Return a new cursor generated from this ExecutionContext’s connection.
Some dialects may wish to change the behavior of connection.cursor(), such as postgresql which may return a PG “server side” cursor.
attribute sqlalchemy.engine.ExecutionContext.cursor: DBAPICursor
DB-API cursor procured from the connection
attribute sqlalchemy.engine.ExecutionContext.dialect: Dialect
dialect which created this ExecutionContext.
attribute sqlalchemy.engine.ExecutionContext.engine: Engine
engine which the Connection is associated with
attribute sqlalchemy.engine.ExecutionContext.execute_style: ExecuteStyle
the style of DBAPI cursor method that will be used to execute a statement.
Added in version 2.0.
attribute sqlalchemy.engine.ExecutionContext.executemany: bool
True if the context has a list of more than one parameter set.
Historically this attribute links to whether cursor.execute() or cursor.executemany() will be used. It also can now mean that “insertmanyvalues” may be used which indicates one or more cursor.execute() calls.
attribute sqlalchemy.engine.ExecutionContext.execution_options: _ExecuteOptions
Execution options associated with the current statement execution
method sqlalchemy.engine.ExecutionContext.fetchall_for_returning(cursor: DBAPICursor) → Sequence[Any]
For a RETURNING result, deliver cursor.fetchall() from the DBAPI cursor.
This is a dialect-specific hook for dialects that have special considerations when calling upon the rows delivered for a “RETURNING” statement. Default implementation is cursor.fetchall().
This hook is currently used only by the insertmanyvalues feature. Dialects that don’t set use_insertmanyvalues=True don’t need to consider this hook.
Added in version 2.0.10.
method sqlalchemy.engine.ExecutionContext.fire_sequence(seq: Sequence_SchemaItem, type_: Integer) → int
given a Sequence, invoke it and return the next int value
method sqlalchemy.engine.ExecutionContext.get_out_parameter_values(out_param_names: Sequence[str]) → Sequence[Any]
Return a sequence of OUT parameter values from a cursor.
For dialects that support OUT parameters, this method will be called when there is a SQLCompiler object which has the SQLCompiler.has_out_parameters flag set. This flag in turn will be set to True if the statement itself has BindParameter objects that have the .isoutparam flag set which are consumed by the SQLCompiler.visit_bindparam() method. If the dialect compiler produces BindParameter objects with .isoutparam set which are not handled by SQLCompiler.visit_bindparam(), it should set this flag explicitly.
The list of names that were rendered for each bound parameter is passed to the method. The method should then return a sequence of values corresponding to the list of parameter objects. Unlike in previous SQLAlchemy versions, the values can be the raw values from the DBAPI; the execution context will apply the appropriate type handler based on what’s present in self.compiled.binds and update the values. The processed dictionary will then be made available via the .out_parameters collection on the result object. Note that SQLAlchemy 1.4 has multiple kinds of result object as part of the 2.0 transition.
Added in version 1.4: - added ExecutionContext.get_out_parameter_values(), which is invoked automatically by the DefaultExecutionContext when there are BindParameter objects with the .isoutparam flag set. This replaces the practice of setting out parameters within the now-removed get_result_proxy() method.
method sqlalchemy.engine.ExecutionContext.get_rowcount() → int | None
Return the DBAPI cursor.rowcount value, or in some cases an interpreted value.
See CursorResult.rowcount for details on this.
method sqlalchemy.engine.ExecutionContext.handle_dbapi_exception(e: BaseException) → None
Receive a DBAPI exception which occurred upon execute, result fetch, etc.
attribute sqlalchemy.engine.ExecutionContext.invoked_statement: Executable | None
The Executable statement object that was given in the first place.
This should be structurally equivalent to compiled.statement, but not necessarily the same object as in a caching scenario the compiled form will have been extracted from the cache.
attribute sqlalchemy.engine.ExecutionContext.isinsert: bool
True if the statement is an INSERT.
attribute sqlalchemy.engine.ExecutionContext.isupdate: bool
True if the statement is an UPDATE.
method sqlalchemy.engine.ExecutionContext.lastrow_has_defaults() → bool
Return True if the last INSERT or UPDATE row contained inlined or database-side defaults.
attribute sqlalchemy.engine.ExecutionContext.no_parameters: bool
True if the execution style does not use parameters
attribute sqlalchemy.engine.ExecutionContext.parameters: _AnyMultiExecuteParams
bind parameters passed to the execute() or exec_driver_sql() methods.
These are always stored as a list of parameter entries. A single-element list corresponds to a cursor.execute() call and a multiple-element list corresponds to cursor.executemany(), except in the case of ExecuteStyle.INSERTMANYVALUES which will use cursor.execute() one or more times.
method sqlalchemy.engine.ExecutionContext.post_exec() → None
Called after the execution of a compiled statement.
If a compiled statement was passed to this ExecutionContext, the last_insert_ids, last_inserted_params, etc. datamembers should be available after this method completes.
attribute sqlalchemy.engine.ExecutionContext.postfetch_cols: util.generic_fn_descriptor[Sequence[Column[Any]] | None]
a list of Column objects for which a server-side default or inline SQL expression value was fired off. Applies to inserts and updates.
method sqlalchemy.engine.ExecutionContext.pre_exec() → None
Called before an execution of a compiled statement.
If a compiled statement was passed to this ExecutionContext, the statement and parameters datamembers must be initialized after this statement is complete.
attribute sqlalchemy.engine.ExecutionContext.prefetch_cols: util.generic_fn_descriptor[Sequence[Column[Any]] | None]
a list of Column objects for which a client-side default was fired off. Applies to inserts and updates.
attribute sqlalchemy.engine.ExecutionContext.root_connection: Connection
Connection object which is the source of this ExecutionContext.
attribute sqlalchemy.engine.ExecutionContext.statement: str
string version of the statement to be executed. Is either passed to the constructor, or must be created from the sql.Compiled object by the time pre_exec() has completed.
class sqlalchemy.sql.compiler.ExpandedState
represents state to use when producing “expanded” and “post compile” bound parameters for a statement.
“expanded” parameters are parameters that are generated at statement execution time to suit a number of parameters passed, the most prominent example being the individual elements inside of an IN expression.
“post compile” parameters are parameters where the SQL literal value will be rendered into the SQL statement at execution time, rather than being passed as separate parameters to the driver.
To create an ExpandedState instance, use the SQLCompiler.construct_expanded_state() method on any SQLCompiler instance.
Members
additional_parameters, parameter_expansion, parameters, positional_parameters, positiontup, processors, statement
Class signature
class sqlalchemy.sql.compiler.ExpandedState (builtins.tuple)
attribute sqlalchemy.sql.compiler.ExpandedState.additional_parameters
synonym for ExpandedState.parameters.
attribute sqlalchemy.sql.compiler.ExpandedState.parameter_expansion: Mapping[str, List[str]]
Mapping representing the intermediary link from original parameter name to list of “expanded” parameter names, for those parameters that were expanded.
attribute sqlalchemy.sql.compiler.ExpandedState.parameters: _CoreSingleExecuteParams
Parameter dictionary with parameters fully expanded.
For a statement that uses named parameters, this dictionary will map exactly to the names in the statement. For a statement that uses positional parameters, the ExpandedState.positional_parameters will yield a tuple with the positional parameter set.
attribute sqlalchemy.sql.compiler.ExpandedState.positional_parameters
Tuple of positional parameters, for statements that were compiled using a positional paramstyle.
attribute sqlalchemy.sql.compiler.ExpandedState.positiontup: Sequence[str] | None
Sequence of string names indicating the order of positional parameters
attribute sqlalchemy.sql.compiler.ExpandedState.processors: Mapping[str, _BindProcessorType[Any]]
mapping of bound value processors
attribute sqlalchemy.sql.compiler.ExpandedState.statement: str
String SQL statement with parameters fully expanded
class sqlalchemy.sql.compiler.GenericTypeCompiler
Members
ensure_kwarg
Class signature
class sqlalchemy.sql.compiler.GenericTypeCompiler (sqlalchemy.sql.compiler.TypeCompiler)
attribute sqlalchemy.sql.compiler.GenericTypeCompiler.ensure_kwarg: str = 'visit_\\w+'
inherited from the TypeCompiler.ensure_kwarg attribute of TypeCompiler
a regular expression that indicates method names for which the method should accept **kw arguments.
The class will scan for methods matching the name template and decorate them if necessary to ensure **kw parameters are accepted.
class sqlalchemy.log.Identified
class sqlalchemy.sql.compiler.IdentifierPreparer
Members
__init__(), format_column(), format_label_name(), format_schema(), format_table(), format_table_seq(), quote(), quote_identifier(), quote_schema(), schema_for_object, unformat_identifiers(), validate_sql_phrase()
Handle quoting and case-folding of identifiers based on options.
method sqlalchemy.sql.compiler.IdentifierPreparer.__init__(dialect: Dialect, initial_quote: str = '"', final_quote: str | None = None, escape_quote: str = '"', quote_case_sensitive_collations: bool = True, omit_schema: bool = False)
Construct a new IdentifierPreparer object.
initial_quote
Character that begins a delimited identifier.
final_quote
Character that ends a delimited identifier. Defaults to initial_quote.
omit_schema
Prevent prepending schema name. Useful for databases that do not support schemae.
method sqlalchemy.sql.compiler.IdentifierPreparer.format_column(column: ColumnElement[Any], use_table: bool = False, name: str | None = None, table_name: str | None = None, use_schema: bool = False, anon_map: Mapping[str, Any] | None = None) → str
Prepare a quoted column name.
method sqlalchemy.sql.compiler.IdentifierPreparer.format_label_name(name, anon_map=None)
Prepare a quoted column name.
method sqlalchemy.sql.compiler.IdentifierPreparer.format_schema(name)
Prepare a quoted schema name.
method sqlalchemy.sql.compiler.IdentifierPreparer.format_table(table: FromClause, use_schema: bool = True, name: str | None = None) → str
Prepare a quoted table and schema name.
method sqlalchemy.sql.compiler.IdentifierPreparer.format_table_seq(table, use_schema=True)
Format table name and schema as a tuple.
method sqlalchemy.sql.compiler.IdentifierPreparer.quote(ident: str, force: Any = None) → str
Conditionally quote an identifier.
The identifier is quoted if it is a reserved word, contains quote-necessary characters, or is an instance of quoted_name which includes quote set to True.
Subclasses can override this to provide database-dependent quoting behavior for identifier names.
Parameters:
• ident – string identifier
• force – 
unused
Deprecated since version 0.9: The IdentifierPreparer.quote.force parameter is deprecated and will be removed in a future release. This flag has no effect on the behavior of the IdentifierPreparer.quote() method; please refer to quoted_name.
method sqlalchemy.sql.compiler.IdentifierPreparer.quote_identifier(value: str) → str
Quote an identifier.
Subclasses should override this to provide database-dependent quoting behavior.
method sqlalchemy.sql.compiler.IdentifierPreparer.quote_schema(schema: str, force: Any = None) → str
Conditionally quote a schema name.
The name is quoted if it is a reserved word, contains quote-necessary characters, or is an instance of quoted_name which includes quote set to True.
Subclasses can override this to provide database-dependent quoting behavior for schema names.
Parameters:
• schema – string schema name
• force – 
unused
Deprecated since version 0.9: The IdentifierPreparer.quote_schema.force parameter is deprecated and will be removed in a future release. This flag has no effect on the behavior of the IdentifierPreparer.quote() method; please refer to quoted_name.
attribute sqlalchemy.sql.compiler.IdentifierPreparer.schema_for_object: _SchemaForObjectCallable = operator.attrgetter('schema')
Return the .schema attribute for an object.
For the default IdentifierPreparer, the schema for an object is always the value of the “.schema” attribute. if the preparer is replaced with one that has a non-empty schema_translate_map, the value of the “.schema” attribute is rendered a symbol that will be converted to a real schema name from the mapping post-compile.
method sqlalchemy.sql.compiler.IdentifierPreparer.unformat_identifiers(identifiers: str) → Sequence[str]
Unpack ‘schema.table.column’-like strings into components.
method sqlalchemy.sql.compiler.IdentifierPreparer.validate_sql_phrase(element, reg)
keyword sequence filter.
a filter for elements that are intended to represent keyword sequences, such as “INITIALLY”, “INITIALLY DEFERRED”, etc. no special characters should be present.
Added in version 1.3.
class sqlalchemy.sql.compiler.SQLCompiler
Default implementation of Compiled.
Compiles ClauseElement objects into SQL strings.
Members
__init__(), ansi_bind_rules, bind_names, bindname_escape_characters, binds, bindtemplate, compilation_bindtemplate, construct_expanded_state(), construct_params(), current_executable, default_from(), delete_extra_from_clause(), delete_limit_clause(), effective_returning, escaped_bind_names, get_select_precolumns(), group_by_clause(), has_out_parameters, implicit_returning, insert_prefetch, insert_single_values_expr, isupdate, literal_execute_params, order_by_clause(), params, positiontup, post_compile_params, postfetch, postfetch_lastrowid, render_literal_value(), render_table_with_column_in_update_from, returning, returning_precedes_values, sql_compiler, stack, translate_select_structure, update_from_clause(), update_limit_clause(), update_prefetch, update_tables_clause(), visit_override_binds()
Class signature
class sqlalchemy.sql.compiler.SQLCompiler (sqlalchemy.sql.compiler.Compiled)
method sqlalchemy.sql.compiler.SQLCompiler.__init__(dialect: Dialect, statement: ClauseElement | None, cache_key: CacheKey | None = None, column_keys: Sequence[str] | None = None, for_executemany: bool = False, linting: Linting = Linting.NO_LINTING, _supporting_against: SQLCompiler | None = None, **kwargs: Any)
Construct a new SQLCompiler object.
Parameters:
• dialect – Dialect to be used
• statement – ClauseElement to be compiled
• column_keys – a list of column names to be compiled into an INSERT or UPDATE statement.
• for_executemany – whether INSERT / UPDATE statements should expect that they are to be invoked in an “executemany” style, which may impact how the statement will be expected to return the values of defaults and autoincrement / sequences and similar. Depending on the backend and driver in use, support for retrieving these values may be disabled which means SQL expressions may be rendered inline, RETURNING may not be rendered, etc.
• kwargs – additional keyword arguments to be consumed by the superclass.
attribute sqlalchemy.sql.compiler.SQLCompiler.ansi_bind_rules: bool = False
SQL 92 doesn’t allow bind parameters to be used in the columns clause of a SELECT, nor does it allow ambiguous expressions like “? = ?”. A compiler subclass can set this flag to False if the target driver/DB enforces this
attribute sqlalchemy.sql.compiler.SQLCompiler.bind_names: Dict[BindParameter[Any], str]
a dictionary of BindParameter instances to “compiled” names that are actually present in the generated SQL
attribute sqlalchemy.sql.compiler.SQLCompiler.bindname_escape_characters: ClassVar[Mapping[str, str]] = {' ': '_', '%': 'P', '(': 'A', ')': 'Z', '.': '_', ':': 'C', '[': '_', ']': '_'}
A mapping (e.g. dict or similar) containing a lookup of characters keyed to replacement characters which will be applied to all ‘bind names’ used in SQL statements as a form of ‘escaping’; the given characters are replaced entirely with the ‘replacement’ character when rendered in the SQL statement, and a similar translation is performed on the incoming names used in parameter dictionaries passed to methods like Connection.execute().
This allows bound parameter names used in bindparam() and other constructs to have any arbitrary characters present without any concern for characters that aren’t allowed at all on the target database.
Third party dialects can establish their own dictionary here to replace the default mapping, which will ensure that the particular characters in the mapping will never appear in a bound parameter name.
The dictionary is evaluated at class creation time, so cannot be modified at runtime; it must be present on the class when the class is first declared.
Note that for dialects that have additional bound parameter rules such as additional restrictions on leading characters, the SQLCompiler.bindparam_string() method may need to be augmented. See the cx_Oracle compiler for an example of this.
Added in version 2.0.0rc1.
attribute sqlalchemy.sql.compiler.SQLCompiler.binds: Dict[str, BindParameter[Any]]
a dictionary of bind parameter keys to BindParameter instances.
attribute sqlalchemy.sql.compiler.SQLCompiler.bindtemplate: str
template to render bound parameters based on paramstyle.
attribute sqlalchemy.sql.compiler.SQLCompiler.compilation_bindtemplate: str
template used by compiler to render parameters before positional paramstyle application
method sqlalchemy.sql.compiler.SQLCompiler.construct_expanded_state(params: _CoreSingleExecuteParams | None = None, escape_names: bool = True) → ExpandedState
Return a new ExpandedState for a given parameter set.
For queries that use “expanding” or other late-rendered parameters, this method will provide for both the finalized SQL string as well as the parameters that would be used for a particular parameter set.
Added in version 2.0.0rc1.
method sqlalchemy.sql.compiler.SQLCompiler.construct_params(params: _CoreSingleExecuteParams | None = None, extracted_parameters: Sequence[BindParameter[Any]] | None = None, escape_names: bool = True, _group_number: int | None = None, _check: bool = True, _no_postcompile: bool = False) → _MutableCoreSingleExecuteParams
return a dictionary of bind parameter keys and values
attribute sqlalchemy.sql.compiler.SQLCompiler.current_executable
Return the current ‘executable’ that is being compiled.
This is currently the Select, Insert, Update, Delete, CompoundSelect object that is being compiled. Specifically it’s assigned to the self.stack list of elements.
When a statement like the above is being compiled, it normally is also assigned to the .statement attribute of the Compiler object. However, all SQL constructs are ultimately nestable, and this attribute should never be consulted by a visit_ method, as it is not guaranteed to be assigned nor guaranteed to correspond to the current statement being compiled.
Added in version 1.3.21: For compatibility with previous versions, use the following recipe:
statement = getattr(self, "current_executable", False)
if statement is False:
    statement = self.stack[-1]["selectable"]
For versions 1.4 and above, ensure only .current_executable is used; the format of “self.stack” may change.
method sqlalchemy.sql.compiler.SQLCompiler.default_from() → str
Called when a SELECT statement has no froms, and no FROM clause is to be appended.
Gives Oracle Database a chance to tack on a FROM DUAL to the string output.
method sqlalchemy.sql.compiler.SQLCompiler.delete_extra_from_clause(delete_stmt, from_table, extra_froms, from_hints, **kw)
Provide a hook to override the generation of an DELETE..FROM clause.
This can be used to implement DELETE..USING for example.
MySQL and MSSQL override this.
method sqlalchemy.sql.compiler.SQLCompiler.delete_limit_clause(delete_stmt)
Provide a hook for MySQL to add LIMIT to the DELETE
attribute sqlalchemy.sql.compiler.SQLCompiler.effective_returning
The effective “returning” columns for INSERT, UPDATE or DELETE.
This is either the so-called “implicit returning” columns which are calculated by the compiler on the fly, or those present based on what’s present in self.statement._returning (expanded into individual columns using the ._all_selected_columns attribute) i.e. those set explicitly using the UpdateBase.returning() method.
Added in version 2.0.
attribute sqlalchemy.sql.compiler.SQLCompiler.escaped_bind_names: util.immutabledict[str, str] = {}
Late escaping of bound parameter names that has to be converted to the original name when looking in the parameter dictionary.
method sqlalchemy.sql.compiler.SQLCompiler.get_select_precolumns(select: Select[Any], **kw: Any) → str
Called when building a SELECT statement, position is just before column list.
method sqlalchemy.sql.compiler.SQLCompiler.group_by_clause(select, **kw)
allow dialects to customize how GROUP BY is rendered.
attribute sqlalchemy.sql.compiler.SQLCompiler.has_out_parameters = False
if True, there are bindparam() objects that have the isoutparam flag set.
attribute sqlalchemy.sql.compiler.SQLCompiler.implicit_returning: Sequence[ColumnElement[Any]] | None = None
list of “implicit” returning columns for a toplevel INSERT or UPDATE statement, used to receive newly generated values of columns.
Added in version 2.0: implicit_returning replaces the previous returning collection, which was not a generalized RETURNING collection and instead was in fact specific to the “implicit returning” feature.
attribute sqlalchemy.sql.compiler.SQLCompiler.insert_prefetch: Sequence[Column[Any]] = ()
list of columns for which default values should be evaluated before an INSERT takes place
attribute sqlalchemy.sql.compiler.SQLCompiler.insert_single_values_expr
When an INSERT is compiled with a single set of parameters inside a VALUES expression, the string is assigned here, where it can be used for insert batching schemes to rewrite the VALUES expression.
Added in version 1.3.8.
Changed in version 2.0: This collection is no longer used by SQLAlchemy’s built-in dialects, in favor of the currently internal _insertmanyvalues collection that is used only by SQLCompiler.
attribute sqlalchemy.sql.compiler.SQLCompiler.isupdate: bool = False
class-level defaults which can be set at the instance level to define if this Compiled instance represents INSERT/UPDATE/DELETE
attribute sqlalchemy.sql.compiler.SQLCompiler.literal_execute_params: FrozenSet[BindParameter[Any]] = frozenset({})
bindparameter objects that are rendered as literal values at statement execution time.
method sqlalchemy.sql.compiler.SQLCompiler.order_by_clause(select, **kw)
allow dialects to customize how ORDER BY is rendered.
attribute sqlalchemy.sql.compiler.SQLCompiler.params
Return the bind param dictionary embedded into this compiled object, for those values that are present.
See also
How do I render SQL expressions as strings, possibly with bound parameters inlined? - includes a usage example for debugging use cases.
attribute sqlalchemy.sql.compiler.SQLCompiler.positiontup: List[str] | None = None
for a compiled construct that uses a positional paramstyle, will be a sequence of strings, indicating the names of bound parameters in order.
This is used in order to render bound parameters in their correct order, and is combined with the Compiled.params dictionary to render parameters.
This sequence always contains the unescaped name of the parameters.
See also
How do I render SQL expressions as strings, possibly with bound parameters inlined? - includes a usage example for debugging use cases.
attribute sqlalchemy.sql.compiler.SQLCompiler.post_compile_params: FrozenSet[BindParameter[Any]] = frozenset({})
bindparameter objects that are rendered as bound parameter placeholders at statement execution time.
attribute sqlalchemy.sql.compiler.SQLCompiler.postfetch: List[Column[Any]] | None
list of columns that can be post-fetched after INSERT or UPDATE to receive server-updated values
attribute sqlalchemy.sql.compiler.SQLCompiler.postfetch_lastrowid = False
if True, and this in insert, use cursor.lastrowid to populate result.inserted_primary_key.
method sqlalchemy.sql.compiler.SQLCompiler.render_literal_value(value: Any, type_: TypeEngine) → str
Render the value of a bind parameter as a quoted literal.
This is used for statement sections that do not accept bind parameters on the target driver/database.
This should be implemented by subclasses using the quoting services of the DBAPI.
attribute sqlalchemy.sql.compiler.SQLCompiler.render_table_with_column_in_update_from: bool = False
set to True classwide to indicate the SET clause in a multi-table UPDATE statement should qualify columns with the table name (i.e. MySQL only)
attribute sqlalchemy.sql.compiler.SQLCompiler.returning
backwards compatibility; returns the effective_returning collection.
attribute sqlalchemy.sql.compiler.SQLCompiler.returning_precedes_values: bool = False
set to True classwide to generate RETURNING clauses before the VALUES or WHERE clause (i.e. MSSQL)
attribute sqlalchemy.sql.compiler.SQLCompiler.sql_compiler
attribute sqlalchemy.sql.compiler.SQLCompiler.stack: List[_CompilerStackEntry]
major statements such as SELECT, INSERT, UPDATE, DELETE are tracked in this stack using an entry format.
attribute sqlalchemy.sql.compiler.SQLCompiler.translate_select_structure: Any = None
if not None, should be a callable which accepts (select_stmt, **kw) and returns a select object. this is used for structural changes mostly to accommodate for LIMIT/OFFSET schemes
method sqlalchemy.sql.compiler.SQLCompiler.update_from_clause(update_stmt, from_table, extra_froms, from_hints, **kw)
Provide a hook to override the generation of an UPDATE..FROM clause.
MySQL and MSSQL override this.
method sqlalchemy.sql.compiler.SQLCompiler.update_limit_clause(update_stmt)
Provide a hook for MySQL to add LIMIT to the UPDATE
attribute sqlalchemy.sql.compiler.SQLCompiler.update_prefetch: Sequence[Column[Any]] = ()
list of columns for which onupdate default values should be evaluated before an UPDATE takes place
method sqlalchemy.sql.compiler.SQLCompiler.update_tables_clause(update_stmt, from_table, extra_froms, **kw)
Provide a hook to override the initial table clause in an UPDATE statement.
MySQL overrides this.
method sqlalchemy.sql.compiler.SQLCompiler.visit_override_binds(override_binds, **kw)
SQL compile the nested element of an _OverrideBinds with bindparams swapped out.
The _OverrideBinds is not normally expected to be compiled; it is meant to be used when an already cached statement is to be used, the compilation was already performed, and only the bound params should be swapped in at execution time.
However, there are test cases that exericise this object, and additionally the ORM subquery loader is known to feed in expressions which include this construct into new queries (discovered in #11173), so it has to do the right thing at compile time as well.
class sqlalchemy.sql.compiler.StrSQLCompiler
A SQLCompiler subclass which allows a small selection of non-standard SQL features to render into a string value.
The StrSQLCompiler is invoked whenever a Core expression element is directly stringified without calling upon the ClauseElement.compile() method. It can render a limited set of non-standard SQL constructs to assist in basic stringification, however for more substantial custom or dialect-specific SQL constructs, it will be necessary to make use of ClauseElement.compile() directly.
See also
How do I render SQL expressions as strings, possibly with bound parameters inlined?
Members
delete_extra_from_clause(), update_from_clause()
Class signature
class sqlalchemy.sql.compiler.StrSQLCompiler (sqlalchemy.sql.compiler.SQLCompiler)
method sqlalchemy.sql.compiler.StrSQLCompiler.delete_extra_from_clause(delete_stmt, from_table, extra_froms, from_hints, **kw)
Provide a hook to override the generation of an DELETE..FROM clause.
This can be used to implement DELETE..USING for example.
MySQL and MSSQL override this.
method sqlalchemy.sql.compiler.StrSQLCompiler.update_from_clause(update_stmt, from_table, extra_froms, from_hints, **kw)
Provide a hook to override the generation of an UPDATE..FROM clause.
MySQL and MSSQL override this.
class sqlalchemy.engine.AdaptedConnection
Interface of an adapted connection object to support the DBAPI protocol.
Used by asyncio dialects to provide a sync-style pep-249 facade on top of the asyncio connection/cursor API provided by the driver.
Members
driver_connection, run_async()
Added in version 1.4.24.
attribute sqlalchemy.engine.AdaptedConnection.driver_connection
The connection object as returned by the driver after a connect.
method sqlalchemy.engine.AdaptedConnection.run_async(fn: Callable[[Any], Awaitable[_T]]) → _T
Run the awaitable returned by the given function, which is passed the raw asyncio driver connection.
This is used to invoke awaitable-only methods on the driver connection within the context of a “synchronous” method, like a connection pool event handler.
E.g.:
engine = create_async_engine(...)


@event.listens_for(engine.sync_engine, "connect")
def register_custom_types(
    dbapi_connection,  # ...
):
    dbapi_connection.run_async(
        lambda connection: connection.set_type_codec(
            "MyCustomType", encoder, decoder, ...
        )
    )
Added in version 1.4.30.
See also
Using awaitable-only driver methods in connection pool and other events



